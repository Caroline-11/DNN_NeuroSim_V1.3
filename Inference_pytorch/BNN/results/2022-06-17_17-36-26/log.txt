2022-06-17 17:36:26 - INFO - saving to ./results/2022-06-17_17-36-26
2022-06-17 17:36:26 - DEBUG - run arguments: Namespace(results_dir='./results', save='2022-06-17_17-36-26', dataset='cifar10', model='alexnet', input_size=None, model_config='', type='torch.cuda.FloatTensor', gpus='0', workers=8, epochs=200, start_epoch=0, batch_size=256, optimizer='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001, print_freq=10, resume='', evaluate=None)
2022-06-17 17:36:28 - INFO - creating model alexnet
2022-06-17 17:36:29 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10'}
2022-06-17 17:36:29 - INFO - number of parameters: 61110184
2022-06-17 17:36:33 - INFO - training regime: {0: {'optimizer': 'SGD', 'lr': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9}, 10: {'lr': 0.005}, 15: {'lr': 0.001, 'weight_decay': 0}, 20: {'lr': 0.0005}, 25: {'lr': 0.0001}}
2022-06-17 17:36:33 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:36:33 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:36:33 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:36:33 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:36:37 - INFO - TRAINING - Epoch: [0][0/196]	Time 3.944 (3.944)	Data 2.323 (2.323)	Loss 7.2709 (7.2709)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
2022-06-17 17:36:38 - INFO - TRAINING - Epoch: [0][10/196]	Time 0.109 (0.450)	Data 0.000 (0.211)	Loss 1.9219 (3.3994)	Prec@1 29.297 (19.780)	Prec@5 88.281 (61.719)
2022-06-17 17:36:39 - INFO - TRAINING - Epoch: [0][20/196]	Time 0.119 (0.292)	Data 0.000 (0.111)	Loss 1.9343 (2.6609)	Prec@1 30.078 (26.451)	Prec@5 84.375 (73.307)
2022-06-17 17:36:40 - INFO - TRAINING - Epoch: [0][30/196]	Time 0.067 (0.233)	Data 0.001 (0.075)	Loss 1.7971 (2.3831)	Prec@1 39.062 (29.599)	Prec@5 86.719 (77.886)
2022-06-17 17:36:42 - INFO - TRAINING - Epoch: [0][40/196]	Time 0.113 (0.203)	Data 0.000 (0.057)	Loss 1.7943 (2.2308)	Prec@1 38.281 (31.850)	Prec@5 90.234 (80.402)
2022-06-17 17:36:43 - INFO - TRAINING - Epoch: [0][50/196]	Time 0.130 (0.185)	Data 0.000 (0.046)	Loss 1.5689 (2.1254)	Prec@1 41.797 (33.333)	Prec@5 91.797 (82.376)
2022-06-17 17:36:44 - INFO - TRAINING - Epoch: [0][60/196]	Time 0.103 (0.173)	Data 0.000 (0.038)	Loss 1.6577 (2.0424)	Prec@1 43.359 (34.939)	Prec@5 90.234 (83.805)
2022-06-17 17:36:45 - INFO - TRAINING - Epoch: [0][70/196]	Time 0.114 (0.164)	Data 0.000 (0.033)	Loss 1.5480 (1.9809)	Prec@1 44.531 (36.273)	Prec@5 93.359 (84.804)
2022-06-17 17:36:46 - INFO - TRAINING - Epoch: [0][80/196]	Time 0.101 (0.157)	Data 0.000 (0.029)	Loss 1.5781 (1.9384)	Prec@1 49.219 (37.365)	Prec@5 92.969 (85.566)
2022-06-17 17:36:47 - INFO - TRAINING - Epoch: [0][90/196]	Time 0.115 (0.152)	Data 0.000 (0.026)	Loss 1.4662 (1.9042)	Prec@1 48.828 (38.152)	Prec@5 92.188 (86.195)
2022-06-17 17:36:48 - INFO - TRAINING - Epoch: [0][100/196]	Time 0.103 (0.148)	Data 0.000 (0.023)	Loss 1.4118 (1.8716)	Prec@1 50.000 (38.993)	Prec@5 95.312 (86.808)
2022-06-17 17:36:49 - INFO - TRAINING - Epoch: [0][110/196]	Time 0.102 (0.145)	Data 0.000 (0.021)	Loss 1.4967 (1.8479)	Prec@1 45.703 (39.654)	Prec@5 93.359 (87.187)
2022-06-17 17:36:50 - INFO - TRAINING - Epoch: [0][120/196]	Time 0.103 (0.142)	Data 0.000 (0.020)	Loss 1.5131 (1.8255)	Prec@1 47.266 (40.173)	Prec@5 92.578 (87.613)
2022-06-17 17:36:51 - INFO - TRAINING - Epoch: [0][130/196]	Time 0.123 (0.140)	Data 0.000 (0.018)	Loss 1.3534 (1.7988)	Prec@1 47.656 (40.858)	Prec@5 95.703 (88.031)
2022-06-17 17:36:53 - INFO - TRAINING - Epoch: [0][140/196]	Time 0.103 (0.138)	Data 0.000 (0.017)	Loss 1.3843 (1.7727)	Prec@1 51.562 (41.719)	Prec@5 95.312 (88.414)
2022-06-17 17:36:54 - INFO - TRAINING - Epoch: [0][150/196]	Time 0.103 (0.136)	Data 0.000 (0.016)	Loss 1.6061 (1.7516)	Prec@1 49.609 (42.369)	Prec@5 92.578 (88.731)
2022-06-17 17:36:55 - INFO - TRAINING - Epoch: [0][160/196]	Time 0.117 (0.134)	Data 0.000 (0.015)	Loss 1.5135 (1.7343)	Prec@1 50.781 (42.874)	Prec@5 91.406 (88.968)
2022-06-17 17:36:56 - INFO - TRAINING - Epoch: [0][170/196]	Time 0.103 (0.133)	Data 0.000 (0.014)	Loss 1.5302 (1.7158)	Prec@1 46.094 (43.416)	Prec@5 93.359 (89.200)
2022-06-17 17:36:57 - INFO - TRAINING - Epoch: [0][180/196]	Time 0.115 (0.132)	Data 0.000 (0.013)	Loss 1.4033 (1.7014)	Prec@1 57.422 (43.895)	Prec@5 95.312 (89.483)
2022-06-17 17:36:58 - INFO - TRAINING - Epoch: [0][190/196]	Time 0.103 (0.130)	Data 0.000 (0.012)	Loss 1.3799 (1.6876)	Prec@1 57.031 (44.357)	Prec@5 95.703 (89.701)
2022-06-17 17:37:01 - INFO - EVALUATING - Epoch: [0][0/40]	Time 1.830 (1.830)	Data 1.788 (1.788)	Loss 1.3392 (1.3392)	Prec@1 54.688 (54.688)	Prec@5 92.578 (92.578)
2022-06-17 17:37:02 - INFO - EVALUATING - Epoch: [0][10/40]	Time 0.041 (0.261)	Data 0.001 (0.215)	Loss 1.2889 (1.2475)	Prec@1 57.031 (57.386)	Prec@5 93.750 (94.673)
2022-06-17 17:37:02 - INFO - EVALUATING - Epoch: [0][20/40]	Time 0.041 (0.161)	Data 0.000 (0.113)	Loss 1.2430 (1.2239)	Prec@1 56.641 (58.705)	Prec@5 94.141 (94.568)
2022-06-17 17:37:04 - INFO - EVALUATING - Epoch: [0][30/40]	Time 0.224 (0.146)	Data 0.184 (0.101)	Loss 1.3863 (1.2470)	Prec@1 52.734 (57.800)	Prec@5 96.094 (94.871)
2022-06-17 17:37:06 - INFO - 
 Epoch: 1	Training Loss 1.6828 	Training Prec@1 44.548 	Training Prec@5 89.762 	Validation Loss 1.2511 	Validation Prec@1 57.590 	Validation Prec@5 94.860 

2022-06-17 17:37:06 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:37:06 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:37:06 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:37:06 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:37:07 - INFO - TRAINING - Epoch: [1][0/196]	Time 1.466 (1.466)	Data 1.409 (1.409)	Loss 1.1457 (1.1457)	Prec@1 58.203 (58.203)	Prec@5 97.266 (97.266)
2022-06-17 17:37:09 - INFO - TRAINING - Epoch: [1][10/196]	Time 0.107 (0.269)	Data 0.000 (0.170)	Loss 1.4472 (1.2489)	Prec@1 55.469 (56.925)	Prec@5 90.625 (95.170)
2022-06-17 17:37:10 - INFO - TRAINING - Epoch: [1][20/196]	Time 0.110 (0.194)	Data 0.000 (0.089)	Loss 1.3638 (1.2701)	Prec@1 53.125 (56.399)	Prec@5 94.531 (95.015)
2022-06-17 17:37:11 - INFO - TRAINING - Epoch: [1][30/196]	Time 0.109 (0.166)	Data 0.000 (0.061)	Loss 1.3762 (1.2785)	Prec@1 56.641 (56.137)	Prec@5 94.531 (94.859)
2022-06-17 17:37:12 - INFO - TRAINING - Epoch: [1][40/196]	Time 0.112 (0.152)	Data 0.000 (0.046)	Loss 1.0297 (1.2684)	Prec@1 61.719 (56.479)	Prec@5 96.484 (94.865)
2022-06-17 17:37:13 - INFO - TRAINING - Epoch: [1][50/196]	Time 0.105 (0.144)	Data 0.000 (0.037)	Loss 1.2979 (1.2685)	Prec@1 57.812 (56.970)	Prec@5 94.531 (94.891)
2022-06-17 17:37:14 - INFO - TRAINING - Epoch: [1][60/196]	Time 0.126 (0.139)	Data 0.000 (0.031)	Loss 1.4020 (1.2719)	Prec@1 55.078 (56.871)	Prec@5 93.359 (94.935)
2022-06-17 17:37:15 - INFO - TRAINING - Epoch: [1][70/196]	Time 0.104 (0.135)	Data 0.000 (0.027)	Loss 1.3049 (1.2676)	Prec@1 58.984 (57.158)	Prec@5 96.484 (95.010)
2022-06-17 17:37:17 - INFO - TRAINING - Epoch: [1][80/196]	Time 0.104 (0.132)	Data 0.000 (0.023)	Loss 1.3555 (1.2771)	Prec@1 51.953 (57.070)	Prec@5 94.531 (94.883)
2022-06-17 17:37:18 - INFO - TRAINING - Epoch: [1][90/196]	Time 0.107 (0.130)	Data 0.000 (0.021)	Loss 1.1860 (1.2722)	Prec@1 61.719 (57.229)	Prec@5 94.531 (94.935)
2022-06-17 17:37:19 - INFO - TRAINING - Epoch: [1][100/196]	Time 0.108 (0.128)	Data 0.000 (0.019)	Loss 1.1149 (1.2690)	Prec@1 60.156 (57.306)	Prec@5 97.266 (94.988)
2022-06-17 17:37:20 - INFO - TRAINING - Epoch: [1][110/196]	Time 0.109 (0.126)	Data 0.000 (0.017)	Loss 1.0690 (1.2569)	Prec@1 62.109 (57.647)	Prec@5 97.266 (95.108)
2022-06-17 17:37:21 - INFO - TRAINING - Epoch: [1][120/196]	Time 0.111 (0.125)	Data 0.000 (0.016)	Loss 1.0454 (1.2477)	Prec@1 61.328 (57.871)	Prec@5 95.312 (95.164)
2022-06-17 17:37:22 - INFO - TRAINING - Epoch: [1][130/196]	Time 0.106 (0.123)	Data 0.000 (0.015)	Loss 1.1321 (1.2373)	Prec@1 62.500 (58.254)	Prec@5 96.094 (95.232)
2022-06-17 17:37:23 - INFO - TRAINING - Epoch: [1][140/196]	Time 0.104 (0.122)	Data 0.000 (0.014)	Loss 1.0499 (1.2276)	Prec@1 62.891 (58.508)	Prec@5 96.484 (95.288)
2022-06-17 17:37:24 - INFO - TRAINING - Epoch: [1][150/196]	Time 0.108 (0.121)	Data 0.000 (0.013)	Loss 1.0643 (1.2215)	Prec@1 62.500 (58.715)	Prec@5 97.656 (95.320)
2022-06-17 17:37:25 - INFO - TRAINING - Epoch: [1][160/196]	Time 0.116 (0.120)	Data 0.000 (0.012)	Loss 1.1620 (1.2152)	Prec@1 63.281 (58.897)	Prec@5 96.094 (95.371)
2022-06-17 17:37:26 - INFO - TRAINING - Epoch: [1][170/196]	Time 0.112 (0.120)	Data 0.000 (0.011)	Loss 1.1047 (1.2082)	Prec@1 61.719 (59.092)	Prec@5 93.750 (95.395)
2022-06-17 17:37:27 - INFO - TRAINING - Epoch: [1][180/196]	Time 0.118 (0.119)	Data 0.000 (0.011)	Loss 1.1147 (1.1991)	Prec@1 60.547 (59.386)	Prec@5 98.047 (95.468)
2022-06-17 17:37:28 - INFO - TRAINING - Epoch: [1][190/196]	Time 0.101 (0.118)	Data 0.000 (0.010)	Loss 1.1284 (1.1955)	Prec@1 64.844 (59.508)	Prec@5 96.484 (95.476)
2022-06-17 17:37:31 - INFO - EVALUATING - Epoch: [1][0/40]	Time 1.623 (1.623)	Data 1.574 (1.574)	Loss 0.9983 (0.9983)	Prec@1 64.453 (64.453)	Prec@5 98.047 (98.047)
2022-06-17 17:37:32 - INFO - EVALUATING - Epoch: [1][10/40]	Time 0.100 (0.250)	Data 0.058 (0.202)	Loss 0.9697 (1.0423)	Prec@1 66.797 (66.158)	Prec@5 96.875 (96.946)
2022-06-17 17:37:33 - INFO - EVALUATING - Epoch: [1][20/40]	Time 0.337 (0.168)	Data 0.297 (0.120)	Loss 0.9226 (1.0215)	Prec@1 68.359 (66.518)	Prec@5 96.484 (96.484)
2022-06-17 17:37:34 - INFO - EVALUATING - Epoch: [1][30/40]	Time 0.041 (0.142)	Data 0.000 (0.095)	Loss 1.1524 (1.0228)	Prec@1 63.672 (66.293)	Prec@5 97.266 (96.749)
2022-06-17 17:37:36 - INFO - 
 Epoch: 2	Training Loss 1.1932 	Training Prec@1 59.610 	Training Prec@5 95.502 	Validation Loss 1.0195 	Validation Prec@1 66.090 	Validation Prec@5 96.830 

2022-06-17 17:37:37 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:37:37 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:37:37 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:37:37 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:37:39 - INFO - TRAINING - Epoch: [2][0/196]	Time 1.368 (1.368)	Data 1.306 (1.306)	Loss 0.9269 (0.9269)	Prec@1 68.359 (68.359)	Prec@5 97.266 (97.266)
2022-06-17 17:37:40 - INFO - TRAINING - Epoch: [2][10/196]	Time 0.118 (0.246)	Data 0.000 (0.150)	Loss 0.9959 (1.0108)	Prec@1 66.797 (66.300)	Prec@5 96.875 (96.804)
2022-06-17 17:37:41 - INFO - TRAINING - Epoch: [2][20/196]	Time 0.106 (0.183)	Data 0.000 (0.079)	Loss 1.1614 (1.0000)	Prec@1 61.328 (65.867)	Prec@5 96.484 (97.154)
2022-06-17 17:37:42 - INFO - TRAINING - Epoch: [2][30/196]	Time 0.117 (0.160)	Data 0.000 (0.054)	Loss 0.8921 (0.9887)	Prec@1 73.438 (66.431)	Prec@5 97.656 (97.140)
2022-06-17 17:37:43 - INFO - TRAINING - Epoch: [2][40/196]	Time 0.108 (0.150)	Data 0.000 (0.041)	Loss 0.9737 (0.9956)	Prec@1 66.406 (66.406)	Prec@5 96.875 (96.980)
2022-06-17 17:37:45 - INFO - TRAINING - Epoch: [2][50/196]	Time 0.102 (0.144)	Data 0.000 (0.033)	Loss 1.1751 (0.9952)	Prec@1 61.328 (66.429)	Prec@5 94.922 (97.005)
2022-06-17 17:37:46 - INFO - TRAINING - Epoch: [2][60/196]	Time 0.128 (0.139)	Data 0.000 (0.027)	Loss 0.9589 (0.9960)	Prec@1 63.672 (66.304)	Prec@5 98.047 (97.029)
2022-06-17 17:37:47 - INFO - TRAINING - Epoch: [2][70/196]	Time 0.141 (0.136)	Data 0.000 (0.024)	Loss 1.1455 (1.0011)	Prec@1 57.812 (65.955)	Prec@5 97.266 (97.007)
2022-06-17 17:37:48 - INFO - TRAINING - Epoch: [2][80/196]	Time 0.103 (0.134)	Data 0.000 (0.021)	Loss 0.9072 (0.9962)	Prec@1 71.094 (66.170)	Prec@5 96.875 (97.029)
2022-06-17 17:37:49 - INFO - TRAINING - Epoch: [2][90/196]	Time 0.110 (0.132)	Data 0.000 (0.018)	Loss 0.9296 (0.9906)	Prec@1 66.797 (66.303)	Prec@5 97.656 (97.034)
2022-06-17 17:37:50 - INFO - TRAINING - Epoch: [2][100/196]	Time 0.106 (0.130)	Data 0.000 (0.017)	Loss 0.9291 (0.9873)	Prec@1 68.359 (66.402)	Prec@5 96.875 (97.095)
2022-06-17 17:37:51 - INFO - TRAINING - Epoch: [2][110/196]	Time 0.108 (0.128)	Data 0.000 (0.015)	Loss 0.8895 (0.9869)	Prec@1 69.922 (66.466)	Prec@5 98.047 (97.114)
2022-06-17 17:37:53 - INFO - TRAINING - Epoch: [2][120/196]	Time 0.112 (0.127)	Data 0.000 (0.014)	Loss 0.8436 (0.9834)	Prec@1 72.656 (66.606)	Prec@5 97.656 (97.124)
2022-06-17 17:37:54 - INFO - TRAINING - Epoch: [2][130/196]	Time 0.119 (0.126)	Data 0.000 (0.013)	Loss 0.8854 (0.9798)	Prec@1 73.047 (66.740)	Prec@5 96.875 (97.164)
2022-06-17 17:37:55 - INFO - TRAINING - Epoch: [2][140/196]	Time 0.122 (0.125)	Data 0.000 (0.012)	Loss 1.0096 (0.9760)	Prec@1 65.234 (66.794)	Prec@5 97.656 (97.207)
2022-06-17 17:37:56 - INFO - TRAINING - Epoch: [2][150/196]	Time 0.117 (0.125)	Data 0.000 (0.011)	Loss 0.9533 (0.9758)	Prec@1 66.406 (66.820)	Prec@5 97.656 (97.214)
2022-06-17 17:37:57 - INFO - TRAINING - Epoch: [2][160/196]	Time 0.116 (0.124)	Data 0.000 (0.011)	Loss 0.9417 (0.9725)	Prec@1 65.625 (66.933)	Prec@5 97.266 (97.212)
2022-06-17 17:37:58 - INFO - TRAINING - Epoch: [2][170/196]	Time 0.115 (0.124)	Data 0.000 (0.010)	Loss 0.8396 (0.9689)	Prec@1 70.703 (66.966)	Prec@5 97.656 (97.247)
2022-06-17 17:38:00 - INFO - TRAINING - Epoch: [2][180/196]	Time 0.126 (0.124)	Data 0.000 (0.009)	Loss 0.8467 (0.9669)	Prec@1 69.531 (67.054)	Prec@5 98.438 (97.238)
2022-06-17 17:38:01 - INFO - TRAINING - Epoch: [2][190/196]	Time 0.109 (0.123)	Data 0.000 (0.009)	Loss 0.8200 (0.9652)	Prec@1 71.094 (67.110)	Prec@5 98.438 (97.282)
2022-06-17 17:38:03 - INFO - EVALUATING - Epoch: [2][0/40]	Time 1.243 (1.243)	Data 1.197 (1.197)	Loss 0.8645 (0.8645)	Prec@1 71.094 (71.094)	Prec@5 97.656 (97.656)
2022-06-17 17:38:04 - INFO - EVALUATING - Epoch: [2][10/40]	Time 0.045 (0.228)	Data 0.001 (0.176)	Loss 0.8648 (0.8926)	Prec@1 71.484 (70.526)	Prec@5 98.828 (98.082)
2022-06-17 17:38:05 - INFO - EVALUATING - Epoch: [2][20/40]	Time 0.103 (0.166)	Data 0.058 (0.118)	Loss 0.9695 (0.8868)	Prec@1 67.578 (70.703)	Prec@5 96.875 (97.786)
2022-06-17 17:38:06 - INFO - EVALUATING - Epoch: [2][30/40]	Time 0.168 (0.147)	Data 0.125 (0.100)	Loss 0.9640 (0.8938)	Prec@1 67.578 (70.237)	Prec@5 98.047 (97.959)
2022-06-17 17:38:08 - INFO - 
 Epoch: 3	Training Loss 0.9646 	Training Prec@1 67.126 	Training Prec@5 97.286 	Validation Loss 0.8998 	Validation Prec@1 70.150 	Validation Prec@5 97.910 

2022-06-17 17:38:08 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:38:08 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:38:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:38:08 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:38:10 - INFO - TRAINING - Epoch: [3][0/196]	Time 1.426 (1.426)	Data 1.370 (1.370)	Loss 0.9304 (0.9304)	Prec@1 68.750 (68.750)	Prec@5 99.219 (99.219)
2022-06-17 17:38:11 - INFO - TRAINING - Epoch: [3][10/196]	Time 0.115 (0.267)	Data 0.000 (0.176)	Loss 0.9599 (0.8499)	Prec@1 71.094 (71.946)	Prec@5 96.094 (98.260)
2022-06-17 17:38:12 - INFO - TRAINING - Epoch: [3][20/196]	Time 0.119 (0.196)	Data 0.000 (0.092)	Loss 0.7882 (0.8734)	Prec@1 70.703 (71.019)	Prec@5 98.047 (97.786)
2022-06-17 17:38:13 - INFO - TRAINING - Epoch: [3][30/196]	Time 0.133 (0.170)	Data 0.000 (0.063)	Loss 1.1478 (0.8675)	Prec@1 62.891 (71.069)	Prec@5 98.438 (97.833)
2022-06-17 17:38:15 - INFO - TRAINING - Epoch: [3][40/196]	Time 0.102 (0.157)	Data 0.000 (0.047)	Loss 0.9237 (0.8746)	Prec@1 66.016 (70.732)	Prec@5 96.875 (97.799)
2022-06-17 17:38:16 - INFO - TRAINING - Epoch: [3][50/196]	Time 0.104 (0.150)	Data 0.000 (0.038)	Loss 0.8996 (0.8632)	Prec@1 71.484 (71.002)	Prec@5 97.656 (97.809)
2022-06-17 17:38:17 - INFO - TRAINING - Epoch: [3][60/196]	Time 0.116 (0.144)	Data 0.000 (0.032)	Loss 0.8008 (0.8657)	Prec@1 71.484 (70.889)	Prec@5 97.656 (97.772)
2022-06-17 17:38:18 - INFO - TRAINING - Epoch: [3][70/196]	Time 0.132 (0.141)	Data 0.000 (0.027)	Loss 0.9640 (0.8550)	Prec@1 68.750 (71.237)	Prec@5 98.047 (97.893)
2022-06-17 17:38:19 - INFO - TRAINING - Epoch: [3][80/196]	Time 0.113 (0.138)	Data 0.000 (0.024)	Loss 0.8141 (0.8534)	Prec@1 71.484 (71.325)	Prec@5 99.219 (97.902)
2022-06-17 17:38:20 - INFO - TRAINING - Epoch: [3][90/196]	Time 0.122 (0.135)	Data 0.000 (0.022)	Loss 0.9286 (0.8554)	Prec@1 66.016 (71.296)	Prec@5 97.656 (97.910)
2022-06-17 17:38:22 - INFO - TRAINING - Epoch: [3][100/196]	Time 0.136 (0.134)	Data 0.000 (0.019)	Loss 0.7186 (0.8530)	Prec@1 72.656 (71.303)	Prec@5 99.609 (97.919)
2022-06-17 17:38:23 - INFO - TRAINING - Epoch: [3][110/196]	Time 0.126 (0.133)	Data 0.000 (0.018)	Loss 0.6358 (0.8490)	Prec@1 80.469 (71.484)	Prec@5 99.609 (97.962)
2022-06-17 17:38:24 - INFO - TRAINING - Epoch: [3][120/196]	Time 0.120 (0.132)	Data 0.000 (0.016)	Loss 0.8061 (0.8442)	Prec@1 73.047 (71.604)	Prec@5 98.828 (97.995)
2022-06-17 17:38:25 - INFO - TRAINING - Epoch: [3][130/196]	Time 0.119 (0.131)	Data 0.000 (0.015)	Loss 0.7953 (0.8418)	Prec@1 75.781 (71.726)	Prec@5 97.656 (97.966)
2022-06-17 17:38:27 - INFO - TRAINING - Epoch: [3][140/196]	Time 0.140 (0.130)	Data 0.000 (0.014)	Loss 0.7826 (0.8401)	Prec@1 70.703 (71.736)	Prec@5 98.438 (97.967)
2022-06-17 17:38:28 - INFO - TRAINING - Epoch: [3][150/196]	Time 0.119 (0.130)	Data 0.000 (0.013)	Loss 0.7867 (0.8384)	Prec@1 72.266 (71.782)	Prec@5 98.828 (97.985)
2022-06-17 17:38:29 - INFO - TRAINING - Epoch: [3][160/196]	Time 0.116 (0.129)	Data 0.000 (0.012)	Loss 0.8020 (0.8374)	Prec@1 74.609 (71.785)	Prec@5 97.656 (98.001)
2022-06-17 17:38:30 - INFO - TRAINING - Epoch: [3][170/196]	Time 0.129 (0.128)	Data 0.000 (0.012)	Loss 0.8259 (0.8368)	Prec@1 71.875 (71.811)	Prec@5 98.828 (98.001)
2022-06-17 17:38:31 - INFO - TRAINING - Epoch: [3][180/196]	Time 0.132 (0.127)	Data 0.000 (0.011)	Loss 0.8722 (0.8359)	Prec@1 72.266 (71.817)	Prec@5 96.484 (97.999)
2022-06-17 17:38:32 - INFO - TRAINING - Epoch: [3][190/196]	Time 0.102 (0.126)	Data 0.000 (0.010)	Loss 0.7255 (0.8336)	Prec@1 74.219 (71.895)	Prec@5 97.656 (98.016)
2022-06-17 17:38:35 - INFO - EVALUATING - Epoch: [3][0/40]	Time 1.902 (1.902)	Data 1.857 (1.857)	Loss 0.6361 (0.6361)	Prec@1 80.859 (80.859)	Prec@5 98.438 (98.438)
2022-06-17 17:38:36 - INFO - EVALUATING - Epoch: [3][10/40]	Time 0.073 (0.274)	Data 0.000 (0.222)	Loss 0.6898 (0.7205)	Prec@1 77.734 (75.817)	Prec@5 97.266 (98.402)
2022-06-17 17:38:37 - INFO - EVALUATING - Epoch: [3][20/40]	Time 0.041 (0.178)	Data 0.000 (0.128)	Loss 0.6698 (0.7269)	Prec@1 75.000 (75.874)	Prec@5 98.828 (98.140)
2022-06-17 17:38:38 - INFO - EVALUATING - Epoch: [3][30/40]	Time 0.061 (0.150)	Data 0.000 (0.100)	Loss 0.7600 (0.7297)	Prec@1 75.391 (75.794)	Prec@5 98.828 (98.286)
2022-06-17 17:38:40 - INFO - 
 Epoch: 4	Training Loss 0.8346 	Training Prec@1 71.874 	Training Prec@5 98.018 	Validation Loss 0.7320 	Validation Prec@1 75.590 	Validation Prec@5 98.360 

2022-06-17 17:38:40 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:38:40 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:38:40 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:38:40 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:38:42 - INFO - TRAINING - Epoch: [4][0/196]	Time 1.857 (1.857)	Data 1.807 (1.807)	Loss 0.6759 (0.6759)	Prec@1 73.047 (73.047)	Prec@5 98.438 (98.438)
2022-06-17 17:38:43 - INFO - TRAINING - Epoch: [4][10/196]	Time 0.110 (0.270)	Data 0.000 (0.165)	Loss 0.5760 (0.6675)	Prec@1 81.250 (75.994)	Prec@5 98.438 (98.615)
2022-06-17 17:38:44 - INFO - TRAINING - Epoch: [4][20/196]	Time 0.118 (0.197)	Data 0.000 (0.086)	Loss 0.7357 (0.6801)	Prec@1 76.562 (76.339)	Prec@5 97.266 (98.605)
2022-06-17 17:38:45 - INFO - TRAINING - Epoch: [4][30/196]	Time 0.116 (0.171)	Data 0.000 (0.059)	Loss 0.7345 (0.6993)	Prec@1 73.828 (76.159)	Prec@5 98.438 (98.463)
2022-06-17 17:38:46 - INFO - TRAINING - Epoch: [4][40/196]	Time 0.114 (0.158)	Data 0.000 (0.044)	Loss 0.6391 (0.7031)	Prec@1 78.125 (76.143)	Prec@5 98.828 (98.561)
2022-06-17 17:38:48 - INFO - TRAINING - Epoch: [4][50/196]	Time 0.121 (0.150)	Data 0.000 (0.036)	Loss 0.6748 (0.7043)	Prec@1 77.344 (76.134)	Prec@5 98.438 (98.591)
2022-06-17 17:38:49 - INFO - TRAINING - Epoch: [4][60/196]	Time 0.103 (0.144)	Data 0.000 (0.030)	Loss 0.7675 (0.7084)	Prec@1 73.047 (75.877)	Prec@5 99.609 (98.566)
2022-06-17 17:38:50 - INFO - TRAINING - Epoch: [4][70/196]	Time 0.126 (0.140)	Data 0.000 (0.026)	Loss 0.7546 (0.7073)	Prec@1 72.266 (75.864)	Prec@5 99.609 (98.592)
2022-06-17 17:38:51 - INFO - TRAINING - Epoch: [4][80/196]	Time 0.114 (0.138)	Data 0.000 (0.023)	Loss 0.6471 (0.7095)	Prec@1 76.562 (75.666)	Prec@5 98.828 (98.587)
2022-06-17 17:38:52 - INFO - TRAINING - Epoch: [4][90/196]	Time 0.122 (0.136)	Data 0.000 (0.020)	Loss 0.7097 (0.7166)	Prec@1 75.391 (75.498)	Prec@5 98.047 (98.541)
2022-06-17 17:38:53 - INFO - TRAINING - Epoch: [4][100/196]	Time 0.106 (0.133)	Data 0.000 (0.018)	Loss 0.7186 (0.7214)	Prec@1 76.172 (75.383)	Prec@5 100.000 (98.550)
2022-06-17 17:38:54 - INFO - TRAINING - Epoch: [4][110/196]	Time 0.124 (0.132)	Data 0.000 (0.017)	Loss 0.6775 (0.7224)	Prec@1 75.000 (75.415)	Prec@5 99.219 (98.557)
2022-06-17 17:38:56 - INFO - TRAINING - Epoch: [4][120/196]	Time 0.111 (0.130)	Data 0.000 (0.015)	Loss 0.7957 (0.7227)	Prec@1 73.438 (75.349)	Prec@5 97.656 (98.544)
2022-06-17 17:38:57 - INFO - TRAINING - Epoch: [4][130/196]	Time 0.105 (0.129)	Data 0.000 (0.014)	Loss 0.8174 (0.7198)	Prec@1 74.609 (75.456)	Prec@5 98.438 (98.557)
2022-06-17 17:38:58 - INFO - TRAINING - Epoch: [4][140/196]	Time 0.115 (0.128)	Data 0.000 (0.013)	Loss 0.6109 (0.7217)	Prec@1 79.688 (75.440)	Prec@5 99.219 (98.529)
2022-06-17 17:38:59 - INFO - TRAINING - Epoch: [4][150/196]	Time 0.121 (0.128)	Data 0.000 (0.012)	Loss 0.7676 (0.7234)	Prec@1 76.562 (75.448)	Prec@5 97.656 (98.510)
2022-06-17 17:39:00 - INFO - TRAINING - Epoch: [4][160/196]	Time 0.122 (0.127)	Data 0.001 (0.011)	Loss 0.6385 (0.7240)	Prec@1 77.344 (75.442)	Prec@5 99.609 (98.510)
2022-06-17 17:39:02 - INFO - TRAINING - Epoch: [4][170/196]	Time 0.107 (0.127)	Data 0.000 (0.011)	Loss 0.7299 (0.7227)	Prec@1 73.828 (75.448)	Prec@5 98.438 (98.527)
2022-06-17 17:39:03 - INFO - TRAINING - Epoch: [4][180/196]	Time 0.121 (0.126)	Data 0.000 (0.010)	Loss 0.6643 (0.7223)	Prec@1 75.000 (75.432)	Prec@5 99.609 (98.535)
2022-06-17 17:39:04 - INFO - TRAINING - Epoch: [4][190/196]	Time 0.105 (0.125)	Data 0.000 (0.010)	Loss 0.7173 (0.7213)	Prec@1 75.391 (75.466)	Prec@5 98.438 (98.554)
2022-06-17 17:39:06 - INFO - EVALUATING - Epoch: [4][0/40]	Time 1.761 (1.761)	Data 1.712 (1.712)	Loss 0.6461 (0.6461)	Prec@1 76.953 (76.953)	Prec@5 98.828 (98.828)
2022-06-17 17:39:07 - INFO - EVALUATING - Epoch: [4][10/40]	Time 0.063 (0.258)	Data 0.000 (0.209)	Loss 0.6863 (0.6820)	Prec@1 78.516 (77.095)	Prec@5 98.438 (98.509)
2022-06-17 17:39:08 - INFO - EVALUATING - Epoch: [4][20/40]	Time 0.086 (0.161)	Data 0.044 (0.111)	Loss 0.6245 (0.6814)	Prec@1 78.516 (77.437)	Prec@5 98.438 (98.251)
2022-06-17 17:39:09 - INFO - EVALUATING - Epoch: [4][30/40]	Time 0.098 (0.143)	Data 0.054 (0.096)	Loss 0.7965 (0.6832)	Prec@1 71.094 (76.953)	Prec@5 98.438 (98.513)
2022-06-17 17:39:11 - INFO - 
 Epoch: 5	Training Loss 0.7235 	Training Prec@1 75.406 	Training Prec@5 98.548 	Validation Loss 0.6819 	Validation Prec@1 76.910 	Validation Prec@5 98.540 

2022-06-17 17:39:11 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:39:11 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:39:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:39:11 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:39:13 - INFO - TRAINING - Epoch: [5][0/196]	Time 1.906 (1.906)	Data 1.851 (1.851)	Loss 0.6539 (0.6539)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
2022-06-17 17:39:14 - INFO - TRAINING - Epoch: [5][10/196]	Time 0.114 (0.282)	Data 0.000 (0.184)	Loss 0.6090 (0.6036)	Prec@1 79.688 (79.155)	Prec@5 98.438 (99.041)
2022-06-17 17:39:15 - INFO - TRAINING - Epoch: [5][20/196]	Time 0.117 (0.201)	Data 0.000 (0.096)	Loss 0.7045 (0.6230)	Prec@1 74.609 (78.571)	Prec@5 97.656 (98.847)
2022-06-17 17:39:17 - INFO - TRAINING - Epoch: [5][30/196]	Time 0.120 (0.172)	Data 0.000 (0.065)	Loss 0.5236 (0.6124)	Prec@1 82.422 (78.944)	Prec@5 99.609 (98.853)
2022-06-17 17:39:18 - INFO - TRAINING - Epoch: [5][40/196]	Time 0.106 (0.157)	Data 0.000 (0.049)	Loss 0.5893 (0.6198)	Prec@1 80.859 (78.582)	Prec@5 99.219 (98.847)
2022-06-17 17:39:19 - INFO - TRAINING - Epoch: [5][50/196]	Time 0.115 (0.148)	Data 0.000 (0.040)	Loss 0.5766 (0.6235)	Prec@1 80.078 (78.508)	Prec@5 99.609 (98.820)
2022-06-17 17:39:20 - INFO - TRAINING - Epoch: [5][60/196]	Time 0.128 (0.142)	Data 0.000 (0.033)	Loss 0.6521 (0.6273)	Prec@1 78.516 (78.509)	Prec@5 98.438 (98.867)
2022-06-17 17:39:21 - INFO - TRAINING - Epoch: [5][70/196]	Time 0.139 (0.139)	Data 0.000 (0.029)	Loss 0.6515 (0.6263)	Prec@1 78.906 (78.576)	Prec@5 97.266 (98.856)
2022-06-17 17:39:22 - INFO - TRAINING - Epoch: [5][80/196]	Time 0.105 (0.134)	Data 0.000 (0.025)	Loss 0.6865 (0.6294)	Prec@1 76.172 (78.482)	Prec@5 98.438 (98.818)
2022-06-17 17:39:23 - INFO - TRAINING - Epoch: [5][90/196]	Time 0.128 (0.133)	Data 0.000 (0.022)	Loss 0.6366 (0.6354)	Prec@1 76.172 (78.241)	Prec@5 99.609 (98.798)
2022-06-17 17:39:24 - INFO - TRAINING - Epoch: [5][100/196]	Time 0.109 (0.131)	Data 0.000 (0.021)	Loss 0.7443 (0.6368)	Prec@1 77.344 (78.144)	Prec@5 98.438 (98.786)
2022-06-17 17:39:26 - INFO - TRAINING - Epoch: [5][110/196]	Time 0.105 (0.129)	Data 0.000 (0.019)	Loss 0.6603 (0.6363)	Prec@1 78.516 (78.104)	Prec@5 98.047 (98.789)
2022-06-17 17:39:27 - INFO - TRAINING - Epoch: [5][120/196]	Time 0.114 (0.128)	Data 0.000 (0.017)	Loss 0.7061 (0.6387)	Prec@1 77.344 (77.976)	Prec@5 99.219 (98.802)
2022-06-17 17:39:28 - INFO - TRAINING - Epoch: [5][130/196]	Time 0.110 (0.127)	Data 0.000 (0.016)	Loss 0.5583 (0.6396)	Prec@1 81.641 (77.979)	Prec@5 98.438 (98.795)
2022-06-17 17:39:29 - INFO - TRAINING - Epoch: [5][140/196]	Time 0.109 (0.126)	Data 0.000 (0.015)	Loss 0.6547 (0.6399)	Prec@1 76.953 (77.998)	Prec@5 98.828 (98.773)
2022-06-17 17:39:30 - INFO - TRAINING - Epoch: [5][150/196]	Time 0.127 (0.125)	Data 0.000 (0.014)	Loss 0.6198 (0.6384)	Prec@1 78.516 (78.019)	Prec@5 98.828 (98.784)
2022-06-17 17:39:31 - INFO - TRAINING - Epoch: [5][160/196]	Time 0.120 (0.125)	Data 0.000 (0.013)	Loss 0.6950 (0.6420)	Prec@1 74.609 (77.950)	Prec@5 97.656 (98.763)
2022-06-17 17:39:32 - INFO - TRAINING - Epoch: [5][170/196]	Time 0.117 (0.124)	Data 0.000 (0.012)	Loss 0.7135 (0.6442)	Prec@1 76.953 (77.844)	Prec@5 98.438 (98.760)
2022-06-17 17:39:34 - INFO - TRAINING - Epoch: [5][180/196]	Time 0.103 (0.123)	Data 0.000 (0.012)	Loss 0.6234 (0.6442)	Prec@1 78.516 (77.870)	Prec@5 100.000 (98.757)
2022-06-17 17:39:35 - INFO - TRAINING - Epoch: [5][190/196]	Time 0.121 (0.122)	Data 0.000 (0.011)	Loss 0.6472 (0.6451)	Prec@1 78.516 (77.843)	Prec@5 99.219 (98.775)
2022-06-17 17:39:37 - INFO - EVALUATING - Epoch: [5][0/40]	Time 1.906 (1.906)	Data 1.861 (1.861)	Loss 0.5955 (0.5955)	Prec@1 82.422 (82.422)	Prec@5 99.219 (99.219)
2022-06-17 17:39:38 - INFO - EVALUATING - Epoch: [5][10/40]	Time 0.044 (0.263)	Data 0.000 (0.214)	Loss 0.6480 (0.6357)	Prec@1 76.172 (78.622)	Prec@5 98.438 (98.544)
2022-06-17 17:39:39 - INFO - EVALUATING - Epoch: [5][20/40]	Time 0.042 (0.165)	Data 0.000 (0.116)	Loss 0.5995 (0.6438)	Prec@1 80.859 (78.553)	Prec@5 99.609 (98.493)
2022-06-17 17:39:40 - INFO - EVALUATING - Epoch: [5][30/40]	Time 0.088 (0.150)	Data 0.045 (0.101)	Loss 0.6205 (0.6418)	Prec@1 79.297 (78.566)	Prec@5 99.609 (98.664)
2022-06-17 17:39:42 - INFO - 
 Epoch: 6	Training Loss 0.6439 	Training Prec@1 77.882 	Training Prec@5 98.778 	Validation Loss 0.6450 	Validation Prec@1 78.350 	Validation Prec@5 98.640 

2022-06-17 17:39:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:39:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:39:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:39:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:39:44 - INFO - TRAINING - Epoch: [6][0/196]	Time 1.616 (1.616)	Data 1.563 (1.563)	Loss 0.6151 (0.6151)	Prec@1 76.562 (76.562)	Prec@5 99.609 (99.609)
2022-06-17 17:39:45 - INFO - TRAINING - Epoch: [6][10/196]	Time 0.112 (0.291)	Data 0.000 (0.189)	Loss 0.6344 (0.5772)	Prec@1 82.031 (80.611)	Prec@5 99.219 (99.254)
2022-06-17 17:39:46 - INFO - TRAINING - Epoch: [6][20/196]	Time 0.116 (0.204)	Data 0.000 (0.099)	Loss 0.5889 (0.5914)	Prec@1 81.250 (80.078)	Prec@5 98.438 (98.977)
2022-06-17 17:39:48 - INFO - TRAINING - Epoch: [6][30/196]	Time 0.124 (0.177)	Data 0.000 (0.067)	Loss 0.6620 (0.6049)	Prec@1 79.688 (79.448)	Prec@5 98.438 (98.879)
2022-06-17 17:39:49 - INFO - TRAINING - Epoch: [6][40/196]	Time 0.121 (0.163)	Data 0.000 (0.051)	Loss 0.5568 (0.6114)	Prec@1 81.250 (79.345)	Prec@5 99.219 (98.904)
2022-06-17 17:39:50 - INFO - TRAINING - Epoch: [6][50/196]	Time 0.121 (0.156)	Data 0.000 (0.041)	Loss 0.5555 (0.6105)	Prec@1 81.250 (79.473)	Prec@5 99.609 (98.928)
2022-06-17 17:39:51 - INFO - TRAINING - Epoch: [6][60/196]	Time 0.126 (0.150)	Data 0.000 (0.034)	Loss 0.6286 (0.6055)	Prec@1 79.688 (79.771)	Prec@5 98.828 (98.918)
2022-06-17 17:39:53 - INFO - TRAINING - Epoch: [6][70/196]	Time 0.127 (0.146)	Data 0.000 (0.029)	Loss 0.4735 (0.6035)	Prec@1 85.156 (79.864)	Prec@5 98.828 (98.927)
2022-06-17 17:39:54 - INFO - TRAINING - Epoch: [6][80/196]	Time 0.123 (0.143)	Data 0.000 (0.026)	Loss 0.6003 (0.6058)	Prec@1 81.250 (79.702)	Prec@5 99.219 (98.934)
2022-06-17 17:39:55 - INFO - TRAINING - Epoch: [6][90/196]	Time 0.154 (0.141)	Data 0.000 (0.023)	Loss 0.5331 (0.6044)	Prec@1 78.906 (79.718)	Prec@5 99.609 (98.918)
2022-06-17 17:39:56 - INFO - TRAINING - Epoch: [6][100/196]	Time 0.115 (0.140)	Data 0.000 (0.021)	Loss 0.5793 (0.6043)	Prec@1 79.297 (79.765)	Prec@5 99.219 (98.933)
2022-06-17 17:39:58 - INFO - TRAINING - Epoch: [6][110/196]	Time 0.138 (0.138)	Data 0.000 (0.019)	Loss 0.6313 (0.6020)	Prec@1 78.125 (79.744)	Prec@5 99.219 (98.958)
2022-06-17 17:39:59 - INFO - TRAINING - Epoch: [6][120/196]	Time 0.123 (0.137)	Data 0.000 (0.017)	Loss 0.5504 (0.5997)	Prec@1 81.250 (79.826)	Prec@5 100.000 (98.980)
2022-06-17 17:40:00 - INFO - TRAINING - Epoch: [6][130/196]	Time 0.124 (0.135)	Data 0.000 (0.016)	Loss 0.8289 (0.6027)	Prec@1 73.438 (79.780)	Prec@5 98.047 (98.965)
2022-06-17 17:40:01 - INFO - TRAINING - Epoch: [6][140/196]	Time 0.132 (0.134)	Data 0.000 (0.015)	Loss 0.4305 (0.6011)	Prec@1 84.375 (79.751)	Prec@5 99.219 (98.956)
2022-06-17 17:40:02 - INFO - TRAINING - Epoch: [6][150/196]	Time 0.110 (0.133)	Data 0.000 (0.014)	Loss 0.5568 (0.6019)	Prec@1 78.906 (79.729)	Prec@5 99.219 (98.955)
2022-06-17 17:40:04 - INFO - TRAINING - Epoch: [6][160/196]	Time 0.105 (0.133)	Data 0.000 (0.013)	Loss 0.6657 (0.6037)	Prec@1 75.000 (79.668)	Prec@5 97.266 (98.925)
2022-06-17 17:40:05 - INFO - TRAINING - Epoch: [6][170/196]	Time 0.121 (0.132)	Data 0.000 (0.012)	Loss 0.4385 (0.6036)	Prec@1 84.375 (79.665)	Prec@5 100.000 (98.931)
2022-06-17 17:40:06 - INFO - TRAINING - Epoch: [6][180/196]	Time 0.125 (0.131)	Data 0.000 (0.012)	Loss 0.5482 (0.6027)	Prec@1 81.250 (79.653)	Prec@5 98.828 (98.934)
2022-06-17 17:40:07 - INFO - TRAINING - Epoch: [6][190/196]	Time 0.106 (0.130)	Data 0.000 (0.011)	Loss 0.4703 (0.5999)	Prec@1 81.641 (79.737)	Prec@5 99.219 (98.930)
2022-06-17 17:40:09 - INFO - EVALUATING - Epoch: [6][0/40]	Time 1.538 (1.538)	Data 1.492 (1.492)	Loss 0.7040 (0.7040)	Prec@1 76.172 (76.172)	Prec@5 98.828 (98.828)
2022-06-17 17:40:11 - INFO - EVALUATING - Epoch: [6][10/40]	Time 0.052 (0.280)	Data 0.000 (0.232)	Loss 0.6197 (0.6696)	Prec@1 79.688 (77.983)	Prec@5 98.047 (98.473)
2022-06-17 17:40:11 - INFO - EVALUATING - Epoch: [6][20/40]	Time 0.161 (0.177)	Data 0.121 (0.127)	Loss 0.5746 (0.6633)	Prec@1 80.078 (78.069)	Prec@5 99.609 (98.586)
2022-06-17 17:40:13 - INFO - EVALUATING - Epoch: [6][30/40]	Time 0.056 (0.160)	Data 0.000 (0.112)	Loss 0.6479 (0.6604)	Prec@1 80.469 (78.415)	Prec@5 99.609 (98.677)
2022-06-17 17:40:15 - INFO - 
 Epoch: 7	Training Loss 0.6001 	Training Prec@1 79.720 	Training Prec@5 98.940 	Validation Loss 0.6619 	Validation Prec@1 78.380 	Validation Prec@5 98.760 

2022-06-17 17:40:15 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:40:15 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:40:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:40:15 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:40:17 - INFO - TRAINING - Epoch: [7][0/196]	Time 1.748 (1.748)	Data 1.694 (1.694)	Loss 0.5737 (0.5737)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
2022-06-17 17:40:18 - INFO - TRAINING - Epoch: [7][10/196]	Time 0.101 (0.271)	Data 0.001 (0.180)	Loss 0.5250 (0.5280)	Prec@1 79.688 (81.818)	Prec@5 99.609 (99.467)
2022-06-17 17:40:19 - INFO - TRAINING - Epoch: [7][20/196]	Time 0.106 (0.198)	Data 0.000 (0.095)	Loss 0.4875 (0.5222)	Prec@1 82.812 (82.273)	Prec@5 99.609 (99.368)
2022-06-17 17:40:20 - INFO - TRAINING - Epoch: [7][30/196]	Time 0.109 (0.170)	Data 0.000 (0.064)	Loss 0.6273 (0.5218)	Prec@1 76.953 (82.107)	Prec@5 99.219 (99.269)
2022-06-17 17:40:21 - INFO - TRAINING - Epoch: [7][40/196]	Time 0.120 (0.158)	Data 0.000 (0.049)	Loss 0.5298 (0.5258)	Prec@1 81.641 (81.869)	Prec@5 98.438 (99.200)
2022-06-17 17:40:23 - INFO - TRAINING - Epoch: [7][50/196]	Time 0.136 (0.150)	Data 0.000 (0.039)	Loss 0.5746 (0.5329)	Prec@1 82.031 (81.556)	Prec@5 99.219 (99.203)
2022-06-17 17:40:24 - INFO - TRAINING - Epoch: [7][60/196]	Time 0.127 (0.145)	Data 0.000 (0.033)	Loss 0.4692 (0.5286)	Prec@1 80.469 (81.583)	Prec@5 99.219 (99.232)
2022-06-17 17:40:25 - INFO - TRAINING - Epoch: [7][70/196]	Time 0.139 (0.142)	Data 0.000 (0.028)	Loss 0.6137 (0.5343)	Prec@1 78.125 (81.388)	Prec@5 98.828 (99.219)
2022-06-17 17:40:26 - INFO - TRAINING - Epoch: [7][80/196]	Time 0.108 (0.139)	Data 0.000 (0.025)	Loss 0.5697 (0.5318)	Prec@1 77.344 (81.390)	Prec@5 99.609 (99.243)
2022-06-17 17:40:27 - INFO - TRAINING - Epoch: [7][90/196]	Time 0.104 (0.136)	Data 0.000 (0.022)	Loss 0.5990 (0.5310)	Prec@1 80.859 (81.529)	Prec@5 97.656 (99.219)
2022-06-17 17:40:29 - INFO - TRAINING - Epoch: [7][100/196]	Time 0.123 (0.135)	Data 0.000 (0.020)	Loss 0.4883 (0.5308)	Prec@1 84.375 (81.617)	Prec@5 98.828 (99.242)
2022-06-17 17:40:30 - INFO - TRAINING - Epoch: [7][110/196]	Time 0.111 (0.133)	Data 0.000 (0.018)	Loss 0.5025 (0.5329)	Prec@1 80.469 (81.542)	Prec@5 99.609 (99.226)
2022-06-17 17:40:31 - INFO - TRAINING - Epoch: [7][120/196]	Time 0.138 (0.132)	Data 0.000 (0.017)	Loss 0.5266 (0.5363)	Prec@1 85.547 (81.431)	Prec@5 98.047 (99.203)
2022-06-17 17:40:32 - INFO - TRAINING - Epoch: [7][130/196]	Time 0.105 (0.131)	Data 0.000 (0.015)	Loss 0.6276 (0.5373)	Prec@1 78.906 (81.384)	Prec@5 98.438 (99.201)
2022-06-17 17:40:33 - INFO - TRAINING - Epoch: [7][140/196]	Time 0.130 (0.130)	Data 0.000 (0.014)	Loss 0.5351 (0.5421)	Prec@1 80.078 (81.197)	Prec@5 98.828 (99.169)
2022-06-17 17:40:34 - INFO - TRAINING - Epoch: [7][150/196]	Time 0.136 (0.129)	Data 0.000 (0.013)	Loss 0.5638 (0.5428)	Prec@1 81.250 (81.240)	Prec@5 98.438 (99.159)
2022-06-17 17:40:36 - INFO - TRAINING - Epoch: [7][160/196]	Time 0.138 (0.129)	Data 0.000 (0.013)	Loss 0.5525 (0.5423)	Prec@1 80.078 (81.301)	Prec@5 99.219 (99.163)
2022-06-17 17:40:37 - INFO - TRAINING - Epoch: [7][170/196]	Time 0.103 (0.128)	Data 0.000 (0.012)	Loss 0.5331 (0.5425)	Prec@1 82.422 (81.307)	Prec@5 98.438 (99.166)
2022-06-17 17:40:38 - INFO - TRAINING - Epoch: [7][180/196]	Time 0.124 (0.128)	Data 0.000 (0.011)	Loss 0.5852 (0.5425)	Prec@1 81.641 (81.295)	Prec@5 99.609 (99.158)
2022-06-17 17:40:39 - INFO - TRAINING - Epoch: [7][190/196]	Time 0.106 (0.127)	Data 0.000 (0.011)	Loss 0.5543 (0.5403)	Prec@1 80.078 (81.356)	Prec@5 99.609 (99.170)
2022-06-17 17:40:42 - INFO - EVALUATING - Epoch: [7][0/40]	Time 1.735 (1.735)	Data 1.689 (1.689)	Loss 0.4913 (0.4913)	Prec@1 86.328 (86.328)	Prec@5 98.047 (98.047)
2022-06-17 17:40:43 - INFO - EVALUATING - Epoch: [7][10/40]	Time 0.061 (0.256)	Data 0.000 (0.204)	Loss 0.5477 (0.5450)	Prec@1 83.203 (81.960)	Prec@5 99.219 (98.793)
2022-06-17 17:40:43 - INFO - EVALUATING - Epoch: [7][20/40]	Time 0.074 (0.162)	Data 0.034 (0.112)	Loss 0.6064 (0.5470)	Prec@1 79.688 (81.827)	Prec@5 99.219 (98.754)
2022-06-17 17:40:44 - INFO - EVALUATING - Epoch: [7][30/40]	Time 0.049 (0.147)	Data 0.000 (0.097)	Loss 0.6562 (0.5513)	Prec@1 81.641 (81.477)	Prec@5 99.609 (98.929)
2022-06-17 17:40:47 - INFO - 
 Epoch: 8	Training Loss 0.5401 	Training Prec@1 81.402 	Training Prec@5 99.160 	Validation Loss 0.5446 	Validation Prec@1 81.580 	Validation Prec@5 98.980 

2022-06-17 17:40:47 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:40:47 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:40:47 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:40:47 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:40:48 - INFO - TRAINING - Epoch: [8][0/196]	Time 1.568 (1.568)	Data 1.515 (1.515)	Loss 0.3651 (0.3651)	Prec@1 87.109 (87.109)	Prec@5 100.000 (100.000)
2022-06-17 17:40:50 - INFO - TRAINING - Epoch: [8][10/196]	Time 0.100 (0.269)	Data 0.000 (0.176)	Loss 0.4572 (0.4458)	Prec@1 84.375 (84.339)	Prec@5 98.828 (99.432)
2022-06-17 17:40:51 - INFO - TRAINING - Epoch: [8][20/196]	Time 0.108 (0.195)	Data 0.000 (0.092)	Loss 0.4549 (0.4492)	Prec@1 83.984 (84.524)	Prec@5 99.219 (99.479)
2022-06-17 17:40:52 - INFO - TRAINING - Epoch: [8][30/196]	Time 0.111 (0.168)	Data 0.000 (0.063)	Loss 0.5617 (0.4663)	Prec@1 81.641 (83.909)	Prec@5 99.219 (99.395)
2022-06-17 17:40:53 - INFO - TRAINING - Epoch: [8][40/196]	Time 0.112 (0.155)	Data 0.000 (0.048)	Loss 0.5647 (0.4711)	Prec@1 80.078 (83.670)	Prec@5 99.219 (99.409)
2022-06-17 17:40:54 - INFO - TRAINING - Epoch: [8][50/196]	Time 0.106 (0.146)	Data 0.000 (0.038)	Loss 0.5452 (0.4748)	Prec@1 82.031 (83.563)	Prec@5 98.828 (99.349)
2022-06-17 17:40:55 - INFO - TRAINING - Epoch: [8][60/196]	Time 0.121 (0.140)	Data 0.000 (0.032)	Loss 0.4752 (0.4831)	Prec@1 83.984 (83.274)	Prec@5 99.219 (99.360)
2022-06-17 17:40:56 - INFO - TRAINING - Epoch: [8][70/196]	Time 0.111 (0.136)	Data 0.000 (0.028)	Loss 0.4503 (0.4786)	Prec@1 84.766 (83.319)	Prec@5 99.609 (99.395)
2022-06-17 17:40:57 - INFO - TRAINING - Epoch: [8][80/196]	Time 0.107 (0.133)	Data 0.000 (0.024)	Loss 0.6243 (0.4827)	Prec@1 80.859 (83.174)	Prec@5 99.609 (99.388)
2022-06-17 17:40:58 - INFO - TRAINING - Epoch: [8][90/196]	Time 0.111 (0.130)	Data 0.000 (0.022)	Loss 0.5705 (0.4834)	Prec@1 80.859 (83.147)	Prec@5 99.609 (99.386)
2022-06-17 17:41:00 - INFO - TRAINING - Epoch: [8][100/196]	Time 0.109 (0.128)	Data 0.000 (0.019)	Loss 0.4843 (0.4848)	Prec@1 84.375 (83.075)	Prec@5 99.219 (99.377)
2022-06-17 17:41:01 - INFO - TRAINING - Epoch: [8][110/196]	Time 0.105 (0.126)	Data 0.000 (0.018)	Loss 0.5237 (0.4890)	Prec@1 83.594 (83.024)	Prec@5 100.000 (99.377)
2022-06-17 17:41:02 - INFO - TRAINING - Epoch: [8][120/196]	Time 0.114 (0.125)	Data 0.000 (0.016)	Loss 0.4760 (0.4892)	Prec@1 82.812 (83.055)	Prec@5 99.609 (99.361)
2022-06-17 17:41:03 - INFO - TRAINING - Epoch: [8][130/196]	Time 0.113 (0.124)	Data 0.000 (0.015)	Loss 0.4621 (0.4895)	Prec@1 87.109 (83.105)	Prec@5 98.438 (99.341)
2022-06-17 17:41:04 - INFO - TRAINING - Epoch: [8][140/196]	Time 0.111 (0.123)	Data 0.000 (0.014)	Loss 0.3649 (0.4931)	Prec@1 86.328 (82.993)	Prec@5 100.000 (99.341)
2022-06-17 17:41:05 - INFO - TRAINING - Epoch: [8][150/196]	Time 0.107 (0.122)	Data 0.000 (0.013)	Loss 0.4141 (0.4934)	Prec@1 85.938 (82.955)	Prec@5 98.828 (99.327)
2022-06-17 17:41:06 - INFO - TRAINING - Epoch: [8][160/196]	Time 0.111 (0.121)	Data 0.000 (0.012)	Loss 0.5736 (0.4943)	Prec@1 79.297 (82.859)	Prec@5 98.828 (99.316)
2022-06-17 17:41:07 - INFO - TRAINING - Epoch: [8][170/196]	Time 0.107 (0.121)	Data 0.000 (0.012)	Loss 0.4312 (0.4934)	Prec@1 85.156 (82.897)	Prec@5 100.000 (99.328)
2022-06-17 17:41:08 - INFO - TRAINING - Epoch: [8][180/196]	Time 0.106 (0.120)	Data 0.000 (0.011)	Loss 0.4343 (0.4932)	Prec@1 84.375 (82.890)	Prec@5 99.219 (99.324)
2022-06-17 17:41:10 - INFO - TRAINING - Epoch: [8][190/196]	Time 0.105 (0.120)	Data 0.000 (0.010)	Loss 0.4755 (0.4932)	Prec@1 82.031 (82.921)	Prec@5 99.609 (99.331)
2022-06-17 17:41:12 - INFO - EVALUATING - Epoch: [8][0/40]	Time 1.398 (1.398)	Data 1.352 (1.352)	Loss 0.4752 (0.4752)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
2022-06-17 17:41:13 - INFO - EVALUATING - Epoch: [8][10/40]	Time 0.053 (0.267)	Data 0.000 (0.218)	Loss 0.5880 (0.5505)	Prec@1 82.422 (81.854)	Prec@5 98.828 (99.041)
2022-06-17 17:41:14 - INFO - EVALUATING - Epoch: [8][20/40]	Time 0.118 (0.168)	Data 0.074 (0.121)	Loss 0.4855 (0.5543)	Prec@1 82.031 (81.827)	Prec@5 99.609 (98.884)
2022-06-17 17:41:15 - INFO - EVALUATING - Epoch: [8][30/40]	Time 0.061 (0.154)	Data 0.000 (0.106)	Loss 0.6828 (0.5542)	Prec@1 80.859 (81.918)	Prec@5 99.609 (99.030)
2022-06-17 17:41:17 - INFO - 
 Epoch: 9	Training Loss 0.4932 	Training Prec@1 82.928 	Training Prec@5 99.330 	Validation Loss 0.5484 	Validation Prec@1 81.990 	Validation Prec@5 99.090 

2022-06-17 17:41:17 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:41:17 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:41:17 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:41:17 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:41:19 - INFO - TRAINING - Epoch: [9][0/196]	Time 1.671 (1.671)	Data 1.618 (1.618)	Loss 0.4850 (0.4850)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
2022-06-17 17:41:20 - INFO - TRAINING - Epoch: [9][10/196]	Time 0.138 (0.284)	Data 0.000 (0.189)	Loss 0.4378 (0.4421)	Prec@1 83.984 (85.582)	Prec@5 99.609 (99.254)
2022-06-17 17:41:22 - INFO - TRAINING - Epoch: [9][20/196]	Time 0.116 (0.205)	Data 0.000 (0.099)	Loss 0.3770 (0.4344)	Prec@1 84.766 (85.324)	Prec@5 100.000 (99.461)
2022-06-17 17:41:23 - INFO - TRAINING - Epoch: [9][30/196]	Time 0.125 (0.176)	Data 0.000 (0.067)	Loss 0.3935 (0.4279)	Prec@1 84.766 (85.156)	Prec@5 99.219 (99.483)
2022-06-17 17:41:24 - INFO - TRAINING - Epoch: [9][40/196]	Time 0.104 (0.162)	Data 0.000 (0.051)	Loss 0.4412 (0.4271)	Prec@1 82.031 (85.109)	Prec@5 99.219 (99.476)
2022-06-17 17:41:25 - INFO - TRAINING - Epoch: [9][50/196]	Time 0.114 (0.153)	Data 0.000 (0.041)	Loss 0.6225 (0.4341)	Prec@1 78.125 (84.919)	Prec@5 98.828 (99.472)
2022-06-17 17:41:26 - INFO - TRAINING - Epoch: [9][60/196]	Time 0.118 (0.148)	Data 0.000 (0.034)	Loss 0.4677 (0.4479)	Prec@1 84.766 (84.676)	Prec@5 100.000 (99.411)
2022-06-17 17:41:27 - INFO - TRAINING - Epoch: [9][70/196]	Time 0.137 (0.143)	Data 0.000 (0.030)	Loss 0.3896 (0.4470)	Prec@1 85.156 (84.590)	Prec@5 100.000 (99.450)
2022-06-17 17:41:29 - INFO - TRAINING - Epoch: [9][80/196]	Time 0.125 (0.140)	Data 0.000 (0.026)	Loss 0.3966 (0.4520)	Prec@1 83.984 (84.389)	Prec@5 99.219 (99.445)
2022-06-17 17:41:30 - INFO - TRAINING - Epoch: [9][90/196]	Time 0.128 (0.137)	Data 0.000 (0.023)	Loss 0.5214 (0.4545)	Prec@1 80.078 (84.289)	Prec@5 98.828 (99.442)
2022-06-17 17:41:31 - INFO - TRAINING - Epoch: [9][100/196]	Time 0.121 (0.135)	Data 0.000 (0.021)	Loss 0.4416 (0.4566)	Prec@1 83.594 (84.189)	Prec@5 99.219 (99.424)
2022-06-17 17:41:32 - INFO - TRAINING - Epoch: [9][110/196]	Time 0.122 (0.134)	Data 0.000 (0.019)	Loss 0.5061 (0.4562)	Prec@1 80.469 (84.157)	Prec@5 100.000 (99.437)
2022-06-17 17:41:33 - INFO - TRAINING - Epoch: [9][120/196]	Time 0.113 (0.132)	Data 0.000 (0.017)	Loss 0.5230 (0.4562)	Prec@1 84.375 (84.214)	Prec@5 99.219 (99.425)
2022-06-17 17:41:34 - INFO - TRAINING - Epoch: [9][130/196]	Time 0.107 (0.131)	Data 0.000 (0.016)	Loss 0.5078 (0.4589)	Prec@1 83.594 (84.142)	Prec@5 99.609 (99.416)
2022-06-17 17:41:36 - INFO - TRAINING - Epoch: [9][140/196]	Time 0.105 (0.130)	Data 0.000 (0.015)	Loss 0.5013 (0.4590)	Prec@1 80.859 (84.142)	Prec@5 99.219 (99.429)
2022-06-17 17:41:37 - INFO - TRAINING - Epoch: [9][150/196]	Time 0.118 (0.129)	Data 0.000 (0.014)	Loss 0.5432 (0.4604)	Prec@1 83.203 (84.127)	Prec@5 99.219 (99.436)
2022-06-17 17:41:38 - INFO - TRAINING - Epoch: [9][160/196]	Time 0.121 (0.128)	Data 0.000 (0.013)	Loss 0.6931 (0.4625)	Prec@1 80.859 (84.098)	Prec@5 98.828 (99.427)
2022-06-17 17:41:39 - INFO - TRAINING - Epoch: [9][170/196]	Time 0.109 (0.128)	Data 0.000 (0.012)	Loss 0.4633 (0.4635)	Prec@1 83.594 (84.046)	Prec@5 99.219 (99.415)
2022-06-17 17:41:40 - INFO - TRAINING - Epoch: [9][180/196]	Time 0.129 (0.127)	Data 0.000 (0.012)	Loss 0.4438 (0.4633)	Prec@1 84.375 (84.036)	Prec@5 100.000 (99.424)
2022-06-17 17:41:41 - INFO - TRAINING - Epoch: [9][190/196]	Time 0.105 (0.126)	Data 0.000 (0.011)	Loss 0.5414 (0.4641)	Prec@1 83.203 (84.003)	Prec@5 100.000 (99.429)
2022-06-17 17:41:44 - INFO - EVALUATING - Epoch: [9][0/40]	Time 1.902 (1.902)	Data 1.856 (1.856)	Loss 0.4580 (0.4580)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
2022-06-17 17:41:45 - INFO - EVALUATING - Epoch: [9][10/40]	Time 0.044 (0.256)	Data 0.000 (0.204)	Loss 0.5449 (0.5363)	Prec@1 80.469 (82.741)	Prec@5 99.609 (99.183)
2022-06-17 17:41:46 - INFO - EVALUATING - Epoch: [9][20/40]	Time 0.125 (0.177)	Data 0.084 (0.129)	Loss 0.4437 (0.5321)	Prec@1 83.594 (83.073)	Prec@5 99.219 (99.033)
2022-06-17 17:41:47 - INFO - EVALUATING - Epoch: [9][30/40]	Time 0.086 (0.153)	Data 0.042 (0.107)	Loss 0.5302 (0.5310)	Prec@1 83.594 (83.052)	Prec@5 100.000 (99.131)
2022-06-17 17:41:49 - INFO - 
 Epoch: 10	Training Loss 0.4643 	Training Prec@1 83.988 	Training Prec@5 99.430 	Validation Loss 0.5286 	Validation Prec@1 82.670 	Validation Prec@5 99.170 

2022-06-17 17:41:49 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:41:49 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:41:49 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:41:49 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:41:49 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:41:51 - INFO - TRAINING - Epoch: [10][0/196]	Time 1.754 (1.754)	Data 1.701 (1.701)	Loss 0.4967 (0.4967)	Prec@1 83.203 (83.203)	Prec@5 100.000 (100.000)
2022-06-17 17:41:52 - INFO - TRAINING - Epoch: [10][10/196]	Time 0.115 (0.263)	Data 0.000 (0.155)	Loss 0.3206 (0.3959)	Prec@1 90.234 (86.683)	Prec@5 99.609 (99.609)
2022-06-17 17:41:53 - INFO - TRAINING - Epoch: [10][20/196]	Time 0.107 (0.192)	Data 0.000 (0.081)	Loss 0.2895 (0.3770)	Prec@1 89.453 (87.165)	Prec@5 99.609 (99.591)
2022-06-17 17:41:54 - INFO - TRAINING - Epoch: [10][30/196]	Time 0.104 (0.166)	Data 0.000 (0.055)	Loss 0.3921 (0.3711)	Prec@1 88.281 (87.387)	Prec@5 100.000 (99.635)
2022-06-17 17:41:55 - INFO - TRAINING - Epoch: [10][40/196]	Time 0.118 (0.153)	Data 0.000 (0.042)	Loss 0.3890 (0.3707)	Prec@1 87.500 (87.109)	Prec@5 99.219 (99.590)
2022-06-17 17:41:57 - INFO - TRAINING - Epoch: [10][50/196]	Time 0.104 (0.145)	Data 0.000 (0.034)	Loss 0.3495 (0.3678)	Prec@1 87.500 (87.048)	Prec@5 99.609 (99.625)
2022-06-17 17:41:58 - INFO - TRAINING - Epoch: [10][60/196]	Time 0.107 (0.139)	Data 0.000 (0.028)	Loss 0.3248 (0.3669)	Prec@1 90.234 (87.007)	Prec@5 99.609 (99.648)
2022-06-17 17:41:59 - INFO - TRAINING - Epoch: [10][70/196]	Time 0.104 (0.136)	Data 0.000 (0.024)	Loss 0.2315 (0.3617)	Prec@1 92.578 (87.109)	Prec@5 100.000 (99.686)
2022-06-17 17:42:00 - INFO - TRAINING - Epoch: [10][80/196]	Time 0.115 (0.132)	Data 0.000 (0.021)	Loss 0.3474 (0.3612)	Prec@1 88.281 (87.133)	Prec@5 99.219 (99.682)
2022-06-17 17:42:01 - INFO - TRAINING - Epoch: [10][90/196]	Time 0.108 (0.129)	Data 0.000 (0.019)	Loss 0.3900 (0.3618)	Prec@1 86.719 (87.212)	Prec@5 99.219 (99.674)
2022-06-17 17:42:02 - INFO - TRAINING - Epoch: [10][100/196]	Time 0.108 (0.128)	Data 0.000 (0.017)	Loss 0.3537 (0.3596)	Prec@1 87.891 (87.322)	Prec@5 100.000 (99.667)
2022-06-17 17:42:03 - INFO - TRAINING - Epoch: [10][110/196]	Time 0.111 (0.126)	Data 0.000 (0.016)	Loss 0.3327 (0.3569)	Prec@1 89.453 (87.458)	Prec@5 98.828 (99.648)
2022-06-17 17:42:04 - INFO - TRAINING - Epoch: [10][120/196]	Time 0.108 (0.125)	Data 0.000 (0.014)	Loss 0.3576 (0.3551)	Prec@1 86.719 (87.516)	Prec@5 99.609 (99.645)
2022-06-17 17:42:05 - INFO - TRAINING - Epoch: [10][130/196]	Time 0.130 (0.124)	Data 0.000 (0.013)	Loss 0.3457 (0.3542)	Prec@1 88.672 (87.536)	Prec@5 99.609 (99.651)
2022-06-17 17:42:06 - INFO - TRAINING - Epoch: [10][140/196]	Time 0.104 (0.123)	Data 0.000 (0.012)	Loss 0.3104 (0.3545)	Prec@1 89.453 (87.553)	Prec@5 99.609 (99.645)
2022-06-17 17:42:08 - INFO - TRAINING - Epoch: [10][150/196]	Time 0.111 (0.122)	Data 0.000 (0.012)	Loss 0.4059 (0.3536)	Prec@1 85.547 (87.575)	Prec@5 100.000 (99.646)
2022-06-17 17:42:09 - INFO - TRAINING - Epoch: [10][160/196]	Time 0.117 (0.122)	Data 0.000 (0.011)	Loss 0.3188 (0.3542)	Prec@1 86.328 (87.539)	Prec@5 99.609 (99.648)
2022-06-17 17:42:10 - INFO - TRAINING - Epoch: [10][170/196]	Time 0.107 (0.121)	Data 0.000 (0.010)	Loss 0.2047 (0.3527)	Prec@1 93.359 (87.607)	Prec@5 100.000 (99.653)
2022-06-17 17:42:11 - INFO - TRAINING - Epoch: [10][180/196]	Time 0.113 (0.120)	Data 0.000 (0.010)	Loss 0.3215 (0.3533)	Prec@1 91.016 (87.569)	Prec@5 99.219 (99.646)
2022-06-17 17:42:12 - INFO - TRAINING - Epoch: [10][190/196]	Time 0.107 (0.120)	Data 0.000 (0.009)	Loss 0.4134 (0.3531)	Prec@1 86.328 (87.600)	Prec@5 99.609 (99.644)
2022-06-17 17:42:15 - INFO - EVALUATING - Epoch: [10][0/40]	Time 1.829 (1.829)	Data 1.783 (1.783)	Loss 0.3669 (0.3669)	Prec@1 87.109 (87.109)	Prec@5 99.609 (99.609)
2022-06-17 17:42:15 - INFO - EVALUATING - Epoch: [10][10/40]	Time 0.043 (0.239)	Data 0.000 (0.190)	Loss 0.4507 (0.4462)	Prec@1 87.109 (86.328)	Prec@5 99.219 (99.396)
2022-06-17 17:42:16 - INFO - EVALUATING - Epoch: [10][20/40]	Time 0.066 (0.177)	Data 0.000 (0.128)	Loss 0.3882 (0.4480)	Prec@1 86.328 (85.751)	Prec@5 99.219 (99.275)
2022-06-17 17:42:17 - INFO - EVALUATING - Epoch: [10][30/40]	Time 0.044 (0.147)	Data 0.000 (0.099)	Loss 0.4838 (0.4436)	Prec@1 83.984 (85.761)	Prec@5 100.000 (99.383)
2022-06-17 17:42:20 - INFO - 
 Epoch: 11	Training Loss 0.3533 	Training Prec@1 87.592 	Training Prec@5 99.640 	Validation Loss 0.4393 	Validation Prec@1 85.700 	Validation Prec@5 99.420 

2022-06-17 17:42:20 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:42:20 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:42:20 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:42:20 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:42:20 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:42:22 - INFO - TRAINING - Epoch: [11][0/196]	Time 1.908 (1.908)	Data 1.854 (1.854)	Loss 0.2327 (0.2327)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 17:42:23 - INFO - TRAINING - Epoch: [11][10/196]	Time 0.104 (0.277)	Data 0.000 (0.187)	Loss 0.3069 (0.2977)	Prec@1 89.453 (89.560)	Prec@5 99.609 (99.680)
2022-06-17 17:42:24 - INFO - TRAINING - Epoch: [11][20/196]	Time 0.106 (0.195)	Data 0.000 (0.098)	Loss 0.2922 (0.2956)	Prec@1 88.281 (89.509)	Prec@5 100.000 (99.758)
2022-06-17 17:42:25 - INFO - TRAINING - Epoch: [11][30/196]	Time 0.112 (0.169)	Data 0.000 (0.067)	Loss 0.3061 (0.3013)	Prec@1 89.062 (89.403)	Prec@5 99.609 (99.723)
2022-06-17 17:42:26 - INFO - TRAINING - Epoch: [11][40/196]	Time 0.115 (0.156)	Data 0.000 (0.050)	Loss 0.4125 (0.3080)	Prec@1 85.938 (89.043)	Prec@5 100.000 (99.724)
2022-06-17 17:42:27 - INFO - TRAINING - Epoch: [11][50/196]	Time 0.114 (0.147)	Data 0.000 (0.041)	Loss 0.3572 (0.3114)	Prec@1 86.719 (89.017)	Prec@5 99.219 (99.709)
2022-06-17 17:42:28 - INFO - TRAINING - Epoch: [11][60/196]	Time 0.117 (0.142)	Data 0.000 (0.034)	Loss 0.3474 (0.3154)	Prec@1 90.625 (88.960)	Prec@5 99.219 (99.705)
2022-06-17 17:42:29 - INFO - TRAINING - Epoch: [11][70/196]	Time 0.104 (0.138)	Data 0.000 (0.029)	Loss 0.3785 (0.3169)	Prec@1 88.281 (88.963)	Prec@5 99.609 (99.703)
2022-06-17 17:42:31 - INFO - TRAINING - Epoch: [11][80/196]	Time 0.120 (0.135)	Data 0.000 (0.026)	Loss 0.3252 (0.3157)	Prec@1 89.844 (89.014)	Prec@5 99.609 (99.701)
2022-06-17 17:42:32 - INFO - TRAINING - Epoch: [11][90/196]	Time 0.114 (0.133)	Data 0.000 (0.023)	Loss 0.3217 (0.3155)	Prec@1 88.672 (89.054)	Prec@5 99.219 (99.691)
2022-06-17 17:42:33 - INFO - TRAINING - Epoch: [11][100/196]	Time 0.138 (0.132)	Data 0.000 (0.021)	Loss 0.2879 (0.3185)	Prec@1 90.234 (88.962)	Prec@5 99.219 (99.702)
2022-06-17 17:42:34 - INFO - TRAINING - Epoch: [11][110/196]	Time 0.119 (0.131)	Data 0.000 (0.019)	Loss 0.3176 (0.3184)	Prec@1 87.500 (88.946)	Prec@5 100.000 (99.711)
2022-06-17 17:42:35 - INFO - TRAINING - Epoch: [11][120/196]	Time 0.120 (0.130)	Data 0.000 (0.017)	Loss 0.2797 (0.3199)	Prec@1 90.234 (88.898)	Prec@5 100.000 (99.706)
2022-06-17 17:42:37 - INFO - TRAINING - Epoch: [11][130/196]	Time 0.107 (0.128)	Data 0.000 (0.016)	Loss 0.3737 (0.3216)	Prec@1 87.500 (88.845)	Prec@5 98.438 (99.672)
2022-06-17 17:42:38 - INFO - TRAINING - Epoch: [11][140/196]	Time 0.135 (0.128)	Data 0.000 (0.015)	Loss 0.2256 (0.3209)	Prec@1 91.406 (88.838)	Prec@5 99.609 (99.673)
2022-06-17 17:42:39 - INFO - TRAINING - Epoch: [11][150/196]	Time 0.130 (0.127)	Data 0.000 (0.014)	Loss 0.3466 (0.3207)	Prec@1 87.891 (88.812)	Prec@5 100.000 (99.684)
2022-06-17 17:42:40 - INFO - TRAINING - Epoch: [11][160/196]	Time 0.113 (0.126)	Data 0.000 (0.013)	Loss 0.3094 (0.3195)	Prec@1 88.281 (88.854)	Prec@5 100.000 (99.697)
2022-06-17 17:42:41 - INFO - TRAINING - Epoch: [11][170/196]	Time 0.122 (0.126)	Data 0.000 (0.012)	Loss 0.3323 (0.3192)	Prec@1 87.500 (88.852)	Prec@5 100.000 (99.708)
2022-06-17 17:42:42 - INFO - TRAINING - Epoch: [11][180/196]	Time 0.110 (0.126)	Data 0.000 (0.012)	Loss 0.3891 (0.3204)	Prec@1 87.500 (88.810)	Prec@5 99.609 (99.709)
2022-06-17 17:42:44 - INFO - TRAINING - Epoch: [11][190/196]	Time 0.103 (0.125)	Data 0.000 (0.011)	Loss 0.3233 (0.3231)	Prec@1 88.281 (88.748)	Prec@5 99.609 (99.697)
2022-06-17 17:42:46 - INFO - EVALUATING - Epoch: [11][0/40]	Time 1.426 (1.426)	Data 1.380 (1.380)	Loss 0.3411 (0.3411)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
2022-06-17 17:42:47 - INFO - EVALUATING - Epoch: [11][10/40]	Time 0.596 (0.273)	Data 0.551 (0.228)	Loss 0.4732 (0.4496)	Prec@1 84.766 (85.724)	Prec@5 99.219 (99.325)
2022-06-17 17:42:48 - INFO - EVALUATING - Epoch: [11][20/40]	Time 0.093 (0.170)	Data 0.053 (0.122)	Loss 0.4188 (0.4591)	Prec@1 85.547 (85.472)	Prec@5 99.219 (99.144)
2022-06-17 17:42:49 - INFO - EVALUATING - Epoch: [11][30/40]	Time 0.047 (0.157)	Data 0.000 (0.111)	Loss 0.5626 (0.4622)	Prec@1 83.203 (85.144)	Prec@5 99.609 (99.257)
2022-06-17 17:42:51 - INFO - 
 Epoch: 12	Training Loss 0.3238 	Training Prec@1 88.718 	Training Prec@5 99.696 	Validation Loss 0.4584 	Validation Prec@1 85.080 	Validation Prec@5 99.290 

2022-06-17 17:42:51 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:42:51 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:42:51 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:42:51 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:42:51 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:42:52 - INFO - TRAINING - Epoch: [12][0/196]	Time 1.275 (1.275)	Data 1.220 (1.220)	Loss 0.3157 (0.3157)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
2022-06-17 17:42:54 - INFO - TRAINING - Epoch: [12][10/196]	Time 0.137 (0.277)	Data 0.000 (0.183)	Loss 0.2226 (0.2808)	Prec@1 92.188 (90.696)	Prec@5 100.000 (99.680)
2022-06-17 17:42:55 - INFO - TRAINING - Epoch: [12][20/196]	Time 0.113 (0.199)	Data 0.000 (0.096)	Loss 0.3164 (0.2913)	Prec@1 90.234 (90.048)	Prec@5 100.000 (99.777)
2022-06-17 17:42:56 - INFO - TRAINING - Epoch: [12][30/196]	Time 0.105 (0.171)	Data 0.000 (0.065)	Loss 0.2459 (0.2900)	Prec@1 90.625 (90.096)	Prec@5 100.000 (99.761)
2022-06-17 17:42:57 - INFO - TRAINING - Epoch: [12][40/196]	Time 0.110 (0.158)	Data 0.000 (0.049)	Loss 0.3405 (0.2925)	Prec@1 89.844 (89.939)	Prec@5 99.609 (99.752)
2022-06-17 17:42:58 - INFO - TRAINING - Epoch: [12][50/196]	Time 0.126 (0.150)	Data 0.000 (0.040)	Loss 0.2614 (0.2923)	Prec@1 91.016 (89.874)	Prec@5 100.000 (99.724)
2022-06-17 17:43:00 - INFO - TRAINING - Epoch: [12][60/196]	Time 0.106 (0.144)	Data 0.000 (0.033)	Loss 0.3255 (0.2994)	Prec@1 86.719 (89.588)	Prec@5 100.000 (99.699)
2022-06-17 17:43:01 - INFO - TRAINING - Epoch: [12][70/196]	Time 0.106 (0.140)	Data 0.000 (0.029)	Loss 0.3385 (0.3006)	Prec@1 90.625 (89.536)	Prec@5 99.609 (99.681)
2022-06-17 17:43:02 - INFO - TRAINING - Epoch: [12][80/196]	Time 0.103 (0.137)	Data 0.000 (0.025)	Loss 0.3090 (0.3000)	Prec@1 87.500 (89.525)	Prec@5 99.609 (99.696)
2022-06-17 17:43:03 - INFO - TRAINING - Epoch: [12][90/196]	Time 0.119 (0.135)	Data 0.000 (0.022)	Loss 0.2687 (0.3025)	Prec@1 91.016 (89.393)	Prec@5 100.000 (99.704)
2022-06-17 17:43:04 - INFO - TRAINING - Epoch: [12][100/196]	Time 0.112 (0.133)	Data 0.000 (0.020)	Loss 0.3251 (0.3038)	Prec@1 88.281 (89.360)	Prec@5 99.609 (99.706)
2022-06-17 17:43:05 - INFO - TRAINING - Epoch: [12][110/196]	Time 0.109 (0.131)	Data 0.000 (0.018)	Loss 0.3268 (0.3046)	Prec@1 87.500 (89.355)	Prec@5 100.000 (99.701)
2022-06-17 17:43:07 - INFO - TRAINING - Epoch: [12][120/196]	Time 0.106 (0.130)	Data 0.000 (0.017)	Loss 0.3829 (0.3037)	Prec@1 85.938 (89.418)	Prec@5 100.000 (99.697)
2022-06-17 17:43:08 - INFO - TRAINING - Epoch: [12][130/196]	Time 0.121 (0.129)	Data 0.000 (0.016)	Loss 0.2617 (0.3019)	Prec@1 91.016 (89.447)	Prec@5 100.000 (99.705)
2022-06-17 17:43:09 - INFO - TRAINING - Epoch: [12][140/196]	Time 0.114 (0.128)	Data 0.000 (0.015)	Loss 0.3104 (0.3028)	Prec@1 87.891 (89.400)	Prec@5 100.000 (99.704)
2022-06-17 17:43:10 - INFO - TRAINING - Epoch: [12][150/196]	Time 0.106 (0.128)	Data 0.000 (0.014)	Loss 0.3724 (0.3023)	Prec@1 87.891 (89.432)	Prec@5 99.219 (99.715)
2022-06-17 17:43:11 - INFO - TRAINING - Epoch: [12][160/196]	Time 0.106 (0.127)	Data 0.000 (0.013)	Loss 0.3232 (0.3023)	Prec@1 87.109 (89.424)	Prec@5 99.609 (99.697)
2022-06-17 17:43:12 - INFO - TRAINING - Epoch: [12][170/196]	Time 0.136 (0.127)	Data 0.000 (0.012)	Loss 0.3288 (0.3024)	Prec@1 89.062 (89.412)	Prec@5 100.000 (99.703)
2022-06-17 17:43:14 - INFO - TRAINING - Epoch: [12][180/196]	Time 0.109 (0.126)	Data 0.000 (0.011)	Loss 0.3140 (0.3036)	Prec@1 89.453 (89.378)	Prec@5 100.000 (99.706)
2022-06-17 17:43:15 - INFO - TRAINING - Epoch: [12][190/196]	Time 0.103 (0.125)	Data 0.000 (0.011)	Loss 0.3804 (0.3056)	Prec@1 90.234 (89.320)	Prec@5 99.609 (99.699)
2022-06-17 17:43:17 - INFO - EVALUATING - Epoch: [12][0/40]	Time 1.323 (1.323)	Data 1.278 (1.278)	Loss 0.3331 (0.3331)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
2022-06-17 17:43:18 - INFO - EVALUATING - Epoch: [12][10/40]	Time 0.044 (0.268)	Data 0.000 (0.217)	Loss 0.4853 (0.4535)	Prec@1 86.328 (85.866)	Prec@5 99.609 (99.219)
2022-06-17 17:43:19 - INFO - EVALUATING - Epoch: [12][20/40]	Time 0.081 (0.166)	Data 0.038 (0.116)	Loss 0.4161 (0.4570)	Prec@1 86.328 (85.658)	Prec@5 99.609 (99.126)
2022-06-17 17:43:20 - INFO - EVALUATING - Epoch: [12][30/40]	Time 0.110 (0.151)	Data 0.066 (0.103)	Loss 0.5863 (0.4619)	Prec@1 85.547 (85.522)	Prec@5 100.000 (99.282)
2022-06-17 17:43:22 - INFO - 
 Epoch: 13	Training Loss 0.3051 	Training Prec@1 89.342 	Training Prec@5 99.702 	Validation Loss 0.4591 	Validation Prec@1 85.430 	Validation Prec@5 99.340 

2022-06-17 17:43:22 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:43:22 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:43:22 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:43:22 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:43:22 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:43:24 - INFO - TRAINING - Epoch: [13][0/196]	Time 1.728 (1.728)	Data 1.674 (1.674)	Loss 0.3005 (0.3005)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
2022-06-17 17:43:25 - INFO - TRAINING - Epoch: [13][10/196]	Time 0.105 (0.256)	Data 0.000 (0.152)	Loss 0.2462 (0.2775)	Prec@1 92.578 (90.376)	Prec@5 100.000 (99.787)
2022-06-17 17:43:26 - INFO - TRAINING - Epoch: [13][20/196]	Time 0.117 (0.186)	Data 0.000 (0.080)	Loss 0.2794 (0.2865)	Prec@1 90.625 (89.955)	Prec@5 99.609 (99.702)
2022-06-17 17:43:27 - INFO - TRAINING - Epoch: [13][30/196]	Time 0.124 (0.165)	Data 0.000 (0.054)	Loss 0.3693 (0.2835)	Prec@1 86.719 (90.020)	Prec@5 99.219 (99.660)
2022-06-17 17:43:28 - INFO - TRAINING - Epoch: [13][40/196]	Time 0.105 (0.152)	Data 0.000 (0.041)	Loss 0.3511 (0.2874)	Prec@1 87.109 (89.958)	Prec@5 99.609 (99.705)
2022-06-17 17:43:29 - INFO - TRAINING - Epoch: [13][50/196]	Time 0.104 (0.144)	Data 0.000 (0.033)	Loss 0.2888 (0.2876)	Prec@1 88.281 (89.890)	Prec@5 100.000 (99.724)
2022-06-17 17:43:30 - INFO - TRAINING - Epoch: [13][60/196]	Time 0.113 (0.139)	Data 0.000 (0.028)	Loss 0.2454 (0.2839)	Prec@1 92.188 (90.017)	Prec@5 100.000 (99.757)
2022-06-17 17:43:32 - INFO - TRAINING - Epoch: [13][70/196]	Time 0.106 (0.136)	Data 0.000 (0.024)	Loss 0.1973 (0.2838)	Prec@1 92.969 (90.053)	Prec@5 99.609 (99.741)
2022-06-17 17:43:33 - INFO - TRAINING - Epoch: [13][80/196]	Time 0.104 (0.133)	Data 0.000 (0.021)	Loss 0.3548 (0.2842)	Prec@1 87.500 (89.984)	Prec@5 99.219 (99.740)
2022-06-17 17:43:34 - INFO - TRAINING - Epoch: [13][90/196]	Time 0.123 (0.131)	Data 0.000 (0.019)	Loss 0.3166 (0.2841)	Prec@1 87.891 (89.908)	Prec@5 99.219 (99.738)
2022-06-17 17:43:35 - INFO - TRAINING - Epoch: [13][100/196]	Time 0.105 (0.130)	Data 0.000 (0.017)	Loss 0.3365 (0.2841)	Prec@1 87.891 (89.886)	Prec@5 100.000 (99.741)
2022-06-17 17:43:36 - INFO - TRAINING - Epoch: [13][110/196]	Time 0.108 (0.128)	Data 0.000 (0.015)	Loss 0.3169 (0.2841)	Prec@1 89.844 (89.907)	Prec@5 99.219 (99.733)
2022-06-17 17:43:37 - INFO - TRAINING - Epoch: [13][120/196]	Time 0.112 (0.128)	Data 0.000 (0.014)	Loss 0.3408 (0.2866)	Prec@1 89.453 (89.860)	Prec@5 98.828 (99.726)
2022-06-17 17:43:38 - INFO - TRAINING - Epoch: [13][130/196]	Time 0.111 (0.127)	Data 0.000 (0.013)	Loss 0.4536 (0.2883)	Prec@1 85.156 (89.808)	Prec@5 99.219 (99.717)
2022-06-17 17:43:40 - INFO - TRAINING - Epoch: [13][140/196]	Time 0.110 (0.126)	Data 0.000 (0.012)	Loss 0.3265 (0.2893)	Prec@1 89.062 (89.761)	Prec@5 100.000 (99.720)
2022-06-17 17:43:41 - INFO - TRAINING - Epoch: [13][150/196]	Time 0.109 (0.125)	Data 0.000 (0.011)	Loss 0.2214 (0.2890)	Prec@1 93.359 (89.789)	Prec@5 99.609 (99.726)
2022-06-17 17:43:42 - INFO - TRAINING - Epoch: [13][160/196]	Time 0.106 (0.125)	Data 0.000 (0.011)	Loss 0.3128 (0.2895)	Prec@1 89.062 (89.769)	Prec@5 99.609 (99.714)
2022-06-17 17:43:43 - INFO - TRAINING - Epoch: [13][170/196]	Time 0.125 (0.124)	Data 0.000 (0.010)	Loss 0.2610 (0.2896)	Prec@1 91.016 (89.764)	Prec@5 99.609 (99.717)
2022-06-17 17:43:44 - INFO - TRAINING - Epoch: [13][180/196]	Time 0.110 (0.124)	Data 0.000 (0.010)	Loss 0.3364 (0.2905)	Prec@1 89.844 (89.736)	Prec@5 99.609 (99.722)
2022-06-17 17:43:45 - INFO - TRAINING - Epoch: [13][190/196]	Time 0.107 (0.123)	Data 0.000 (0.009)	Loss 0.3745 (0.2913)	Prec@1 88.672 (89.723)	Prec@5 100.000 (99.718)
2022-06-17 17:43:48 - INFO - EVALUATING - Epoch: [13][0/40]	Time 2.017 (2.017)	Data 1.971 (1.971)	Loss 0.3669 (0.3669)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
2022-06-17 17:43:49 - INFO - EVALUATING - Epoch: [13][10/40]	Time 0.045 (0.275)	Data 0.000 (0.222)	Loss 0.4399 (0.4481)	Prec@1 85.938 (85.902)	Prec@5 98.828 (99.325)
2022-06-17 17:43:50 - INFO - EVALUATING - Epoch: [13][20/40]	Time 0.043 (0.176)	Data 0.001 (0.125)	Loss 0.3740 (0.4489)	Prec@1 85.938 (85.863)	Prec@5 99.219 (99.200)
2022-06-17 17:43:51 - INFO - EVALUATING - Epoch: [13][30/40]	Time 0.046 (0.154)	Data 0.000 (0.105)	Loss 0.4947 (0.4397)	Prec@1 85.156 (85.975)	Prec@5 100.000 (99.345)
2022-06-17 17:43:54 - INFO - 
 Epoch: 14	Training Loss 0.2920 	Training Prec@1 89.680 	Training Prec@5 99.720 	Validation Loss 0.4375 	Validation Prec@1 85.930 	Validation Prec@5 99.370 

2022-06-17 17:43:54 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:43:54 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:43:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:43:54 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:43:54 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:43:55 - INFO - TRAINING - Epoch: [14][0/196]	Time 1.954 (1.954)	Data 1.901 (1.901)	Loss 0.2624 (0.2624)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
2022-06-17 17:43:57 - INFO - TRAINING - Epoch: [14][10/196]	Time 0.107 (0.276)	Data 0.000 (0.183)	Loss 0.2328 (0.2369)	Prec@1 90.625 (91.477)	Prec@5 99.609 (99.929)
2022-06-17 17:43:58 - INFO - TRAINING - Epoch: [14][20/196]	Time 0.107 (0.197)	Data 0.000 (0.096)	Loss 0.3298 (0.2454)	Prec@1 88.672 (91.313)	Prec@5 99.609 (99.833)
2022-06-17 17:43:59 - INFO - TRAINING - Epoch: [14][30/196]	Time 0.111 (0.170)	Data 0.000 (0.065)	Loss 0.3321 (0.2520)	Prec@1 88.672 (91.129)	Prec@5 100.000 (99.849)
2022-06-17 17:44:00 - INFO - TRAINING - Epoch: [14][40/196]	Time 0.113 (0.156)	Data 0.000 (0.049)	Loss 0.2810 (0.2612)	Prec@1 91.406 (90.911)	Prec@5 99.609 (99.829)
2022-06-17 17:44:01 - INFO - TRAINING - Epoch: [14][50/196]	Time 0.113 (0.148)	Data 0.000 (0.040)	Loss 0.2902 (0.2621)	Prec@1 90.234 (91.008)	Prec@5 99.219 (99.809)
2022-06-17 17:44:02 - INFO - TRAINING - Epoch: [14][60/196]	Time 0.107 (0.141)	Data 0.000 (0.033)	Loss 0.2656 (0.2618)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.801)
2022-06-17 17:44:03 - INFO - TRAINING - Epoch: [14][70/196]	Time 0.102 (0.138)	Data 0.000 (0.029)	Loss 0.2697 (0.2696)	Prec@1 88.672 (90.774)	Prec@5 100.000 (99.785)
2022-06-17 17:44:04 - INFO - TRAINING - Epoch: [14][80/196]	Time 0.114 (0.134)	Data 0.000 (0.025)	Loss 0.2316 (0.2693)	Prec@1 92.188 (90.721)	Prec@5 100.000 (99.793)
2022-06-17 17:44:06 - INFO - TRAINING - Epoch: [14][90/196]	Time 0.118 (0.132)	Data 0.000 (0.022)	Loss 0.3473 (0.2688)	Prec@1 88.672 (90.737)	Prec@5 100.000 (99.811)
2022-06-17 17:44:07 - INFO - TRAINING - Epoch: [14][100/196]	Time 0.108 (0.130)	Data 0.000 (0.020)	Loss 0.3147 (0.2696)	Prec@1 88.672 (90.695)	Prec@5 100.000 (99.783)
2022-06-17 17:44:08 - INFO - TRAINING - Epoch: [14][110/196]	Time 0.109 (0.128)	Data 0.000 (0.018)	Loss 0.2845 (0.2714)	Prec@1 91.016 (90.643)	Prec@5 99.609 (99.771)
2022-06-17 17:44:09 - INFO - TRAINING - Epoch: [14][120/196]	Time 0.122 (0.127)	Data 0.000 (0.017)	Loss 0.3273 (0.2735)	Prec@1 89.062 (90.535)	Prec@5 99.609 (99.774)
2022-06-17 17:44:10 - INFO - TRAINING - Epoch: [14][130/196]	Time 0.120 (0.126)	Data 0.000 (0.016)	Loss 0.2792 (0.2720)	Prec@1 89.453 (90.571)	Prec@5 100.000 (99.770)
2022-06-17 17:44:11 - INFO - TRAINING - Epoch: [14][140/196]	Time 0.108 (0.125)	Data 0.000 (0.015)	Loss 0.2816 (0.2739)	Prec@1 90.625 (90.492)	Prec@5 100.000 (99.773)
2022-06-17 17:44:12 - INFO - TRAINING - Epoch: [14][150/196]	Time 0.105 (0.124)	Data 0.000 (0.014)	Loss 0.2599 (0.2735)	Prec@1 89.844 (90.475)	Prec@5 100.000 (99.780)
2022-06-17 17:44:13 - INFO - TRAINING - Epoch: [14][160/196]	Time 0.122 (0.123)	Data 0.000 (0.013)	Loss 0.2078 (0.2731)	Prec@1 94.141 (90.504)	Prec@5 100.000 (99.779)
2022-06-17 17:44:14 - INFO - TRAINING - Epoch: [14][170/196]	Time 0.115 (0.123)	Data 0.000 (0.012)	Loss 0.2593 (0.2744)	Prec@1 91.406 (90.467)	Prec@5 100.000 (99.774)
2022-06-17 17:44:16 - INFO - TRAINING - Epoch: [14][180/196]	Time 0.105 (0.122)	Data 0.000 (0.011)	Loss 0.3093 (0.2736)	Prec@1 89.062 (90.498)	Prec@5 99.609 (99.773)
2022-06-17 17:44:17 - INFO - TRAINING - Epoch: [14][190/196]	Time 0.110 (0.121)	Data 0.000 (0.011)	Loss 0.3057 (0.2744)	Prec@1 87.891 (90.476)	Prec@5 100.000 (99.759)
2022-06-17 17:44:19 - INFO - EVALUATING - Epoch: [14][0/40]	Time 1.879 (1.879)	Data 1.833 (1.833)	Loss 0.3186 (0.3186)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
2022-06-17 17:44:20 - INFO - EVALUATING - Epoch: [14][10/40]	Time 0.064 (0.275)	Data 0.000 (0.227)	Loss 0.4207 (0.4335)	Prec@1 87.109 (86.151)	Prec@5 99.219 (99.077)
2022-06-17 17:44:21 - INFO - EVALUATING - Epoch: [14][20/40]	Time 0.044 (0.175)	Data 0.001 (0.127)	Loss 0.3504 (0.4356)	Prec@1 88.672 (86.031)	Prec@5 99.219 (99.070)
2022-06-17 17:44:22 - INFO - EVALUATING - Epoch: [14][30/40]	Time 0.059 (0.153)	Data 0.001 (0.105)	Loss 0.4829 (0.4336)	Prec@1 85.547 (86.101)	Prec@5 100.000 (99.206)
2022-06-17 17:44:25 - INFO - 
 Epoch: 15	Training Loss 0.2745 	Training Prec@1 90.462 	Training Prec@5 99.758 	Validation Loss 0.4293 	Validation Prec@1 86.080 	Validation Prec@5 99.300 

2022-06-17 17:44:25 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:44:25 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:44:25 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:44:25 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:44:25 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:44:25 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:44:25 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:44:26 - INFO - TRAINING - Epoch: [15][0/196]	Time 1.790 (1.790)	Data 1.734 (1.734)	Loss 0.2733 (0.2733)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
2022-06-17 17:44:28 - INFO - TRAINING - Epoch: [15][10/196]	Time 0.128 (0.270)	Data 0.000 (0.171)	Loss 0.2346 (0.2524)	Prec@1 91.016 (90.874)	Prec@5 100.000 (99.822)
2022-06-17 17:44:29 - INFO - TRAINING - Epoch: [15][20/196]	Time 0.108 (0.195)	Data 0.000 (0.090)	Loss 0.1614 (0.2326)	Prec@1 94.141 (91.443)	Prec@5 100.000 (99.870)
2022-06-17 17:44:30 - INFO - TRAINING - Epoch: [15][30/196]	Time 0.109 (0.168)	Data 0.000 (0.061)	Loss 0.2652 (0.2344)	Prec@1 90.625 (91.557)	Prec@5 100.000 (99.899)
2022-06-17 17:44:31 - INFO - TRAINING - Epoch: [15][40/196]	Time 0.114 (0.155)	Data 0.000 (0.046)	Loss 0.2117 (0.2311)	Prec@1 90.625 (91.673)	Prec@5 99.609 (99.876)
2022-06-17 17:44:32 - INFO - TRAINING - Epoch: [15][50/196]	Time 0.126 (0.147)	Data 0.000 (0.037)	Loss 0.2579 (0.2278)	Prec@1 91.797 (91.973)	Prec@5 100.000 (99.877)
2022-06-17 17:44:33 - INFO - TRAINING - Epoch: [15][60/196]	Time 0.102 (0.142)	Data 0.000 (0.031)	Loss 0.2551 (0.2246)	Prec@1 91.016 (92.123)	Prec@5 99.609 (99.878)
2022-06-17 17:44:34 - INFO - TRAINING - Epoch: [15][70/196]	Time 0.107 (0.138)	Data 0.000 (0.027)	Loss 0.2513 (0.2246)	Prec@1 90.234 (92.154)	Prec@5 99.609 (99.868)
2022-06-17 17:44:36 - INFO - TRAINING - Epoch: [15][80/196]	Time 0.124 (0.136)	Data 0.000 (0.023)	Loss 0.2203 (0.2227)	Prec@1 92.578 (92.260)	Prec@5 100.000 (99.860)
2022-06-17 17:44:37 - INFO - TRAINING - Epoch: [15][90/196]	Time 0.119 (0.134)	Data 0.000 (0.021)	Loss 0.1729 (0.2211)	Prec@1 92.969 (92.312)	Prec@5 100.000 (99.854)
2022-06-17 17:44:38 - INFO - TRAINING - Epoch: [15][100/196]	Time 0.103 (0.131)	Data 0.000 (0.019)	Loss 0.1891 (0.2190)	Prec@1 93.750 (92.427)	Prec@5 100.000 (99.849)
2022-06-17 17:44:39 - INFO - TRAINING - Epoch: [15][110/196]	Time 0.102 (0.130)	Data 0.000 (0.017)	Loss 0.2613 (0.2178)	Prec@1 91.797 (92.525)	Prec@5 99.219 (99.838)
2022-06-17 17:44:40 - INFO - TRAINING - Epoch: [15][120/196]	Time 0.123 (0.128)	Data 0.000 (0.016)	Loss 0.2472 (0.2166)	Prec@1 92.188 (92.556)	Prec@5 100.000 (99.839)
2022-06-17 17:44:41 - INFO - TRAINING - Epoch: [15][130/196]	Time 0.118 (0.128)	Data 0.000 (0.015)	Loss 0.2116 (0.2152)	Prec@1 92.969 (92.557)	Prec@5 99.609 (99.842)
2022-06-17 17:44:42 - INFO - TRAINING - Epoch: [15][140/196]	Time 0.111 (0.127)	Data 0.000 (0.014)	Loss 0.1394 (0.2134)	Prec@1 96.875 (92.639)	Prec@5 99.609 (99.850)
2022-06-17 17:44:44 - INFO - TRAINING - Epoch: [15][150/196]	Time 0.104 (0.126)	Data 0.000 (0.013)	Loss 0.2041 (0.2142)	Prec@1 93.750 (92.591)	Prec@5 100.000 (99.853)
2022-06-17 17:44:45 - INFO - TRAINING - Epoch: [15][160/196]	Time 0.123 (0.126)	Data 0.000 (0.012)	Loss 0.2405 (0.2142)	Prec@1 90.625 (92.578)	Prec@5 99.609 (99.845)
2022-06-17 17:44:46 - INFO - TRAINING - Epoch: [15][170/196]	Time 0.108 (0.125)	Data 0.000 (0.011)	Loss 0.1756 (0.2141)	Prec@1 93.750 (92.576)	Prec@5 100.000 (99.847)
2022-06-17 17:44:47 - INFO - TRAINING - Epoch: [15][180/196]	Time 0.109 (0.125)	Data 0.000 (0.011)	Loss 0.1704 (0.2129)	Prec@1 93.359 (92.628)	Prec@5 100.000 (99.849)
2022-06-17 17:44:48 - INFO - TRAINING - Epoch: [15][190/196]	Time 0.101 (0.124)	Data 0.000 (0.010)	Loss 0.1890 (0.2124)	Prec@1 92.578 (92.617)	Prec@5 100.000 (99.855)
2022-06-17 17:44:51 - INFO - EVALUATING - Epoch: [15][0/40]	Time 1.838 (1.838)	Data 1.792 (1.792)	Loss 0.2830 (0.2830)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
2022-06-17 17:44:52 - INFO - EVALUATING - Epoch: [15][10/40]	Time 0.048 (0.267)	Data 0.000 (0.220)	Loss 0.4374 (0.4003)	Prec@1 87.109 (87.393)	Prec@5 99.609 (99.538)
2022-06-17 17:44:52 - INFO - EVALUATING - Epoch: [15][20/40]	Time 0.068 (0.165)	Data 0.000 (0.116)	Loss 0.3278 (0.4016)	Prec@1 88.281 (87.221)	Prec@5 99.609 (99.423)
2022-06-17 17:44:53 - INFO - EVALUATING - Epoch: [15][30/40]	Time 0.096 (0.146)	Data 0.056 (0.100)	Loss 0.4617 (0.3933)	Prec@1 85.156 (87.361)	Prec@5 100.000 (99.483)
2022-06-17 17:44:56 - INFO - 
 Epoch: 16	Training Loss 0.2127 	Training Prec@1 92.602 	Training Prec@5 99.858 	Validation Loss 0.3896 	Validation Prec@1 87.400 	Validation Prec@5 99.560 

2022-06-17 17:44:56 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:44:56 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:44:56 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:44:56 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:44:56 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:44:56 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:44:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:44:58 - INFO - TRAINING - Epoch: [16][0/196]	Time 1.941 (1.941)	Data 1.888 (1.888)	Loss 0.1794 (0.1794)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 17:44:59 - INFO - TRAINING - Epoch: [16][10/196]	Time 0.109 (0.280)	Data 0.000 (0.172)	Loss 0.1486 (0.1765)	Prec@1 94.922 (93.750)	Prec@5 99.609 (99.893)
2022-06-17 17:45:00 - INFO - TRAINING - Epoch: [16][20/196]	Time 0.114 (0.201)	Data 0.000 (0.090)	Loss 0.2324 (0.1760)	Prec@1 90.234 (93.564)	Prec@5 99.609 (99.907)
2022-06-17 17:45:01 - INFO - TRAINING - Epoch: [16][30/196]	Time 0.111 (0.172)	Data 0.000 (0.061)	Loss 0.1366 (0.1774)	Prec@1 95.703 (93.624)	Prec@5 99.609 (99.912)
2022-06-17 17:45:02 - INFO - TRAINING - Epoch: [16][40/196]	Time 0.124 (0.158)	Data 0.000 (0.046)	Loss 0.1931 (0.1782)	Prec@1 91.406 (93.483)	Prec@5 100.000 (99.914)
2022-06-17 17:45:03 - INFO - TRAINING - Epoch: [16][50/196]	Time 0.105 (0.149)	Data 0.000 (0.037)	Loss 0.1333 (0.1795)	Prec@1 95.703 (93.559)	Prec@5 100.000 (99.900)
2022-06-17 17:45:05 - INFO - TRAINING - Epoch: [16][60/196]	Time 0.103 (0.144)	Data 0.000 (0.031)	Loss 0.1606 (0.1803)	Prec@1 94.531 (93.616)	Prec@5 100.000 (99.898)
2022-06-17 17:45:06 - INFO - TRAINING - Epoch: [16][70/196]	Time 0.128 (0.140)	Data 0.000 (0.027)	Loss 0.2165 (0.1811)	Prec@1 91.406 (93.673)	Prec@5 100.000 (99.895)
2022-06-17 17:45:07 - INFO - TRAINING - Epoch: [16][80/196]	Time 0.102 (0.137)	Data 0.000 (0.024)	Loss 0.1840 (0.1816)	Prec@1 92.969 (93.678)	Prec@5 100.000 (99.904)
2022-06-17 17:45:08 - INFO - TRAINING - Epoch: [16][90/196]	Time 0.104 (0.135)	Data 0.000 (0.021)	Loss 0.1738 (0.1838)	Prec@1 93.359 (93.643)	Prec@5 100.000 (99.901)
2022-06-17 17:45:09 - INFO - TRAINING - Epoch: [16][100/196]	Time 0.104 (0.132)	Data 0.000 (0.019)	Loss 0.1843 (0.1852)	Prec@1 94.531 (93.595)	Prec@5 99.609 (99.892)
2022-06-17 17:45:10 - INFO - TRAINING - Epoch: [16][110/196]	Time 0.130 (0.131)	Data 0.000 (0.017)	Loss 0.2631 (0.1861)	Prec@1 91.016 (93.592)	Prec@5 100.000 (99.887)
2022-06-17 17:45:12 - INFO - TRAINING - Epoch: [16][120/196]	Time 0.107 (0.130)	Data 0.000 (0.016)	Loss 0.2011 (0.1881)	Prec@1 92.578 (93.524)	Prec@5 100.000 (99.881)
2022-06-17 17:45:13 - INFO - TRAINING - Epoch: [16][130/196]	Time 0.104 (0.129)	Data 0.000 (0.015)	Loss 0.1890 (0.1887)	Prec@1 92.578 (93.511)	Prec@5 100.000 (99.884)
2022-06-17 17:45:14 - INFO - TRAINING - Epoch: [16][140/196]	Time 0.135 (0.128)	Data 0.000 (0.014)	Loss 0.2004 (0.1885)	Prec@1 94.531 (93.542)	Prec@5 100.000 (99.884)
2022-06-17 17:45:15 - INFO - TRAINING - Epoch: [16][150/196]	Time 0.107 (0.127)	Data 0.000 (0.013)	Loss 0.1679 (0.1886)	Prec@1 93.750 (93.533)	Prec@5 100.000 (99.891)
2022-06-17 17:45:16 - INFO - TRAINING - Epoch: [16][160/196]	Time 0.102 (0.126)	Data 0.000 (0.012)	Loss 0.2196 (0.1893)	Prec@1 91.797 (93.473)	Prec@5 100.000 (99.898)
2022-06-17 17:45:17 - INFO - TRAINING - Epoch: [16][170/196]	Time 0.104 (0.125)	Data 0.000 (0.011)	Loss 0.1831 (0.1893)	Prec@1 94.531 (93.483)	Prec@5 99.609 (99.897)
2022-06-17 17:45:18 - INFO - TRAINING - Epoch: [16][180/196]	Time 0.103 (0.125)	Data 0.000 (0.011)	Loss 0.2752 (0.1898)	Prec@1 90.234 (93.450)	Prec@5 100.000 (99.903)
2022-06-17 17:45:20 - INFO - TRAINING - Epoch: [16][190/196]	Time 0.103 (0.124)	Data 0.000 (0.010)	Loss 0.1695 (0.1899)	Prec@1 94.531 (93.472)	Prec@5 100.000 (99.898)
2022-06-17 17:45:22 - INFO - EVALUATING - Epoch: [16][0/40]	Time 2.008 (2.008)	Data 1.963 (1.963)	Loss 0.2914 (0.2914)	Prec@1 90.234 (90.234)	Prec@5 99.609 (99.609)
2022-06-17 17:45:23 - INFO - EVALUATING - Epoch: [16][10/40]	Time 0.062 (0.263)	Data 0.000 (0.213)	Loss 0.4440 (0.4001)	Prec@1 87.500 (87.216)	Prec@5 99.609 (99.396)
2022-06-17 17:45:24 - INFO - EVALUATING - Epoch: [16][20/40]	Time 0.160 (0.168)	Data 0.119 (0.120)	Loss 0.3214 (0.3999)	Prec@1 88.281 (87.202)	Prec@5 100.000 (99.405)
2022-06-17 17:45:25 - INFO - EVALUATING - Epoch: [16][30/40]	Time 0.187 (0.155)	Data 0.143 (0.109)	Loss 0.4582 (0.3933)	Prec@1 84.766 (87.311)	Prec@5 100.000 (99.458)
2022-06-17 17:45:27 - INFO - 
 Epoch: 17	Training Loss 0.1906 	Training Prec@1 93.450 	Training Prec@5 99.894 	Validation Loss 0.3891 	Validation Prec@1 87.220 	Validation Prec@5 99.540 

2022-06-17 17:45:27 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:45:27 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:45:27 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:45:27 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:45:27 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:45:27 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:45:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:45:29 - INFO - TRAINING - Epoch: [17][0/196]	Time 2.054 (2.054)	Data 2.003 (2.003)	Loss 0.1389 (0.1389)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
2022-06-17 17:45:30 - INFO - TRAINING - Epoch: [17][10/196]	Time 0.109 (0.287)	Data 0.000 (0.182)	Loss 0.1582 (0.1569)	Prec@1 94.141 (94.780)	Prec@5 100.000 (99.964)
2022-06-17 17:45:31 - INFO - TRAINING - Epoch: [17][20/196]	Time 0.113 (0.202)	Data 0.000 (0.096)	Loss 0.2103 (0.1721)	Prec@1 94.141 (94.103)	Prec@5 99.219 (99.888)
2022-06-17 17:45:32 - INFO - TRAINING - Epoch: [17][30/196]	Time 0.102 (0.171)	Data 0.000 (0.065)	Loss 0.1682 (0.1694)	Prec@1 94.531 (94.166)	Prec@5 100.000 (99.912)
2022-06-17 17:45:33 - INFO - TRAINING - Epoch: [17][40/196]	Time 0.112 (0.156)	Data 0.000 (0.049)	Loss 0.1807 (0.1661)	Prec@1 93.750 (94.255)	Prec@5 99.609 (99.924)
2022-06-17 17:45:34 - INFO - TRAINING - Epoch: [17][50/196]	Time 0.110 (0.146)	Data 0.000 (0.040)	Loss 0.3203 (0.1716)	Prec@1 89.062 (94.164)	Prec@5 98.828 (99.908)
2022-06-17 17:45:35 - INFO - TRAINING - Epoch: [17][60/196]	Time 0.109 (0.140)	Data 0.000 (0.033)	Loss 0.2008 (0.1717)	Prec@1 93.359 (94.134)	Prec@5 100.000 (99.917)
2022-06-17 17:45:36 - INFO - TRAINING - Epoch: [17][70/196]	Time 0.112 (0.136)	Data 0.000 (0.028)	Loss 0.2367 (0.1737)	Prec@1 93.359 (94.097)	Prec@5 100.000 (99.912)
2022-06-17 17:45:38 - INFO - TRAINING - Epoch: [17][80/196]	Time 0.110 (0.133)	Data 0.001 (0.025)	Loss 0.1826 (0.1747)	Prec@1 93.750 (94.015)	Prec@5 100.000 (99.918)
2022-06-17 17:45:39 - INFO - TRAINING - Epoch: [17][90/196]	Time 0.111 (0.131)	Data 0.000 (0.022)	Loss 0.2733 (0.1769)	Prec@1 89.453 (93.909)	Prec@5 99.219 (99.906)
2022-06-17 17:45:40 - INFO - TRAINING - Epoch: [17][100/196]	Time 0.120 (0.129)	Data 0.000 (0.020)	Loss 0.1480 (0.1761)	Prec@1 95.703 (93.897)	Prec@5 100.000 (99.907)
2022-06-17 17:45:41 - INFO - TRAINING - Epoch: [17][110/196]	Time 0.108 (0.128)	Data 0.000 (0.018)	Loss 0.1430 (0.1763)	Prec@1 94.531 (93.863)	Prec@5 100.000 (99.912)
2022-06-17 17:45:42 - INFO - TRAINING - Epoch: [17][120/196]	Time 0.110 (0.126)	Data 0.000 (0.017)	Loss 0.1664 (0.1771)	Prec@1 92.188 (93.821)	Prec@5 100.000 (99.913)
2022-06-17 17:45:43 - INFO - TRAINING - Epoch: [17][130/196]	Time 0.109 (0.125)	Data 0.000 (0.016)	Loss 0.1662 (0.1771)	Prec@1 94.922 (93.813)	Prec@5 100.000 (99.917)
2022-06-17 17:45:44 - INFO - TRAINING - Epoch: [17][140/196]	Time 0.102 (0.124)	Data 0.000 (0.014)	Loss 0.1821 (0.1787)	Prec@1 94.922 (93.786)	Prec@5 100.000 (99.909)
2022-06-17 17:45:45 - INFO - TRAINING - Epoch: [17][150/196]	Time 0.130 (0.123)	Data 0.000 (0.014)	Loss 0.2629 (0.1790)	Prec@1 89.844 (93.773)	Prec@5 100.000 (99.909)
2022-06-17 17:45:47 - INFO - TRAINING - Epoch: [17][160/196]	Time 0.114 (0.123)	Data 0.000 (0.013)	Loss 0.1586 (0.1789)	Prec@1 93.750 (93.777)	Prec@5 100.000 (99.915)
2022-06-17 17:45:48 - INFO - TRAINING - Epoch: [17][170/196]	Time 0.112 (0.122)	Data 0.000 (0.012)	Loss 0.1887 (0.1795)	Prec@1 94.531 (93.729)	Prec@5 99.609 (99.915)
2022-06-17 17:45:49 - INFO - TRAINING - Epoch: [17][180/196]	Time 0.103 (0.121)	Data 0.000 (0.011)	Loss 0.1712 (0.1798)	Prec@1 93.750 (93.713)	Prec@5 100.000 (99.918)
2022-06-17 17:45:50 - INFO - TRAINING - Epoch: [17][190/196]	Time 0.103 (0.120)	Data 0.000 (0.011)	Loss 0.1673 (0.1799)	Prec@1 92.578 (93.703)	Prec@5 100.000 (99.920)
2022-06-17 17:45:52 - INFO - EVALUATING - Epoch: [17][0/40]	Time 1.879 (1.879)	Data 1.832 (1.832)	Loss 0.2737 (0.2737)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
2022-06-17 17:45:53 - INFO - EVALUATING - Epoch: [17][10/40]	Time 0.106 (0.263)	Data 0.061 (0.216)	Loss 0.4363 (0.3904)	Prec@1 86.719 (87.820)	Prec@5 99.609 (99.467)
2022-06-17 17:45:54 - INFO - EVALUATING - Epoch: [17][20/40]	Time 0.062 (0.169)	Data 0.000 (0.122)	Loss 0.3259 (0.3919)	Prec@1 87.500 (87.556)	Prec@5 100.000 (99.479)
2022-06-17 17:45:55 - INFO - EVALUATING - Epoch: [17][30/40]	Time 0.096 (0.146)	Data 0.051 (0.099)	Loss 0.4507 (0.3863)	Prec@1 85.938 (87.613)	Prec@5 100.000 (99.521)
2022-06-17 17:45:58 - INFO - 
 Epoch: 18	Training Loss 0.1799 	Training Prec@1 93.698 	Training Prec@5 99.918 	Validation Loss 0.3833 	Validation Prec@1 87.620 	Validation Prec@5 99.590 

2022-06-17 17:45:58 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:45:58 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:45:58 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:45:58 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:45:58 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:45:58 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:45:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:46:00 - INFO - TRAINING - Epoch: [18][0/196]	Time 1.999 (1.999)	Data 1.944 (1.944)	Loss 0.1918 (0.1918)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 17:46:01 - INFO - TRAINING - Epoch: [18][10/196]	Time 0.101 (0.279)	Data 0.000 (0.182)	Loss 0.1886 (0.1821)	Prec@1 94.141 (93.608)	Prec@5 100.000 (99.964)
2022-06-17 17:46:02 - INFO - TRAINING - Epoch: [18][20/196]	Time 0.106 (0.196)	Data 0.000 (0.096)	Loss 0.1644 (0.1760)	Prec@1 94.531 (94.010)	Prec@5 100.000 (99.926)
2022-06-17 17:46:03 - INFO - TRAINING - Epoch: [18][30/196]	Time 0.104 (0.167)	Data 0.000 (0.065)	Loss 0.1580 (0.1698)	Prec@1 94.531 (94.166)	Prec@5 100.000 (99.950)
2022-06-17 17:46:04 - INFO - TRAINING - Epoch: [18][40/196]	Time 0.102 (0.152)	Data 0.000 (0.049)	Loss 0.1344 (0.1657)	Prec@1 94.531 (94.303)	Prec@5 100.000 (99.962)
2022-06-17 17:46:05 - INFO - TRAINING - Epoch: [18][50/196]	Time 0.109 (0.143)	Data 0.000 (0.040)	Loss 0.1769 (0.1667)	Prec@1 93.359 (94.217)	Prec@5 100.000 (99.962)
2022-06-17 17:46:06 - INFO - TRAINING - Epoch: [18][60/196]	Time 0.105 (0.137)	Data 0.000 (0.033)	Loss 0.1874 (0.1693)	Prec@1 92.969 (94.089)	Prec@5 100.000 (99.942)
2022-06-17 17:46:07 - INFO - TRAINING - Epoch: [18][70/196]	Time 0.101 (0.132)	Data 0.000 (0.029)	Loss 0.2131 (0.1704)	Prec@1 92.188 (94.069)	Prec@5 100.000 (99.934)
2022-06-17 17:46:08 - INFO - TRAINING - Epoch: [18][80/196]	Time 0.101 (0.129)	Data 0.000 (0.025)	Loss 0.1843 (0.1719)	Prec@1 93.750 (94.078)	Prec@5 100.000 (99.932)
2022-06-17 17:46:09 - INFO - TRAINING - Epoch: [18][90/196]	Time 0.108 (0.127)	Data 0.000 (0.022)	Loss 0.1716 (0.1721)	Prec@1 94.922 (94.089)	Prec@5 100.000 (99.923)
2022-06-17 17:46:10 - INFO - TRAINING - Epoch: [18][100/196]	Time 0.105 (0.125)	Data 0.000 (0.020)	Loss 0.2033 (0.1740)	Prec@1 94.531 (94.040)	Prec@5 100.000 (99.919)
2022-06-17 17:46:11 - INFO - TRAINING - Epoch: [18][110/196]	Time 0.112 (0.124)	Data 0.000 (0.018)	Loss 0.2144 (0.1749)	Prec@1 91.797 (93.954)	Prec@5 100.000 (99.923)
2022-06-17 17:46:12 - INFO - TRAINING - Epoch: [18][120/196]	Time 0.101 (0.122)	Data 0.000 (0.017)	Loss 0.1721 (0.1745)	Prec@1 94.141 (93.937)	Prec@5 100.000 (99.929)
2022-06-17 17:46:13 - INFO - TRAINING - Epoch: [18][130/196]	Time 0.119 (0.121)	Data 0.000 (0.016)	Loss 0.1722 (0.1762)	Prec@1 94.922 (93.881)	Prec@5 100.000 (99.925)
2022-06-17 17:46:14 - INFO - TRAINING - Epoch: [18][140/196]	Time 0.105 (0.120)	Data 0.000 (0.015)	Loss 0.1467 (0.1758)	Prec@1 94.531 (93.894)	Prec@5 100.000 (99.922)
2022-06-17 17:46:16 - INFO - TRAINING - Epoch: [18][150/196]	Time 0.117 (0.120)	Data 0.000 (0.014)	Loss 0.1633 (0.1763)	Prec@1 94.141 (93.859)	Prec@5 100.000 (99.917)
2022-06-17 17:46:17 - INFO - TRAINING - Epoch: [18][160/196]	Time 0.106 (0.119)	Data 0.000 (0.013)	Loss 0.2261 (0.1776)	Prec@1 93.359 (93.818)	Prec@5 99.609 (99.915)
2022-06-17 17:46:18 - INFO - TRAINING - Epoch: [18][170/196]	Time 0.109 (0.119)	Data 0.000 (0.012)	Loss 0.1596 (0.1782)	Prec@1 92.969 (93.789)	Prec@5 100.000 (99.909)
2022-06-17 17:46:19 - INFO - TRAINING - Epoch: [18][180/196]	Time 0.106 (0.119)	Data 0.000 (0.011)	Loss 0.1679 (0.1785)	Prec@1 94.531 (93.774)	Prec@5 100.000 (99.907)
2022-06-17 17:46:20 - INFO - TRAINING - Epoch: [18][190/196]	Time 0.102 (0.118)	Data 0.000 (0.011)	Loss 0.1756 (0.1789)	Prec@1 95.312 (93.770)	Prec@5 99.609 (99.906)
2022-06-17 17:46:23 - INFO - EVALUATING - Epoch: [18][0/40]	Time 1.835 (1.835)	Data 1.789 (1.789)	Loss 0.2946 (0.2946)	Prec@1 91.016 (91.016)	Prec@5 99.219 (99.219)
2022-06-17 17:46:24 - INFO - EVALUATING - Epoch: [18][10/40]	Time 0.044 (0.254)	Data 0.000 (0.205)	Loss 0.4368 (0.3918)	Prec@1 87.109 (88.175)	Prec@5 100.000 (99.503)
2022-06-17 17:46:24 - INFO - EVALUATING - Epoch: [18][20/40]	Time 0.044 (0.170)	Data 0.000 (0.121)	Loss 0.3281 (0.3919)	Prec@1 87.109 (87.853)	Prec@5 100.000 (99.461)
2022-06-17 17:46:25 - INFO - EVALUATING - Epoch: [18][30/40]	Time 0.090 (0.143)	Data 0.046 (0.093)	Loss 0.4382 (0.3858)	Prec@1 85.938 (87.865)	Prec@5 100.000 (99.521)
2022-06-17 17:46:28 - INFO - 
 Epoch: 19	Training Loss 0.1784 	Training Prec@1 93.794 	Training Prec@5 99.906 	Validation Loss 0.3819 	Validation Prec@1 87.850 	Validation Prec@5 99.600 

2022-06-17 17:46:28 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:46:28 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:46:28 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:46:28 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:46:28 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:46:28 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:46:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:46:29 - INFO - TRAINING - Epoch: [19][0/196]	Time 1.617 (1.617)	Data 1.562 (1.562)	Loss 0.2274 (0.2274)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 17:46:30 - INFO - TRAINING - Epoch: [19][10/196]	Time 0.110 (0.250)	Data 0.052 (0.161)	Loss 0.1558 (0.1808)	Prec@1 95.312 (93.821)	Prec@5 100.000 (99.964)
2022-06-17 17:46:32 - INFO - TRAINING - Epoch: [19][20/196]	Time 0.112 (0.182)	Data 0.000 (0.084)	Loss 0.1153 (0.1799)	Prec@1 94.531 (93.824)	Prec@5 100.000 (99.926)
2022-06-17 17:46:33 - INFO - TRAINING - Epoch: [19][30/196]	Time 0.108 (0.159)	Data 0.000 (0.057)	Loss 0.0932 (0.1772)	Prec@1 97.266 (93.889)	Prec@5 100.000 (99.950)
2022-06-17 17:46:34 - INFO - TRAINING - Epoch: [19][40/196]	Time 0.107 (0.146)	Data 0.000 (0.043)	Loss 0.1288 (0.1746)	Prec@1 96.094 (93.969)	Prec@5 100.000 (99.952)
2022-06-17 17:46:35 - INFO - TRAINING - Epoch: [19][50/196]	Time 0.104 (0.139)	Data 0.000 (0.035)	Loss 0.1250 (0.1700)	Prec@1 95.703 (94.133)	Prec@5 100.000 (99.939)
2022-06-17 17:46:36 - INFO - TRAINING - Epoch: [19][60/196]	Time 0.106 (0.135)	Data 0.000 (0.029)	Loss 0.1752 (0.1690)	Prec@1 93.750 (94.121)	Prec@5 100.000 (99.942)
2022-06-17 17:46:37 - INFO - TRAINING - Epoch: [19][70/196]	Time 0.104 (0.132)	Data 0.000 (0.025)	Loss 0.1018 (0.1694)	Prec@1 97.266 (94.130)	Prec@5 100.000 (99.950)
2022-06-17 17:46:38 - INFO - TRAINING - Epoch: [19][80/196]	Time 0.105 (0.129)	Data 0.000 (0.022)	Loss 0.1564 (0.1671)	Prec@1 93.359 (94.203)	Prec@5 100.000 (99.952)
2022-06-17 17:46:39 - INFO - TRAINING - Epoch: [19][90/196]	Time 0.108 (0.127)	Data 0.000 (0.020)	Loss 0.1977 (0.1657)	Prec@1 94.531 (94.265)	Prec@5 99.219 (99.944)
2022-06-17 17:46:40 - INFO - TRAINING - Epoch: [19][100/196]	Time 0.109 (0.126)	Data 0.000 (0.018)	Loss 0.1592 (0.1651)	Prec@1 95.312 (94.307)	Prec@5 99.609 (99.946)
2022-06-17 17:46:42 - INFO - TRAINING - Epoch: [19][110/196]	Time 0.104 (0.124)	Data 0.000 (0.016)	Loss 0.1831 (0.1645)	Prec@1 94.531 (94.355)	Prec@5 100.000 (99.947)
2022-06-17 17:46:43 - INFO - TRAINING - Epoch: [19][120/196]	Time 0.106 (0.123)	Data 0.000 (0.015)	Loss 0.1650 (0.1643)	Prec@1 93.359 (94.370)	Prec@5 100.000 (99.952)
2022-06-17 17:46:44 - INFO - TRAINING - Epoch: [19][130/196]	Time 0.123 (0.122)	Data 0.000 (0.014)	Loss 0.1202 (0.1646)	Prec@1 96.094 (94.343)	Prec@5 100.000 (99.949)
2022-06-17 17:46:45 - INFO - TRAINING - Epoch: [19][140/196]	Time 0.102 (0.121)	Data 0.000 (0.013)	Loss 0.1947 (0.1662)	Prec@1 93.750 (94.293)	Prec@5 100.000 (99.950)
2022-06-17 17:46:46 - INFO - TRAINING - Epoch: [19][150/196]	Time 0.107 (0.120)	Data 0.000 (0.012)	Loss 0.2239 (0.1661)	Prec@1 92.578 (94.301)	Prec@5 100.000 (99.946)
2022-06-17 17:46:47 - INFO - TRAINING - Epoch: [19][160/196]	Time 0.115 (0.119)	Data 0.000 (0.011)	Loss 0.1660 (0.1667)	Prec@1 94.531 (94.279)	Prec@5 99.609 (99.942)
2022-06-17 17:46:48 - INFO - TRAINING - Epoch: [19][170/196]	Time 0.110 (0.119)	Data 0.000 (0.011)	Loss 0.1564 (0.1671)	Prec@1 94.922 (94.262)	Prec@5 100.000 (99.938)
2022-06-17 17:46:49 - INFO - TRAINING - Epoch: [19][180/196]	Time 0.109 (0.118)	Data 0.000 (0.010)	Loss 0.1572 (0.1665)	Prec@1 96.094 (94.287)	Prec@5 99.219 (99.931)
2022-06-17 17:46:50 - INFO - TRAINING - Epoch: [19][190/196]	Time 0.104 (0.118)	Data 0.000 (0.010)	Loss 0.1694 (0.1676)	Prec@1 93.359 (94.245)	Prec@5 100.000 (99.928)
2022-06-17 17:46:53 - INFO - EVALUATING - Epoch: [19][0/40]	Time 1.981 (1.981)	Data 1.936 (1.936)	Loss 0.2795 (0.2795)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
2022-06-17 17:46:54 - INFO - EVALUATING - Epoch: [19][10/40]	Time 0.044 (0.272)	Data 0.000 (0.225)	Loss 0.4299 (0.3849)	Prec@1 87.891 (88.246)	Prec@5 99.609 (99.396)
2022-06-17 17:46:55 - INFO - EVALUATING - Epoch: [19][20/40]	Time 0.153 (0.172)	Data 0.112 (0.123)	Loss 0.3149 (0.3920)	Prec@1 87.109 (87.705)	Prec@5 100.000 (99.312)
2022-06-17 17:46:56 - INFO - EVALUATING - Epoch: [19][30/40]	Time 0.049 (0.149)	Data 0.000 (0.101)	Loss 0.4900 (0.3871)	Prec@1 83.984 (87.727)	Prec@5 100.000 (99.395)
2022-06-17 17:46:57 - INFO - 
 Epoch: 20	Training Loss 0.1672 	Training Prec@1 94.246 	Training Prec@5 99.928 	Validation Loss 0.3827 	Validation Prec@1 87.740 	Validation Prec@5 99.490 

2022-06-17 17:46:57 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:46:57 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:46:57 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:46:57 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:46:57 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:46:57 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:46:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:46:57 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:46:59 - INFO - TRAINING - Epoch: [20][0/196]	Time 1.783 (1.783)	Data 1.727 (1.727)	Loss 0.1379 (0.1379)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2022-06-17 17:47:00 - INFO - TRAINING - Epoch: [20][10/196]	Time 0.106 (0.270)	Data 0.000 (0.170)	Loss 0.1206 (0.1560)	Prec@1 94.922 (94.531)	Prec@5 100.000 (99.964)
2022-06-17 17:47:02 - INFO - TRAINING - Epoch: [20][20/196]	Time 0.114 (0.197)	Data 0.000 (0.089)	Loss 0.1671 (0.1615)	Prec@1 96.484 (94.475)	Prec@5 100.000 (99.944)
2022-06-17 17:47:03 - INFO - TRAINING - Epoch: [20][30/196]	Time 0.110 (0.168)	Data 0.000 (0.060)	Loss 0.1183 (0.1554)	Prec@1 95.703 (94.695)	Prec@5 100.000 (99.962)
2022-06-17 17:47:04 - INFO - TRAINING - Epoch: [20][40/196]	Time 0.118 (0.154)	Data 0.000 (0.046)	Loss 0.1609 (0.1541)	Prec@1 95.312 (94.731)	Prec@5 100.000 (99.943)
2022-06-17 17:47:05 - INFO - TRAINING - Epoch: [20][50/196]	Time 0.117 (0.146)	Data 0.000 (0.037)	Loss 0.1546 (0.1536)	Prec@1 93.750 (94.715)	Prec@5 100.000 (99.954)
2022-06-17 17:47:06 - INFO - TRAINING - Epoch: [20][60/196]	Time 0.109 (0.141)	Data 0.000 (0.031)	Loss 0.1888 (0.1561)	Prec@1 94.531 (94.653)	Prec@5 100.000 (99.955)
2022-06-17 17:47:07 - INFO - TRAINING - Epoch: [20][70/196]	Time 0.111 (0.137)	Data 0.000 (0.027)	Loss 0.1772 (0.1550)	Prec@1 94.531 (94.713)	Prec@5 100.000 (99.956)
2022-06-17 17:47:08 - INFO - TRAINING - Epoch: [20][80/196]	Time 0.116 (0.134)	Data 0.000 (0.023)	Loss 0.1559 (0.1527)	Prec@1 94.531 (94.763)	Prec@5 100.000 (99.961)
2022-06-17 17:47:09 - INFO - TRAINING - Epoch: [20][90/196]	Time 0.102 (0.131)	Data 0.000 (0.021)	Loss 0.1678 (0.1545)	Prec@1 93.750 (94.660)	Prec@5 100.000 (99.957)
2022-06-17 17:47:11 - INFO - TRAINING - Epoch: [20][100/196]	Time 0.118 (0.130)	Data 0.000 (0.019)	Loss 0.1756 (0.1556)	Prec@1 93.359 (94.612)	Prec@5 100.000 (99.957)
2022-06-17 17:47:12 - INFO - TRAINING - Epoch: [20][110/196]	Time 0.104 (0.129)	Data 0.000 (0.017)	Loss 0.1896 (0.1560)	Prec@1 92.969 (94.595)	Prec@5 100.000 (99.958)
2022-06-17 17:47:13 - INFO - TRAINING - Epoch: [20][120/196]	Time 0.115 (0.127)	Data 0.000 (0.016)	Loss 0.1800 (0.1564)	Prec@1 94.141 (94.576)	Prec@5 100.000 (99.955)
2022-06-17 17:47:14 - INFO - TRAINING - Epoch: [20][130/196]	Time 0.102 (0.126)	Data 0.000 (0.015)	Loss 0.1801 (0.1567)	Prec@1 95.703 (94.570)	Prec@5 100.000 (99.949)
2022-06-17 17:47:15 - INFO - TRAINING - Epoch: [20][140/196]	Time 0.114 (0.125)	Data 0.000 (0.014)	Loss 0.1415 (0.1577)	Prec@1 95.312 (94.556)	Prec@5 99.609 (99.942)
2022-06-17 17:47:16 - INFO - TRAINING - Epoch: [20][150/196]	Time 0.106 (0.124)	Data 0.000 (0.013)	Loss 0.1207 (0.1580)	Prec@1 95.312 (94.555)	Prec@5 100.000 (99.946)
2022-06-17 17:47:17 - INFO - TRAINING - Epoch: [20][160/196]	Time 0.122 (0.124)	Data 0.000 (0.012)	Loss 0.2264 (0.1586)	Prec@1 92.969 (94.539)	Prec@5 99.609 (99.944)
2022-06-17 17:47:18 - INFO - TRAINING - Epoch: [20][170/196]	Time 0.102 (0.123)	Data 0.000 (0.011)	Loss 0.1116 (0.1587)	Prec@1 96.484 (94.536)	Prec@5 100.000 (99.941)
2022-06-17 17:47:20 - INFO - TRAINING - Epoch: [20][180/196]	Time 0.114 (0.123)	Data 0.000 (0.011)	Loss 0.2012 (0.1589)	Prec@1 93.750 (94.499)	Prec@5 100.000 (99.937)
2022-06-17 17:47:21 - INFO - TRAINING - Epoch: [20][190/196]	Time 0.104 (0.122)	Data 0.000 (0.010)	Loss 0.1853 (0.1592)	Prec@1 93.359 (94.492)	Prec@5 100.000 (99.937)
2022-06-17 17:47:23 - INFO - EVALUATING - Epoch: [20][0/40]	Time 1.946 (1.946)	Data 1.901 (1.901)	Loss 0.2910 (0.2910)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
2022-06-17 17:47:24 - INFO - EVALUATING - Epoch: [20][10/40]	Time 0.044 (0.262)	Data 0.001 (0.212)	Loss 0.4333 (0.3873)	Prec@1 87.500 (87.997)	Prec@5 99.219 (99.325)
2022-06-17 17:47:25 - INFO - EVALUATING - Epoch: [20][20/40]	Time 0.041 (0.163)	Data 0.000 (0.111)	Loss 0.3352 (0.3939)	Prec@1 86.719 (87.798)	Prec@5 100.000 (99.293)
2022-06-17 17:47:26 - INFO - EVALUATING - Epoch: [20][30/40]	Time 0.144 (0.149)	Data 0.103 (0.099)	Loss 0.4521 (0.3863)	Prec@1 85.938 (87.815)	Prec@5 100.000 (99.395)
2022-06-17 17:47:28 - INFO - 
 Epoch: 21	Training Loss 0.1589 	Training Prec@1 94.500 	Training Prec@5 99.936 	Validation Loss 0.3814 	Validation Prec@1 87.850 	Validation Prec@5 99.490 

2022-06-17 17:47:28 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:47:28 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:47:28 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:47:28 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:47:28 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:47:28 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:47:28 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:47:28 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:47:29 - INFO - TRAINING - Epoch: [21][0/196]	Time 1.535 (1.535)	Data 1.481 (1.481)	Loss 0.1132 (0.1132)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 17:47:31 - INFO - TRAINING - Epoch: [21][10/196]	Time 0.211 (0.259)	Data 0.158 (0.165)	Loss 0.1836 (0.1529)	Prec@1 95.312 (94.886)	Prec@5 100.000 (99.929)
2022-06-17 17:47:32 - INFO - TRAINING - Epoch: [21][20/196]	Time 0.118 (0.192)	Data 0.000 (0.087)	Loss 0.0927 (0.1441)	Prec@1 97.266 (95.275)	Prec@5 100.000 (99.944)
2022-06-17 17:47:33 - INFO - TRAINING - Epoch: [21][30/196]	Time 0.126 (0.170)	Data 0.000 (0.059)	Loss 0.1576 (0.1451)	Prec@1 94.531 (95.035)	Prec@5 100.000 (99.937)
2022-06-17 17:47:34 - INFO - TRAINING - Epoch: [21][40/196]	Time 0.116 (0.156)	Data 0.000 (0.045)	Loss 0.1683 (0.1508)	Prec@1 94.531 (94.693)	Prec@5 100.000 (99.952)
2022-06-17 17:47:35 - INFO - TRAINING - Epoch: [21][50/196]	Time 0.112 (0.147)	Data 0.000 (0.036)	Loss 0.1209 (0.1528)	Prec@1 96.875 (94.784)	Prec@5 100.000 (99.946)
2022-06-17 17:47:36 - INFO - TRAINING - Epoch: [21][60/196]	Time 0.117 (0.141)	Data 0.000 (0.030)	Loss 0.1179 (0.1519)	Prec@1 96.875 (94.832)	Prec@5 100.000 (99.949)
2022-06-17 17:47:38 - INFO - TRAINING - Epoch: [21][70/196]	Time 0.118 (0.138)	Data 0.000 (0.026)	Loss 0.1508 (0.1530)	Prec@1 96.094 (94.839)	Prec@5 100.000 (99.945)
2022-06-17 17:47:39 - INFO - TRAINING - Epoch: [21][80/196]	Time 0.107 (0.134)	Data 0.000 (0.023)	Loss 0.1096 (0.1540)	Prec@1 96.875 (94.792)	Prec@5 100.000 (99.932)
2022-06-17 17:47:40 - INFO - TRAINING - Epoch: [21][90/196]	Time 0.104 (0.132)	Data 0.000 (0.020)	Loss 0.1986 (0.1540)	Prec@1 94.141 (94.776)	Prec@5 100.000 (99.936)
2022-06-17 17:47:41 - INFO - TRAINING - Epoch: [21][100/196]	Time 0.113 (0.130)	Data 0.000 (0.018)	Loss 0.1706 (0.1518)	Prec@1 94.141 (94.872)	Prec@5 100.000 (99.942)
2022-06-17 17:47:42 - INFO - TRAINING - Epoch: [21][110/196]	Time 0.132 (0.128)	Data 0.000 (0.017)	Loss 0.1339 (0.1513)	Prec@1 94.922 (94.859)	Prec@5 100.000 (99.944)
2022-06-17 17:47:43 - INFO - TRAINING - Epoch: [21][120/196]	Time 0.110 (0.128)	Data 0.000 (0.015)	Loss 0.1621 (0.1527)	Prec@1 92.969 (94.783)	Prec@5 99.609 (99.935)
2022-06-17 17:47:44 - INFO - TRAINING - Epoch: [21][130/196]	Time 0.098 (0.126)	Data 0.000 (0.014)	Loss 0.1542 (0.1527)	Prec@1 94.531 (94.776)	Prec@5 100.000 (99.937)
2022-06-17 17:47:45 - INFO - TRAINING - Epoch: [21][140/196]	Time 0.120 (0.125)	Data 0.000 (0.013)	Loss 0.1137 (0.1527)	Prec@1 97.266 (94.786)	Prec@5 100.000 (99.939)
2022-06-17 17:47:47 - INFO - TRAINING - Epoch: [21][150/196]	Time 0.109 (0.124)	Data 0.000 (0.012)	Loss 0.1582 (0.1526)	Prec@1 95.312 (94.769)	Prec@5 100.000 (99.941)
2022-06-17 17:47:48 - INFO - TRAINING - Epoch: [21][160/196]	Time 0.109 (0.123)	Data 0.000 (0.012)	Loss 0.2094 (0.1521)	Prec@1 92.969 (94.769)	Prec@5 100.000 (99.942)
2022-06-17 17:47:49 - INFO - TRAINING - Epoch: [21][170/196]	Time 0.135 (0.123)	Data 0.000 (0.011)	Loss 0.1057 (0.1524)	Prec@1 96.094 (94.764)	Prec@5 100.000 (99.941)
2022-06-17 17:47:50 - INFO - TRAINING - Epoch: [21][180/196]	Time 0.114 (0.123)	Data 0.000 (0.010)	Loss 0.1818 (0.1524)	Prec@1 94.531 (94.758)	Prec@5 100.000 (99.940)
2022-06-17 17:47:51 - INFO - TRAINING - Epoch: [21][190/196]	Time 0.101 (0.122)	Data 0.000 (0.010)	Loss 0.1680 (0.1527)	Prec@1 92.578 (94.715)	Prec@5 100.000 (99.943)
2022-06-17 17:47:53 - INFO - EVALUATING - Epoch: [21][0/40]	Time 1.522 (1.522)	Data 1.476 (1.476)	Loss 0.2740 (0.2740)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 17:47:54 - INFO - EVALUATING - Epoch: [21][10/40]	Time 0.044 (0.241)	Data 0.000 (0.192)	Loss 0.4342 (0.3863)	Prec@1 87.109 (88.246)	Prec@5 99.219 (99.325)
2022-06-17 17:47:55 - INFO - EVALUATING - Epoch: [21][20/40]	Time 0.043 (0.156)	Data 0.000 (0.106)	Loss 0.3340 (0.3923)	Prec@1 86.719 (87.853)	Prec@5 100.000 (99.349)
2022-06-17 17:47:56 - INFO - EVALUATING - Epoch: [21][30/40]	Time 0.048 (0.142)	Data 0.000 (0.093)	Loss 0.4631 (0.3874)	Prec@1 84.766 (87.840)	Prec@5 100.000 (99.408)
2022-06-17 17:47:59 - INFO - 
 Epoch: 22	Training Loss 0.1529 	Training Prec@1 94.708 	Training Prec@5 99.942 	Validation Loss 0.3829 	Validation Prec@1 87.890 	Validation Prec@5 99.490 

2022-06-17 17:47:59 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:47:59 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:47:59 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:47:59 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:47:59 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:47:59 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:47:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:47:59 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:48:00 - INFO - TRAINING - Epoch: [22][0/196]	Time 1.439 (1.439)	Data 1.385 (1.385)	Loss 0.1702 (0.1702)	Prec@1 95.703 (95.703)	Prec@5 99.609 (99.609)
2022-06-17 17:48:02 - INFO - TRAINING - Epoch: [22][10/196]	Time 0.113 (0.268)	Data 0.000 (0.171)	Loss 0.1645 (0.1472)	Prec@1 93.359 (94.851)	Prec@5 100.000 (99.964)
2022-06-17 17:48:03 - INFO - TRAINING - Epoch: [22][20/196]	Time 0.107 (0.193)	Data 0.000 (0.090)	Loss 0.1662 (0.1453)	Prec@1 92.969 (94.922)	Prec@5 100.000 (99.981)
2022-06-17 17:48:04 - INFO - TRAINING - Epoch: [22][30/196]	Time 0.106 (0.166)	Data 0.000 (0.061)	Loss 0.1025 (0.1459)	Prec@1 95.703 (94.972)	Prec@5 100.000 (99.962)
2022-06-17 17:48:05 - INFO - TRAINING - Epoch: [22][40/196]	Time 0.117 (0.153)	Data 0.000 (0.046)	Loss 0.1791 (0.1446)	Prec@1 92.578 (94.931)	Prec@5 99.609 (99.943)
2022-06-17 17:48:06 - INFO - TRAINING - Epoch: [22][50/196]	Time 0.123 (0.146)	Data 0.000 (0.037)	Loss 0.1795 (0.1485)	Prec@1 92.969 (94.776)	Prec@5 100.000 (99.946)
2022-06-17 17:48:07 - INFO - TRAINING - Epoch: [22][60/196]	Time 0.115 (0.140)	Data 0.000 (0.031)	Loss 0.1108 (0.1472)	Prec@1 96.484 (94.896)	Prec@5 100.000 (99.942)
2022-06-17 17:48:08 - INFO - TRAINING - Epoch: [22][70/196]	Time 0.132 (0.138)	Data 0.000 (0.027)	Loss 0.1449 (0.1486)	Prec@1 95.312 (94.850)	Prec@5 100.000 (99.945)
2022-06-17 17:48:10 - INFO - TRAINING - Epoch: [22][80/196]	Time 0.131 (0.135)	Data 0.000 (0.024)	Loss 0.1461 (0.1464)	Prec@1 94.531 (94.975)	Prec@5 100.000 (99.952)
2022-06-17 17:48:11 - INFO - TRAINING - Epoch: [22][90/196]	Time 0.104 (0.132)	Data 0.000 (0.021)	Loss 0.1383 (0.1473)	Prec@1 95.312 (94.930)	Prec@5 100.000 (99.953)
2022-06-17 17:48:12 - INFO - TRAINING - Epoch: [22][100/196]	Time 0.108 (0.131)	Data 0.000 (0.019)	Loss 0.1415 (0.1478)	Prec@1 95.703 (94.903)	Prec@5 100.000 (99.942)
2022-06-17 17:48:13 - INFO - TRAINING - Epoch: [22][110/196]	Time 0.112 (0.129)	Data 0.000 (0.017)	Loss 0.1244 (0.1468)	Prec@1 96.094 (94.957)	Prec@5 100.000 (99.944)
2022-06-17 17:48:14 - INFO - TRAINING - Epoch: [22][120/196]	Time 0.118 (0.128)	Data 0.000 (0.016)	Loss 0.1469 (0.1472)	Prec@1 93.750 (94.938)	Prec@5 100.000 (99.939)
2022-06-17 17:48:15 - INFO - TRAINING - Epoch: [22][130/196]	Time 0.112 (0.127)	Data 0.000 (0.015)	Loss 0.1278 (0.1470)	Prec@1 94.922 (94.937)	Prec@5 100.000 (99.934)
2022-06-17 17:48:16 - INFO - TRAINING - Epoch: [22][140/196]	Time 0.108 (0.126)	Data 0.000 (0.014)	Loss 0.1312 (0.1468)	Prec@1 95.703 (94.936)	Prec@5 100.000 (99.939)
2022-06-17 17:48:18 - INFO - TRAINING - Epoch: [22][150/196]	Time 0.112 (0.126)	Data 0.000 (0.013)	Loss 0.1648 (0.1469)	Prec@1 92.969 (94.961)	Prec@5 99.609 (99.930)
2022-06-17 17:48:19 - INFO - TRAINING - Epoch: [22][160/196]	Time 0.141 (0.126)	Data 0.000 (0.012)	Loss 0.1132 (0.1477)	Prec@1 96.484 (94.944)	Prec@5 100.000 (99.925)
2022-06-17 17:48:20 - INFO - TRAINING - Epoch: [22][170/196]	Time 0.114 (0.125)	Data 0.000 (0.011)	Loss 0.2134 (0.1483)	Prec@1 91.797 (94.947)	Prec@5 100.000 (99.922)
2022-06-17 17:48:21 - INFO - TRAINING - Epoch: [22][180/196]	Time 0.110 (0.125)	Data 0.000 (0.011)	Loss 0.1799 (0.1483)	Prec@1 92.188 (94.941)	Prec@5 100.000 (99.920)
2022-06-17 17:48:22 - INFO - TRAINING - Epoch: [22][190/196]	Time 0.100 (0.124)	Data 0.000 (0.010)	Loss 0.1438 (0.1490)	Prec@1 94.141 (94.881)	Prec@5 100.000 (99.920)
2022-06-17 17:48:25 - INFO - EVALUATING - Epoch: [22][0/40]	Time 1.760 (1.760)	Data 1.714 (1.714)	Loss 0.2768 (0.2768)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.609)
2022-06-17 17:48:26 - INFO - EVALUATING - Epoch: [22][10/40]	Time 0.068 (0.273)	Data 0.000 (0.223)	Loss 0.4500 (0.3921)	Prec@1 87.109 (87.926)	Prec@5 99.609 (99.325)
2022-06-17 17:48:27 - INFO - EVALUATING - Epoch: [22][20/40]	Time 0.126 (0.175)	Data 0.082 (0.123)	Loss 0.3213 (0.3966)	Prec@1 87.891 (87.667)	Prec@5 100.000 (99.349)
2022-06-17 17:48:28 - INFO - EVALUATING - Epoch: [22][30/40]	Time 0.107 (0.153)	Data 0.063 (0.103)	Loss 0.4629 (0.3894)	Prec@1 85.156 (87.714)	Prec@5 100.000 (99.408)
2022-06-17 17:48:30 - INFO - 
 Epoch: 23	Training Loss 0.1487 	Training Prec@1 94.890 	Training Prec@5 99.920 	Validation Loss 0.3848 	Validation Prec@1 87.760 	Validation Prec@5 99.500 

2022-06-17 17:48:30 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:48:30 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:48:30 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:48:30 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:48:30 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:48:30 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:48:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:48:30 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:48:31 - INFO - TRAINING - Epoch: [23][0/196]	Time 1.360 (1.360)	Data 1.307 (1.307)	Loss 0.1776 (0.1776)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 17:48:33 - INFO - TRAINING - Epoch: [23][10/196]	Time 0.113 (0.270)	Data 0.000 (0.168)	Loss 0.1580 (0.1364)	Prec@1 95.312 (95.028)	Prec@5 100.000 (99.929)
2022-06-17 17:48:34 - INFO - TRAINING - Epoch: [23][20/196]	Time 0.128 (0.200)	Data 0.000 (0.088)	Loss 0.1202 (0.1377)	Prec@1 96.094 (95.108)	Prec@5 100.000 (99.926)
2022-06-17 17:48:35 - INFO - TRAINING - Epoch: [23][30/196]	Time 0.120 (0.173)	Data 0.000 (0.060)	Loss 0.1742 (0.1390)	Prec@1 94.141 (95.136)	Prec@5 99.609 (99.899)
2022-06-17 17:48:36 - INFO - TRAINING - Epoch: [23][40/196]	Time 0.111 (0.159)	Data 0.000 (0.045)	Loss 0.1388 (0.1441)	Prec@1 95.312 (94.950)	Prec@5 100.000 (99.886)
2022-06-17 17:48:37 - INFO - TRAINING - Epoch: [23][50/196]	Time 0.122 (0.151)	Data 0.000 (0.037)	Loss 0.1633 (0.1443)	Prec@1 94.531 (94.968)	Prec@5 99.609 (99.885)
2022-06-17 17:48:39 - INFO - TRAINING - Epoch: [23][60/196]	Time 0.127 (0.146)	Data 0.000 (0.031)	Loss 0.1817 (0.1460)	Prec@1 93.359 (94.960)	Prec@5 100.000 (99.904)
2022-06-17 17:48:40 - INFO - TRAINING - Epoch: [23][70/196]	Time 0.106 (0.141)	Data 0.000 (0.026)	Loss 0.1486 (0.1468)	Prec@1 94.922 (94.966)	Prec@5 100.000 (99.912)
2022-06-17 17:48:41 - INFO - TRAINING - Epoch: [23][80/196]	Time 0.103 (0.138)	Data 0.000 (0.023)	Loss 0.1071 (0.1469)	Prec@1 95.312 (94.845)	Prec@5 100.000 (99.923)
2022-06-17 17:48:42 - INFO - TRAINING - Epoch: [23][90/196]	Time 0.123 (0.136)	Data 0.000 (0.021)	Loss 0.1753 (0.1472)	Prec@1 92.969 (94.849)	Prec@5 100.000 (99.923)
2022-06-17 17:48:43 - INFO - TRAINING - Epoch: [23][100/196]	Time 0.101 (0.134)	Data 0.000 (0.019)	Loss 0.1383 (0.1464)	Prec@1 95.312 (94.864)	Prec@5 100.000 (99.930)
2022-06-17 17:48:44 - INFO - TRAINING - Epoch: [23][110/196]	Time 0.117 (0.132)	Data 0.000 (0.017)	Loss 0.1114 (0.1463)	Prec@1 96.875 (94.890)	Prec@5 100.000 (99.933)
2022-06-17 17:48:45 - INFO - TRAINING - Epoch: [23][120/196]	Time 0.125 (0.131)	Data 0.000 (0.016)	Loss 0.1234 (0.1461)	Prec@1 97.266 (94.896)	Prec@5 100.000 (99.932)
2022-06-17 17:48:47 - INFO - TRAINING - Epoch: [23][130/196]	Time 0.102 (0.130)	Data 0.000 (0.014)	Loss 0.1037 (0.1457)	Prec@1 97.266 (94.892)	Prec@5 100.000 (99.937)
2022-06-17 17:48:48 - INFO - TRAINING - Epoch: [23][140/196]	Time 0.103 (0.129)	Data 0.000 (0.013)	Loss 0.1007 (0.1459)	Prec@1 97.656 (94.922)	Prec@5 100.000 (99.939)
2022-06-17 17:48:49 - INFO - TRAINING - Epoch: [23][150/196]	Time 0.133 (0.128)	Data 0.000 (0.013)	Loss 0.1537 (0.1463)	Prec@1 93.750 (94.893)	Prec@5 100.000 (99.941)
2022-06-17 17:48:50 - INFO - TRAINING - Epoch: [23][160/196]	Time 0.119 (0.128)	Data 0.000 (0.012)	Loss 0.1519 (0.1459)	Prec@1 94.531 (94.905)	Prec@5 100.000 (99.944)
2022-06-17 17:48:51 - INFO - TRAINING - Epoch: [23][170/196]	Time 0.101 (0.127)	Data 0.000 (0.011)	Loss 0.0938 (0.1466)	Prec@1 96.875 (94.874)	Prec@5 99.609 (99.938)
2022-06-17 17:48:53 - INFO - TRAINING - Epoch: [23][180/196]	Time 0.124 (0.127)	Data 0.000 (0.011)	Loss 0.1248 (0.1472)	Prec@1 95.312 (94.836)	Prec@5 100.000 (99.940)
2022-06-17 17:48:54 - INFO - TRAINING - Epoch: [23][190/196]	Time 0.108 (0.126)	Data 0.000 (0.010)	Loss 0.1313 (0.1474)	Prec@1 95.312 (94.828)	Prec@5 100.000 (99.939)
2022-06-17 17:48:56 - INFO - EVALUATING - Epoch: [23][0/40]	Time 1.966 (1.966)	Data 1.920 (1.920)	Loss 0.2738 (0.2738)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.609)
2022-06-17 17:48:57 - INFO - EVALUATING - Epoch: [23][10/40]	Time 0.045 (0.258)	Data 0.000 (0.208)	Loss 0.4262 (0.3889)	Prec@1 87.891 (87.855)	Prec@5 99.609 (99.432)
2022-06-17 17:48:58 - INFO - EVALUATING - Epoch: [23][20/40]	Time 0.043 (0.176)	Data 0.000 (0.128)	Loss 0.3254 (0.3927)	Prec@1 87.109 (87.798)	Prec@5 100.000 (99.442)
2022-06-17 17:48:59 - INFO - EVALUATING - Epoch: [23][30/40]	Time 0.144 (0.161)	Data 0.100 (0.114)	Loss 0.4791 (0.3879)	Prec@1 85.938 (87.765)	Prec@5 100.000 (99.521)
2022-06-17 17:49:01 - INFO - 
 Epoch: 24	Training Loss 0.1474 	Training Prec@1 94.822 	Training Prec@5 99.938 	Validation Loss 0.3840 	Validation Prec@1 87.830 	Validation Prec@5 99.580 

2022-06-17 17:49:01 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:49:01 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:49:01 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:49:01 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:49:01 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:49:01 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:49:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:49:01 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:49:03 - INFO - TRAINING - Epoch: [24][0/196]	Time 1.597 (1.597)	Data 1.545 (1.545)	Loss 0.0989 (0.0989)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 17:49:04 - INFO - TRAINING - Epoch: [24][10/196]	Time 0.103 (0.272)	Data 0.000 (0.178)	Loss 0.1458 (0.1445)	Prec@1 94.922 (95.455)	Prec@5 100.000 (99.858)
2022-06-17 17:49:05 - INFO - TRAINING - Epoch: [24][20/196]	Time 0.103 (0.192)	Data 0.000 (0.093)	Loss 0.1055 (0.1420)	Prec@1 96.875 (95.145)	Prec@5 100.000 (99.907)
2022-06-17 17:49:06 - INFO - TRAINING - Epoch: [24][30/196]	Time 0.132 (0.167)	Data 0.000 (0.063)	Loss 0.1330 (0.1394)	Prec@1 94.922 (95.186)	Prec@5 100.000 (99.924)
2022-06-17 17:49:07 - INFO - TRAINING - Epoch: [24][40/196]	Time 0.111 (0.153)	Data 0.000 (0.048)	Loss 0.1723 (0.1364)	Prec@1 94.141 (95.303)	Prec@5 99.609 (99.905)
2022-06-17 17:49:08 - INFO - TRAINING - Epoch: [24][50/196]	Time 0.102 (0.143)	Data 0.000 (0.039)	Loss 0.1459 (0.1362)	Prec@1 94.922 (95.312)	Prec@5 100.000 (99.908)
2022-06-17 17:49:09 - INFO - TRAINING - Epoch: [24][60/196]	Time 0.120 (0.138)	Data 0.000 (0.032)	Loss 0.1425 (0.1364)	Prec@1 96.484 (95.325)	Prec@5 99.609 (99.910)
2022-06-17 17:49:11 - INFO - TRAINING - Epoch: [24][70/196]	Time 0.104 (0.135)	Data 0.000 (0.028)	Loss 0.1566 (0.1368)	Prec@1 94.141 (95.285)	Prec@5 100.000 (99.917)
2022-06-17 17:49:12 - INFO - TRAINING - Epoch: [24][80/196]	Time 0.128 (0.132)	Data 0.000 (0.024)	Loss 0.2165 (0.1381)	Prec@1 92.578 (95.255)	Prec@5 99.609 (99.913)
2022-06-17 17:49:13 - INFO - TRAINING - Epoch: [24][90/196]	Time 0.116 (0.129)	Data 0.000 (0.022)	Loss 0.1471 (0.1399)	Prec@1 94.141 (95.154)	Prec@5 99.609 (99.914)
2022-06-17 17:49:14 - INFO - TRAINING - Epoch: [24][100/196]	Time 0.129 (0.128)	Data 0.000 (0.020)	Loss 0.1662 (0.1406)	Prec@1 94.141 (95.142)	Prec@5 100.000 (99.911)
2022-06-17 17:49:15 - INFO - TRAINING - Epoch: [24][110/196]	Time 0.111 (0.126)	Data 0.000 (0.018)	Loss 0.1381 (0.1410)	Prec@1 95.703 (95.126)	Prec@5 99.609 (99.916)
2022-06-17 17:49:16 - INFO - TRAINING - Epoch: [24][120/196]	Time 0.115 (0.124)	Data 0.000 (0.016)	Loss 0.1205 (0.1406)	Prec@1 97.656 (95.148)	Prec@5 100.000 (99.916)
2022-06-17 17:49:17 - INFO - TRAINING - Epoch: [24][130/196]	Time 0.103 (0.123)	Data 0.000 (0.015)	Loss 0.1541 (0.1418)	Prec@1 94.922 (95.119)	Prec@5 100.000 (99.917)
2022-06-17 17:49:18 - INFO - TRAINING - Epoch: [24][140/196]	Time 0.105 (0.122)	Data 0.000 (0.014)	Loss 0.2006 (0.1425)	Prec@1 92.578 (95.077)	Prec@5 99.609 (99.920)
2022-06-17 17:49:19 - INFO - TRAINING - Epoch: [24][150/196]	Time 0.114 (0.121)	Data 0.000 (0.013)	Loss 0.1185 (0.1423)	Prec@1 94.531 (95.087)	Prec@5 99.609 (99.917)
2022-06-17 17:49:20 - INFO - TRAINING - Epoch: [24][160/196]	Time 0.106 (0.120)	Data 0.000 (0.012)	Loss 0.2402 (0.1430)	Prec@1 92.969 (95.050)	Prec@5 100.000 (99.922)
2022-06-17 17:49:21 - INFO - TRAINING - Epoch: [24][170/196]	Time 0.103 (0.120)	Data 0.000 (0.012)	Loss 0.1148 (0.1421)	Prec@1 96.875 (95.079)	Prec@5 100.000 (99.925)
2022-06-17 17:49:23 - INFO - TRAINING - Epoch: [24][180/196]	Time 0.108 (0.120)	Data 0.000 (0.011)	Loss 0.1779 (0.1431)	Prec@1 94.141 (95.054)	Prec@5 100.000 (99.927)
2022-06-17 17:49:24 - INFO - TRAINING - Epoch: [24][190/196]	Time 0.102 (0.119)	Data 0.000 (0.011)	Loss 0.1760 (0.1437)	Prec@1 94.531 (95.038)	Prec@5 100.000 (99.920)
2022-06-17 17:49:26 - INFO - EVALUATING - Epoch: [24][0/40]	Time 1.916 (1.916)	Data 1.871 (1.871)	Loss 0.2728 (0.2728)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 17:49:27 - INFO - EVALUATING - Epoch: [24][10/40]	Time 0.045 (0.274)	Data 0.000 (0.225)	Loss 0.4396 (0.3945)	Prec@1 89.062 (88.281)	Prec@5 99.609 (99.432)
2022-06-17 17:49:28 - INFO - EVALUATING - Epoch: [24][20/40]	Time 0.125 (0.178)	Data 0.083 (0.128)	Loss 0.3127 (0.3972)	Prec@1 87.500 (88.021)	Prec@5 100.000 (99.442)
2022-06-17 17:49:29 - INFO - EVALUATING - Epoch: [24][30/40]	Time 0.089 (0.149)	Data 0.045 (0.101)	Loss 0.4647 (0.3915)	Prec@1 85.547 (87.991)	Prec@5 100.000 (99.496)
2022-06-17 17:49:31 - INFO - 
 Epoch: 25	Training Loss 0.1440 	Training Prec@1 95.028 	Training Prec@5 99.920 	Validation Loss 0.3879 	Validation Prec@1 87.990 	Validation Prec@5 99.560 

2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:49:31 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:49:33 - INFO - TRAINING - Epoch: [25][0/196]	Time 1.524 (1.524)	Data 1.471 (1.471)	Loss 0.1386 (0.1386)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 17:49:34 - INFO - TRAINING - Epoch: [25][10/196]	Time 0.347 (0.259)	Data 0.298 (0.179)	Loss 0.1317 (0.1382)	Prec@1 95.703 (94.993)	Prec@5 100.000 (99.964)
2022-06-17 17:49:35 - INFO - TRAINING - Epoch: [25][20/196]	Time 0.115 (0.187)	Data 0.000 (0.094)	Loss 0.1406 (0.1367)	Prec@1 96.094 (95.517)	Prec@5 100.000 (99.926)
2022-06-17 17:49:36 - INFO - TRAINING - Epoch: [25][30/196]	Time 0.109 (0.163)	Data 0.000 (0.064)	Loss 0.0948 (0.1309)	Prec@1 97.266 (95.754)	Prec@5 100.000 (99.912)
2022-06-17 17:49:38 - INFO - TRAINING - Epoch: [25][40/196]	Time 0.113 (0.150)	Data 0.000 (0.048)	Loss 0.0963 (0.1304)	Prec@1 96.484 (95.694)	Prec@5 100.000 (99.914)
2022-06-17 17:49:39 - INFO - TRAINING - Epoch: [25][50/196]	Time 0.105 (0.144)	Data 0.000 (0.039)	Loss 0.2019 (0.1350)	Prec@1 93.750 (95.596)	Prec@5 100.000 (99.908)
2022-06-17 17:49:40 - INFO - TRAINING - Epoch: [25][60/196]	Time 0.144 (0.140)	Data 0.000 (0.032)	Loss 0.1733 (0.1376)	Prec@1 91.016 (95.421)	Prec@5 100.000 (99.904)
2022-06-17 17:49:41 - INFO - TRAINING - Epoch: [25][70/196]	Time 0.130 (0.137)	Data 0.000 (0.028)	Loss 0.2299 (0.1381)	Prec@1 92.188 (95.395)	Prec@5 100.000 (99.912)
2022-06-17 17:49:42 - INFO - TRAINING - Epoch: [25][80/196]	Time 0.140 (0.134)	Data 0.001 (0.025)	Loss 0.0915 (0.1380)	Prec@1 96.875 (95.356)	Prec@5 100.000 (99.923)
2022-06-17 17:49:43 - INFO - TRAINING - Epoch: [25][90/196]	Time 0.112 (0.132)	Data 0.000 (0.022)	Loss 0.0871 (0.1382)	Prec@1 96.094 (95.330)	Prec@5 100.000 (99.927)
2022-06-17 17:49:44 - INFO - TRAINING - Epoch: [25][100/196]	Time 0.114 (0.129)	Data 0.000 (0.020)	Loss 0.0999 (0.1377)	Prec@1 96.484 (95.301)	Prec@5 100.000 (99.934)
2022-06-17 17:49:46 - INFO - TRAINING - Epoch: [25][110/196]	Time 0.104 (0.128)	Data 0.000 (0.018)	Loss 0.1475 (0.1375)	Prec@1 95.312 (95.288)	Prec@5 100.000 (99.930)
2022-06-17 17:49:47 - INFO - TRAINING - Epoch: [25][120/196]	Time 0.108 (0.127)	Data 0.000 (0.017)	Loss 0.1858 (0.1371)	Prec@1 94.141 (95.309)	Prec@5 100.000 (99.935)
2022-06-17 17:49:48 - INFO - TRAINING - Epoch: [25][130/196]	Time 0.141 (0.127)	Data 0.000 (0.015)	Loss 0.1562 (0.1379)	Prec@1 94.531 (95.268)	Prec@5 99.609 (99.931)
2022-06-17 17:49:49 - INFO - TRAINING - Epoch: [25][140/196]	Time 0.110 (0.126)	Data 0.000 (0.014)	Loss 0.1400 (0.1370)	Prec@1 95.312 (95.318)	Prec@5 100.000 (99.936)
2022-06-17 17:49:50 - INFO - TRAINING - Epoch: [25][150/196]	Time 0.117 (0.125)	Data 0.000 (0.013)	Loss 0.1678 (0.1371)	Prec@1 95.312 (95.312)	Prec@5 100.000 (99.935)
2022-06-17 17:49:51 - INFO - TRAINING - Epoch: [25][160/196]	Time 0.101 (0.124)	Data 0.000 (0.013)	Loss 0.1119 (0.1366)	Prec@1 95.312 (95.317)	Prec@5 100.000 (99.934)
2022-06-17 17:49:53 - INFO - TRAINING - Epoch: [25][170/196]	Time 0.110 (0.124)	Data 0.000 (0.012)	Loss 0.1156 (0.1372)	Prec@1 96.484 (95.292)	Prec@5 100.000 (99.936)
2022-06-17 17:49:54 - INFO - TRAINING - Epoch: [25][180/196]	Time 0.111 (0.123)	Data 0.000 (0.011)	Loss 0.1265 (0.1370)	Prec@1 96.484 (95.297)	Prec@5 100.000 (99.940)
2022-06-17 17:49:55 - INFO - TRAINING - Epoch: [25][190/196]	Time 0.101 (0.123)	Data 0.000 (0.011)	Loss 0.1449 (0.1368)	Prec@1 94.922 (95.317)	Prec@5 100.000 (99.939)
2022-06-17 17:49:57 - INFO - EVALUATING - Epoch: [25][0/40]	Time 1.536 (1.536)	Data 1.491 (1.491)	Loss 0.2645 (0.2645)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 17:49:58 - INFO - EVALUATING - Epoch: [25][10/40]	Time 0.288 (0.248)	Data 0.246 (0.199)	Loss 0.4327 (0.3910)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.361)
2022-06-17 17:49:59 - INFO - EVALUATING - Epoch: [25][20/40]	Time 0.445 (0.185)	Data 0.401 (0.137)	Loss 0.3072 (0.3943)	Prec@1 87.891 (87.946)	Prec@5 100.000 (99.386)
2022-06-17 17:50:00 - INFO - EVALUATING - Epoch: [25][30/40]	Time 0.044 (0.155)	Data 0.000 (0.106)	Loss 0.4675 (0.3888)	Prec@1 85.156 (87.815)	Prec@5 100.000 (99.458)
2022-06-17 17:50:02 - INFO - 
 Epoch: 26	Training Loss 0.1362 	Training Prec@1 95.336 	Training Prec@5 99.940 	Validation Loss 0.3849 	Validation Prec@1 87.830 	Validation Prec@5 99.530 

2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:50:02 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:50:04 - INFO - TRAINING - Epoch: [26][0/196]	Time 1.875 (1.875)	Data 1.821 (1.821)	Loss 0.1362 (0.1362)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 17:50:05 - INFO - TRAINING - Epoch: [26][10/196]	Time 0.103 (0.269)	Data 0.000 (0.166)	Loss 0.1395 (0.1328)	Prec@1 96.484 (95.455)	Prec@5 100.000 (99.964)
2022-06-17 17:50:06 - INFO - TRAINING - Epoch: [26][20/196]	Time 0.104 (0.192)	Data 0.000 (0.087)	Loss 0.1491 (0.1376)	Prec@1 94.531 (95.275)	Prec@5 100.000 (99.963)
2022-06-17 17:50:07 - INFO - TRAINING - Epoch: [26][30/196]	Time 0.104 (0.165)	Data 0.000 (0.059)	Loss 0.1550 (0.1360)	Prec@1 93.750 (95.186)	Prec@5 99.609 (99.962)
2022-06-17 17:50:08 - INFO - TRAINING - Epoch: [26][40/196]	Time 0.111 (0.151)	Data 0.000 (0.045)	Loss 0.1400 (0.1355)	Prec@1 94.141 (95.093)	Prec@5 100.000 (99.971)
2022-06-17 17:50:09 - INFO - TRAINING - Epoch: [26][50/196]	Time 0.099 (0.143)	Data 0.000 (0.036)	Loss 0.1186 (0.1340)	Prec@1 96.094 (95.228)	Prec@5 100.000 (99.969)
2022-06-17 17:50:10 - INFO - TRAINING - Epoch: [26][60/196]	Time 0.106 (0.138)	Data 0.000 (0.030)	Loss 0.0951 (0.1358)	Prec@1 97.266 (95.229)	Prec@5 99.609 (99.955)
2022-06-17 17:50:12 - INFO - TRAINING - Epoch: [26][70/196]	Time 0.117 (0.134)	Data 0.000 (0.026)	Loss 0.1155 (0.1360)	Prec@1 95.703 (95.230)	Prec@5 100.000 (99.961)
2022-06-17 17:50:13 - INFO - TRAINING - Epoch: [26][80/196]	Time 0.117 (0.132)	Data 0.000 (0.023)	Loss 0.0875 (0.1369)	Prec@1 96.875 (95.153)	Prec@5 100.000 (99.957)
2022-06-17 17:50:14 - INFO - TRAINING - Epoch: [26][90/196]	Time 0.111 (0.129)	Data 0.000 (0.020)	Loss 0.1349 (0.1355)	Prec@1 95.703 (95.209)	Prec@5 100.000 (99.957)
2022-06-17 17:50:15 - INFO - TRAINING - Epoch: [26][100/196]	Time 0.106 (0.127)	Data 0.000 (0.018)	Loss 0.1947 (0.1354)	Prec@1 93.750 (95.212)	Prec@5 99.609 (99.954)
2022-06-17 17:50:16 - INFO - TRAINING - Epoch: [26][110/196]	Time 0.116 (0.126)	Data 0.000 (0.017)	Loss 0.1891 (0.1379)	Prec@1 92.578 (95.101)	Prec@5 99.609 (99.954)
2022-06-17 17:50:17 - INFO - TRAINING - Epoch: [26][120/196]	Time 0.123 (0.125)	Data 0.000 (0.015)	Loss 0.1442 (0.1375)	Prec@1 96.875 (95.148)	Prec@5 100.000 (99.958)
2022-06-17 17:50:18 - INFO - TRAINING - Epoch: [26][130/196]	Time 0.131 (0.124)	Data 0.000 (0.014)	Loss 0.0830 (0.1367)	Prec@1 97.656 (95.220)	Prec@5 100.000 (99.958)
2022-06-17 17:50:19 - INFO - TRAINING - Epoch: [26][140/196]	Time 0.113 (0.124)	Data 0.000 (0.013)	Loss 0.1273 (0.1354)	Prec@1 96.484 (95.235)	Prec@5 100.000 (99.961)
2022-06-17 17:50:21 - INFO - TRAINING - Epoch: [26][150/196]	Time 0.116 (0.123)	Data 0.000 (0.012)	Loss 0.1086 (0.1352)	Prec@1 97.266 (95.253)	Prec@5 100.000 (99.956)
2022-06-17 17:50:22 - INFO - TRAINING - Epoch: [26][160/196]	Time 0.125 (0.123)	Data 0.000 (0.012)	Loss 0.1050 (0.1346)	Prec@1 98.438 (95.293)	Prec@5 100.000 (99.956)
2022-06-17 17:50:23 - INFO - TRAINING - Epoch: [26][170/196]	Time 0.116 (0.122)	Data 0.000 (0.011)	Loss 0.1482 (0.1351)	Prec@1 93.750 (95.265)	Prec@5 100.000 (99.954)
2022-06-17 17:50:24 - INFO - TRAINING - Epoch: [26][180/196]	Time 0.137 (0.122)	Data 0.000 (0.010)	Loss 0.1232 (0.1347)	Prec@1 95.312 (95.276)	Prec@5 100.000 (99.955)
2022-06-17 17:50:25 - INFO - TRAINING - Epoch: [26][190/196]	Time 0.101 (0.121)	Data 0.000 (0.010)	Loss 0.1616 (0.1362)	Prec@1 94.141 (95.259)	Prec@5 100.000 (99.955)
2022-06-17 17:50:27 - INFO - EVALUATING - Epoch: [26][0/40]	Time 1.473 (1.473)	Data 1.426 (1.426)	Loss 0.2627 (0.2627)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 17:50:29 - INFO - EVALUATING - Epoch: [26][10/40]	Time 0.043 (0.273)	Data 0.000 (0.222)	Loss 0.4315 (0.3929)	Prec@1 89.062 (88.388)	Prec@5 99.609 (99.396)
2022-06-17 17:50:30 - INFO - EVALUATING - Epoch: [26][20/40]	Time 0.328 (0.185)	Data 0.286 (0.135)	Loss 0.3121 (0.3958)	Prec@1 87.891 (88.058)	Prec@5 100.000 (99.405)
2022-06-17 17:50:30 - INFO - EVALUATING - Epoch: [26][30/40]	Time 0.042 (0.153)	Data 0.000 (0.101)	Loss 0.4587 (0.3902)	Prec@1 85.547 (88.054)	Prec@5 100.000 (99.433)
2022-06-17 17:50:33 - INFO - 
 Epoch: 27	Training Loss 0.1357 	Training Prec@1 95.278 	Training Prec@5 99.954 	Validation Loss 0.3861 	Validation Prec@1 88.060 	Validation Prec@5 99.510 

2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:50:33 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:50:35 - INFO - TRAINING - Epoch: [27][0/196]	Time 2.074 (2.074)	Data 2.020 (2.020)	Loss 0.1243 (0.1243)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 17:50:36 - INFO - TRAINING - Epoch: [27][10/196]	Time 0.101 (0.291)	Data 0.000 (0.184)	Loss 0.2265 (0.1500)	Prec@1 91.406 (94.638)	Prec@5 100.000 (99.964)
2022-06-17 17:50:37 - INFO - TRAINING - Epoch: [27][20/196]	Time 0.118 (0.207)	Data 0.000 (0.096)	Loss 0.1308 (0.1408)	Prec@1 96.094 (95.331)	Prec@5 100.000 (99.944)
2022-06-17 17:50:38 - INFO - TRAINING - Epoch: [27][30/196]	Time 0.100 (0.178)	Data 0.000 (0.065)	Loss 0.1216 (0.1456)	Prec@1 94.922 (95.149)	Prec@5 100.000 (99.912)
2022-06-17 17:50:39 - INFO - TRAINING - Epoch: [27][40/196]	Time 0.120 (0.164)	Data 0.000 (0.050)	Loss 0.1368 (0.1427)	Prec@1 95.312 (95.160)	Prec@5 100.000 (99.933)
2022-06-17 17:50:41 - INFO - TRAINING - Epoch: [27][50/196]	Time 0.106 (0.155)	Data 0.000 (0.040)	Loss 0.0975 (0.1386)	Prec@1 96.094 (95.205)	Prec@5 100.000 (99.939)
2022-06-17 17:50:42 - INFO - TRAINING - Epoch: [27][60/196]	Time 0.132 (0.149)	Data 0.000 (0.033)	Loss 0.1332 (0.1371)	Prec@1 96.094 (95.268)	Prec@5 100.000 (99.942)
2022-06-17 17:50:43 - INFO - TRAINING - Epoch: [27][70/196]	Time 0.105 (0.146)	Data 0.000 (0.029)	Loss 0.1066 (0.1339)	Prec@1 96.875 (95.434)	Prec@5 100.000 (99.945)
2022-06-17 17:50:44 - INFO - TRAINING - Epoch: [27][80/196]	Time 0.129 (0.143)	Data 0.000 (0.025)	Loss 0.1263 (0.1349)	Prec@1 95.703 (95.419)	Prec@5 100.000 (99.937)
2022-06-17 17:50:46 - INFO - TRAINING - Epoch: [27][90/196]	Time 0.112 (0.140)	Data 0.000 (0.022)	Loss 0.1492 (0.1339)	Prec@1 94.531 (95.467)	Prec@5 100.000 (99.940)
2022-06-17 17:50:47 - INFO - TRAINING - Epoch: [27][100/196]	Time 0.129 (0.138)	Data 0.000 (0.020)	Loss 0.1354 (0.1336)	Prec@1 95.312 (95.471)	Prec@5 99.609 (99.942)
2022-06-17 17:50:48 - INFO - TRAINING - Epoch: [27][110/196]	Time 0.105 (0.136)	Data 0.000 (0.018)	Loss 0.1357 (0.1339)	Prec@1 95.703 (95.457)	Prec@5 99.609 (99.940)
2022-06-17 17:50:49 - INFO - TRAINING - Epoch: [27][120/196]	Time 0.125 (0.135)	Data 0.001 (0.017)	Loss 0.1749 (0.1354)	Prec@1 92.969 (95.413)	Prec@5 100.000 (99.939)
2022-06-17 17:50:50 - INFO - TRAINING - Epoch: [27][130/196]	Time 0.101 (0.134)	Data 0.000 (0.016)	Loss 0.1349 (0.1352)	Prec@1 95.312 (95.390)	Prec@5 100.000 (99.943)
2022-06-17 17:50:51 - INFO - TRAINING - Epoch: [27][140/196]	Time 0.129 (0.133)	Data 0.000 (0.015)	Loss 0.1393 (0.1356)	Prec@1 96.484 (95.368)	Prec@5 100.000 (99.945)
2022-06-17 17:50:53 - INFO - TRAINING - Epoch: [27][150/196]	Time 0.129 (0.132)	Data 0.000 (0.014)	Loss 0.1190 (0.1355)	Prec@1 96.484 (95.380)	Prec@5 100.000 (99.946)
2022-06-17 17:50:54 - INFO - TRAINING - Epoch: [27][160/196]	Time 0.139 (0.131)	Data 0.000 (0.013)	Loss 0.1815 (0.1356)	Prec@1 93.750 (95.385)	Prec@5 99.609 (99.942)
2022-06-17 17:50:55 - INFO - TRAINING - Epoch: [27][170/196]	Time 0.106 (0.131)	Data 0.000 (0.012)	Loss 0.1008 (0.1349)	Prec@1 96.875 (95.390)	Prec@5 100.000 (99.943)
2022-06-17 17:50:56 - INFO - TRAINING - Epoch: [27][180/196]	Time 0.109 (0.130)	Data 0.000 (0.011)	Loss 0.1239 (0.1350)	Prec@1 96.094 (95.371)	Prec@5 100.000 (99.944)
2022-06-17 17:50:57 - INFO - TRAINING - Epoch: [27][190/196]	Time 0.102 (0.129)	Data 0.000 (0.011)	Loss 0.1000 (0.1347)	Prec@1 97.266 (95.384)	Prec@5 100.000 (99.943)
2022-06-17 17:51:00 - INFO - EVALUATING - Epoch: [27][0/40]	Time 1.832 (1.832)	Data 1.786 (1.786)	Loss 0.2641 (0.2641)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 17:51:01 - INFO - EVALUATING - Epoch: [27][10/40]	Time 0.063 (0.276)	Data 0.000 (0.225)	Loss 0.4343 (0.3913)	Prec@1 88.281 (88.423)	Prec@5 99.609 (99.432)
2022-06-17 17:51:02 - INFO - EVALUATING - Epoch: [27][20/40]	Time 0.228 (0.178)	Data 0.186 (0.127)	Loss 0.3122 (0.3944)	Prec@1 87.500 (88.058)	Prec@5 100.000 (99.405)
2022-06-17 17:51:03 - INFO - EVALUATING - Epoch: [27][30/40]	Time 0.042 (0.151)	Data 0.000 (0.101)	Loss 0.4624 (0.3880)	Prec@1 85.156 (87.991)	Prec@5 100.000 (99.471)
2022-06-17 17:51:04 - INFO - 
 Epoch: 28	Training Loss 0.1339 	Training Prec@1 95.420 	Training Prec@5 99.944 	Validation Loss 0.3839 	Validation Prec@1 87.960 	Validation Prec@5 99.540 

2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:51:04 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:51:06 - INFO - TRAINING - Epoch: [28][0/196]	Time 1.783 (1.783)	Data 1.732 (1.732)	Loss 0.1417 (0.1417)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
2022-06-17 17:51:07 - INFO - TRAINING - Epoch: [28][10/196]	Time 0.106 (0.260)	Data 0.000 (0.158)	Loss 0.1117 (0.1240)	Prec@1 95.703 (95.455)	Prec@5 100.000 (100.000)
2022-06-17 17:51:08 - INFO - TRAINING - Epoch: [28][20/196]	Time 0.110 (0.189)	Data 0.000 (0.083)	Loss 0.1689 (0.1269)	Prec@1 93.750 (95.517)	Prec@5 100.000 (99.981)
2022-06-17 17:51:10 - INFO - TRAINING - Epoch: [28][30/196]	Time 0.109 (0.164)	Data 0.000 (0.056)	Loss 0.1108 (0.1324)	Prec@1 97.656 (95.426)	Prec@5 100.000 (99.975)
2022-06-17 17:51:11 - INFO - TRAINING - Epoch: [28][40/196]	Time 0.114 (0.151)	Data 0.000 (0.043)	Loss 0.2051 (0.1342)	Prec@1 93.359 (95.398)	Prec@5 100.000 (99.962)
2022-06-17 17:51:12 - INFO - TRAINING - Epoch: [28][50/196]	Time 0.109 (0.144)	Data 0.000 (0.034)	Loss 0.1434 (0.1348)	Prec@1 96.094 (95.443)	Prec@5 99.219 (99.946)
2022-06-17 17:51:13 - INFO - TRAINING - Epoch: [28][60/196]	Time 0.118 (0.138)	Data 0.000 (0.029)	Loss 0.1155 (0.1330)	Prec@1 95.703 (95.517)	Prec@5 100.000 (99.949)
2022-06-17 17:51:14 - INFO - TRAINING - Epoch: [28][70/196]	Time 0.111 (0.135)	Data 0.000 (0.025)	Loss 0.1138 (0.1347)	Prec@1 96.094 (95.456)	Prec@5 100.000 (99.939)
2022-06-17 17:51:15 - INFO - TRAINING - Epoch: [28][80/196]	Time 0.105 (0.131)	Data 0.000 (0.022)	Loss 0.1358 (0.1338)	Prec@1 94.922 (95.486)	Prec@5 100.000 (99.937)
2022-06-17 17:51:16 - INFO - TRAINING - Epoch: [28][90/196]	Time 0.102 (0.129)	Data 0.000 (0.019)	Loss 0.1416 (0.1356)	Prec@1 94.922 (95.394)	Prec@5 100.000 (99.944)
2022-06-17 17:51:17 - INFO - TRAINING - Epoch: [28][100/196]	Time 0.105 (0.127)	Data 0.000 (0.017)	Loss 0.1216 (0.1351)	Prec@1 97.656 (95.413)	Prec@5 100.000 (99.946)
2022-06-17 17:51:18 - INFO - TRAINING - Epoch: [28][110/196]	Time 0.108 (0.126)	Data 0.000 (0.016)	Loss 0.2037 (0.1348)	Prec@1 92.969 (95.418)	Prec@5 100.000 (99.944)
2022-06-17 17:51:20 - INFO - TRAINING - Epoch: [28][120/196]	Time 0.101 (0.125)	Data 0.000 (0.015)	Loss 0.1610 (0.1333)	Prec@1 92.969 (95.467)	Prec@5 100.000 (99.948)
2022-06-17 17:51:21 - INFO - TRAINING - Epoch: [28][130/196]	Time 0.107 (0.124)	Data 0.000 (0.014)	Loss 0.1009 (0.1329)	Prec@1 96.094 (95.474)	Prec@5 100.000 (99.949)
2022-06-17 17:51:22 - INFO - TRAINING - Epoch: [28][140/196]	Time 0.116 (0.123)	Data 0.000 (0.013)	Loss 0.1136 (0.1330)	Prec@1 97.266 (95.465)	Prec@5 100.000 (99.947)
2022-06-17 17:51:23 - INFO - TRAINING - Epoch: [28][150/196]	Time 0.139 (0.123)	Data 0.001 (0.012)	Loss 0.1388 (0.1323)	Prec@1 94.531 (95.473)	Prec@5 100.000 (99.948)
2022-06-17 17:51:24 - INFO - TRAINING - Epoch: [28][160/196]	Time 0.106 (0.122)	Data 0.000 (0.011)	Loss 0.1242 (0.1320)	Prec@1 95.312 (95.470)	Prec@5 100.000 (99.949)
2022-06-17 17:51:25 - INFO - TRAINING - Epoch: [28][170/196]	Time 0.108 (0.122)	Data 0.000 (0.010)	Loss 0.1336 (0.1318)	Prec@1 94.531 (95.482)	Prec@5 100.000 (99.952)
2022-06-17 17:51:26 - INFO - TRAINING - Epoch: [28][180/196]	Time 0.101 (0.121)	Data 0.000 (0.010)	Loss 0.1405 (0.1321)	Prec@1 94.922 (95.477)	Prec@5 100.000 (99.953)
2022-06-17 17:51:27 - INFO - TRAINING - Epoch: [28][190/196]	Time 0.101 (0.120)	Data 0.000 (0.009)	Loss 0.0952 (0.1328)	Prec@1 96.875 (95.460)	Prec@5 100.000 (99.951)
2022-06-17 17:51:30 - INFO - EVALUATING - Epoch: [28][0/40]	Time 2.055 (2.055)	Data 2.009 (2.009)	Loss 0.2580 (0.2580)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 17:51:31 - INFO - EVALUATING - Epoch: [28][10/40]	Time 0.062 (0.276)	Data 0.000 (0.227)	Loss 0.4385 (0.3902)	Prec@1 88.281 (88.104)	Prec@5 99.609 (99.432)
2022-06-17 17:51:32 - INFO - EVALUATING - Epoch: [28][20/40]	Time 0.041 (0.168)	Data 0.000 (0.119)	Loss 0.3106 (0.3929)	Prec@1 87.891 (87.909)	Prec@5 100.000 (99.405)
2022-06-17 17:51:33 - INFO - EVALUATING - Epoch: [28][30/40]	Time 0.043 (0.147)	Data 0.000 (0.099)	Loss 0.4657 (0.3876)	Prec@1 84.766 (87.790)	Prec@5 100.000 (99.483)
2022-06-17 17:51:35 - INFO - 
 Epoch: 29	Training Loss 0.1325 	Training Prec@1 95.456 	Training Prec@5 99.952 	Validation Loss 0.3838 	Validation Prec@1 87.850 	Validation Prec@5 99.550 

2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:51:35 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:51:36 - INFO - TRAINING - Epoch: [29][0/196]	Time 1.574 (1.574)	Data 1.520 (1.520)	Loss 0.1337 (0.1337)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 17:51:38 - INFO - TRAINING - Epoch: [29][10/196]	Time 0.102 (0.266)	Data 0.000 (0.170)	Loss 0.1507 (0.1317)	Prec@1 95.703 (95.632)	Prec@5 99.609 (99.929)
2022-06-17 17:51:39 - INFO - TRAINING - Epoch: [29][20/196]	Time 0.113 (0.191)	Data 0.000 (0.089)	Loss 0.1186 (0.1316)	Prec@1 96.094 (95.406)	Prec@5 100.000 (99.944)
2022-06-17 17:51:40 - INFO - TRAINING - Epoch: [29][30/196]	Time 0.116 (0.167)	Data 0.000 (0.061)	Loss 0.1138 (0.1316)	Prec@1 96.094 (95.451)	Prec@5 100.000 (99.962)
2022-06-17 17:51:41 - INFO - TRAINING - Epoch: [29][40/196]	Time 0.111 (0.154)	Data 0.000 (0.046)	Loss 0.1487 (0.1320)	Prec@1 94.922 (95.351)	Prec@5 100.000 (99.971)
2022-06-17 17:51:42 - INFO - TRAINING - Epoch: [29][50/196]	Time 0.109 (0.145)	Data 0.000 (0.037)	Loss 0.1319 (0.1339)	Prec@1 96.094 (95.312)	Prec@5 100.000 (99.962)
2022-06-17 17:51:43 - INFO - TRAINING - Epoch: [29][60/196]	Time 0.124 (0.140)	Data 0.000 (0.031)	Loss 0.1198 (0.1328)	Prec@1 95.703 (95.293)	Prec@5 100.000 (99.968)
2022-06-17 17:51:44 - INFO - TRAINING - Epoch: [29][70/196]	Time 0.102 (0.136)	Data 0.001 (0.027)	Loss 0.1313 (0.1310)	Prec@1 95.703 (95.357)	Prec@5 100.000 (99.972)
2022-06-17 17:51:46 - INFO - TRAINING - Epoch: [29][80/196]	Time 0.107 (0.134)	Data 0.000 (0.023)	Loss 0.1354 (0.1310)	Prec@1 95.703 (95.370)	Prec@5 99.609 (99.966)
2022-06-17 17:51:47 - INFO - TRAINING - Epoch: [29][90/196]	Time 0.109 (0.132)	Data 0.000 (0.021)	Loss 0.1507 (0.1313)	Prec@1 93.750 (95.360)	Prec@5 100.000 (99.970)
2022-06-17 17:51:48 - INFO - TRAINING - Epoch: [29][100/196]	Time 0.103 (0.130)	Data 0.000 (0.019)	Loss 0.0706 (0.1295)	Prec@1 98.438 (95.398)	Prec@5 100.000 (99.973)
2022-06-17 17:51:49 - INFO - TRAINING - Epoch: [29][110/196]	Time 0.102 (0.129)	Data 0.000 (0.017)	Loss 0.1394 (0.1296)	Prec@1 95.312 (95.436)	Prec@5 99.609 (99.968)
2022-06-17 17:51:50 - INFO - TRAINING - Epoch: [29][120/196]	Time 0.125 (0.128)	Data 0.000 (0.016)	Loss 0.1325 (0.1296)	Prec@1 94.922 (95.461)	Prec@5 99.609 (99.968)
2022-06-17 17:51:51 - INFO - TRAINING - Epoch: [29][130/196]	Time 0.123 (0.127)	Data 0.000 (0.015)	Loss 0.1422 (0.1305)	Prec@1 96.094 (95.474)	Prec@5 100.000 (99.970)
2022-06-17 17:51:52 - INFO - TRAINING - Epoch: [29][140/196]	Time 0.107 (0.125)	Data 0.000 (0.014)	Loss 0.1528 (0.1310)	Prec@1 93.359 (95.429)	Prec@5 100.000 (99.964)
2022-06-17 17:51:53 - INFO - TRAINING - Epoch: [29][150/196]	Time 0.104 (0.124)	Data 0.000 (0.013)	Loss 0.0986 (0.1314)	Prec@1 97.266 (95.431)	Prec@5 100.000 (99.961)
2022-06-17 17:51:55 - INFO - TRAINING - Epoch: [29][160/196]	Time 0.113 (0.124)	Data 0.000 (0.012)	Loss 0.1138 (0.1318)	Prec@1 95.312 (95.436)	Prec@5 100.000 (99.961)
2022-06-17 17:51:56 - INFO - TRAINING - Epoch: [29][170/196]	Time 0.110 (0.123)	Data 0.000 (0.011)	Loss 0.1687 (0.1324)	Prec@1 94.141 (95.420)	Prec@5 100.000 (99.957)
2022-06-17 17:51:57 - INFO - TRAINING - Epoch: [29][180/196]	Time 0.111 (0.123)	Data 0.000 (0.011)	Loss 0.0928 (0.1320)	Prec@1 96.484 (95.431)	Prec@5 100.000 (99.959)
2022-06-17 17:51:58 - INFO - TRAINING - Epoch: [29][190/196]	Time 0.102 (0.122)	Data 0.000 (0.010)	Loss 0.1309 (0.1330)	Prec@1 95.312 (95.417)	Prec@5 100.000 (99.955)
2022-06-17 17:52:01 - INFO - EVALUATING - Epoch: [29][0/40]	Time 1.878 (1.878)	Data 1.833 (1.833)	Loss 0.2606 (0.2606)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 17:52:01 - INFO - EVALUATING - Epoch: [29][10/40]	Time 0.050 (0.252)	Data 0.000 (0.205)	Loss 0.4411 (0.3909)	Prec@1 87.500 (88.281)	Prec@5 99.219 (99.361)
2022-06-17 17:52:03 - INFO - EVALUATING - Epoch: [29][20/40]	Time 0.059 (0.182)	Data 0.000 (0.136)	Loss 0.3120 (0.3943)	Prec@1 88.281 (87.984)	Prec@5 100.000 (99.349)
2022-06-17 17:52:03 - INFO - EVALUATING - Epoch: [29][30/40]	Time 0.093 (0.149)	Data 0.049 (0.103)	Loss 0.4701 (0.3882)	Prec@1 85.547 (88.017)	Prec@5 100.000 (99.446)
2022-06-17 17:52:05 - INFO - 
 Epoch: 30	Training Loss 0.1337 	Training Prec@1 95.392 	Training Prec@5 99.954 	Validation Loss 0.3839 	Validation Prec@1 88.050 	Validation Prec@5 99.520 

2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:52:05 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:52:07 - INFO - TRAINING - Epoch: [30][0/196]	Time 1.949 (1.949)	Data 1.897 (1.897)	Loss 0.1253 (0.1253)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2022-06-17 17:52:08 - INFO - TRAINING - Epoch: [30][10/196]	Time 0.114 (0.279)	Data 0.000 (0.173)	Loss 0.1513 (0.1367)	Prec@1 95.312 (95.206)	Prec@5 100.000 (99.964)
2022-06-17 17:52:10 - INFO - TRAINING - Epoch: [30][20/196]	Time 0.126 (0.202)	Data 0.000 (0.091)	Loss 0.0891 (0.1335)	Prec@1 96.094 (95.294)	Prec@5 100.000 (99.944)
2022-06-17 17:52:11 - INFO - TRAINING - Epoch: [30][30/196]	Time 0.122 (0.174)	Data 0.000 (0.061)	Loss 0.1207 (0.1350)	Prec@1 94.141 (95.262)	Prec@5 100.000 (99.924)
2022-06-17 17:52:12 - INFO - TRAINING - Epoch: [30][40/196]	Time 0.110 (0.159)	Data 0.000 (0.047)	Loss 0.1393 (0.1360)	Prec@1 95.703 (95.274)	Prec@5 99.609 (99.924)
2022-06-17 17:52:13 - INFO - TRAINING - Epoch: [30][50/196]	Time 0.130 (0.151)	Data 0.000 (0.037)	Loss 0.1282 (0.1358)	Prec@1 96.094 (95.267)	Prec@5 100.000 (99.939)
2022-06-17 17:52:14 - INFO - TRAINING - Epoch: [30][60/196]	Time 0.125 (0.146)	Data 0.000 (0.031)	Loss 0.1355 (0.1358)	Prec@1 96.484 (95.332)	Prec@5 100.000 (99.942)
2022-06-17 17:52:15 - INFO - TRAINING - Epoch: [30][70/196]	Time 0.117 (0.141)	Data 0.000 (0.027)	Loss 0.1584 (0.1358)	Prec@1 95.703 (95.406)	Prec@5 100.000 (99.950)
2022-06-17 17:52:16 - INFO - TRAINING - Epoch: [30][80/196]	Time 0.106 (0.138)	Data 0.000 (0.024)	Loss 0.0891 (0.1352)	Prec@1 97.266 (95.404)	Prec@5 100.000 (99.947)
2022-06-17 17:52:18 - INFO - TRAINING - Epoch: [30][90/196]	Time 0.128 (0.135)	Data 0.000 (0.021)	Loss 0.0904 (0.1347)	Prec@1 96.875 (95.403)	Prec@5 100.000 (99.953)
2022-06-17 17:52:19 - INFO - TRAINING - Epoch: [30][100/196]	Time 0.110 (0.133)	Data 0.000 (0.019)	Loss 0.1498 (0.1342)	Prec@1 94.922 (95.394)	Prec@5 100.000 (99.954)
2022-06-17 17:52:20 - INFO - TRAINING - Epoch: [30][110/196]	Time 0.118 (0.132)	Data 0.000 (0.017)	Loss 0.1771 (0.1340)	Prec@1 93.359 (95.418)	Prec@5 100.000 (99.958)
2022-06-17 17:52:21 - INFO - TRAINING - Epoch: [30][120/196]	Time 0.108 (0.130)	Data 0.000 (0.016)	Loss 0.1171 (0.1340)	Prec@1 96.094 (95.429)	Prec@5 100.000 (99.958)
2022-06-17 17:52:22 - INFO - TRAINING - Epoch: [30][130/196]	Time 0.128 (0.129)	Data 0.000 (0.015)	Loss 0.1758 (0.1347)	Prec@1 92.578 (95.390)	Prec@5 100.000 (99.952)
2022-06-17 17:52:23 - INFO - TRAINING - Epoch: [30][140/196]	Time 0.121 (0.128)	Data 0.000 (0.014)	Loss 0.1280 (0.1348)	Prec@1 96.094 (95.368)	Prec@5 100.000 (99.953)
2022-06-17 17:52:25 - INFO - TRAINING - Epoch: [30][150/196]	Time 0.117 (0.127)	Data 0.000 (0.013)	Loss 0.1592 (0.1346)	Prec@1 93.750 (95.372)	Prec@5 100.000 (99.953)
2022-06-17 17:52:26 - INFO - TRAINING - Epoch: [30][160/196]	Time 0.108 (0.126)	Data 0.000 (0.012)	Loss 0.1050 (0.1334)	Prec@1 96.094 (95.424)	Prec@5 100.000 (99.954)
2022-06-17 17:52:27 - INFO - TRAINING - Epoch: [30][170/196]	Time 0.110 (0.126)	Data 0.000 (0.011)	Loss 0.1421 (0.1335)	Prec@1 94.922 (95.434)	Prec@5 100.000 (99.947)
2022-06-17 17:52:28 - INFO - TRAINING - Epoch: [30][180/196]	Time 0.124 (0.125)	Data 0.000 (0.011)	Loss 0.0829 (0.1323)	Prec@1 97.656 (95.466)	Prec@5 100.000 (99.948)
2022-06-17 17:52:29 - INFO - TRAINING - Epoch: [30][190/196]	Time 0.102 (0.124)	Data 0.000 (0.010)	Loss 0.1425 (0.1326)	Prec@1 94.922 (95.447)	Prec@5 100.000 (99.945)
2022-06-17 17:52:32 - INFO - EVALUATING - Epoch: [30][0/40]	Time 1.949 (1.949)	Data 1.903 (1.903)	Loss 0.2628 (0.2628)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 17:52:33 - INFO - EVALUATING - Epoch: [30][10/40]	Time 0.042 (0.261)	Data 0.000 (0.214)	Loss 0.4381 (0.3909)	Prec@1 87.500 (88.352)	Prec@5 99.219 (99.432)
2022-06-17 17:52:33 - INFO - EVALUATING - Epoch: [30][20/40]	Time 0.120 (0.167)	Data 0.078 (0.120)	Loss 0.3165 (0.3941)	Prec@1 88.281 (88.039)	Prec@5 100.000 (99.368)
2022-06-17 17:52:34 - INFO - EVALUATING - Epoch: [30][30/40]	Time 0.100 (0.154)	Data 0.056 (0.108)	Loss 0.4651 (0.3885)	Prec@1 85.547 (87.966)	Prec@5 100.000 (99.458)
2022-06-17 17:52:36 - INFO - 
 Epoch: 31	Training Loss 0.1335 	Training Prec@1 95.424 	Training Prec@5 99.946 	Validation Loss 0.3843 	Validation Prec@1 87.950 	Validation Prec@5 99.530 

2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:52:36 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:52:38 - INFO - TRAINING - Epoch: [31][0/196]	Time 1.672 (1.672)	Data 1.619 (1.619)	Loss 0.1386 (0.1386)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 17:52:39 - INFO - TRAINING - Epoch: [31][10/196]	Time 0.109 (0.279)	Data 0.000 (0.183)	Loss 0.1435 (0.1221)	Prec@1 94.922 (96.058)	Prec@5 100.000 (100.000)
2022-06-17 17:52:40 - INFO - TRAINING - Epoch: [31][20/196]	Time 0.104 (0.197)	Data 0.000 (0.096)	Loss 0.1454 (0.1309)	Prec@1 95.312 (95.722)	Prec@5 100.000 (99.981)
2022-06-17 17:52:42 - INFO - TRAINING - Epoch: [31][30/196]	Time 0.117 (0.171)	Data 0.000 (0.065)	Loss 0.1264 (0.1314)	Prec@1 96.875 (95.691)	Prec@5 100.000 (99.975)
2022-06-17 17:52:43 - INFO - TRAINING - Epoch: [31][40/196]	Time 0.130 (0.157)	Data 0.000 (0.049)	Loss 0.1972 (0.1351)	Prec@1 92.969 (95.513)	Prec@5 100.000 (99.971)
2022-06-17 17:52:44 - INFO - TRAINING - Epoch: [31][50/196]	Time 0.122 (0.150)	Data 0.000 (0.040)	Loss 0.1082 (0.1361)	Prec@1 97.656 (95.427)	Prec@5 100.000 (99.962)
2022-06-17 17:52:45 - INFO - TRAINING - Epoch: [31][60/196]	Time 0.127 (0.145)	Data 0.000 (0.033)	Loss 0.1442 (0.1364)	Prec@1 95.312 (95.402)	Prec@5 99.609 (99.955)
2022-06-17 17:52:46 - INFO - TRAINING - Epoch: [31][70/196]	Time 0.111 (0.140)	Data 0.000 (0.029)	Loss 0.1620 (0.1353)	Prec@1 94.141 (95.434)	Prec@5 100.000 (99.961)
2022-06-17 17:52:47 - INFO - TRAINING - Epoch: [31][80/196]	Time 0.125 (0.137)	Data 0.000 (0.025)	Loss 0.1653 (0.1343)	Prec@1 93.359 (95.481)	Prec@5 100.000 (99.961)
2022-06-17 17:52:49 - INFO - TRAINING - Epoch: [31][90/196]	Time 0.113 (0.134)	Data 0.000 (0.022)	Loss 0.1072 (0.1334)	Prec@1 95.703 (95.488)	Prec@5 100.000 (99.961)
2022-06-17 17:52:50 - INFO - TRAINING - Epoch: [31][100/196]	Time 0.119 (0.132)	Data 0.000 (0.020)	Loss 0.1193 (0.1347)	Prec@1 95.312 (95.417)	Prec@5 100.000 (99.961)
2022-06-17 17:52:51 - INFO - TRAINING - Epoch: [31][110/196]	Time 0.108 (0.130)	Data 0.000 (0.018)	Loss 0.1116 (0.1345)	Prec@1 97.656 (95.450)	Prec@5 100.000 (99.961)
2022-06-17 17:52:52 - INFO - TRAINING - Epoch: [31][120/196]	Time 0.103 (0.129)	Data 0.000 (0.017)	Loss 0.1196 (0.1362)	Prec@1 96.094 (95.380)	Prec@5 100.000 (99.955)
2022-06-17 17:52:53 - INFO - TRAINING - Epoch: [31][130/196]	Time 0.101 (0.127)	Data 0.000 (0.016)	Loss 0.1488 (0.1351)	Prec@1 94.922 (95.414)	Prec@5 100.000 (99.952)
2022-06-17 17:52:54 - INFO - TRAINING - Epoch: [31][140/196]	Time 0.103 (0.126)	Data 0.000 (0.015)	Loss 0.0973 (0.1349)	Prec@1 96.484 (95.434)	Prec@5 100.000 (99.953)
2022-06-17 17:52:55 - INFO - TRAINING - Epoch: [31][150/196]	Time 0.111 (0.125)	Data 0.000 (0.014)	Loss 0.1830 (0.1355)	Prec@1 94.141 (95.400)	Prec@5 100.000 (99.951)
2022-06-17 17:52:56 - INFO - TRAINING - Epoch: [31][160/196]	Time 0.123 (0.125)	Data 0.000 (0.013)	Loss 0.1261 (0.1359)	Prec@1 96.875 (95.385)	Prec@5 100.000 (99.951)
2022-06-17 17:52:57 - INFO - TRAINING - Epoch: [31][170/196]	Time 0.119 (0.124)	Data 0.000 (0.012)	Loss 0.1273 (0.1356)	Prec@1 95.703 (95.360)	Prec@5 99.609 (99.947)
2022-06-17 17:52:59 - INFO - TRAINING - Epoch: [31][180/196]	Time 0.118 (0.124)	Data 0.000 (0.011)	Loss 0.0916 (0.1354)	Prec@1 96.484 (95.369)	Prec@5 100.000 (99.950)
2022-06-17 17:53:00 - INFO - TRAINING - Epoch: [31][190/196]	Time 0.101 (0.123)	Data 0.000 (0.011)	Loss 0.1242 (0.1347)	Prec@1 96.484 (95.400)	Prec@5 99.609 (99.947)
2022-06-17 17:53:02 - INFO - EVALUATING - Epoch: [31][0/40]	Time 1.958 (1.958)	Data 1.913 (1.913)	Loss 0.2589 (0.2589)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.609)
2022-06-17 17:53:03 - INFO - EVALUATING - Epoch: [31][10/40]	Time 0.054 (0.270)	Data 0.000 (0.221)	Loss 0.4390 (0.3905)	Prec@1 87.500 (88.246)	Prec@5 99.219 (99.361)
2022-06-17 17:53:04 - INFO - EVALUATING - Epoch: [31][20/40]	Time 0.203 (0.172)	Data 0.163 (0.123)	Loss 0.3144 (0.3936)	Prec@1 88.281 (88.039)	Prec@5 100.000 (99.349)
2022-06-17 17:53:05 - INFO - EVALUATING - Epoch: [31][30/40]	Time 0.226 (0.156)	Data 0.182 (0.108)	Loss 0.4655 (0.3868)	Prec@1 85.156 (88.017)	Prec@5 100.000 (99.446)
2022-06-17 17:53:07 - INFO - 
 Epoch: 32	Training Loss 0.1348 	Training Prec@1 95.384 	Training Prec@5 99.948 	Validation Loss 0.3829 	Validation Prec@1 88.050 	Validation Prec@5 99.530 

2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:53:07 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:53:08 - INFO - TRAINING - Epoch: [32][0/196]	Time 1.365 (1.365)	Data 1.312 (1.312)	Loss 0.1159 (0.1159)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 17:53:10 - INFO - TRAINING - Epoch: [32][10/196]	Time 0.109 (0.267)	Data 0.000 (0.172)	Loss 0.0864 (0.1234)	Prec@1 96.875 (95.703)	Prec@5 100.000 (99.893)
2022-06-17 17:53:11 - INFO - TRAINING - Epoch: [32][20/196]	Time 0.104 (0.190)	Data 0.000 (0.090)	Loss 0.1566 (0.1253)	Prec@1 96.484 (95.815)	Prec@5 100.000 (99.907)
2022-06-17 17:53:12 - INFO - TRAINING - Epoch: [32][30/196]	Time 0.108 (0.163)	Data 0.000 (0.061)	Loss 0.1401 (0.1268)	Prec@1 96.094 (95.766)	Prec@5 100.000 (99.924)
2022-06-17 17:53:13 - INFO - TRAINING - Epoch: [32][40/196]	Time 0.105 (0.150)	Data 0.000 (0.046)	Loss 0.1593 (0.1292)	Prec@1 93.359 (95.617)	Prec@5 99.609 (99.924)
2022-06-17 17:53:14 - INFO - TRAINING - Epoch: [32][50/196]	Time 0.103 (0.142)	Data 0.000 (0.037)	Loss 0.0892 (0.1283)	Prec@1 97.266 (95.489)	Prec@5 100.000 (99.939)
2022-06-17 17:53:15 - INFO - TRAINING - Epoch: [32][60/196]	Time 0.102 (0.138)	Data 0.000 (0.031)	Loss 0.1415 (0.1299)	Prec@1 94.922 (95.479)	Prec@5 100.000 (99.942)
2022-06-17 17:53:17 - INFO - TRAINING - Epoch: [32][70/196]	Time 0.122 (0.134)	Data 0.000 (0.027)	Loss 0.1274 (0.1312)	Prec@1 96.484 (95.494)	Prec@5 100.000 (99.939)
2022-06-17 17:53:18 - INFO - TRAINING - Epoch: [32][80/196]	Time 0.111 (0.131)	Data 0.000 (0.024)	Loss 0.1228 (0.1316)	Prec@1 96.094 (95.491)	Prec@5 100.000 (99.942)
2022-06-17 17:53:19 - INFO - TRAINING - Epoch: [32][90/196]	Time 0.106 (0.129)	Data 0.000 (0.021)	Loss 0.1353 (0.1307)	Prec@1 94.531 (95.566)	Prec@5 100.000 (99.940)
2022-06-17 17:53:20 - INFO - TRAINING - Epoch: [32][100/196]	Time 0.110 (0.127)	Data 0.000 (0.019)	Loss 0.1645 (0.1309)	Prec@1 95.312 (95.614)	Prec@5 100.000 (99.934)
2022-06-17 17:53:21 - INFO - TRAINING - Epoch: [32][110/196]	Time 0.108 (0.125)	Data 0.000 (0.017)	Loss 0.1849 (0.1311)	Prec@1 93.750 (95.598)	Prec@5 100.000 (99.937)
2022-06-17 17:53:22 - INFO - TRAINING - Epoch: [32][120/196]	Time 0.113 (0.124)	Data 0.000 (0.016)	Loss 0.1376 (0.1307)	Prec@1 95.703 (95.593)	Prec@5 100.000 (99.942)
2022-06-17 17:53:23 - INFO - TRAINING - Epoch: [32][130/196]	Time 0.109 (0.123)	Data 0.000 (0.015)	Loss 0.0847 (0.1303)	Prec@1 98.438 (95.620)	Prec@5 100.000 (99.943)
2022-06-17 17:53:24 - INFO - TRAINING - Epoch: [32][140/196]	Time 0.108 (0.122)	Data 0.000 (0.014)	Loss 0.1422 (0.1307)	Prec@1 96.094 (95.598)	Prec@5 99.609 (99.939)
2022-06-17 17:53:25 - INFO - TRAINING - Epoch: [32][150/196]	Time 0.118 (0.122)	Data 0.000 (0.013)	Loss 0.1262 (0.1305)	Prec@1 96.484 (95.615)	Prec@5 100.000 (99.941)
2022-06-17 17:53:27 - INFO - TRAINING - Epoch: [32][160/196]	Time 0.110 (0.121)	Data 0.000 (0.012)	Loss 0.1465 (0.1310)	Prec@1 96.094 (95.587)	Prec@5 100.000 (99.944)
2022-06-17 17:53:28 - INFO - TRAINING - Epoch: [32][170/196]	Time 0.111 (0.120)	Data 0.000 (0.011)	Loss 0.1214 (0.1312)	Prec@1 95.703 (95.584)	Prec@5 100.000 (99.947)
2022-06-17 17:53:29 - INFO - TRAINING - Epoch: [32][180/196]	Time 0.103 (0.120)	Data 0.000 (0.011)	Loss 0.0871 (0.1307)	Prec@1 97.266 (95.608)	Prec@5 100.000 (99.950)
2022-06-17 17:53:30 - INFO - TRAINING - Epoch: [32][190/196]	Time 0.102 (0.119)	Data 0.000 (0.010)	Loss 0.2128 (0.1305)	Prec@1 93.359 (95.623)	Prec@5 100.000 (99.953)
2022-06-17 17:53:32 - INFO - EVALUATING - Epoch: [32][0/40]	Time 1.575 (1.575)	Data 1.530 (1.530)	Loss 0.2680 (0.2680)	Prec@1 92.578 (92.578)	Prec@5 99.609 (99.609)
2022-06-17 17:53:33 - INFO - EVALUATING - Epoch: [32][10/40]	Time 0.069 (0.270)	Data 0.000 (0.219)	Loss 0.4444 (0.3948)	Prec@1 87.891 (88.175)	Prec@5 99.609 (99.396)
2022-06-17 17:53:34 - INFO - EVALUATING - Epoch: [32][20/40]	Time 0.121 (0.171)	Data 0.080 (0.121)	Loss 0.3174 (0.3961)	Prec@1 88.281 (88.039)	Prec@5 100.000 (99.405)
2022-06-17 17:53:35 - INFO - EVALUATING - Epoch: [32][30/40]	Time 0.052 (0.161)	Data 0.000 (0.112)	Loss 0.4696 (0.3895)	Prec@1 85.156 (87.954)	Prec@5 100.000 (99.471)
2022-06-17 17:53:37 - INFO - 
 Epoch: 33	Training Loss 0.1303 	Training Prec@1 95.632 	Training Prec@5 99.954 	Validation Loss 0.3849 	Validation Prec@1 87.950 	Validation Prec@5 99.540 

2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:53:37 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:53:39 - INFO - TRAINING - Epoch: [33][0/196]	Time 1.280 (1.280)	Data 1.227 (1.227)	Loss 0.0984 (0.0984)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 17:53:40 - INFO - TRAINING - Epoch: [33][10/196]	Time 0.131 (0.273)	Data 0.000 (0.172)	Loss 0.1382 (0.1344)	Prec@1 94.531 (95.277)	Prec@5 100.000 (99.964)
2022-06-17 17:53:41 - INFO - TRAINING - Epoch: [33][20/196]	Time 0.108 (0.200)	Data 0.000 (0.090)	Loss 0.1246 (0.1292)	Prec@1 95.312 (95.610)	Prec@5 99.609 (99.963)
2022-06-17 17:53:43 - INFO - TRAINING - Epoch: [33][30/196]	Time 0.107 (0.171)	Data 0.000 (0.061)	Loss 0.1756 (0.1308)	Prec@1 93.750 (95.476)	Prec@5 100.000 (99.962)
2022-06-17 17:53:44 - INFO - TRAINING - Epoch: [33][40/196]	Time 0.104 (0.157)	Data 0.000 (0.046)	Loss 0.1348 (0.1302)	Prec@1 95.703 (95.522)	Prec@5 100.000 (99.971)
2022-06-17 17:53:45 - INFO - TRAINING - Epoch: [33][50/196]	Time 0.130 (0.149)	Data 0.000 (0.037)	Loss 0.1308 (0.1273)	Prec@1 96.094 (95.665)	Prec@5 100.000 (99.977)
2022-06-17 17:53:46 - INFO - TRAINING - Epoch: [33][60/196]	Time 0.111 (0.143)	Data 0.000 (0.031)	Loss 0.1482 (0.1292)	Prec@1 95.312 (95.569)	Prec@5 100.000 (99.981)
2022-06-17 17:53:47 - INFO - TRAINING - Epoch: [33][70/196]	Time 0.114 (0.138)	Data 0.000 (0.027)	Loss 0.1445 (0.1288)	Prec@1 95.312 (95.588)	Prec@5 99.609 (99.967)
2022-06-17 17:53:48 - INFO - TRAINING - Epoch: [33][80/196]	Time 0.110 (0.135)	Data 0.000 (0.024)	Loss 0.1120 (0.1288)	Prec@1 97.656 (95.587)	Prec@5 100.000 (99.971)
2022-06-17 17:53:49 - INFO - TRAINING - Epoch: [33][90/196]	Time 0.106 (0.132)	Data 0.000 (0.021)	Loss 0.0871 (0.1286)	Prec@1 97.656 (95.604)	Prec@5 100.000 (99.970)
2022-06-17 17:53:50 - INFO - TRAINING - Epoch: [33][100/196]	Time 0.105 (0.130)	Data 0.000 (0.019)	Loss 0.1185 (0.1300)	Prec@1 96.875 (95.610)	Prec@5 100.000 (99.973)
2022-06-17 17:53:52 - INFO - TRAINING - Epoch: [33][110/196]	Time 0.124 (0.128)	Data 0.000 (0.017)	Loss 0.1183 (0.1305)	Prec@1 97.266 (95.583)	Prec@5 100.000 (99.968)
2022-06-17 17:53:53 - INFO - TRAINING - Epoch: [33][120/196]	Time 0.116 (0.127)	Data 0.000 (0.016)	Loss 0.1680 (0.1324)	Prec@1 94.141 (95.526)	Prec@5 100.000 (99.964)
2022-06-17 17:53:54 - INFO - TRAINING - Epoch: [33][130/196]	Time 0.128 (0.127)	Data 0.000 (0.015)	Loss 0.1211 (0.1324)	Prec@1 95.312 (95.491)	Prec@5 99.609 (99.961)
2022-06-17 17:53:55 - INFO - TRAINING - Epoch: [33][140/196]	Time 0.115 (0.126)	Data 0.000 (0.014)	Loss 0.0994 (0.1312)	Prec@1 96.484 (95.545)	Prec@5 100.000 (99.964)
2022-06-17 17:53:56 - INFO - TRAINING - Epoch: [33][150/196]	Time 0.114 (0.124)	Data 0.000 (0.013)	Loss 0.0561 (0.1304)	Prec@1 97.656 (95.584)	Prec@5 100.000 (99.959)
2022-06-17 17:53:57 - INFO - TRAINING - Epoch: [33][160/196]	Time 0.106 (0.124)	Data 0.000 (0.012)	Loss 0.1176 (0.1301)	Prec@1 95.703 (95.587)	Prec@5 100.000 (99.956)
2022-06-17 17:53:58 - INFO - TRAINING - Epoch: [33][170/196]	Time 0.113 (0.123)	Data 0.000 (0.011)	Loss 0.1244 (0.1296)	Prec@1 94.922 (95.600)	Prec@5 100.000 (99.959)
2022-06-17 17:53:59 - INFO - TRAINING - Epoch: [33][180/196]	Time 0.112 (0.123)	Data 0.000 (0.011)	Loss 0.1617 (0.1305)	Prec@1 95.312 (95.563)	Prec@5 100.000 (99.959)
2022-06-17 17:54:00 - INFO - TRAINING - Epoch: [33][190/196]	Time 0.102 (0.121)	Data 0.000 (0.010)	Loss 0.1454 (0.1308)	Prec@1 96.484 (95.546)	Prec@5 99.609 (99.953)
2022-06-17 17:54:03 - INFO - EVALUATING - Epoch: [33][0/40]	Time 1.804 (1.804)	Data 1.759 (1.759)	Loss 0.2551 (0.2551)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 17:54:04 - INFO - EVALUATING - Epoch: [33][10/40]	Time 0.052 (0.269)	Data 0.000 (0.219)	Loss 0.4408 (0.3924)	Prec@1 87.500 (88.033)	Prec@5 99.219 (99.432)
2022-06-17 17:54:05 - INFO - EVALUATING - Epoch: [33][20/40]	Time 0.061 (0.164)	Data 0.001 (0.115)	Loss 0.3152 (0.3949)	Prec@1 87.891 (87.928)	Prec@5 100.000 (99.405)
2022-06-17 17:54:06 - INFO - EVALUATING - Epoch: [33][30/40]	Time 0.095 (0.146)	Data 0.053 (0.099)	Loss 0.4628 (0.3895)	Prec@1 86.328 (87.954)	Prec@5 100.000 (99.483)
2022-06-17 17:54:08 - INFO - 
 Epoch: 34	Training Loss 0.1312 	Training Prec@1 95.532 	Training Prec@5 99.954 	Validation Loss 0.3850 	Validation Prec@1 88.010 	Validation Prec@5 99.550 

2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:54:08 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:54:09 - INFO - TRAINING - Epoch: [34][0/196]	Time 1.768 (1.768)	Data 1.715 (1.715)	Loss 0.1509 (0.1509)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 17:54:10 - INFO - TRAINING - Epoch: [34][10/196]	Time 0.102 (0.265)	Data 0.000 (0.174)	Loss 0.1224 (0.1312)	Prec@1 94.922 (95.277)	Prec@5 100.000 (99.929)
2022-06-17 17:54:12 - INFO - TRAINING - Epoch: [34][20/196]	Time 0.115 (0.194)	Data 0.000 (0.091)	Loss 0.1263 (0.1289)	Prec@1 95.312 (95.368)	Prec@5 100.000 (99.963)
2022-06-17 17:54:13 - INFO - TRAINING - Epoch: [34][30/196]	Time 0.111 (0.166)	Data 0.000 (0.062)	Loss 0.1292 (0.1287)	Prec@1 95.312 (95.451)	Prec@5 100.000 (99.950)
2022-06-17 17:54:14 - INFO - TRAINING - Epoch: [34][40/196]	Time 0.108 (0.153)	Data 0.000 (0.047)	Loss 0.1034 (0.1308)	Prec@1 97.656 (95.408)	Prec@5 100.000 (99.962)
2022-06-17 17:54:15 - INFO - TRAINING - Epoch: [34][50/196]	Time 0.116 (0.145)	Data 0.000 (0.038)	Loss 0.1112 (0.1312)	Prec@1 96.484 (95.512)	Prec@5 99.609 (99.939)
2022-06-17 17:54:16 - INFO - TRAINING - Epoch: [34][60/196]	Time 0.126 (0.140)	Data 0.000 (0.032)	Loss 0.1453 (0.1287)	Prec@1 95.312 (95.620)	Prec@5 99.609 (99.930)
2022-06-17 17:54:17 - INFO - TRAINING - Epoch: [34][70/196]	Time 0.120 (0.135)	Data 0.000 (0.027)	Loss 0.0944 (0.1263)	Prec@1 98.047 (95.802)	Prec@5 100.000 (99.939)
2022-06-17 17:54:18 - INFO - TRAINING - Epoch: [34][80/196]	Time 0.116 (0.133)	Data 0.000 (0.024)	Loss 0.0769 (0.1257)	Prec@1 98.438 (95.819)	Prec@5 100.000 (99.942)
2022-06-17 17:54:19 - INFO - TRAINING - Epoch: [34][90/196]	Time 0.111 (0.131)	Data 0.000 (0.021)	Loss 0.1030 (0.1270)	Prec@1 96.094 (95.763)	Prec@5 100.000 (99.936)
2022-06-17 17:54:21 - INFO - TRAINING - Epoch: [34][100/196]	Time 0.119 (0.129)	Data 0.000 (0.019)	Loss 0.1053 (0.1271)	Prec@1 95.312 (95.750)	Prec@5 100.000 (99.938)
2022-06-17 17:54:22 - INFO - TRAINING - Epoch: [34][110/196]	Time 0.112 (0.128)	Data 0.000 (0.018)	Loss 0.1388 (0.1274)	Prec@1 93.750 (95.738)	Prec@5 100.000 (99.944)
2022-06-17 17:54:23 - INFO - TRAINING - Epoch: [34][120/196]	Time 0.113 (0.127)	Data 0.000 (0.016)	Loss 0.0803 (0.1269)	Prec@1 97.266 (95.726)	Prec@5 100.000 (99.942)
2022-06-17 17:54:24 - INFO - TRAINING - Epoch: [34][130/196]	Time 0.112 (0.126)	Data 0.000 (0.015)	Loss 0.1354 (0.1265)	Prec@1 96.094 (95.721)	Prec@5 100.000 (99.943)
2022-06-17 17:54:25 - INFO - TRAINING - Epoch: [34][140/196]	Time 0.119 (0.125)	Data 0.000 (0.014)	Loss 0.1334 (0.1272)	Prec@1 95.703 (95.681)	Prec@5 100.000 (99.942)
2022-06-17 17:54:26 - INFO - TRAINING - Epoch: [34][150/196]	Time 0.118 (0.125)	Data 0.000 (0.013)	Loss 0.1227 (0.1266)	Prec@1 96.484 (95.724)	Prec@5 100.000 (99.943)
2022-06-17 17:54:28 - INFO - TRAINING - Epoch: [34][160/196]	Time 0.115 (0.124)	Data 0.000 (0.012)	Loss 0.1571 (0.1273)	Prec@1 93.359 (95.684)	Prec@5 100.000 (99.942)
2022-06-17 17:54:29 - INFO - TRAINING - Epoch: [34][170/196]	Time 0.110 (0.123)	Data 0.000 (0.012)	Loss 0.1318 (0.1283)	Prec@1 96.094 (95.657)	Prec@5 99.609 (99.941)
2022-06-17 17:54:30 - INFO - TRAINING - Epoch: [34][180/196]	Time 0.122 (0.123)	Data 0.000 (0.011)	Loss 0.0935 (0.1288)	Prec@1 96.094 (95.638)	Prec@5 100.000 (99.940)
2022-06-17 17:54:31 - INFO - TRAINING - Epoch: [34][190/196]	Time 0.105 (0.122)	Data 0.000 (0.010)	Loss 0.0975 (0.1289)	Prec@1 95.703 (95.629)	Prec@5 100.000 (99.939)
2022-06-17 17:54:33 - INFO - EVALUATING - Epoch: [34][0/40]	Time 1.612 (1.612)	Data 1.566 (1.566)	Loss 0.2607 (0.2607)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 17:54:34 - INFO - EVALUATING - Epoch: [34][10/40]	Time 0.062 (0.229)	Data 0.000 (0.177)	Loss 0.4374 (0.3911)	Prec@1 87.500 (88.068)	Prec@5 99.609 (99.467)
2022-06-17 17:54:35 - INFO - EVALUATING - Epoch: [34][20/40]	Time 0.071 (0.164)	Data 0.001 (0.113)	Loss 0.3250 (0.3950)	Prec@1 87.891 (87.760)	Prec@5 100.000 (99.423)
2022-06-17 17:54:36 - INFO - EVALUATING - Epoch: [34][30/40]	Time 0.224 (0.150)	Data 0.182 (0.102)	Loss 0.4661 (0.3889)	Prec@1 85.547 (87.765)	Prec@5 100.000 (99.458)
2022-06-17 17:54:38 - INFO - 
 Epoch: 35	Training Loss 0.1289 	Training Prec@1 95.628 	Training Prec@5 99.938 	Validation Loss 0.3840 	Validation Prec@1 87.820 	Validation Prec@5 99.540 

2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:54:38 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:54:39 - INFO - TRAINING - Epoch: [35][0/196]	Time 1.264 (1.264)	Data 1.209 (1.209)	Loss 0.0932 (0.0932)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 17:54:41 - INFO - TRAINING - Epoch: [35][10/196]	Time 0.104 (0.254)	Data 0.000 (0.161)	Loss 0.1685 (0.1258)	Prec@1 94.922 (95.810)	Prec@5 100.000 (100.000)
2022-06-17 17:54:42 - INFO - TRAINING - Epoch: [35][20/196]	Time 0.105 (0.187)	Data 0.000 (0.084)	Loss 0.1371 (0.1268)	Prec@1 94.141 (95.554)	Prec@5 100.000 (100.000)
2022-06-17 17:54:43 - INFO - TRAINING - Epoch: [35][30/196]	Time 0.111 (0.162)	Data 0.000 (0.057)	Loss 0.1191 (0.1332)	Prec@1 96.094 (95.476)	Prec@5 100.000 (99.975)
2022-06-17 17:54:44 - INFO - TRAINING - Epoch: [35][40/196]	Time 0.110 (0.149)	Data 0.000 (0.043)	Loss 0.1568 (0.1337)	Prec@1 94.922 (95.360)	Prec@5 100.000 (99.971)
2022-06-17 17:54:45 - INFO - TRAINING - Epoch: [35][50/196]	Time 0.110 (0.142)	Data 0.000 (0.035)	Loss 0.1396 (0.1352)	Prec@1 95.703 (95.244)	Prec@5 100.000 (99.969)
2022-06-17 17:54:46 - INFO - TRAINING - Epoch: [35][60/196]	Time 0.118 (0.138)	Data 0.000 (0.029)	Loss 0.1239 (0.1368)	Prec@1 96.484 (95.236)	Prec@5 100.000 (99.955)
2022-06-17 17:54:47 - INFO - TRAINING - Epoch: [35][70/196]	Time 0.124 (0.135)	Data 0.000 (0.025)	Loss 0.1203 (0.1369)	Prec@1 95.703 (95.175)	Prec@5 100.000 (99.961)
2022-06-17 17:54:49 - INFO - TRAINING - Epoch: [35][80/196]	Time 0.105 (0.132)	Data 0.000 (0.022)	Loss 0.1398 (0.1356)	Prec@1 94.141 (95.216)	Prec@5 100.000 (99.966)
2022-06-17 17:54:50 - INFO - TRAINING - Epoch: [35][90/196]	Time 0.124 (0.131)	Data 0.000 (0.020)	Loss 0.0905 (0.1341)	Prec@1 95.703 (95.261)	Prec@5 100.000 (99.970)
2022-06-17 17:54:51 - INFO - TRAINING - Epoch: [35][100/196]	Time 0.112 (0.129)	Data 0.000 (0.018)	Loss 0.1168 (0.1329)	Prec@1 94.531 (95.270)	Prec@5 100.000 (99.969)
2022-06-17 17:54:52 - INFO - TRAINING - Epoch: [35][110/196]	Time 0.109 (0.128)	Data 0.000 (0.016)	Loss 0.1502 (0.1322)	Prec@1 95.312 (95.288)	Prec@5 100.000 (99.968)
2022-06-17 17:54:53 - INFO - TRAINING - Epoch: [35][120/196]	Time 0.118 (0.127)	Data 0.000 (0.015)	Loss 0.1736 (0.1315)	Prec@1 95.312 (95.351)	Prec@5 100.000 (99.971)
2022-06-17 17:54:54 - INFO - TRAINING - Epoch: [35][130/196]	Time 0.112 (0.126)	Data 0.000 (0.014)	Loss 0.1176 (0.1317)	Prec@1 96.094 (95.375)	Prec@5 100.000 (99.967)
2022-06-17 17:54:55 - INFO - TRAINING - Epoch: [35][140/196]	Time 0.105 (0.125)	Data 0.000 (0.013)	Loss 0.0966 (0.1320)	Prec@1 96.875 (95.373)	Prec@5 100.000 (99.967)
2022-06-17 17:54:57 - INFO - TRAINING - Epoch: [35][150/196]	Time 0.106 (0.124)	Data 0.000 (0.012)	Loss 0.1587 (0.1323)	Prec@1 93.359 (95.354)	Prec@5 99.609 (99.964)
2022-06-17 17:54:58 - INFO - TRAINING - Epoch: [35][160/196]	Time 0.106 (0.124)	Data 0.000 (0.011)	Loss 0.1485 (0.1318)	Prec@1 95.703 (95.395)	Prec@5 99.609 (99.964)
2022-06-17 17:54:59 - INFO - TRAINING - Epoch: [35][170/196]	Time 0.108 (0.123)	Data 0.001 (0.011)	Loss 0.1221 (0.1312)	Prec@1 94.922 (95.420)	Prec@5 100.000 (99.961)
2022-06-17 17:55:00 - INFO - TRAINING - Epoch: [35][180/196]	Time 0.103 (0.122)	Data 0.000 (0.010)	Loss 0.2113 (0.1317)	Prec@1 92.969 (95.390)	Prec@5 100.000 (99.961)
2022-06-17 17:55:01 - INFO - TRAINING - Epoch: [35][190/196]	Time 0.106 (0.121)	Data 0.000 (0.010)	Loss 0.0751 (0.1311)	Prec@1 97.266 (95.433)	Prec@5 100.000 (99.961)
2022-06-17 17:55:04 - INFO - EVALUATING - Epoch: [35][0/40]	Time 2.142 (2.142)	Data 2.097 (2.097)	Loss 0.2619 (0.2619)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 17:55:05 - INFO - EVALUATING - Epoch: [35][10/40]	Time 0.045 (0.288)	Data 0.001 (0.234)	Loss 0.4315 (0.3890)	Prec@1 87.500 (88.104)	Prec@5 99.609 (99.432)
2022-06-17 17:55:05 - INFO - EVALUATING - Epoch: [35][20/40]	Time 0.044 (0.174)	Data 0.000 (0.123)	Loss 0.3214 (0.3931)	Prec@1 88.281 (87.946)	Prec@5 100.000 (99.405)
2022-06-17 17:55:07 - INFO - EVALUATING - Epoch: [35][30/40]	Time 0.111 (0.160)	Data 0.070 (0.110)	Loss 0.4600 (0.3873)	Prec@1 85.938 (87.941)	Prec@5 100.000 (99.458)
2022-06-17 17:55:09 - INFO - 
 Epoch: 36	Training Loss 0.1311 	Training Prec@1 95.426 	Training Prec@5 99.962 	Validation Loss 0.3829 	Validation Prec@1 87.960 	Validation Prec@5 99.530 

2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:55:09 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:55:10 - INFO - TRAINING - Epoch: [36][0/196]	Time 1.602 (1.602)	Data 1.548 (1.548)	Loss 0.1240 (0.1240)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 17:55:11 - INFO - TRAINING - Epoch: [36][10/196]	Time 0.113 (0.255)	Data 0.000 (0.156)	Loss 0.1220 (0.1141)	Prec@1 96.484 (96.307)	Prec@5 99.609 (99.929)
2022-06-17 17:55:13 - INFO - TRAINING - Epoch: [36][20/196]	Time 0.110 (0.189)	Data 0.000 (0.082)	Loss 0.1605 (0.1267)	Prec@1 94.922 (95.926)	Prec@5 100.000 (99.944)
2022-06-17 17:55:14 - INFO - TRAINING - Epoch: [36][30/196]	Time 0.124 (0.165)	Data 0.000 (0.056)	Loss 0.1755 (0.1250)	Prec@1 93.359 (95.930)	Prec@5 100.000 (99.950)
2022-06-17 17:55:15 - INFO - TRAINING - Epoch: [36][40/196]	Time 0.113 (0.154)	Data 0.000 (0.042)	Loss 0.1359 (0.1264)	Prec@1 95.312 (95.856)	Prec@5 100.000 (99.952)
2022-06-17 17:55:16 - INFO - TRAINING - Epoch: [36][50/196]	Time 0.119 (0.147)	Data 0.000 (0.034)	Loss 0.1265 (0.1266)	Prec@1 95.312 (95.726)	Prec@5 100.000 (99.946)
2022-06-17 17:55:17 - INFO - TRAINING - Epoch: [36][60/196]	Time 0.122 (0.142)	Data 0.000 (0.028)	Loss 0.0907 (0.1278)	Prec@1 97.266 (95.716)	Prec@5 100.000 (99.955)
2022-06-17 17:55:18 - INFO - TRAINING - Epoch: [36][70/196]	Time 0.117 (0.139)	Data 0.000 (0.024)	Loss 0.1498 (0.1291)	Prec@1 95.312 (95.665)	Prec@5 100.000 (99.961)
2022-06-17 17:55:20 - INFO - TRAINING - Epoch: [36][80/196]	Time 0.099 (0.137)	Data 0.000 (0.021)	Loss 0.1293 (0.1305)	Prec@1 96.484 (95.558)	Prec@5 100.000 (99.961)
2022-06-17 17:55:21 - INFO - TRAINING - Epoch: [36][90/196]	Time 0.126 (0.135)	Data 0.000 (0.019)	Loss 0.0879 (0.1290)	Prec@1 97.266 (95.669)	Prec@5 100.000 (99.966)
2022-06-17 17:55:22 - INFO - TRAINING - Epoch: [36][100/196]	Time 0.123 (0.134)	Data 0.000 (0.017)	Loss 0.0723 (0.1285)	Prec@1 98.047 (95.637)	Prec@5 100.000 (99.969)
2022-06-17 17:55:23 - INFO - TRAINING - Epoch: [36][110/196]	Time 0.132 (0.133)	Data 0.000 (0.016)	Loss 0.1420 (0.1273)	Prec@1 95.703 (95.696)	Prec@5 100.000 (99.968)
2022-06-17 17:55:25 - INFO - TRAINING - Epoch: [36][120/196]	Time 0.102 (0.132)	Data 0.000 (0.014)	Loss 0.1075 (0.1278)	Prec@1 95.312 (95.681)	Prec@5 100.000 (99.968)
2022-06-17 17:55:26 - INFO - TRAINING - Epoch: [36][130/196]	Time 0.121 (0.131)	Data 0.000 (0.013)	Loss 0.1679 (0.1296)	Prec@1 94.922 (95.596)	Prec@5 99.609 (99.964)
2022-06-17 17:55:27 - INFO - TRAINING - Epoch: [36][140/196]	Time 0.126 (0.131)	Data 0.000 (0.012)	Loss 0.0901 (0.1293)	Prec@1 96.875 (95.601)	Prec@5 100.000 (99.967)
2022-06-17 17:55:28 - INFO - TRAINING - Epoch: [36][150/196]	Time 0.132 (0.130)	Data 0.000 (0.012)	Loss 0.0979 (0.1294)	Prec@1 96.875 (95.566)	Prec@5 100.000 (99.969)
2022-06-17 17:55:29 - INFO - TRAINING - Epoch: [36][160/196]	Time 0.106 (0.129)	Data 0.000 (0.011)	Loss 0.1051 (0.1286)	Prec@1 96.484 (95.587)	Prec@5 100.000 (99.968)
2022-06-17 17:55:31 - INFO - TRAINING - Epoch: [36][170/196]	Time 0.118 (0.129)	Data 0.000 (0.010)	Loss 0.1166 (0.1280)	Prec@1 96.484 (95.614)	Prec@5 100.000 (99.970)
2022-06-17 17:55:32 - INFO - TRAINING - Epoch: [36][180/196]	Time 0.123 (0.128)	Data 0.000 (0.010)	Loss 0.1035 (0.1273)	Prec@1 96.094 (95.623)	Prec@5 100.000 (99.968)
2022-06-17 17:55:33 - INFO - TRAINING - Epoch: [36][190/196]	Time 0.106 (0.128)	Data 0.000 (0.009)	Loss 0.1178 (0.1277)	Prec@1 94.922 (95.601)	Prec@5 100.000 (99.965)
2022-06-17 17:55:35 - INFO - EVALUATING - Epoch: [36][0/40]	Time 1.424 (1.424)	Data 1.379 (1.379)	Loss 0.2572 (0.2572)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 17:55:37 - INFO - EVALUATING - Epoch: [36][10/40]	Time 0.044 (0.273)	Data 0.000 (0.226)	Loss 0.4401 (0.3903)	Prec@1 87.891 (88.352)	Prec@5 99.219 (99.396)
2022-06-17 17:55:37 - INFO - EVALUATING - Epoch: [36][20/40]	Time 0.381 (0.183)	Data 0.340 (0.136)	Loss 0.3229 (0.3933)	Prec@1 87.891 (88.077)	Prec@5 100.000 (99.386)
2022-06-17 17:55:38 - INFO - EVALUATING - Epoch: [36][30/40]	Time 0.044 (0.155)	Data 0.000 (0.108)	Loss 0.4560 (0.3876)	Prec@1 85.547 (87.966)	Prec@5 100.000 (99.483)
2022-06-17 17:55:40 - INFO - 
 Epoch: 37	Training Loss 0.1274 	Training Prec@1 95.610 	Training Prec@5 99.966 	Validation Loss 0.3830 	Validation Prec@1 88.000 	Validation Prec@5 99.550 

2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:55:40 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:55:42 - INFO - TRAINING - Epoch: [37][0/196]	Time 1.721 (1.721)	Data 1.668 (1.668)	Loss 0.1567 (0.1567)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 17:55:43 - INFO - TRAINING - Epoch: [37][10/196]	Time 0.111 (0.261)	Data 0.000 (0.163)	Loss 0.1292 (0.1317)	Prec@1 96.484 (95.455)	Prec@5 100.000 (99.964)
2022-06-17 17:55:44 - INFO - TRAINING - Epoch: [37][20/196]	Time 0.111 (0.191)	Data 0.000 (0.085)	Loss 0.1261 (0.1262)	Prec@1 94.922 (95.703)	Prec@5 100.000 (99.963)
2022-06-17 17:55:45 - INFO - TRAINING - Epoch: [37][30/196]	Time 0.103 (0.166)	Data 0.000 (0.058)	Loss 0.1373 (0.1244)	Prec@1 94.141 (95.817)	Prec@5 100.000 (99.962)
2022-06-17 17:55:46 - INFO - TRAINING - Epoch: [37][40/196]	Time 0.116 (0.154)	Data 0.000 (0.044)	Loss 0.1582 (0.1241)	Prec@1 93.750 (95.722)	Prec@5 100.000 (99.971)
2022-06-17 17:55:48 - INFO - TRAINING - Epoch: [37][50/196]	Time 0.126 (0.147)	Data 0.000 (0.035)	Loss 0.1230 (0.1270)	Prec@1 95.312 (95.581)	Prec@5 100.000 (99.977)
2022-06-17 17:55:49 - INFO - TRAINING - Epoch: [37][60/196]	Time 0.122 (0.142)	Data 0.000 (0.030)	Loss 0.1482 (0.1274)	Prec@1 92.969 (95.588)	Prec@5 100.000 (99.962)
2022-06-17 17:55:50 - INFO - TRAINING - Epoch: [37][70/196]	Time 0.108 (0.139)	Data 0.000 (0.025)	Loss 0.1094 (0.1278)	Prec@1 95.703 (95.593)	Prec@5 100.000 (99.967)
2022-06-17 17:55:51 - INFO - TRAINING - Epoch: [37][80/196]	Time 0.123 (0.137)	Data 0.000 (0.022)	Loss 0.0974 (0.1281)	Prec@1 96.484 (95.583)	Prec@5 100.000 (99.971)
2022-06-17 17:55:52 - INFO - TRAINING - Epoch: [37][90/196]	Time 0.122 (0.135)	Data 0.000 (0.020)	Loss 0.1312 (0.1288)	Prec@1 96.094 (95.574)	Prec@5 100.000 (99.970)
2022-06-17 17:55:54 - INFO - TRAINING - Epoch: [37][100/196]	Time 0.118 (0.133)	Data 0.000 (0.018)	Loss 0.1070 (0.1273)	Prec@1 96.094 (95.649)	Prec@5 100.000 (99.969)
2022-06-17 17:55:55 - INFO - TRAINING - Epoch: [37][110/196]	Time 0.106 (0.132)	Data 0.000 (0.016)	Loss 0.1418 (0.1271)	Prec@1 94.922 (95.689)	Prec@5 100.000 (99.972)
2022-06-17 17:55:56 - INFO - TRAINING - Epoch: [37][120/196]	Time 0.125 (0.130)	Data 0.000 (0.015)	Loss 0.1048 (0.1273)	Prec@1 96.875 (95.677)	Prec@5 100.000 (99.968)
2022-06-17 17:55:57 - INFO - TRAINING - Epoch: [37][130/196]	Time 0.128 (0.130)	Data 0.000 (0.014)	Loss 0.1031 (0.1266)	Prec@1 96.875 (95.718)	Prec@5 100.000 (99.967)
2022-06-17 17:55:58 - INFO - TRAINING - Epoch: [37][140/196]	Time 0.102 (0.129)	Data 0.000 (0.013)	Loss 0.1291 (0.1272)	Prec@1 94.922 (95.723)	Prec@5 100.000 (99.970)
2022-06-17 17:56:00 - INFO - TRAINING - Epoch: [37][150/196]	Time 0.107 (0.128)	Data 0.000 (0.012)	Loss 0.1476 (0.1270)	Prec@1 95.312 (95.752)	Prec@5 100.000 (99.969)
2022-06-17 17:56:01 - INFO - TRAINING - Epoch: [37][160/196]	Time 0.127 (0.128)	Data 0.000 (0.011)	Loss 0.1156 (0.1277)	Prec@1 96.484 (95.752)	Prec@5 100.000 (99.971)
2022-06-17 17:56:02 - INFO - TRAINING - Epoch: [37][170/196]	Time 0.137 (0.127)	Data 0.000 (0.011)	Loss 0.1203 (0.1271)	Prec@1 95.703 (95.744)	Prec@5 100.000 (99.973)
2022-06-17 17:56:03 - INFO - TRAINING - Epoch: [37][180/196]	Time 0.120 (0.127)	Data 0.000 (0.010)	Loss 0.1879 (0.1270)	Prec@1 92.578 (95.744)	Prec@5 100.000 (99.972)
2022-06-17 17:56:04 - INFO - TRAINING - Epoch: [37][190/196]	Time 0.103 (0.126)	Data 0.000 (0.010)	Loss 0.1603 (0.1277)	Prec@1 94.922 (95.703)	Prec@5 100.000 (99.969)
2022-06-17 17:56:07 - INFO - EVALUATING - Epoch: [37][0/40]	Time 1.810 (1.810)	Data 1.764 (1.764)	Loss 0.2654 (0.2654)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 17:56:08 - INFO - EVALUATING - Epoch: [37][10/40]	Time 0.044 (0.268)	Data 0.000 (0.218)	Loss 0.4456 (0.3958)	Prec@1 87.891 (87.926)	Prec@5 99.609 (99.432)
2022-06-17 17:56:08 - INFO - EVALUATING - Epoch: [37][20/40]	Time 0.044 (0.166)	Data 0.000 (0.115)	Loss 0.3283 (0.3986)	Prec@1 87.891 (87.891)	Prec@5 100.000 (99.386)
2022-06-17 17:56:09 - INFO - EVALUATING - Epoch: [37][30/40]	Time 0.187 (0.146)	Data 0.144 (0.097)	Loss 0.4634 (0.3915)	Prec@1 85.547 (87.891)	Prec@5 100.000 (99.446)
2022-06-17 17:56:11 - INFO - 
 Epoch: 38	Training Loss 0.1282 	Training Prec@1 95.676 	Training Prec@5 99.968 	Validation Loss 0.3868 	Validation Prec@1 87.960 	Validation Prec@5 99.530 

2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:56:11 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:56:13 - INFO - TRAINING - Epoch: [38][0/196]	Time 1.646 (1.646)	Data 1.593 (1.593)	Loss 0.1132 (0.1132)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 17:56:14 - INFO - TRAINING - Epoch: [38][10/196]	Time 0.123 (0.262)	Data 0.000 (0.160)	Loss 0.0893 (0.1292)	Prec@1 97.266 (95.774)	Prec@5 100.000 (99.929)
2022-06-17 17:56:15 - INFO - TRAINING - Epoch: [38][20/196]	Time 0.128 (0.192)	Data 0.000 (0.084)	Loss 0.1707 (0.1301)	Prec@1 94.922 (95.685)	Prec@5 100.000 (99.907)
2022-06-17 17:56:16 - INFO - TRAINING - Epoch: [38][30/196]	Time 0.115 (0.168)	Data 0.000 (0.057)	Loss 0.1292 (0.1300)	Prec@1 96.094 (95.754)	Prec@5 100.000 (99.937)
2022-06-17 17:56:17 - INFO - TRAINING - Epoch: [38][40/196]	Time 0.109 (0.153)	Data 0.000 (0.043)	Loss 0.1512 (0.1295)	Prec@1 94.531 (95.722)	Prec@5 100.000 (99.943)
2022-06-17 17:56:18 - INFO - TRAINING - Epoch: [38][50/196]	Time 0.105 (0.144)	Data 0.000 (0.035)	Loss 0.1170 (0.1259)	Prec@1 96.484 (95.810)	Prec@5 99.609 (99.946)
2022-06-17 17:56:20 - INFO - TRAINING - Epoch: [38][60/196]	Time 0.108 (0.139)	Data 0.000 (0.029)	Loss 0.0893 (0.1263)	Prec@1 97.266 (95.716)	Prec@5 100.000 (99.949)
2022-06-17 17:56:21 - INFO - TRAINING - Epoch: [38][70/196]	Time 0.103 (0.136)	Data 0.000 (0.025)	Loss 0.1406 (0.1256)	Prec@1 96.094 (95.780)	Prec@5 100.000 (99.945)
2022-06-17 17:56:22 - INFO - TRAINING - Epoch: [38][80/196]	Time 0.104 (0.133)	Data 0.000 (0.022)	Loss 0.1369 (0.1271)	Prec@1 96.484 (95.742)	Prec@5 100.000 (99.942)
2022-06-17 17:56:23 - INFO - TRAINING - Epoch: [38][90/196]	Time 0.120 (0.131)	Data 0.000 (0.020)	Loss 0.1189 (0.1254)	Prec@1 95.312 (95.802)	Prec@5 100.000 (99.948)
2022-06-17 17:56:24 - INFO - TRAINING - Epoch: [38][100/196]	Time 0.109 (0.129)	Data 0.000 (0.018)	Loss 0.1396 (0.1254)	Prec@1 94.922 (95.769)	Prec@5 100.000 (99.942)
2022-06-17 17:56:25 - INFO - TRAINING - Epoch: [38][110/196]	Time 0.107 (0.128)	Data 0.000 (0.016)	Loss 0.1559 (0.1262)	Prec@1 95.703 (95.745)	Prec@5 100.000 (99.940)
2022-06-17 17:56:26 - INFO - TRAINING - Epoch: [38][120/196]	Time 0.107 (0.127)	Data 0.000 (0.015)	Loss 0.1249 (0.1267)	Prec@1 94.922 (95.710)	Prec@5 100.000 (99.942)
2022-06-17 17:56:28 - INFO - TRAINING - Epoch: [38][130/196]	Time 0.113 (0.126)	Data 0.000 (0.014)	Loss 0.1634 (0.1270)	Prec@1 93.359 (95.700)	Prec@5 100.000 (99.943)
2022-06-17 17:56:29 - INFO - TRAINING - Epoch: [38][140/196]	Time 0.109 (0.126)	Data 0.000 (0.013)	Loss 0.1962 (0.1280)	Prec@1 92.969 (95.689)	Prec@5 99.609 (99.945)
2022-06-17 17:56:30 - INFO - TRAINING - Epoch: [38][150/196]	Time 0.121 (0.125)	Data 0.000 (0.012)	Loss 0.1028 (0.1278)	Prec@1 96.875 (95.711)	Prec@5 100.000 (99.948)
2022-06-17 17:56:31 - INFO - TRAINING - Epoch: [38][160/196]	Time 0.137 (0.124)	Data 0.000 (0.011)	Loss 0.1494 (0.1280)	Prec@1 94.531 (95.686)	Prec@5 100.000 (99.951)
2022-06-17 17:56:32 - INFO - TRAINING - Epoch: [38][170/196]	Time 0.117 (0.124)	Data 0.000 (0.011)	Loss 0.1208 (0.1276)	Prec@1 96.875 (95.717)	Prec@5 100.000 (99.954)
2022-06-17 17:56:33 - INFO - TRAINING - Epoch: [38][180/196]	Time 0.109 (0.123)	Data 0.000 (0.010)	Loss 0.1316 (0.1278)	Prec@1 95.703 (95.699)	Prec@5 100.000 (99.953)
2022-06-17 17:56:34 - INFO - TRAINING - Epoch: [38][190/196]	Time 0.101 (0.122)	Data 0.000 (0.009)	Loss 0.1411 (0.1282)	Prec@1 95.312 (95.701)	Prec@5 100.000 (99.953)
2022-06-17 17:56:36 - INFO - EVALUATING - Epoch: [38][0/40]	Time 1.496 (1.496)	Data 1.450 (1.450)	Loss 0.2606 (0.2606)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 17:56:38 - INFO - EVALUATING - Epoch: [38][10/40]	Time 0.066 (0.238)	Data 0.000 (0.192)	Loss 0.4409 (0.3923)	Prec@1 88.281 (88.317)	Prec@5 99.609 (99.467)
2022-06-17 17:56:39 - INFO - EVALUATING - Epoch: [38][20/40]	Time 0.041 (0.170)	Data 0.000 (0.123)	Loss 0.3220 (0.3967)	Prec@1 88.281 (88.002)	Prec@5 100.000 (99.423)
2022-06-17 17:56:40 - INFO - EVALUATING - Epoch: [38][30/40]	Time 0.108 (0.150)	Data 0.066 (0.104)	Loss 0.4649 (0.3903)	Prec@1 85.547 (88.004)	Prec@5 100.000 (99.483)
2022-06-17 17:56:42 - INFO - 
 Epoch: 39	Training Loss 0.1283 	Training Prec@1 95.690 	Training Prec@5 99.954 	Validation Loss 0.3859 	Validation Prec@1 88.030 	Validation Prec@5 99.550 

2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:56:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:56:43 - INFO - TRAINING - Epoch: [39][0/196]	Time 1.690 (1.690)	Data 1.636 (1.636)	Loss 0.1578 (0.1578)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 17:56:45 - INFO - TRAINING - Epoch: [39][10/196]	Time 0.118 (0.264)	Data 0.000 (0.149)	Loss 0.1212 (0.1287)	Prec@1 95.703 (95.384)	Prec@5 100.000 (99.929)
2022-06-17 17:56:46 - INFO - TRAINING - Epoch: [39][20/196]	Time 0.127 (0.193)	Data 0.000 (0.078)	Loss 0.1028 (0.1238)	Prec@1 95.703 (95.554)	Prec@5 100.000 (99.963)
2022-06-17 17:56:47 - INFO - TRAINING - Epoch: [39][30/196]	Time 0.108 (0.168)	Data 0.000 (0.053)	Loss 0.1044 (0.1269)	Prec@1 97.266 (95.451)	Prec@5 100.000 (99.962)
2022-06-17 17:56:48 - INFO - TRAINING - Epoch: [39][40/196]	Time 0.129 (0.157)	Data 0.000 (0.040)	Loss 0.1090 (0.1257)	Prec@1 96.484 (95.636)	Prec@5 99.609 (99.943)
2022-06-17 17:56:49 - INFO - TRAINING - Epoch: [39][50/196]	Time 0.104 (0.150)	Data 0.000 (0.032)	Loss 0.1070 (0.1267)	Prec@1 96.484 (95.642)	Prec@5 100.000 (99.946)
2022-06-17 17:56:50 - INFO - TRAINING - Epoch: [39][60/196]	Time 0.128 (0.144)	Data 0.000 (0.027)	Loss 0.1080 (0.1252)	Prec@1 96.094 (95.703)	Prec@5 100.000 (99.949)
2022-06-17 17:56:52 - INFO - TRAINING - Epoch: [39][70/196]	Time 0.107 (0.141)	Data 0.000 (0.023)	Loss 0.2031 (0.1269)	Prec@1 94.531 (95.665)	Prec@5 100.000 (99.956)
2022-06-17 17:56:53 - INFO - TRAINING - Epoch: [39][80/196]	Time 0.108 (0.138)	Data 0.000 (0.020)	Loss 0.1077 (0.1278)	Prec@1 96.875 (95.669)	Prec@5 100.000 (99.952)
2022-06-17 17:56:54 - INFO - TRAINING - Epoch: [39][90/196]	Time 0.108 (0.136)	Data 0.000 (0.018)	Loss 0.1000 (0.1279)	Prec@1 97.266 (95.630)	Prec@5 100.000 (99.953)
2022-06-17 17:56:55 - INFO - TRAINING - Epoch: [39][100/196]	Time 0.124 (0.135)	Data 0.000 (0.016)	Loss 0.1526 (0.1281)	Prec@1 94.922 (95.634)	Prec@5 100.000 (99.957)
2022-06-17 17:56:56 - INFO - TRAINING - Epoch: [39][110/196]	Time 0.110 (0.133)	Data 0.000 (0.015)	Loss 0.1242 (0.1277)	Prec@1 95.703 (95.650)	Prec@5 100.000 (99.961)
2022-06-17 17:56:58 - INFO - TRAINING - Epoch: [39][120/196]	Time 0.133 (0.132)	Data 0.000 (0.014)	Loss 0.1212 (0.1279)	Prec@1 96.875 (95.651)	Prec@5 100.000 (99.964)
2022-06-17 17:56:59 - INFO - TRAINING - Epoch: [39][130/196]	Time 0.103 (0.131)	Data 0.000 (0.013)	Loss 0.1594 (0.1282)	Prec@1 94.531 (95.646)	Prec@5 99.609 (99.961)
2022-06-17 17:57:00 - INFO - TRAINING - Epoch: [39][140/196]	Time 0.129 (0.131)	Data 0.000 (0.012)	Loss 0.1344 (0.1281)	Prec@1 95.703 (95.639)	Prec@5 100.000 (99.964)
2022-06-17 17:57:01 - INFO - TRAINING - Epoch: [39][150/196]	Time 0.113 (0.130)	Data 0.000 (0.011)	Loss 0.0710 (0.1281)	Prec@1 99.219 (95.659)	Prec@5 100.000 (99.961)
2022-06-17 17:57:02 - INFO - TRAINING - Epoch: [39][160/196]	Time 0.132 (0.129)	Data 0.000 (0.010)	Loss 0.1452 (0.1286)	Prec@1 96.484 (95.625)	Prec@5 100.000 (99.961)
2022-06-17 17:57:04 - INFO - TRAINING - Epoch: [39][170/196]	Time 0.106 (0.129)	Data 0.000 (0.010)	Loss 0.1044 (0.1279)	Prec@1 97.266 (95.635)	Prec@5 99.609 (99.961)
2022-06-17 17:57:05 - INFO - TRAINING - Epoch: [39][180/196]	Time 0.120 (0.128)	Data 0.000 (0.009)	Loss 0.1028 (0.1279)	Prec@1 96.484 (95.636)	Prec@5 100.000 (99.961)
2022-06-17 17:57:06 - INFO - TRAINING - Epoch: [39][190/196]	Time 0.105 (0.127)	Data 0.000 (0.009)	Loss 0.1235 (0.1272)	Prec@1 96.094 (95.650)	Prec@5 100.000 (99.963)
2022-06-17 17:57:08 - INFO - EVALUATING - Epoch: [39][0/40]	Time 1.736 (1.736)	Data 1.691 (1.691)	Loss 0.2608 (0.2608)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 17:57:10 - INFO - EVALUATING - Epoch: [39][10/40]	Time 0.057 (0.274)	Data 0.001 (0.224)	Loss 0.4422 (0.3910)	Prec@1 87.891 (88.317)	Prec@5 99.609 (99.432)
2022-06-17 17:57:10 - INFO - EVALUATING - Epoch: [39][20/40]	Time 0.041 (0.170)	Data 0.000 (0.121)	Loss 0.3252 (0.3951)	Prec@1 88.281 (88.114)	Prec@5 100.000 (99.405)
2022-06-17 17:57:11 - INFO - EVALUATING - Epoch: [39][30/40]	Time 0.074 (0.155)	Data 0.031 (0.108)	Loss 0.4705 (0.3888)	Prec@1 85.938 (88.092)	Prec@5 100.000 (99.471)
2022-06-17 17:57:13 - INFO - 
 Epoch: 40	Training Loss 0.1272 	Training Prec@1 95.646 	Training Prec@5 99.964 	Validation Loss 0.3843 	Validation Prec@1 88.060 	Validation Prec@5 99.550 

2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:57:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:57:15 - INFO - TRAINING - Epoch: [40][0/196]	Time 1.686 (1.686)	Data 1.633 (1.633)	Loss 0.1004 (0.1004)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 17:57:16 - INFO - TRAINING - Epoch: [40][10/196]	Time 0.112 (0.282)	Data 0.000 (0.180)	Loss 0.1311 (0.1102)	Prec@1 94.922 (95.703)	Prec@5 100.000 (99.964)
2022-06-17 17:57:17 - INFO - TRAINING - Epoch: [40][20/196]	Time 0.108 (0.201)	Data 0.000 (0.095)	Loss 0.1370 (0.1275)	Prec@1 94.922 (95.312)	Prec@5 100.000 (99.981)
2022-06-17 17:57:19 - INFO - TRAINING - Epoch: [40][30/196]	Time 0.114 (0.174)	Data 0.000 (0.064)	Loss 0.1095 (0.1250)	Prec@1 96.094 (95.464)	Prec@5 100.000 (99.987)
2022-06-17 17:57:20 - INFO - TRAINING - Epoch: [40][40/196]	Time 0.123 (0.159)	Data 0.000 (0.049)	Loss 0.1151 (0.1292)	Prec@1 96.484 (95.398)	Prec@5 100.000 (99.952)
2022-06-17 17:57:21 - INFO - TRAINING - Epoch: [40][50/196]	Time 0.127 (0.151)	Data 0.000 (0.039)	Loss 0.1008 (0.1284)	Prec@1 96.875 (95.420)	Prec@5 100.000 (99.946)
2022-06-17 17:57:22 - INFO - TRAINING - Epoch: [40][60/196]	Time 0.105 (0.145)	Data 0.000 (0.033)	Loss 0.1252 (0.1261)	Prec@1 96.484 (95.530)	Prec@5 100.000 (99.955)
2022-06-17 17:57:23 - INFO - TRAINING - Epoch: [40][70/196]	Time 0.102 (0.141)	Data 0.000 (0.028)	Loss 0.1309 (0.1271)	Prec@1 96.094 (95.505)	Prec@5 100.000 (99.956)
2022-06-17 17:57:24 - INFO - TRAINING - Epoch: [40][80/196]	Time 0.111 (0.138)	Data 0.000 (0.025)	Loss 0.1329 (0.1272)	Prec@1 95.312 (95.501)	Prec@5 100.000 (99.957)
2022-06-17 17:57:26 - INFO - TRAINING - Epoch: [40][90/196]	Time 0.121 (0.136)	Data 0.000 (0.022)	Loss 0.1458 (0.1263)	Prec@1 96.484 (95.549)	Prec@5 100.000 (99.957)
2022-06-17 17:57:27 - INFO - TRAINING - Epoch: [40][100/196]	Time 0.112 (0.134)	Data 0.000 (0.020)	Loss 0.1064 (0.1251)	Prec@1 96.094 (95.618)	Prec@5 100.000 (99.961)
2022-06-17 17:57:28 - INFO - TRAINING - Epoch: [40][110/196]	Time 0.118 (0.133)	Data 0.000 (0.018)	Loss 0.0990 (0.1255)	Prec@1 97.266 (95.643)	Prec@5 100.000 (99.947)
2022-06-17 17:57:29 - INFO - TRAINING - Epoch: [40][120/196]	Time 0.125 (0.131)	Data 0.000 (0.017)	Loss 0.1189 (0.1245)	Prec@1 94.922 (95.687)	Prec@5 100.000 (99.948)
2022-06-17 17:57:30 - INFO - TRAINING - Epoch: [40][130/196]	Time 0.118 (0.130)	Data 0.000 (0.015)	Loss 0.1694 (0.1252)	Prec@1 94.922 (95.643)	Prec@5 100.000 (99.952)
2022-06-17 17:57:31 - INFO - TRAINING - Epoch: [40][140/196]	Time 0.108 (0.129)	Data 0.000 (0.014)	Loss 0.1427 (0.1248)	Prec@1 94.531 (95.681)	Prec@5 100.000 (99.950)
2022-06-17 17:57:33 - INFO - TRAINING - Epoch: [40][150/196]	Time 0.103 (0.129)	Data 0.000 (0.013)	Loss 0.1155 (0.1251)	Prec@1 94.141 (95.662)	Prec@5 100.000 (99.946)
2022-06-17 17:57:34 - INFO - TRAINING - Epoch: [40][160/196]	Time 0.124 (0.128)	Data 0.000 (0.013)	Loss 0.1333 (0.1256)	Prec@1 94.922 (95.638)	Prec@5 100.000 (99.944)
2022-06-17 17:57:35 - INFO - TRAINING - Epoch: [40][170/196]	Time 0.132 (0.127)	Data 0.000 (0.012)	Loss 0.1326 (0.1257)	Prec@1 95.312 (95.644)	Prec@5 100.000 (99.947)
2022-06-17 17:57:36 - INFO - TRAINING - Epoch: [40][180/196]	Time 0.126 (0.127)	Data 0.000 (0.011)	Loss 0.0930 (0.1253)	Prec@1 98.828 (95.666)	Prec@5 99.609 (99.946)
2022-06-17 17:57:37 - INFO - TRAINING - Epoch: [40][190/196]	Time 0.102 (0.126)	Data 0.000 (0.011)	Loss 0.1094 (0.1259)	Prec@1 96.094 (95.646)	Prec@5 100.000 (99.945)
2022-06-17 17:57:39 - INFO - EVALUATING - Epoch: [40][0/40]	Time 1.562 (1.562)	Data 1.517 (1.517)	Loss 0.2588 (0.2588)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 17:57:41 - INFO - EVALUATING - Epoch: [40][10/40]	Time 0.044 (0.270)	Data 0.000 (0.221)	Loss 0.4366 (0.3925)	Prec@1 87.500 (87.997)	Prec@5 99.219 (99.361)
2022-06-17 17:57:41 - INFO - EVALUATING - Epoch: [40][20/40]	Time 0.045 (0.166)	Data 0.000 (0.116)	Loss 0.3175 (0.3950)	Prec@1 87.891 (87.909)	Prec@5 100.000 (99.349)
2022-06-17 17:57:42 - INFO - EVALUATING - Epoch: [40][30/40]	Time 0.101 (0.143)	Data 0.058 (0.094)	Loss 0.4759 (0.3888)	Prec@1 85.938 (87.954)	Prec@5 100.000 (99.433)
2022-06-17 17:57:44 - INFO - 
 Epoch: 41	Training Loss 0.1261 	Training Prec@1 95.648 	Training Prec@5 99.946 	Validation Loss 0.3840 	Validation Prec@1 88.030 	Validation Prec@5 99.520 

2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:57:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:57:46 - INFO - TRAINING - Epoch: [41][0/196]	Time 1.853 (1.853)	Data 1.800 (1.800)	Loss 0.1512 (0.1512)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 17:57:47 - INFO - TRAINING - Epoch: [41][10/196]	Time 0.111 (0.271)	Data 0.000 (0.164)	Loss 0.1316 (0.1215)	Prec@1 94.531 (95.668)	Prec@5 100.000 (99.893)
2022-06-17 17:57:48 - INFO - TRAINING - Epoch: [41][20/196]	Time 0.128 (0.196)	Data 0.000 (0.086)	Loss 0.0958 (0.1274)	Prec@1 97.266 (95.629)	Prec@5 100.000 (99.851)
2022-06-17 17:57:49 - INFO - TRAINING - Epoch: [41][30/196]	Time 0.105 (0.170)	Data 0.000 (0.058)	Loss 0.1901 (0.1300)	Prec@1 94.141 (95.552)	Prec@5 100.000 (99.849)
2022-06-17 17:57:50 - INFO - TRAINING - Epoch: [41][40/196]	Time 0.132 (0.155)	Data 0.000 (0.044)	Loss 0.1526 (0.1291)	Prec@1 94.141 (95.627)	Prec@5 100.000 (99.886)
2022-06-17 17:57:52 - INFO - TRAINING - Epoch: [41][50/196]	Time 0.105 (0.147)	Data 0.000 (0.036)	Loss 0.0701 (0.1262)	Prec@1 97.656 (95.711)	Prec@5 100.000 (99.900)
2022-06-17 17:57:53 - INFO - TRAINING - Epoch: [41][60/196]	Time 0.129 (0.142)	Data 0.000 (0.030)	Loss 0.0945 (0.1261)	Prec@1 96.875 (95.678)	Prec@5 100.000 (99.917)
2022-06-17 17:57:54 - INFO - TRAINING - Epoch: [41][70/196]	Time 0.115 (0.139)	Data 0.000 (0.026)	Loss 0.1355 (0.1242)	Prec@1 96.484 (95.758)	Prec@5 100.000 (99.928)
2022-06-17 17:57:55 - INFO - TRAINING - Epoch: [41][80/196]	Time 0.110 (0.136)	Data 0.000 (0.023)	Loss 0.1543 (0.1252)	Prec@1 94.531 (95.722)	Prec@5 100.000 (99.928)
2022-06-17 17:57:56 - INFO - TRAINING - Epoch: [41][90/196]	Time 0.104 (0.134)	Data 0.000 (0.020)	Loss 0.1367 (0.1251)	Prec@1 94.531 (95.720)	Prec@5 100.000 (99.936)
2022-06-17 17:57:57 - INFO - TRAINING - Epoch: [41][100/196]	Time 0.113 (0.132)	Data 0.000 (0.018)	Loss 0.0772 (0.1233)	Prec@1 98.047 (95.784)	Prec@5 100.000 (99.942)
2022-06-17 17:57:59 - INFO - TRAINING - Epoch: [41][110/196]	Time 0.119 (0.131)	Data 0.000 (0.016)	Loss 0.1281 (0.1240)	Prec@1 94.922 (95.759)	Prec@5 100.000 (99.944)
2022-06-17 17:58:00 - INFO - TRAINING - Epoch: [41][120/196]	Time 0.114 (0.130)	Data 0.000 (0.015)	Loss 0.1137 (0.1222)	Prec@1 95.703 (95.835)	Prec@5 100.000 (99.948)
2022-06-17 17:58:01 - INFO - TRAINING - Epoch: [41][130/196]	Time 0.108 (0.128)	Data 0.000 (0.014)	Loss 0.1797 (0.1235)	Prec@1 93.750 (95.790)	Prec@5 100.000 (99.949)
2022-06-17 17:58:02 - INFO - TRAINING - Epoch: [41][140/196]	Time 0.111 (0.127)	Data 0.000 (0.013)	Loss 0.1345 (0.1237)	Prec@1 94.531 (95.783)	Prec@5 100.000 (99.953)
2022-06-17 17:58:03 - INFO - TRAINING - Epoch: [41][150/196]	Time 0.125 (0.126)	Data 0.000 (0.012)	Loss 0.1408 (0.1229)	Prec@1 94.141 (95.796)	Prec@5 100.000 (99.953)
2022-06-17 17:58:04 - INFO - TRAINING - Epoch: [41][160/196]	Time 0.132 (0.126)	Data 0.000 (0.011)	Loss 0.1608 (0.1237)	Prec@1 93.750 (95.742)	Prec@5 100.000 (99.956)
2022-06-17 17:58:05 - INFO - TRAINING - Epoch: [41][170/196]	Time 0.108 (0.125)	Data 0.000 (0.011)	Loss 0.1180 (0.1241)	Prec@1 95.312 (95.735)	Prec@5 100.000 (99.954)
2022-06-17 17:58:07 - INFO - TRAINING - Epoch: [41][180/196]	Time 0.107 (0.124)	Data 0.000 (0.010)	Loss 0.0524 (0.1234)	Prec@1 98.438 (95.766)	Prec@5 100.000 (99.957)
2022-06-17 17:58:08 - INFO - TRAINING - Epoch: [41][190/196]	Time 0.101 (0.124)	Data 0.000 (0.010)	Loss 0.1657 (0.1231)	Prec@1 94.141 (95.769)	Prec@5 100.000 (99.957)
2022-06-17 17:58:10 - INFO - EVALUATING - Epoch: [41][0/40]	Time 1.967 (1.967)	Data 1.921 (1.921)	Loss 0.2656 (0.2656)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 17:58:11 - INFO - EVALUATING - Epoch: [41][10/40]	Time 0.070 (0.255)	Data 0.000 (0.207)	Loss 0.4416 (0.3955)	Prec@1 88.281 (88.068)	Prec@5 99.609 (99.396)
2022-06-17 17:58:12 - INFO - EVALUATING - Epoch: [41][20/40]	Time 0.087 (0.158)	Data 0.045 (0.111)	Loss 0.3218 (0.3972)	Prec@1 87.891 (88.002)	Prec@5 100.000 (99.368)
2022-06-17 17:58:13 - INFO - EVALUATING - Epoch: [41][30/40]	Time 0.098 (0.142)	Data 0.056 (0.096)	Loss 0.4694 (0.3903)	Prec@1 85.938 (88.042)	Prec@5 100.000 (99.433)
2022-06-17 17:58:15 - INFO - 
 Epoch: 42	Training Loss 0.1232 	Training Prec@1 95.756 	Training Prec@5 99.956 	Validation Loss 0.3855 	Validation Prec@1 88.050 	Validation Prec@5 99.510 

2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:58:15 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:58:17 - INFO - TRAINING - Epoch: [42][0/196]	Time 2.001 (2.001)	Data 1.949 (1.949)	Loss 0.1228 (0.1228)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 17:58:18 - INFO - TRAINING - Epoch: [42][10/196]	Time 0.103 (0.285)	Data 0.000 (0.177)	Loss 0.1246 (0.1383)	Prec@1 95.312 (95.348)	Prec@5 100.000 (100.000)
2022-06-17 17:58:19 - INFO - TRAINING - Epoch: [42][20/196]	Time 0.127 (0.202)	Data 0.000 (0.093)	Loss 0.1276 (0.1318)	Prec@1 95.312 (95.499)	Prec@5 99.609 (99.963)
2022-06-17 17:58:20 - INFO - TRAINING - Epoch: [42][30/196]	Time 0.114 (0.173)	Data 0.000 (0.063)	Loss 0.1150 (0.1304)	Prec@1 96.094 (95.489)	Prec@5 100.000 (99.950)
2022-06-17 17:58:21 - INFO - TRAINING - Epoch: [42][40/196]	Time 0.119 (0.160)	Data 0.000 (0.048)	Loss 0.0826 (0.1279)	Prec@1 98.047 (95.722)	Prec@5 100.000 (99.962)
2022-06-17 17:58:22 - INFO - TRAINING - Epoch: [42][50/196]	Time 0.106 (0.150)	Data 0.000 (0.038)	Loss 0.0671 (0.1261)	Prec@1 98.828 (95.833)	Prec@5 100.000 (99.962)
2022-06-17 17:58:23 - INFO - TRAINING - Epoch: [42][60/196]	Time 0.121 (0.145)	Data 0.000 (0.032)	Loss 0.1454 (0.1274)	Prec@1 94.141 (95.793)	Prec@5 100.000 (99.949)
2022-06-17 17:58:25 - INFO - TRAINING - Epoch: [42][70/196]	Time 0.128 (0.140)	Data 0.000 (0.028)	Loss 0.1264 (0.1274)	Prec@1 96.094 (95.819)	Prec@5 100.000 (99.939)
2022-06-17 17:58:26 - INFO - TRAINING - Epoch: [42][80/196]	Time 0.113 (0.136)	Data 0.000 (0.024)	Loss 0.1770 (0.1274)	Prec@1 94.141 (95.804)	Prec@5 99.609 (99.932)
2022-06-17 17:58:27 - INFO - TRAINING - Epoch: [42][90/196]	Time 0.133 (0.134)	Data 0.000 (0.022)	Loss 0.1029 (0.1279)	Prec@1 96.484 (95.746)	Prec@5 100.000 (99.940)
2022-06-17 17:58:28 - INFO - TRAINING - Epoch: [42][100/196]	Time 0.111 (0.132)	Data 0.000 (0.020)	Loss 0.0893 (0.1273)	Prec@1 97.266 (95.757)	Prec@5 100.000 (99.938)
2022-06-17 17:58:29 - INFO - TRAINING - Epoch: [42][110/196]	Time 0.111 (0.130)	Data 0.000 (0.018)	Loss 0.1623 (0.1288)	Prec@1 93.359 (95.703)	Prec@5 100.000 (99.944)
2022-06-17 17:58:30 - INFO - TRAINING - Epoch: [42][120/196]	Time 0.126 (0.129)	Data 0.000 (0.016)	Loss 0.1058 (0.1265)	Prec@1 96.875 (95.781)	Prec@5 100.000 (99.945)
2022-06-17 17:58:31 - INFO - TRAINING - Epoch: [42][130/196]	Time 0.111 (0.128)	Data 0.000 (0.015)	Loss 0.0894 (0.1266)	Prec@1 98.047 (95.754)	Prec@5 100.000 (99.943)
2022-06-17 17:58:32 - INFO - TRAINING - Epoch: [42][140/196]	Time 0.102 (0.126)	Data 0.000 (0.014)	Loss 0.1175 (0.1269)	Prec@1 95.312 (95.739)	Prec@5 100.000 (99.947)
2022-06-17 17:58:33 - INFO - TRAINING - Epoch: [42][150/196]	Time 0.113 (0.125)	Data 0.000 (0.013)	Loss 0.0998 (0.1263)	Prec@1 96.484 (95.768)	Prec@5 100.000 (99.948)
2022-06-17 17:58:35 - INFO - TRAINING - Epoch: [42][160/196]	Time 0.116 (0.125)	Data 0.000 (0.012)	Loss 0.0965 (0.1264)	Prec@1 95.703 (95.747)	Prec@5 100.000 (99.949)
2022-06-17 17:58:36 - INFO - TRAINING - Epoch: [42][170/196]	Time 0.107 (0.124)	Data 0.000 (0.012)	Loss 0.1383 (0.1266)	Prec@1 95.312 (95.749)	Prec@5 99.609 (99.950)
2022-06-17 17:58:37 - INFO - TRAINING - Epoch: [42][180/196]	Time 0.119 (0.124)	Data 0.000 (0.011)	Loss 0.1305 (0.1269)	Prec@1 96.094 (95.755)	Prec@5 100.000 (99.950)
2022-06-17 17:58:38 - INFO - TRAINING - Epoch: [42][190/196]	Time 0.111 (0.123)	Data 0.000 (0.011)	Loss 0.1063 (0.1269)	Prec@1 96.875 (95.734)	Prec@5 100.000 (99.949)
2022-06-17 17:58:41 - INFO - EVALUATING - Epoch: [42][0/40]	Time 1.944 (1.944)	Data 1.898 (1.898)	Loss 0.2644 (0.2644)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
2022-06-17 17:58:42 - INFO - EVALUATING - Epoch: [42][10/40]	Time 0.044 (0.275)	Data 0.000 (0.224)	Loss 0.4424 (0.3938)	Prec@1 88.281 (88.423)	Prec@5 99.609 (99.396)
2022-06-17 17:58:42 - INFO - EVALUATING - Epoch: [42][20/40]	Time 0.041 (0.169)	Data 0.000 (0.117)	Loss 0.3216 (0.3958)	Prec@1 88.281 (88.170)	Prec@5 100.000 (99.405)
2022-06-17 17:58:44 - INFO - EVALUATING - Epoch: [42][30/40]	Time 0.265 (0.156)	Data 0.223 (0.107)	Loss 0.4683 (0.3896)	Prec@1 85.547 (88.080)	Prec@5 100.000 (99.458)
2022-06-17 17:58:46 - INFO - 
 Epoch: 43	Training Loss 0.1274 	Training Prec@1 95.732 	Training Prec@5 99.950 	Validation Loss 0.3857 	Validation Prec@1 88.090 	Validation Prec@5 99.540 

2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:58:46 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:58:48 - INFO - TRAINING - Epoch: [43][0/196]	Time 1.972 (1.972)	Data 1.917 (1.917)	Loss 0.1059 (0.1059)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 17:58:49 - INFO - TRAINING - Epoch: [43][10/196]	Time 0.101 (0.276)	Data 0.000 (0.178)	Loss 0.1555 (0.1221)	Prec@1 93.359 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 17:58:50 - INFO - TRAINING - Epoch: [43][20/196]	Time 0.118 (0.197)	Data 0.000 (0.093)	Loss 0.0891 (0.1176)	Prec@1 97.656 (95.647)	Prec@5 100.000 (99.981)
2022-06-17 17:58:51 - INFO - TRAINING - Epoch: [43][30/196]	Time 0.106 (0.168)	Data 0.001 (0.063)	Loss 0.0788 (0.1209)	Prec@1 98.438 (95.665)	Prec@5 100.000 (99.987)
2022-06-17 17:58:52 - INFO - TRAINING - Epoch: [43][40/196]	Time 0.117 (0.154)	Data 0.000 (0.048)	Loss 0.1450 (0.1212)	Prec@1 95.703 (95.675)	Prec@5 100.000 (99.990)
2022-06-17 17:58:53 - INFO - TRAINING - Epoch: [43][50/196]	Time 0.122 (0.146)	Data 0.000 (0.039)	Loss 0.0990 (0.1241)	Prec@1 96.094 (95.581)	Prec@5 100.000 (99.992)
2022-06-17 17:58:55 - INFO - TRAINING - Epoch: [43][60/196]	Time 0.120 (0.140)	Data 0.001 (0.032)	Loss 0.0695 (0.1241)	Prec@1 98.828 (95.588)	Prec@5 100.000 (99.981)
2022-06-17 17:58:56 - INFO - TRAINING - Epoch: [43][70/196]	Time 0.105 (0.136)	Data 0.000 (0.028)	Loss 0.1131 (0.1221)	Prec@1 95.703 (95.703)	Prec@5 100.000 (99.983)
2022-06-17 17:58:57 - INFO - TRAINING - Epoch: [43][80/196]	Time 0.114 (0.133)	Data 0.000 (0.024)	Loss 0.0924 (0.1229)	Prec@1 97.266 (95.693)	Prec@5 100.000 (99.986)
2022-06-17 17:58:58 - INFO - TRAINING - Epoch: [43][90/196]	Time 0.105 (0.130)	Data 0.000 (0.022)	Loss 0.2065 (0.1241)	Prec@1 93.359 (95.600)	Prec@5 99.219 (99.974)
2022-06-17 17:58:59 - INFO - TRAINING - Epoch: [43][100/196]	Time 0.097 (0.128)	Data 0.000 (0.020)	Loss 0.1023 (0.1243)	Prec@1 95.703 (95.634)	Prec@5 100.000 (99.969)
2022-06-17 17:59:00 - INFO - TRAINING - Epoch: [43][110/196]	Time 0.117 (0.127)	Data 0.000 (0.018)	Loss 0.1239 (0.1228)	Prec@1 95.703 (95.686)	Prec@5 100.000 (99.972)
2022-06-17 17:59:01 - INFO - TRAINING - Epoch: [43][120/196]	Time 0.127 (0.126)	Data 0.000 (0.016)	Loss 0.2109 (0.1226)	Prec@1 94.531 (95.729)	Prec@5 99.219 (99.968)
2022-06-17 17:59:02 - INFO - TRAINING - Epoch: [43][130/196]	Time 0.123 (0.126)	Data 0.000 (0.015)	Loss 0.1591 (0.1230)	Prec@1 94.922 (95.727)	Prec@5 100.000 (99.967)
2022-06-17 17:59:03 - INFO - TRAINING - Epoch: [43][140/196]	Time 0.108 (0.124)	Data 0.000 (0.014)	Loss 0.1414 (0.1245)	Prec@1 94.141 (95.709)	Prec@5 100.000 (99.958)
2022-06-17 17:59:05 - INFO - TRAINING - Epoch: [43][150/196]	Time 0.110 (0.123)	Data 0.000 (0.013)	Loss 0.1072 (0.1250)	Prec@1 96.094 (95.695)	Prec@5 100.000 (99.961)
2022-06-17 17:59:06 - INFO - TRAINING - Epoch: [43][160/196]	Time 0.104 (0.123)	Data 0.000 (0.012)	Loss 0.0796 (0.1246)	Prec@1 96.875 (95.686)	Prec@5 100.000 (99.959)
2022-06-17 17:59:07 - INFO - TRAINING - Epoch: [43][170/196]	Time 0.103 (0.122)	Data 0.000 (0.012)	Loss 0.1464 (0.1257)	Prec@1 96.094 (95.644)	Prec@5 100.000 (99.961)
2022-06-17 17:59:08 - INFO - TRAINING - Epoch: [43][180/196]	Time 0.111 (0.121)	Data 0.000 (0.011)	Loss 0.0983 (0.1258)	Prec@1 96.875 (95.647)	Prec@5 100.000 (99.959)
2022-06-17 17:59:09 - INFO - TRAINING - Epoch: [43][190/196]	Time 0.104 (0.121)	Data 0.000 (0.011)	Loss 0.1595 (0.1258)	Prec@1 93.750 (95.644)	Prec@5 100.000 (99.957)
2022-06-17 17:59:11 - INFO - EVALUATING - Epoch: [43][0/40]	Time 1.558 (1.558)	Data 1.512 (1.512)	Loss 0.2626 (0.2626)	Prec@1 92.969 (92.969)	Prec@5 99.609 (99.609)
2022-06-17 17:59:13 - INFO - EVALUATING - Epoch: [43][10/40]	Time 0.058 (0.285)	Data 0.000 (0.236)	Loss 0.4557 (0.3936)	Prec@1 87.500 (88.423)	Prec@5 99.219 (99.361)
2022-06-17 17:59:13 - INFO - EVALUATING - Epoch: [43][20/40]	Time 0.042 (0.179)	Data 0.000 (0.131)	Loss 0.3148 (0.3969)	Prec@1 88.281 (88.132)	Prec@5 100.000 (99.349)
2022-06-17 17:59:14 - INFO - EVALUATING - Epoch: [43][30/40]	Time 0.094 (0.153)	Data 0.052 (0.106)	Loss 0.4684 (0.3899)	Prec@1 85.547 (88.168)	Prec@5 100.000 (99.420)
2022-06-17 17:59:17 - INFO - 
 Epoch: 44	Training Loss 0.1249 	Training Prec@1 95.680 	Training Prec@5 99.958 	Validation Loss 0.3855 	Validation Prec@1 88.240 	Validation Prec@5 99.520 

2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:59:17 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:59:18 - INFO - TRAINING - Epoch: [44][0/196]	Time 1.426 (1.426)	Data 1.372 (1.372)	Loss 0.1936 (0.1936)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 17:59:20 - INFO - TRAINING - Epoch: [44][10/196]	Time 0.109 (0.276)	Data 0.000 (0.172)	Loss 0.1207 (0.1380)	Prec@1 95.312 (95.206)	Prec@5 100.000 (99.964)
2022-06-17 17:59:21 - INFO - TRAINING - Epoch: [44][20/196]	Time 0.106 (0.197)	Data 0.000 (0.090)	Loss 0.0970 (0.1335)	Prec@1 96.484 (95.387)	Prec@5 100.000 (99.963)
2022-06-17 17:59:22 - INFO - TRAINING - Epoch: [44][30/196]	Time 0.115 (0.173)	Data 0.000 (0.061)	Loss 0.1382 (0.1312)	Prec@1 94.922 (95.602)	Prec@5 100.000 (99.950)
2022-06-17 17:59:23 - INFO - TRAINING - Epoch: [44][40/196]	Time 0.117 (0.157)	Data 0.000 (0.046)	Loss 0.1493 (0.1253)	Prec@1 94.531 (95.779)	Prec@5 100.000 (99.962)
2022-06-17 17:59:25 - INFO - TRAINING - Epoch: [44][50/196]	Time 0.109 (0.150)	Data 0.000 (0.037)	Loss 0.1606 (0.1266)	Prec@1 91.797 (95.695)	Prec@5 100.000 (99.946)
2022-06-17 17:59:26 - INFO - TRAINING - Epoch: [44][60/196]	Time 0.114 (0.145)	Data 0.000 (0.031)	Loss 0.1022 (0.1272)	Prec@1 97.656 (95.722)	Prec@5 100.000 (99.955)
2022-06-17 17:59:27 - INFO - TRAINING - Epoch: [44][70/196]	Time 0.121 (0.142)	Data 0.000 (0.027)	Loss 0.1116 (0.1263)	Prec@1 96.094 (95.714)	Prec@5 100.000 (99.961)
2022-06-17 17:59:28 - INFO - TRAINING - Epoch: [44][80/196]	Time 0.103 (0.139)	Data 0.000 (0.024)	Loss 0.1097 (0.1258)	Prec@1 97.266 (95.747)	Prec@5 100.000 (99.957)
2022-06-17 17:59:29 - INFO - TRAINING - Epoch: [44][90/196]	Time 0.119 (0.137)	Data 0.000 (0.021)	Loss 0.1596 (0.1275)	Prec@1 94.531 (95.695)	Prec@5 100.000 (99.953)
2022-06-17 17:59:31 - INFO - TRAINING - Epoch: [44][100/196]	Time 0.119 (0.135)	Data 0.000 (0.019)	Loss 0.1593 (0.1259)	Prec@1 94.141 (95.769)	Prec@5 99.609 (99.950)
2022-06-17 17:59:32 - INFO - TRAINING - Epoch: [44][110/196]	Time 0.106 (0.133)	Data 0.000 (0.017)	Loss 0.0955 (0.1274)	Prec@1 96.484 (95.717)	Prec@5 100.000 (99.951)
2022-06-17 17:59:33 - INFO - TRAINING - Epoch: [44][120/196]	Time 0.109 (0.132)	Data 0.000 (0.016)	Loss 0.1391 (0.1284)	Prec@1 94.531 (95.661)	Prec@5 100.000 (99.952)
2022-06-17 17:59:34 - INFO - TRAINING - Epoch: [44][130/196]	Time 0.113 (0.131)	Data 0.000 (0.015)	Loss 0.0586 (0.1276)	Prec@1 98.047 (95.691)	Prec@5 100.000 (99.955)
2022-06-17 17:59:35 - INFO - TRAINING - Epoch: [44][140/196]	Time 0.136 (0.130)	Data 0.000 (0.014)	Loss 0.1339 (0.1274)	Prec@1 94.531 (95.700)	Prec@5 100.000 (99.950)
2022-06-17 17:59:36 - INFO - TRAINING - Epoch: [44][150/196]	Time 0.116 (0.129)	Data 0.000 (0.013)	Loss 0.1431 (0.1283)	Prec@1 94.922 (95.675)	Prec@5 100.000 (99.946)
2022-06-17 17:59:37 - INFO - TRAINING - Epoch: [44][160/196]	Time 0.129 (0.128)	Data 0.000 (0.012)	Loss 0.1038 (0.1270)	Prec@1 96.484 (95.720)	Prec@5 100.000 (99.949)
2022-06-17 17:59:39 - INFO - TRAINING - Epoch: [44][170/196]	Time 0.103 (0.127)	Data 0.000 (0.011)	Loss 0.1157 (0.1265)	Prec@1 95.312 (95.751)	Prec@5 100.000 (99.950)
2022-06-17 17:59:40 - INFO - TRAINING - Epoch: [44][180/196]	Time 0.109 (0.126)	Data 0.000 (0.011)	Loss 0.1098 (0.1261)	Prec@1 96.875 (95.759)	Prec@5 100.000 (99.953)
2022-06-17 17:59:41 - INFO - TRAINING - Epoch: [44][190/196]	Time 0.106 (0.126)	Data 0.000 (0.010)	Loss 0.1274 (0.1262)	Prec@1 95.703 (95.719)	Prec@5 100.000 (99.955)
2022-06-17 17:59:43 - INFO - EVALUATING - Epoch: [44][0/40]	Time 1.606 (1.606)	Data 1.560 (1.560)	Loss 0.2632 (0.2632)	Prec@1 92.578 (92.578)	Prec@5 99.609 (99.609)
2022-06-17 17:59:44 - INFO - EVALUATING - Epoch: [44][10/40]	Time 0.045 (0.254)	Data 0.000 (0.205)	Loss 0.4508 (0.3960)	Prec@1 87.891 (88.104)	Prec@5 99.609 (99.432)
2022-06-17 17:59:45 - INFO - EVALUATING - Epoch: [44][20/40]	Time 0.041 (0.177)	Data 0.000 (0.128)	Loss 0.3220 (0.3978)	Prec@1 87.891 (87.965)	Prec@5 100.000 (99.442)
2022-06-17 17:59:46 - INFO - EVALUATING - Epoch: [44][30/40]	Time 0.089 (0.149)	Data 0.049 (0.102)	Loss 0.4661 (0.3910)	Prec@1 85.547 (87.954)	Prec@5 100.000 (99.483)
2022-06-17 17:59:48 - INFO - 
 Epoch: 45	Training Loss 0.1259 	Training Prec@1 95.722 	Training Prec@5 99.956 	Validation Loss 0.3866 	Validation Prec@1 88.020 	Validation Prec@5 99.550 

2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 17:59:48 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 17:59:49 - INFO - TRAINING - Epoch: [45][0/196]	Time 1.480 (1.480)	Data 1.426 (1.426)	Loss 0.0915 (0.0915)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 17:59:51 - INFO - TRAINING - Epoch: [45][10/196]	Time 0.105 (0.275)	Data 0.000 (0.178)	Loss 0.1281 (0.1268)	Prec@1 96.094 (96.094)	Prec@5 100.000 (99.893)
2022-06-17 17:59:52 - INFO - TRAINING - Epoch: [45][20/196]	Time 0.112 (0.198)	Data 0.000 (0.093)	Loss 0.0914 (0.1180)	Prec@1 96.875 (96.075)	Prec@5 100.000 (99.926)
2022-06-17 17:59:53 - INFO - TRAINING - Epoch: [45][30/196]	Time 0.105 (0.172)	Data 0.000 (0.063)	Loss 0.0946 (0.1223)	Prec@1 96.484 (95.905)	Prec@5 100.000 (99.924)
2022-06-17 17:59:54 - INFO - TRAINING - Epoch: [45][40/196]	Time 0.114 (0.158)	Data 0.000 (0.048)	Loss 0.1087 (0.1207)	Prec@1 96.484 (95.856)	Prec@5 100.000 (99.943)
2022-06-17 17:59:56 - INFO - TRAINING - Epoch: [45][50/196]	Time 0.103 (0.148)	Data 0.000 (0.039)	Loss 0.0850 (0.1205)	Prec@1 97.656 (95.902)	Prec@5 100.000 (99.954)
2022-06-17 17:59:57 - INFO - TRAINING - Epoch: [45][60/196]	Time 0.123 (0.143)	Data 0.001 (0.032)	Loss 0.1053 (0.1214)	Prec@1 96.094 (95.818)	Prec@5 100.000 (99.955)
2022-06-17 17:59:58 - INFO - TRAINING - Epoch: [45][70/196]	Time 0.115 (0.138)	Data 0.000 (0.028)	Loss 0.1328 (0.1205)	Prec@1 95.703 (95.813)	Prec@5 99.609 (99.956)
2022-06-17 17:59:59 - INFO - TRAINING - Epoch: [45][80/196]	Time 0.104 (0.135)	Data 0.001 (0.024)	Loss 0.1396 (0.1218)	Prec@1 95.703 (95.761)	Prec@5 100.000 (99.961)
2022-06-17 18:00:00 - INFO - TRAINING - Epoch: [45][90/196]	Time 0.105 (0.132)	Data 0.000 (0.022)	Loss 0.1719 (0.1227)	Prec@1 94.141 (95.716)	Prec@5 100.000 (99.966)
2022-06-17 18:00:01 - INFO - TRAINING - Epoch: [45][100/196]	Time 0.126 (0.131)	Data 0.000 (0.020)	Loss 0.1029 (0.1229)	Prec@1 97.266 (95.703)	Prec@5 100.000 (99.965)
2022-06-17 18:00:02 - INFO - TRAINING - Epoch: [45][110/196]	Time 0.114 (0.130)	Data 0.000 (0.018)	Loss 0.0864 (0.1234)	Prec@1 97.656 (95.682)	Prec@5 100.000 (99.961)
2022-06-17 18:00:03 - INFO - TRAINING - Epoch: [45][120/196]	Time 0.102 (0.128)	Data 0.000 (0.017)	Loss 0.1144 (0.1231)	Prec@1 96.875 (95.732)	Prec@5 99.219 (99.958)
2022-06-17 18:00:05 - INFO - TRAINING - Epoch: [45][130/196]	Time 0.102 (0.126)	Data 0.000 (0.015)	Loss 0.0998 (0.1239)	Prec@1 95.703 (95.679)	Prec@5 100.000 (99.961)
2022-06-17 18:00:06 - INFO - TRAINING - Epoch: [45][140/196]	Time 0.106 (0.126)	Data 0.000 (0.014)	Loss 0.1181 (0.1241)	Prec@1 96.484 (95.681)	Prec@5 100.000 (99.961)
2022-06-17 18:00:07 - INFO - TRAINING - Epoch: [45][150/196]	Time 0.105 (0.125)	Data 0.000 (0.013)	Loss 0.1190 (0.1234)	Prec@1 94.922 (95.698)	Prec@5 100.000 (99.961)
2022-06-17 18:00:08 - INFO - TRAINING - Epoch: [45][160/196]	Time 0.114 (0.124)	Data 0.000 (0.012)	Loss 0.1061 (0.1230)	Prec@1 96.875 (95.701)	Prec@5 100.000 (99.959)
2022-06-17 18:00:09 - INFO - TRAINING - Epoch: [45][170/196]	Time 0.117 (0.123)	Data 0.000 (0.012)	Loss 0.0972 (0.1228)	Prec@1 97.266 (95.710)	Prec@5 100.000 (99.954)
2022-06-17 18:00:10 - INFO - TRAINING - Epoch: [45][180/196]	Time 0.106 (0.123)	Data 0.000 (0.011)	Loss 0.1529 (0.1233)	Prec@1 93.359 (95.666)	Prec@5 100.000 (99.957)
2022-06-17 18:00:11 - INFO - TRAINING - Epoch: [45][190/196]	Time 0.101 (0.122)	Data 0.000 (0.011)	Loss 0.1655 (0.1244)	Prec@1 95.703 (95.638)	Prec@5 100.000 (99.957)
2022-06-17 18:00:14 - INFO - EVALUATING - Epoch: [45][0/40]	Time 1.657 (1.657)	Data 1.611 (1.611)	Loss 0.2672 (0.2672)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:00:15 - INFO - EVALUATING - Epoch: [45][10/40]	Time 0.069 (0.283)	Data 0.000 (0.233)	Loss 0.4550 (0.3982)	Prec@1 87.500 (88.104)	Prec@5 99.609 (99.467)
2022-06-17 18:00:16 - INFO - EVALUATING - Epoch: [45][20/40]	Time 0.042 (0.172)	Data 0.001 (0.124)	Loss 0.3216 (0.3994)	Prec@1 87.891 (88.039)	Prec@5 100.000 (99.423)
2022-06-17 18:00:17 - INFO - EVALUATING - Epoch: [45][30/40]	Time 0.042 (0.160)	Data 0.000 (0.113)	Loss 0.4786 (0.3926)	Prec@1 85.938 (88.054)	Prec@5 100.000 (99.471)
2022-06-17 18:00:19 - INFO - 
 Epoch: 46	Training Loss 0.1247 	Training Prec@1 95.640 	Training Prec@5 99.958 	Validation Loss 0.3876 	Validation Prec@1 88.060 	Validation Prec@5 99.540 

2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:00:19 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:00:20 - INFO - TRAINING - Epoch: [46][0/196]	Time 1.665 (1.665)	Data 1.611 (1.611)	Loss 0.1090 (0.1090)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:00:22 - INFO - TRAINING - Epoch: [46][10/196]	Time 0.107 (0.262)	Data 0.000 (0.163)	Loss 0.1345 (0.1075)	Prec@1 94.141 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:00:23 - INFO - TRAINING - Epoch: [46][20/196]	Time 0.107 (0.190)	Data 0.000 (0.086)	Loss 0.1409 (0.1149)	Prec@1 95.312 (96.019)	Prec@5 100.000 (100.000)
2022-06-17 18:00:24 - INFO - TRAINING - Epoch: [46][30/196]	Time 0.112 (0.163)	Data 0.000 (0.058)	Loss 0.1894 (0.1180)	Prec@1 93.359 (96.031)	Prec@5 100.000 (100.000)
2022-06-17 18:00:25 - INFO - TRAINING - Epoch: [46][40/196]	Time 0.111 (0.150)	Data 0.000 (0.044)	Loss 0.1159 (0.1196)	Prec@1 95.703 (96.037)	Prec@5 100.000 (99.990)
2022-06-17 18:00:26 - INFO - TRAINING - Epoch: [46][50/196]	Time 0.110 (0.141)	Data 0.000 (0.035)	Loss 0.1383 (0.1201)	Prec@1 95.703 (95.941)	Prec@5 100.000 (99.985)
2022-06-17 18:00:27 - INFO - TRAINING - Epoch: [46][60/196]	Time 0.112 (0.136)	Data 0.000 (0.030)	Loss 0.1266 (0.1209)	Prec@1 94.922 (95.863)	Prec@5 100.000 (99.981)
2022-06-17 18:00:28 - INFO - TRAINING - Epoch: [46][70/196]	Time 0.105 (0.132)	Data 0.000 (0.026)	Loss 0.1500 (0.1227)	Prec@1 94.531 (95.764)	Prec@5 100.000 (99.983)
2022-06-17 18:00:29 - INFO - TRAINING - Epoch: [46][80/196]	Time 0.105 (0.130)	Data 0.000 (0.022)	Loss 0.1284 (0.1225)	Prec@1 95.312 (95.747)	Prec@5 100.000 (99.986)
2022-06-17 18:00:30 - INFO - TRAINING - Epoch: [46][90/196]	Time 0.108 (0.128)	Data 0.000 (0.020)	Loss 0.0820 (0.1220)	Prec@1 96.484 (95.729)	Prec@5 100.000 (99.987)
2022-06-17 18:00:32 - INFO - TRAINING - Epoch: [46][100/196]	Time 0.113 (0.127)	Data 0.000 (0.018)	Loss 0.0984 (0.1215)	Prec@1 96.094 (95.769)	Prec@5 100.000 (99.988)
2022-06-17 18:00:33 - INFO - TRAINING - Epoch: [46][110/196]	Time 0.112 (0.125)	Data 0.000 (0.016)	Loss 0.1357 (0.1217)	Prec@1 95.703 (95.777)	Prec@5 100.000 (99.979)
2022-06-17 18:00:34 - INFO - TRAINING - Epoch: [46][120/196]	Time 0.108 (0.124)	Data 0.000 (0.015)	Loss 0.1489 (0.1210)	Prec@1 94.922 (95.777)	Prec@5 100.000 (99.981)
2022-06-17 18:00:35 - INFO - TRAINING - Epoch: [46][130/196]	Time 0.116 (0.123)	Data 0.000 (0.014)	Loss 0.0911 (0.1203)	Prec@1 98.047 (95.819)	Prec@5 100.000 (99.979)
2022-06-17 18:00:36 - INFO - TRAINING - Epoch: [46][140/196]	Time 0.131 (0.123)	Data 0.000 (0.013)	Loss 0.1374 (0.1204)	Prec@1 94.531 (95.786)	Prec@5 100.000 (99.978)
2022-06-17 18:00:37 - INFO - TRAINING - Epoch: [46][150/196]	Time 0.113 (0.122)	Data 0.000 (0.012)	Loss 0.0740 (0.1199)	Prec@1 96.484 (95.801)	Prec@5 100.000 (99.979)
2022-06-17 18:00:38 - INFO - TRAINING - Epoch: [46][160/196]	Time 0.106 (0.122)	Data 0.001 (0.011)	Loss 0.0936 (0.1200)	Prec@1 98.438 (95.807)	Prec@5 99.609 (99.973)
2022-06-17 18:00:40 - INFO - TRAINING - Epoch: [46][170/196]	Time 0.110 (0.122)	Data 0.000 (0.011)	Loss 0.1109 (0.1205)	Prec@1 96.484 (95.804)	Prec@5 100.000 (99.975)
2022-06-17 18:00:41 - INFO - TRAINING - Epoch: [46][180/196]	Time 0.106 (0.121)	Data 0.000 (0.010)	Loss 0.1298 (0.1209)	Prec@1 96.875 (95.794)	Prec@5 100.000 (99.972)
2022-06-17 18:00:42 - INFO - TRAINING - Epoch: [46][190/196]	Time 0.089 (0.121)	Data 0.000 (0.010)	Loss 0.1737 (0.1219)	Prec@1 92.578 (95.738)	Prec@5 99.609 (99.969)
2022-06-17 18:00:44 - INFO - EVALUATING - Epoch: [46][0/40]	Time 1.886 (1.886)	Data 1.840 (1.840)	Loss 0.2589 (0.2589)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:00:45 - INFO - EVALUATING - Epoch: [46][10/40]	Time 0.119 (0.258)	Data 0.076 (0.212)	Loss 0.4449 (0.3936)	Prec@1 88.281 (88.033)	Prec@5 99.219 (99.361)
2022-06-17 18:00:46 - INFO - EVALUATING - Epoch: [46][20/40]	Time 0.092 (0.174)	Data 0.047 (0.128)	Loss 0.3196 (0.3971)	Prec@1 87.500 (87.928)	Prec@5 100.000 (99.368)
2022-06-17 18:00:47 - INFO - EVALUATING - Epoch: [46][30/40]	Time 0.050 (0.159)	Data 0.000 (0.113)	Loss 0.4728 (0.3905)	Prec@1 85.938 (88.004)	Prec@5 100.000 (99.446)
2022-06-17 18:00:49 - INFO - 
 Epoch: 47	Training Loss 0.1220 	Training Prec@1 95.736 	Training Prec@5 99.970 	Validation Loss 0.3862 	Validation Prec@1 88.030 	Validation Prec@5 99.520 

2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:00:49 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:00:51 - INFO - TRAINING - Epoch: [47][0/196]	Time 1.820 (1.820)	Data 1.767 (1.767)	Loss 0.1142 (0.1142)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:00:52 - INFO - TRAINING - Epoch: [47][10/196]	Time 0.119 (0.271)	Data 0.000 (0.161)	Loss 0.1557 (0.1306)	Prec@1 94.531 (95.739)	Prec@5 100.000 (99.929)
2022-06-17 18:00:53 - INFO - TRAINING - Epoch: [47][20/196]	Time 0.107 (0.200)	Data 0.000 (0.084)	Loss 0.1835 (0.1271)	Prec@1 94.531 (95.908)	Prec@5 100.000 (99.963)
2022-06-17 18:00:54 - INFO - TRAINING - Epoch: [47][30/196]	Time 0.116 (0.172)	Data 0.000 (0.057)	Loss 0.1414 (0.1275)	Prec@1 96.094 (95.817)	Prec@5 100.000 (99.950)
2022-06-17 18:00:56 - INFO - TRAINING - Epoch: [47][40/196]	Time 0.112 (0.158)	Data 0.000 (0.043)	Loss 0.1453 (0.1273)	Prec@1 94.531 (95.779)	Prec@5 99.609 (99.952)
2022-06-17 18:00:57 - INFO - TRAINING - Epoch: [47][50/196]	Time 0.126 (0.150)	Data 0.000 (0.035)	Loss 0.1393 (0.1290)	Prec@1 94.141 (95.657)	Prec@5 100.000 (99.931)
2022-06-17 18:00:58 - INFO - TRAINING - Epoch: [47][60/196]	Time 0.103 (0.144)	Data 0.000 (0.029)	Loss 0.0959 (0.1303)	Prec@1 95.703 (95.594)	Prec@5 100.000 (99.942)
2022-06-17 18:00:59 - INFO - TRAINING - Epoch: [47][70/196]	Time 0.115 (0.140)	Data 0.000 (0.025)	Loss 0.1162 (0.1293)	Prec@1 96.875 (95.654)	Prec@5 100.000 (99.939)
2022-06-17 18:01:00 - INFO - TRAINING - Epoch: [47][80/196]	Time 0.105 (0.137)	Data 0.000 (0.022)	Loss 0.1083 (0.1288)	Prec@1 95.703 (95.616)	Prec@5 100.000 (99.942)
2022-06-17 18:01:01 - INFO - TRAINING - Epoch: [47][90/196]	Time 0.122 (0.135)	Data 0.000 (0.020)	Loss 0.1120 (0.1279)	Prec@1 96.484 (95.664)	Prec@5 100.000 (99.944)
2022-06-17 18:01:02 - INFO - TRAINING - Epoch: [47][100/196]	Time 0.107 (0.132)	Data 0.000 (0.018)	Loss 0.1112 (0.1273)	Prec@1 96.484 (95.657)	Prec@5 100.000 (99.946)
2022-06-17 18:01:04 - INFO - TRAINING - Epoch: [47][110/196]	Time 0.112 (0.131)	Data 0.000 (0.016)	Loss 0.1029 (0.1267)	Prec@1 95.312 (95.664)	Prec@5 100.000 (99.947)
2022-06-17 18:01:05 - INFO - TRAINING - Epoch: [47][120/196]	Time 0.110 (0.129)	Data 0.000 (0.015)	Loss 0.1245 (0.1263)	Prec@1 95.703 (95.684)	Prec@5 100.000 (99.952)
2022-06-17 18:01:06 - INFO - TRAINING - Epoch: [47][130/196]	Time 0.119 (0.128)	Data 0.000 (0.014)	Loss 0.1373 (0.1251)	Prec@1 96.094 (95.742)	Prec@5 100.000 (99.955)
2022-06-17 18:01:07 - INFO - TRAINING - Epoch: [47][140/196]	Time 0.105 (0.127)	Data 0.000 (0.013)	Loss 0.1071 (0.1264)	Prec@1 96.094 (95.709)	Prec@5 100.000 (99.953)
2022-06-17 18:01:08 - INFO - TRAINING - Epoch: [47][150/196]	Time 0.120 (0.126)	Data 0.000 (0.012)	Loss 0.1456 (0.1261)	Prec@1 95.312 (95.706)	Prec@5 100.000 (99.951)
2022-06-17 18:01:09 - INFO - TRAINING - Epoch: [47][160/196]	Time 0.108 (0.126)	Data 0.000 (0.011)	Loss 0.1308 (0.1264)	Prec@1 94.141 (95.689)	Prec@5 100.000 (99.951)
2022-06-17 18:01:10 - INFO - TRAINING - Epoch: [47][170/196]	Time 0.123 (0.125)	Data 0.000 (0.011)	Loss 0.1252 (0.1262)	Prec@1 94.922 (95.687)	Prec@5 100.000 (99.954)
2022-06-17 18:01:12 - INFO - TRAINING - Epoch: [47][180/196]	Time 0.104 (0.125)	Data 0.000 (0.010)	Loss 0.1129 (0.1262)	Prec@1 96.094 (95.675)	Prec@5 100.000 (99.953)
2022-06-17 18:01:13 - INFO - TRAINING - Epoch: [47][190/196]	Time 0.102 (0.124)	Data 0.000 (0.010)	Loss 0.1375 (0.1259)	Prec@1 94.141 (95.674)	Prec@5 100.000 (99.955)
2022-06-17 18:01:15 - INFO - EVALUATING - Epoch: [47][0/40]	Time 2.005 (2.005)	Data 1.960 (1.960)	Loss 0.2650 (0.2650)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:01:16 - INFO - EVALUATING - Epoch: [47][10/40]	Time 0.268 (0.269)	Data 0.227 (0.220)	Loss 0.4536 (0.3966)	Prec@1 87.500 (88.246)	Prec@5 99.219 (99.396)
2022-06-17 18:01:17 - INFO - EVALUATING - Epoch: [47][20/40]	Time 0.041 (0.175)	Data 0.000 (0.126)	Loss 0.3223 (0.3993)	Prec@1 88.281 (88.002)	Prec@5 100.000 (99.405)
2022-06-17 18:01:18 - INFO - EVALUATING - Epoch: [47][30/40]	Time 0.044 (0.153)	Data 0.000 (0.105)	Loss 0.4734 (0.3919)	Prec@1 84.766 (88.017)	Prec@5 100.000 (99.471)
2022-06-17 18:01:20 - INFO - 
 Epoch: 48	Training Loss 0.1257 	Training Prec@1 95.686 	Training Prec@5 99.956 	Validation Loss 0.3877 	Validation Prec@1 88.010 	Validation Prec@5 99.560 

2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:01:20 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:01:22 - INFO - TRAINING - Epoch: [48][0/196]	Time 1.801 (1.801)	Data 1.748 (1.748)	Loss 0.1605 (0.1605)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2022-06-17 18:01:23 - INFO - TRAINING - Epoch: [48][10/196]	Time 0.103 (0.268)	Data 0.000 (0.159)	Loss 0.0898 (0.1360)	Prec@1 96.094 (95.277)	Prec@5 100.000 (99.929)
2022-06-17 18:01:24 - INFO - TRAINING - Epoch: [48][20/196]	Time 0.102 (0.193)	Data 0.000 (0.084)	Loss 0.1095 (0.1372)	Prec@1 96.094 (95.312)	Prec@5 100.000 (99.888)
2022-06-17 18:01:25 - INFO - TRAINING - Epoch: [48][30/196]	Time 0.111 (0.167)	Data 0.000 (0.057)	Loss 0.1096 (0.1323)	Prec@1 96.875 (95.502)	Prec@5 100.000 (99.924)
2022-06-17 18:01:26 - INFO - TRAINING - Epoch: [48][40/196]	Time 0.113 (0.153)	Data 0.000 (0.043)	Loss 0.0882 (0.1291)	Prec@1 98.438 (95.694)	Prec@5 100.000 (99.943)
2022-06-17 18:01:27 - INFO - TRAINING - Epoch: [48][50/196]	Time 0.105 (0.146)	Data 0.000 (0.035)	Loss 0.1194 (0.1277)	Prec@1 94.922 (95.718)	Prec@5 100.000 (99.954)
2022-06-17 18:01:28 - INFO - TRAINING - Epoch: [48][60/196]	Time 0.107 (0.140)	Data 0.000 (0.029)	Loss 0.2011 (0.1277)	Prec@1 92.578 (95.710)	Prec@5 100.000 (99.955)
2022-06-17 18:01:30 - INFO - TRAINING - Epoch: [48][70/196]	Time 0.108 (0.136)	Data 0.000 (0.025)	Loss 0.1479 (0.1289)	Prec@1 94.922 (95.654)	Prec@5 100.000 (99.956)
2022-06-17 18:01:31 - INFO - TRAINING - Epoch: [48][80/196]	Time 0.127 (0.133)	Data 0.000 (0.022)	Loss 0.1794 (0.1265)	Prec@1 94.141 (95.742)	Prec@5 99.609 (99.957)
2022-06-17 18:01:32 - INFO - TRAINING - Epoch: [48][90/196]	Time 0.106 (0.131)	Data 0.000 (0.020)	Loss 0.1579 (0.1263)	Prec@1 94.922 (95.716)	Prec@5 99.609 (99.948)
2022-06-17 18:01:33 - INFO - TRAINING - Epoch: [48][100/196]	Time 0.106 (0.129)	Data 0.000 (0.018)	Loss 0.1024 (0.1258)	Prec@1 96.484 (95.699)	Prec@5 100.000 (99.946)
2022-06-17 18:01:34 - INFO - TRAINING - Epoch: [48][110/196]	Time 0.110 (0.128)	Data 0.000 (0.016)	Loss 0.1321 (0.1250)	Prec@1 95.703 (95.710)	Prec@5 100.000 (99.951)
2022-06-17 18:01:35 - INFO - TRAINING - Epoch: [48][120/196]	Time 0.120 (0.127)	Data 0.000 (0.015)	Loss 0.0741 (0.1244)	Prec@1 97.656 (95.697)	Prec@5 100.000 (99.952)
2022-06-17 18:01:36 - INFO - TRAINING - Epoch: [48][130/196]	Time 0.105 (0.126)	Data 0.000 (0.014)	Loss 0.1360 (0.1235)	Prec@1 95.312 (95.751)	Prec@5 100.000 (99.955)
2022-06-17 18:01:37 - INFO - TRAINING - Epoch: [48][140/196]	Time 0.106 (0.125)	Data 0.000 (0.013)	Loss 0.1450 (0.1240)	Prec@1 94.531 (95.734)	Prec@5 100.000 (99.950)
2022-06-17 18:01:39 - INFO - TRAINING - Epoch: [48][150/196]	Time 0.109 (0.124)	Data 0.000 (0.012)	Loss 0.1596 (0.1247)	Prec@1 94.922 (95.711)	Prec@5 100.000 (99.951)
2022-06-17 18:01:40 - INFO - TRAINING - Epoch: [48][160/196]	Time 0.122 (0.123)	Data 0.000 (0.011)	Loss 0.1112 (0.1244)	Prec@1 96.875 (95.730)	Prec@5 100.000 (99.954)
2022-06-17 18:01:41 - INFO - TRAINING - Epoch: [48][170/196]	Time 0.103 (0.122)	Data 0.000 (0.011)	Loss 0.1255 (0.1251)	Prec@1 94.922 (95.689)	Prec@5 100.000 (99.957)
2022-06-17 18:01:42 - INFO - TRAINING - Epoch: [48][180/196]	Time 0.103 (0.122)	Data 0.000 (0.010)	Loss 0.1304 (0.1241)	Prec@1 94.922 (95.712)	Prec@5 100.000 (99.959)
2022-06-17 18:01:43 - INFO - TRAINING - Epoch: [48][190/196]	Time 0.103 (0.121)	Data 0.000 (0.009)	Loss 0.0659 (0.1232)	Prec@1 98.047 (95.728)	Prec@5 100.000 (99.961)
2022-06-17 18:01:45 - INFO - EVALUATING - Epoch: [48][0/40]	Time 1.480 (1.480)	Data 1.435 (1.435)	Loss 0.2616 (0.2616)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:01:47 - INFO - EVALUATING - Epoch: [48][10/40]	Time 0.044 (0.284)	Data 0.000 (0.237)	Loss 0.4539 (0.3973)	Prec@1 87.500 (88.317)	Prec@5 99.219 (99.432)
2022-06-17 18:01:47 - INFO - EVALUATING - Epoch: [48][20/40]	Time 0.082 (0.176)	Data 0.038 (0.128)	Loss 0.3191 (0.3992)	Prec@1 87.500 (88.114)	Prec@5 100.000 (99.405)
2022-06-17 18:01:49 - INFO - EVALUATING - Epoch: [48][30/40]	Time 0.097 (0.155)	Data 0.053 (0.108)	Loss 0.4768 (0.3918)	Prec@1 85.156 (88.155)	Prec@5 100.000 (99.471)
2022-06-17 18:01:50 - INFO - 
 Epoch: 49	Training Loss 0.1229 	Training Prec@1 95.754 	Training Prec@5 99.960 	Validation Loss 0.3875 	Validation Prec@1 88.110 	Validation Prec@5 99.550 

2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:01:50 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:01:52 - INFO - TRAINING - Epoch: [49][0/196]	Time 1.416 (1.416)	Data 1.362 (1.362)	Loss 0.1050 (0.1050)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:01:53 - INFO - TRAINING - Epoch: [49][10/196]	Time 0.104 (0.239)	Data 0.000 (0.143)	Loss 0.1458 (0.1222)	Prec@1 94.922 (95.668)	Prec@5 100.000 (100.000)
2022-06-17 18:01:54 - INFO - TRAINING - Epoch: [49][20/196]	Time 0.108 (0.181)	Data 0.000 (0.083)	Loss 0.0942 (0.1277)	Prec@1 95.703 (95.424)	Prec@5 100.000 (99.944)
2022-06-17 18:01:55 - INFO - TRAINING - Epoch: [49][30/196]	Time 0.122 (0.159)	Data 0.000 (0.057)	Loss 0.1625 (0.1237)	Prec@1 93.359 (95.640)	Prec@5 100.000 (99.950)
2022-06-17 18:01:56 - INFO - TRAINING - Epoch: [49][40/196]	Time 0.101 (0.147)	Data 0.000 (0.043)	Loss 0.1181 (0.1232)	Prec@1 96.875 (95.779)	Prec@5 100.000 (99.962)
2022-06-17 18:01:57 - INFO - TRAINING - Epoch: [49][50/196]	Time 0.108 (0.139)	Data 0.000 (0.034)	Loss 0.0847 (0.1217)	Prec@1 96.484 (95.803)	Prec@5 100.000 (99.954)
2022-06-17 18:01:59 - INFO - TRAINING - Epoch: [49][60/196]	Time 0.109 (0.135)	Data 0.000 (0.029)	Loss 0.1713 (0.1210)	Prec@1 94.531 (95.863)	Prec@5 100.000 (99.955)
2022-06-17 18:02:00 - INFO - TRAINING - Epoch: [49][70/196]	Time 0.103 (0.131)	Data 0.000 (0.025)	Loss 0.1138 (0.1221)	Prec@1 95.703 (95.808)	Prec@5 100.000 (99.961)
2022-06-17 18:02:01 - INFO - TRAINING - Epoch: [49][80/196]	Time 0.102 (0.128)	Data 0.000 (0.022)	Loss 0.0962 (0.1226)	Prec@1 97.656 (95.800)	Prec@5 100.000 (99.966)
2022-06-17 18:02:02 - INFO - TRAINING - Epoch: [49][90/196]	Time 0.111 (0.126)	Data 0.000 (0.019)	Loss 0.1347 (0.1214)	Prec@1 94.531 (95.810)	Prec@5 100.000 (99.966)
2022-06-17 18:02:03 - INFO - TRAINING - Epoch: [49][100/196]	Time 0.102 (0.125)	Data 0.000 (0.018)	Loss 0.0853 (0.1209)	Prec@1 98.828 (95.873)	Prec@5 99.609 (99.957)
2022-06-17 18:02:04 - INFO - TRAINING - Epoch: [49][110/196]	Time 0.117 (0.124)	Data 0.000 (0.016)	Loss 0.1180 (0.1208)	Prec@1 95.703 (95.879)	Prec@5 100.000 (99.961)
2022-06-17 18:02:05 - INFO - TRAINING - Epoch: [49][120/196]	Time 0.116 (0.123)	Data 0.000 (0.015)	Loss 0.0733 (0.1218)	Prec@1 97.266 (95.800)	Prec@5 100.000 (99.958)
2022-06-17 18:02:06 - INFO - TRAINING - Epoch: [49][130/196]	Time 0.141 (0.122)	Data 0.000 (0.014)	Loss 0.1134 (0.1219)	Prec@1 95.312 (95.784)	Prec@5 100.000 (99.952)
2022-06-17 18:02:07 - INFO - TRAINING - Epoch: [49][140/196]	Time 0.132 (0.121)	Data 0.000 (0.013)	Loss 0.0857 (0.1218)	Prec@1 96.484 (95.795)	Prec@5 100.000 (99.956)
2022-06-17 18:02:09 - INFO - TRAINING - Epoch: [49][150/196]	Time 0.116 (0.121)	Data 0.000 (0.012)	Loss 0.1074 (0.1215)	Prec@1 96.484 (95.825)	Prec@5 100.000 (99.959)
2022-06-17 18:02:10 - INFO - TRAINING - Epoch: [49][160/196]	Time 0.112 (0.121)	Data 0.000 (0.011)	Loss 0.1180 (0.1222)	Prec@1 96.875 (95.810)	Prec@5 100.000 (99.956)
2022-06-17 18:02:11 - INFO - TRAINING - Epoch: [49][170/196]	Time 0.109 (0.120)	Data 0.000 (0.011)	Loss 0.1038 (0.1214)	Prec@1 96.094 (95.820)	Prec@5 100.000 (99.959)
2022-06-17 18:02:12 - INFO - TRAINING - Epoch: [49][180/196]	Time 0.107 (0.120)	Data 0.000 (0.010)	Loss 0.1037 (0.1216)	Prec@1 96.484 (95.811)	Prec@5 100.000 (99.959)
2022-06-17 18:02:13 - INFO - TRAINING - Epoch: [49][190/196]	Time 0.102 (0.119)	Data 0.000 (0.009)	Loss 0.1173 (0.1211)	Prec@1 97.266 (95.822)	Prec@5 100.000 (99.959)
2022-06-17 18:02:16 - INFO - EVALUATING - Epoch: [49][0/40]	Time 1.821 (1.821)	Data 1.776 (1.776)	Loss 0.2588 (0.2588)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:02:17 - INFO - EVALUATING - Epoch: [49][10/40]	Time 0.044 (0.268)	Data 0.000 (0.219)	Loss 0.4501 (0.3962)	Prec@1 88.281 (88.317)	Prec@5 99.219 (99.467)
2022-06-17 18:02:17 - INFO - EVALUATING - Epoch: [49][20/40]	Time 0.068 (0.165)	Data 0.000 (0.115)	Loss 0.3217 (0.3997)	Prec@1 87.109 (88.039)	Prec@5 100.000 (99.405)
2022-06-17 18:02:18 - INFO - EVALUATING - Epoch: [49][30/40]	Time 0.199 (0.148)	Data 0.155 (0.101)	Loss 0.4805 (0.3930)	Prec@1 85.547 (87.991)	Prec@5 100.000 (99.458)
2022-06-17 18:02:20 - INFO - 
 Epoch: 50	Training Loss 0.1213 	Training Prec@1 95.822 	Training Prec@5 99.958 	Validation Loss 0.3882 	Validation Prec@1 88.000 	Validation Prec@5 99.530 

2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:02:20 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:02:22 - INFO - TRAINING - Epoch: [50][0/196]	Time 1.992 (1.992)	Data 1.938 (1.938)	Loss 0.1335 (0.1335)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 18:02:23 - INFO - TRAINING - Epoch: [50][10/196]	Time 0.111 (0.288)	Data 0.000 (0.177)	Loss 0.0474 (0.1188)	Prec@1 98.828 (95.632)	Prec@5 100.000 (99.964)
2022-06-17 18:02:24 - INFO - TRAINING - Epoch: [50][20/196]	Time 0.126 (0.207)	Data 0.000 (0.093)	Loss 0.1474 (0.1261)	Prec@1 96.484 (95.592)	Prec@5 100.000 (99.981)
2022-06-17 18:02:26 - INFO - TRAINING - Epoch: [50][30/196]	Time 0.113 (0.177)	Data 0.000 (0.063)	Loss 0.1294 (0.1242)	Prec@1 95.703 (95.590)	Prec@5 100.000 (99.987)
2022-06-17 18:02:27 - INFO - TRAINING - Epoch: [50][40/196]	Time 0.121 (0.163)	Data 0.000 (0.048)	Loss 0.0936 (0.1231)	Prec@1 95.703 (95.541)	Prec@5 100.000 (99.981)
2022-06-17 18:02:28 - INFO - TRAINING - Epoch: [50][50/196]	Time 0.118 (0.154)	Data 0.000 (0.038)	Loss 0.0679 (0.1188)	Prec@1 97.266 (95.841)	Prec@5 100.000 (99.954)
2022-06-17 18:02:29 - INFO - TRAINING - Epoch: [50][60/196]	Time 0.122 (0.148)	Data 0.000 (0.032)	Loss 0.1076 (0.1181)	Prec@1 96.875 (95.876)	Prec@5 100.000 (99.955)
2022-06-17 18:02:30 - INFO - TRAINING - Epoch: [50][70/196]	Time 0.122 (0.143)	Data 0.000 (0.028)	Loss 0.1488 (0.1192)	Prec@1 94.922 (95.901)	Prec@5 100.000 (99.956)
2022-06-17 18:02:31 - INFO - TRAINING - Epoch: [50][80/196]	Time 0.116 (0.140)	Data 0.000 (0.024)	Loss 0.1225 (0.1203)	Prec@1 95.703 (95.882)	Prec@5 100.000 (99.952)
2022-06-17 18:02:33 - INFO - TRAINING - Epoch: [50][90/196]	Time 0.125 (0.137)	Data 0.000 (0.022)	Loss 0.1384 (0.1206)	Prec@1 95.703 (95.888)	Prec@5 99.609 (99.944)
2022-06-17 18:02:34 - INFO - TRAINING - Epoch: [50][100/196]	Time 0.125 (0.136)	Data 0.000 (0.020)	Loss 0.1024 (0.1201)	Prec@1 96.094 (95.877)	Prec@5 100.000 (99.950)
2022-06-17 18:02:35 - INFO - TRAINING - Epoch: [50][110/196]	Time 0.115 (0.134)	Data 0.000 (0.018)	Loss 0.1397 (0.1200)	Prec@1 95.312 (95.854)	Prec@5 99.609 (99.947)
2022-06-17 18:02:36 - INFO - TRAINING - Epoch: [50][120/196]	Time 0.112 (0.132)	Data 0.000 (0.016)	Loss 0.1698 (0.1195)	Prec@1 92.969 (95.855)	Prec@5 100.000 (99.952)
2022-06-17 18:02:37 - INFO - TRAINING - Epoch: [50][130/196]	Time 0.127 (0.131)	Data 0.000 (0.015)	Loss 0.0788 (0.1192)	Prec@1 98.047 (95.885)	Prec@5 99.609 (99.946)
2022-06-17 18:02:39 - INFO - TRAINING - Epoch: [50][140/196]	Time 0.128 (0.130)	Data 0.000 (0.014)	Loss 0.1075 (0.1205)	Prec@1 96.484 (95.847)	Prec@5 100.000 (99.947)
2022-06-17 18:02:40 - INFO - TRAINING - Epoch: [50][150/196]	Time 0.122 (0.129)	Data 0.000 (0.013)	Loss 0.1444 (0.1196)	Prec@1 94.922 (95.884)	Prec@5 100.000 (99.951)
2022-06-17 18:02:41 - INFO - TRAINING - Epoch: [50][160/196]	Time 0.118 (0.128)	Data 0.000 (0.012)	Loss 0.1340 (0.1196)	Prec@1 95.312 (95.878)	Prec@5 100.000 (99.954)
2022-06-17 18:02:42 - INFO - TRAINING - Epoch: [50][170/196]	Time 0.126 (0.128)	Data 0.000 (0.012)	Loss 0.1145 (0.1197)	Prec@1 94.531 (95.884)	Prec@5 100.000 (99.954)
2022-06-17 18:02:43 - INFO - TRAINING - Epoch: [50][180/196]	Time 0.127 (0.127)	Data 0.000 (0.011)	Loss 0.1474 (0.1200)	Prec@1 94.531 (95.867)	Prec@5 100.000 (99.955)
2022-06-17 18:02:44 - INFO - TRAINING - Epoch: [50][190/196]	Time 0.101 (0.126)	Data 0.000 (0.010)	Loss 0.1360 (0.1206)	Prec@1 96.094 (95.850)	Prec@5 100.000 (99.957)
2022-06-17 18:02:46 - INFO - EVALUATING - Epoch: [50][0/40]	Time 1.534 (1.534)	Data 1.489 (1.489)	Loss 0.2556 (0.2556)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:02:48 - INFO - EVALUATING - Epoch: [50][10/40]	Time 0.062 (0.264)	Data 0.000 (0.215)	Loss 0.4515 (0.3938)	Prec@1 87.500 (88.317)	Prec@5 99.219 (99.432)
2022-06-17 18:02:48 - INFO - EVALUATING - Epoch: [50][20/40]	Time 0.041 (0.163)	Data 0.000 (0.113)	Loss 0.3200 (0.3976)	Prec@1 87.891 (88.058)	Prec@5 100.000 (99.386)
2022-06-17 18:02:49 - INFO - EVALUATING - Epoch: [50][30/40]	Time 0.104 (0.147)	Data 0.060 (0.099)	Loss 0.4719 (0.3907)	Prec@1 84.766 (88.067)	Prec@5 100.000 (99.458)
2022-06-17 18:02:52 - INFO - 
 Epoch: 51	Training Loss 0.1204 	Training Prec@1 95.854 	Training Prec@5 99.958 	Validation Loss 0.3869 	Validation Prec@1 88.140 	Validation Prec@5 99.530 

2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:02:52 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:02:53 - INFO - TRAINING - Epoch: [51][0/196]	Time 1.612 (1.612)	Data 1.560 (1.560)	Loss 0.1395 (0.1395)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 18:02:55 - INFO - TRAINING - Epoch: [51][10/196]	Time 0.111 (0.273)	Data 0.000 (0.180)	Loss 0.1721 (0.1204)	Prec@1 94.141 (95.845)	Prec@5 100.000 (99.964)
2022-06-17 18:02:56 - INFO - TRAINING - Epoch: [51][20/196]	Time 0.118 (0.199)	Data 0.000 (0.094)	Loss 0.1097 (0.1119)	Prec@1 96.875 (96.261)	Prec@5 100.000 (99.981)
2022-06-17 18:02:57 - INFO - TRAINING - Epoch: [51][30/196]	Time 0.119 (0.173)	Data 0.000 (0.064)	Loss 0.1697 (0.1154)	Prec@1 93.359 (96.094)	Prec@5 100.000 (99.975)
2022-06-17 18:02:58 - INFO - TRAINING - Epoch: [51][40/196]	Time 0.110 (0.160)	Data 0.000 (0.049)	Loss 0.1439 (0.1150)	Prec@1 93.750 (96.027)	Prec@5 100.000 (99.981)
2022-06-17 18:02:59 - INFO - TRAINING - Epoch: [51][50/196]	Time 0.133 (0.153)	Data 0.000 (0.039)	Loss 0.1176 (0.1164)	Prec@1 96.484 (95.994)	Prec@5 100.000 (99.985)
2022-06-17 18:03:01 - INFO - TRAINING - Epoch: [51][60/196]	Time 0.120 (0.147)	Data 0.000 (0.033)	Loss 0.1302 (0.1152)	Prec@1 95.312 (96.043)	Prec@5 100.000 (99.987)
2022-06-17 18:03:02 - INFO - TRAINING - Epoch: [51][70/196]	Time 0.125 (0.144)	Data 0.000 (0.028)	Loss 0.1249 (0.1193)	Prec@1 97.266 (95.934)	Prec@5 100.000 (99.967)
2022-06-17 18:03:03 - INFO - TRAINING - Epoch: [51][80/196]	Time 0.136 (0.142)	Data 0.000 (0.025)	Loss 0.0889 (0.1178)	Prec@1 97.656 (95.992)	Prec@5 100.000 (99.961)
2022-06-17 18:03:04 - INFO - TRAINING - Epoch: [51][90/196]	Time 0.107 (0.140)	Data 0.000 (0.022)	Loss 0.1042 (0.1175)	Prec@1 95.703 (95.965)	Prec@5 100.000 (99.966)
2022-06-17 18:03:05 - INFO - TRAINING - Epoch: [51][100/196]	Time 0.135 (0.138)	Data 0.000 (0.020)	Loss 0.0883 (0.1175)	Prec@1 97.656 (95.931)	Prec@5 100.000 (99.969)
2022-06-17 18:03:07 - INFO - TRAINING - Epoch: [51][110/196]	Time 0.122 (0.136)	Data 0.000 (0.018)	Loss 0.0990 (0.1164)	Prec@1 96.484 (95.974)	Prec@5 100.000 (99.972)
2022-06-17 18:03:08 - INFO - TRAINING - Epoch: [51][120/196]	Time 0.106 (0.135)	Data 0.000 (0.017)	Loss 0.0989 (0.1158)	Prec@1 96.484 (96.036)	Prec@5 100.000 (99.971)
2022-06-17 18:03:09 - INFO - TRAINING - Epoch: [51][130/196]	Time 0.102 (0.134)	Data 0.000 (0.015)	Loss 0.0607 (0.1156)	Prec@1 98.828 (96.070)	Prec@5 100.000 (99.970)
2022-06-17 18:03:10 - INFO - TRAINING - Epoch: [51][140/196]	Time 0.134 (0.133)	Data 0.000 (0.014)	Loss 0.1438 (0.1165)	Prec@1 94.922 (96.005)	Prec@5 100.000 (99.967)
2022-06-17 18:03:11 - INFO - TRAINING - Epoch: [51][150/196]	Time 0.124 (0.132)	Data 0.000 (0.013)	Loss 0.1000 (0.1170)	Prec@1 97.266 (95.988)	Prec@5 100.000 (99.964)
2022-06-17 18:03:13 - INFO - TRAINING - Epoch: [51][160/196]	Time 0.122 (0.131)	Data 0.000 (0.013)	Loss 0.0915 (0.1172)	Prec@1 96.484 (95.985)	Prec@5 100.000 (99.961)
2022-06-17 18:03:14 - INFO - TRAINING - Epoch: [51][170/196]	Time 0.134 (0.130)	Data 0.000 (0.012)	Loss 0.1710 (0.1178)	Prec@1 93.750 (95.961)	Prec@5 99.609 (99.959)
2022-06-17 18:03:15 - INFO - TRAINING - Epoch: [51][180/196]	Time 0.125 (0.130)	Data 0.000 (0.011)	Loss 0.1051 (0.1184)	Prec@1 98.047 (95.947)	Prec@5 100.000 (99.961)
2022-06-17 18:03:16 - INFO - TRAINING - Epoch: [51][190/196]	Time 0.103 (0.129)	Data 0.000 (0.011)	Loss 0.1187 (0.1179)	Prec@1 96.094 (95.971)	Prec@5 100.000 (99.961)
2022-06-17 18:03:18 - INFO - EVALUATING - Epoch: [51][0/40]	Time 1.652 (1.652)	Data 1.606 (1.606)	Loss 0.2579 (0.2579)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:03:19 - INFO - EVALUATING - Epoch: [51][10/40]	Time 0.044 (0.247)	Data 0.000 (0.198)	Loss 0.4454 (0.3933)	Prec@1 87.500 (88.352)	Prec@5 99.219 (99.361)
2022-06-17 18:03:20 - INFO - EVALUATING - Epoch: [51][20/40]	Time 0.041 (0.164)	Data 0.000 (0.116)	Loss 0.3313 (0.3977)	Prec@1 87.500 (88.058)	Prec@5 100.000 (99.368)
2022-06-17 18:03:21 - INFO - EVALUATING - Epoch: [51][30/40]	Time 0.105 (0.146)	Data 0.061 (0.099)	Loss 0.4780 (0.3908)	Prec@1 85.156 (88.017)	Prec@5 100.000 (99.433)
2022-06-17 18:03:23 - INFO - 
 Epoch: 52	Training Loss 0.1178 	Training Prec@1 95.976 	Training Prec@5 99.962 	Validation Loss 0.3871 	Validation Prec@1 88.050 	Validation Prec@5 99.520 

2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:03:23 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:03:25 - INFO - TRAINING - Epoch: [52][0/196]	Time 1.573 (1.573)	Data 1.522 (1.522)	Loss 0.1753 (0.1753)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:03:26 - INFO - TRAINING - Epoch: [52][10/196]	Time 0.114 (0.265)	Data 0.000 (0.172)	Loss 0.1197 (0.1260)	Prec@1 95.703 (96.058)	Prec@5 100.000 (99.929)
2022-06-17 18:03:27 - INFO - TRAINING - Epoch: [52][20/196]	Time 0.119 (0.194)	Data 0.000 (0.090)	Loss 0.1131 (0.1269)	Prec@1 96.094 (95.908)	Prec@5 100.000 (99.944)
2022-06-17 18:03:29 - INFO - TRAINING - Epoch: [52][30/196]	Time 0.122 (0.170)	Data 0.000 (0.061)	Loss 0.0889 (0.1234)	Prec@1 97.266 (96.056)	Prec@5 100.000 (99.962)
2022-06-17 18:03:30 - INFO - TRAINING - Epoch: [52][40/196]	Time 0.117 (0.159)	Data 0.000 (0.046)	Loss 0.0860 (0.1261)	Prec@1 96.484 (95.856)	Prec@5 100.000 (99.962)
2022-06-17 18:03:31 - INFO - TRAINING - Epoch: [52][50/196]	Time 0.103 (0.151)	Data 0.000 (0.037)	Loss 0.1527 (0.1232)	Prec@1 95.312 (95.941)	Prec@5 100.000 (99.969)
2022-06-17 18:03:32 - INFO - TRAINING - Epoch: [52][60/196]	Time 0.102 (0.145)	Data 0.000 (0.031)	Loss 0.0721 (0.1234)	Prec@1 98.047 (95.876)	Prec@5 100.000 (99.968)
2022-06-17 18:03:33 - INFO - TRAINING - Epoch: [52][70/196]	Time 0.129 (0.142)	Data 0.000 (0.027)	Loss 0.0668 (0.1245)	Prec@1 98.828 (95.830)	Prec@5 100.000 (99.961)
2022-06-17 18:03:35 - INFO - TRAINING - Epoch: [52][80/196]	Time 0.120 (0.140)	Data 0.000 (0.024)	Loss 0.1129 (0.1225)	Prec@1 96.484 (95.877)	Prec@5 100.000 (99.961)
2022-06-17 18:03:36 - INFO - TRAINING - Epoch: [52][90/196]	Time 0.115 (0.137)	Data 0.000 (0.021)	Loss 0.0579 (0.1222)	Prec@1 98.828 (95.862)	Prec@5 100.000 (99.961)
2022-06-17 18:03:37 - INFO - TRAINING - Epoch: [52][100/196]	Time 0.127 (0.136)	Data 0.000 (0.019)	Loss 0.1793 (0.1220)	Prec@1 94.141 (95.900)	Prec@5 100.000 (99.957)
2022-06-17 18:03:38 - INFO - TRAINING - Epoch: [52][110/196]	Time 0.129 (0.135)	Data 0.000 (0.017)	Loss 0.1025 (0.1212)	Prec@1 96.875 (95.918)	Prec@5 100.000 (99.961)
2022-06-17 18:03:39 - INFO - TRAINING - Epoch: [52][120/196]	Time 0.102 (0.133)	Data 0.000 (0.016)	Loss 0.1450 (0.1217)	Prec@1 94.922 (95.913)	Prec@5 100.000 (99.964)
2022-06-17 18:03:41 - INFO - TRAINING - Epoch: [52][130/196]	Time 0.132 (0.133)	Data 0.000 (0.015)	Loss 0.1168 (0.1212)	Prec@1 97.656 (95.951)	Prec@5 100.000 (99.961)
2022-06-17 18:03:42 - INFO - TRAINING - Epoch: [52][140/196]	Time 0.128 (0.132)	Data 0.000 (0.014)	Loss 0.1169 (0.1213)	Prec@1 94.922 (95.952)	Prec@5 100.000 (99.958)
2022-06-17 18:03:43 - INFO - TRAINING - Epoch: [52][150/196]	Time 0.128 (0.131)	Data 0.000 (0.013)	Loss 0.0803 (0.1206)	Prec@1 96.875 (95.975)	Prec@5 100.000 (99.959)
2022-06-17 18:03:44 - INFO - TRAINING - Epoch: [52][160/196]	Time 0.132 (0.131)	Data 0.000 (0.012)	Loss 0.0773 (0.1206)	Prec@1 97.656 (95.963)	Prec@5 100.000 (99.959)
2022-06-17 18:03:45 - INFO - TRAINING - Epoch: [52][170/196]	Time 0.124 (0.130)	Data 0.000 (0.011)	Loss 0.1289 (0.1207)	Prec@1 94.922 (95.959)	Prec@5 100.000 (99.957)
2022-06-17 18:03:47 - INFO - TRAINING - Epoch: [52][180/196]	Time 0.114 (0.130)	Data 0.000 (0.011)	Loss 0.1238 (0.1209)	Prec@1 96.094 (95.949)	Prec@5 100.000 (99.959)
2022-06-17 18:03:48 - INFO - TRAINING - Epoch: [52][190/196]	Time 0.117 (0.129)	Data 0.000 (0.010)	Loss 0.1060 (0.1207)	Prec@1 95.312 (95.961)	Prec@5 100.000 (99.957)
2022-06-17 18:03:50 - INFO - EVALUATING - Epoch: [52][0/40]	Time 1.419 (1.419)	Data 1.373 (1.373)	Loss 0.2581 (0.2581)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:03:51 - INFO - EVALUATING - Epoch: [52][10/40]	Time 0.044 (0.227)	Data 0.000 (0.181)	Loss 0.4582 (0.3997)	Prec@1 87.891 (88.246)	Prec@5 99.219 (99.467)
2022-06-17 18:03:52 - INFO - EVALUATING - Epoch: [52][20/40]	Time 0.052 (0.172)	Data 0.000 (0.126)	Loss 0.3264 (0.4034)	Prec@1 87.109 (87.909)	Prec@5 100.000 (99.405)
2022-06-17 18:03:53 - INFO - EVALUATING - Epoch: [52][30/40]	Time 0.109 (0.152)	Data 0.066 (0.107)	Loss 0.4898 (0.3964)	Prec@1 85.547 (87.928)	Prec@5 100.000 (99.471)
2022-06-17 18:03:55 - INFO - 
 Epoch: 53	Training Loss 0.1211 	Training Prec@1 95.956 	Training Prec@5 99.958 	Validation Loss 0.3915 	Validation Prec@1 87.980 	Validation Prec@5 99.540 

2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:03:55 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:03:57 - INFO - TRAINING - Epoch: [53][0/196]	Time 1.529 (1.529)	Data 1.477 (1.477)	Loss 0.1277 (0.1277)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 18:03:58 - INFO - TRAINING - Epoch: [53][10/196]	Time 0.103 (0.264)	Data 0.000 (0.178)	Loss 0.1174 (0.1181)	Prec@1 96.094 (95.668)	Prec@5 100.000 (99.964)
2022-06-17 18:03:59 - INFO - TRAINING - Epoch: [53][20/196]	Time 0.122 (0.195)	Data 0.000 (0.097)	Loss 0.1518 (0.1271)	Prec@1 94.141 (95.424)	Prec@5 100.000 (99.963)
2022-06-17 18:04:00 - INFO - TRAINING - Epoch: [53][30/196]	Time 0.121 (0.169)	Data 0.000 (0.066)	Loss 0.1032 (0.1229)	Prec@1 95.312 (95.653)	Prec@5 100.000 (99.962)
2022-06-17 18:04:02 - INFO - TRAINING - Epoch: [53][40/196]	Time 0.119 (0.158)	Data 0.000 (0.050)	Loss 0.0786 (0.1205)	Prec@1 98.828 (95.827)	Prec@5 100.000 (99.971)
2022-06-17 18:04:03 - INFO - TRAINING - Epoch: [53][50/196]	Time 0.121 (0.151)	Data 0.000 (0.040)	Loss 0.1035 (0.1186)	Prec@1 96.484 (95.864)	Prec@5 100.000 (99.969)
2022-06-17 18:04:04 - INFO - TRAINING - Epoch: [53][60/196]	Time 0.120 (0.145)	Data 0.000 (0.034)	Loss 0.1567 (0.1167)	Prec@1 93.359 (95.908)	Prec@5 99.609 (99.968)
2022-06-17 18:04:05 - INFO - TRAINING - Epoch: [53][70/196]	Time 0.124 (0.142)	Data 0.001 (0.029)	Loss 0.0885 (0.1184)	Prec@1 97.266 (95.901)	Prec@5 100.000 (99.967)
2022-06-17 18:04:06 - INFO - TRAINING - Epoch: [53][80/196]	Time 0.101 (0.138)	Data 0.000 (0.025)	Loss 0.0968 (0.1184)	Prec@1 96.875 (95.939)	Prec@5 100.000 (99.971)
2022-06-17 18:04:08 - INFO - TRAINING - Epoch: [53][90/196]	Time 0.129 (0.136)	Data 0.000 (0.023)	Loss 0.1238 (0.1176)	Prec@1 95.312 (95.952)	Prec@5 100.000 (99.970)
2022-06-17 18:04:09 - INFO - TRAINING - Epoch: [53][100/196]	Time 0.136 (0.134)	Data 0.000 (0.020)	Loss 0.1111 (0.1184)	Prec@1 96.875 (95.904)	Prec@5 100.000 (99.969)
2022-06-17 18:04:10 - INFO - TRAINING - Epoch: [53][110/196]	Time 0.123 (0.133)	Data 0.000 (0.019)	Loss 0.1476 (0.1193)	Prec@1 94.922 (95.840)	Prec@5 100.000 (99.972)
2022-06-17 18:04:11 - INFO - TRAINING - Epoch: [53][120/196]	Time 0.127 (0.132)	Data 0.000 (0.017)	Loss 0.1743 (0.1194)	Prec@1 93.750 (95.829)	Prec@5 100.000 (99.968)
2022-06-17 18:04:12 - INFO - TRAINING - Epoch: [53][130/196]	Time 0.127 (0.131)	Data 0.000 (0.016)	Loss 0.0890 (0.1192)	Prec@1 97.266 (95.870)	Prec@5 100.000 (99.964)
2022-06-17 18:04:14 - INFO - TRAINING - Epoch: [53][140/196]	Time 0.106 (0.130)	Data 0.000 (0.015)	Loss 0.1434 (0.1202)	Prec@1 94.531 (95.847)	Prec@5 100.000 (99.958)
2022-06-17 18:04:15 - INFO - TRAINING - Epoch: [53][150/196]	Time 0.116 (0.129)	Data 0.000 (0.014)	Loss 0.0986 (0.1208)	Prec@1 96.094 (95.817)	Prec@5 100.000 (99.959)
2022-06-17 18:04:16 - INFO - TRAINING - Epoch: [53][160/196]	Time 0.129 (0.129)	Data 0.000 (0.013)	Loss 0.1465 (0.1202)	Prec@1 94.922 (95.858)	Prec@5 99.609 (99.959)
2022-06-17 18:04:17 - INFO - TRAINING - Epoch: [53][170/196]	Time 0.128 (0.129)	Data 0.000 (0.012)	Loss 0.0959 (0.1188)	Prec@1 96.484 (95.913)	Prec@5 100.000 (99.959)
2022-06-17 18:04:18 - INFO - TRAINING - Epoch: [53][180/196]	Time 0.102 (0.128)	Data 0.000 (0.012)	Loss 0.0918 (0.1183)	Prec@1 96.875 (95.934)	Prec@5 100.000 (99.961)
2022-06-17 18:04:19 - INFO - TRAINING - Epoch: [53][190/196]	Time 0.106 (0.127)	Data 0.000 (0.011)	Loss 0.1370 (0.1186)	Prec@1 96.875 (95.936)	Prec@5 100.000 (99.963)
2022-06-17 18:04:22 - INFO - EVALUATING - Epoch: [53][0/40]	Time 2.037 (2.037)	Data 1.991 (1.991)	Loss 0.2591 (0.2591)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:04:23 - INFO - EVALUATING - Epoch: [53][10/40]	Time 0.044 (0.268)	Data 0.000 (0.222)	Loss 0.4526 (0.3973)	Prec@1 87.891 (88.459)	Prec@5 99.219 (99.432)
2022-06-17 18:04:24 - INFO - EVALUATING - Epoch: [53][20/40]	Time 0.208 (0.172)	Data 0.167 (0.125)	Loss 0.3355 (0.4020)	Prec@1 87.500 (88.188)	Prec@5 100.000 (99.386)
2022-06-17 18:04:25 - INFO - EVALUATING - Epoch: [53][30/40]	Time 0.044 (0.152)	Data 0.000 (0.106)	Loss 0.4930 (0.3957)	Prec@1 85.938 (88.155)	Prec@5 100.000 (99.446)
2022-06-17 18:04:27 - INFO - 
 Epoch: 54	Training Loss 0.1189 	Training Prec@1 95.932 	Training Prec@5 99.964 	Validation Loss 0.3911 	Validation Prec@1 88.100 	Validation Prec@5 99.530 

2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:04:27 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:04:29 - INFO - TRAINING - Epoch: [54][0/196]	Time 1.899 (1.899)	Data 1.847 (1.847)	Loss 0.1162 (0.1162)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:04:30 - INFO - TRAINING - Epoch: [54][10/196]	Time 0.103 (0.273)	Data 0.000 (0.168)	Loss 0.1117 (0.1291)	Prec@1 95.703 (95.277)	Prec@5 100.000 (100.000)
2022-06-17 18:04:31 - INFO - TRAINING - Epoch: [54][20/196]	Time 0.111 (0.197)	Data 0.000 (0.088)	Loss 0.1040 (0.1218)	Prec@1 96.484 (95.666)	Prec@5 100.000 (99.981)
2022-06-17 18:04:32 - INFO - TRAINING - Epoch: [54][30/196]	Time 0.115 (0.168)	Data 0.000 (0.060)	Loss 0.0813 (0.1189)	Prec@1 98.828 (95.880)	Prec@5 100.000 (99.975)
2022-06-17 18:04:33 - INFO - TRAINING - Epoch: [54][40/196]	Time 0.112 (0.155)	Data 0.000 (0.045)	Loss 0.0947 (0.1181)	Prec@1 96.875 (95.989)	Prec@5 100.000 (99.981)
2022-06-17 18:04:34 - INFO - TRAINING - Epoch: [54][50/196]	Time 0.111 (0.147)	Data 0.000 (0.037)	Loss 0.1294 (0.1182)	Prec@1 96.484 (96.017)	Prec@5 99.609 (99.969)
2022-06-17 18:04:35 - INFO - TRAINING - Epoch: [54][60/196]	Time 0.124 (0.142)	Data 0.000 (0.031)	Loss 0.1312 (0.1179)	Prec@1 96.484 (96.036)	Prec@5 100.000 (99.968)
2022-06-17 18:04:36 - INFO - TRAINING - Epoch: [54][70/196]	Time 0.114 (0.138)	Data 0.000 (0.026)	Loss 0.1337 (0.1182)	Prec@1 94.531 (96.055)	Prec@5 100.000 (99.972)
2022-06-17 18:04:38 - INFO - TRAINING - Epoch: [54][80/196]	Time 0.105 (0.136)	Data 0.000 (0.023)	Loss 0.1302 (0.1197)	Prec@1 94.922 (96.007)	Prec@5 100.000 (99.971)
2022-06-17 18:04:39 - INFO - TRAINING - Epoch: [54][90/196]	Time 0.126 (0.134)	Data 0.000 (0.021)	Loss 0.1289 (0.1201)	Prec@1 94.531 (95.961)	Prec@5 99.609 (99.970)
2022-06-17 18:04:40 - INFO - TRAINING - Epoch: [54][100/196]	Time 0.117 (0.133)	Data 0.000 (0.019)	Loss 0.0915 (0.1196)	Prec@1 96.875 (95.985)	Prec@5 100.000 (99.973)
2022-06-17 18:04:41 - INFO - TRAINING - Epoch: [54][110/196]	Time 0.106 (0.131)	Data 0.000 (0.017)	Loss 0.1481 (0.1188)	Prec@1 94.922 (95.995)	Prec@5 100.000 (99.975)
2022-06-17 18:04:42 - INFO - TRAINING - Epoch: [54][120/196]	Time 0.126 (0.130)	Data 0.000 (0.016)	Loss 0.1063 (0.1189)	Prec@1 96.094 (95.945)	Prec@5 100.000 (99.974)
2022-06-17 18:04:44 - INFO - TRAINING - Epoch: [54][130/196]	Time 0.119 (0.129)	Data 0.000 (0.014)	Loss 0.1103 (0.1190)	Prec@1 96.484 (95.930)	Prec@5 100.000 (99.973)
2022-06-17 18:04:45 - INFO - TRAINING - Epoch: [54][140/196]	Time 0.102 (0.128)	Data 0.000 (0.013)	Loss 0.1178 (0.1194)	Prec@1 96.875 (95.908)	Prec@5 100.000 (99.975)
2022-06-17 18:04:46 - INFO - TRAINING - Epoch: [54][150/196]	Time 0.118 (0.128)	Data 0.000 (0.013)	Loss 0.1251 (0.1194)	Prec@1 94.531 (95.900)	Prec@5 100.000 (99.977)
2022-06-17 18:04:47 - INFO - TRAINING - Epoch: [54][160/196]	Time 0.108 (0.127)	Data 0.000 (0.012)	Loss 0.1149 (0.1188)	Prec@1 96.484 (95.921)	Prec@5 100.000 (99.978)
2022-06-17 18:04:48 - INFO - TRAINING - Epoch: [54][170/196]	Time 0.120 (0.127)	Data 0.000 (0.011)	Loss 0.1435 (0.1193)	Prec@1 95.703 (95.945)	Prec@5 100.000 (99.977)
2022-06-17 18:04:49 - INFO - TRAINING - Epoch: [54][180/196]	Time 0.105 (0.126)	Data 0.000 (0.011)	Loss 0.1042 (0.1189)	Prec@1 96.094 (95.951)	Prec@5 100.000 (99.976)
2022-06-17 18:04:51 - INFO - TRAINING - Epoch: [54][190/196]	Time 0.108 (0.125)	Data 0.000 (0.010)	Loss 0.1372 (0.1182)	Prec@1 96.484 (95.979)	Prec@5 99.609 (99.973)
2022-06-17 18:04:53 - INFO - EVALUATING - Epoch: [54][0/40]	Time 1.652 (1.652)	Data 1.606 (1.606)	Loss 0.2618 (0.2618)	Prec@1 92.969 (92.969)	Prec@5 99.609 (99.609)
2022-06-17 18:04:54 - INFO - EVALUATING - Epoch: [54][10/40]	Time 0.044 (0.280)	Data 0.000 (0.231)	Loss 0.4572 (0.3999)	Prec@1 87.891 (88.246)	Prec@5 99.219 (99.396)
2022-06-17 18:04:55 - INFO - EVALUATING - Epoch: [54][20/40]	Time 0.044 (0.170)	Data 0.000 (0.121)	Loss 0.3322 (0.4017)	Prec@1 88.281 (88.021)	Prec@5 100.000 (99.423)
2022-06-17 18:04:56 - INFO - EVALUATING - Epoch: [54][30/40]	Time 0.216 (0.156)	Data 0.175 (0.109)	Loss 0.4864 (0.3945)	Prec@1 86.719 (88.143)	Prec@5 100.000 (99.471)
2022-06-17 18:04:58 - INFO - 
 Epoch: 55	Training Loss 0.1185 	Training Prec@1 95.976 	Training Prec@5 99.970 	Validation Loss 0.3898 	Validation Prec@1 88.190 	Validation Prec@5 99.550 

2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:04:58 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:04:59 - INFO - TRAINING - Epoch: [55][0/196]	Time 1.275 (1.275)	Data 1.221 (1.221)	Loss 0.1654 (0.1654)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:05:01 - INFO - TRAINING - Epoch: [55][10/196]	Time 0.110 (0.285)	Data 0.000 (0.199)	Loss 0.0895 (0.1237)	Prec@1 97.266 (95.774)	Prec@5 100.000 (99.929)
2022-06-17 18:05:02 - INFO - TRAINING - Epoch: [55][20/196]	Time 0.112 (0.201)	Data 0.000 (0.104)	Loss 0.1278 (0.1210)	Prec@1 93.750 (95.833)	Prec@5 100.000 (99.944)
2022-06-17 18:05:03 - INFO - TRAINING - Epoch: [55][30/196]	Time 0.139 (0.174)	Data 0.000 (0.071)	Loss 0.0692 (0.1197)	Prec@1 97.266 (95.917)	Prec@5 100.000 (99.950)
2022-06-17 18:05:04 - INFO - TRAINING - Epoch: [55][40/196]	Time 0.108 (0.158)	Data 0.000 (0.054)	Loss 0.1392 (0.1236)	Prec@1 94.531 (95.732)	Prec@5 100.000 (99.952)
2022-06-17 18:05:06 - INFO - TRAINING - Epoch: [55][50/196]	Time 0.110 (0.150)	Data 0.000 (0.043)	Loss 0.1015 (0.1206)	Prec@1 95.703 (95.826)	Prec@5 99.609 (99.946)
2022-06-17 18:05:07 - INFO - TRAINING - Epoch: [55][60/196]	Time 0.120 (0.144)	Data 0.000 (0.036)	Loss 0.1648 (0.1197)	Prec@1 94.141 (95.844)	Prec@5 100.000 (99.949)
2022-06-17 18:05:08 - INFO - TRAINING - Epoch: [55][70/196]	Time 0.116 (0.140)	Data 0.000 (0.031)	Loss 0.1683 (0.1204)	Prec@1 94.141 (95.841)	Prec@5 100.000 (99.956)
2022-06-17 18:05:09 - INFO - TRAINING - Epoch: [55][80/196]	Time 0.108 (0.137)	Data 0.000 (0.027)	Loss 0.1508 (0.1203)	Prec@1 95.312 (95.824)	Prec@5 100.000 (99.957)
2022-06-17 18:05:10 - INFO - TRAINING - Epoch: [55][90/196]	Time 0.109 (0.135)	Data 0.000 (0.024)	Loss 0.1147 (0.1193)	Prec@1 95.312 (95.849)	Prec@5 100.000 (99.961)
2022-06-17 18:05:11 - INFO - TRAINING - Epoch: [55][100/196]	Time 0.117 (0.133)	Data 0.000 (0.022)	Loss 0.1544 (0.1203)	Prec@1 93.750 (95.831)	Prec@5 100.000 (99.961)
2022-06-17 18:05:13 - INFO - TRAINING - Epoch: [55][110/196]	Time 0.136 (0.132)	Data 0.000 (0.020)	Loss 0.1241 (0.1200)	Prec@1 96.094 (95.840)	Prec@5 100.000 (99.961)
2022-06-17 18:05:14 - INFO - TRAINING - Epoch: [55][120/196]	Time 0.101 (0.131)	Data 0.000 (0.018)	Loss 0.1269 (0.1189)	Prec@1 96.484 (95.894)	Prec@5 100.000 (99.964)
2022-06-17 18:05:15 - INFO - TRAINING - Epoch: [55][130/196]	Time 0.139 (0.129)	Data 0.000 (0.017)	Loss 0.1483 (0.1186)	Prec@1 94.531 (95.912)	Prec@5 100.000 (99.964)
2022-06-17 18:05:16 - INFO - TRAINING - Epoch: [55][140/196]	Time 0.110 (0.128)	Data 0.000 (0.016)	Loss 0.1111 (0.1190)	Prec@1 96.875 (95.916)	Prec@5 99.609 (99.961)
2022-06-17 18:05:17 - INFO - TRAINING - Epoch: [55][150/196]	Time 0.102 (0.128)	Data 0.000 (0.015)	Loss 0.1354 (0.1193)	Prec@1 95.703 (95.892)	Prec@5 100.000 (99.961)
2022-06-17 18:05:18 - INFO - TRAINING - Epoch: [55][160/196]	Time 0.100 (0.127)	Data 0.000 (0.014)	Loss 0.0789 (0.1190)	Prec@1 96.875 (95.880)	Prec@5 100.000 (99.961)
2022-06-17 18:05:19 - INFO - TRAINING - Epoch: [55][170/196]	Time 0.114 (0.126)	Data 0.000 (0.013)	Loss 0.1131 (0.1194)	Prec@1 96.094 (95.868)	Prec@5 100.000 (99.963)
2022-06-17 18:05:21 - INFO - TRAINING - Epoch: [55][180/196]	Time 0.112 (0.125)	Data 0.000 (0.012)	Loss 0.1132 (0.1191)	Prec@1 95.703 (95.897)	Prec@5 100.000 (99.963)
2022-06-17 18:05:22 - INFO - TRAINING - Epoch: [55][190/196]	Time 0.101 (0.125)	Data 0.000 (0.012)	Loss 0.1933 (0.1195)	Prec@1 92.578 (95.861)	Prec@5 100.000 (99.963)
2022-06-17 18:05:24 - INFO - EVALUATING - Epoch: [55][0/40]	Time 1.756 (1.756)	Data 1.710 (1.710)	Loss 0.2572 (0.2572)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:05:25 - INFO - EVALUATING - Epoch: [55][10/40]	Time 0.064 (0.276)	Data 0.000 (0.226)	Loss 0.4558 (0.3995)	Prec@1 87.500 (88.033)	Prec@5 99.219 (99.432)
2022-06-17 18:05:26 - INFO - EVALUATING - Epoch: [55][20/40]	Time 0.043 (0.189)	Data 0.000 (0.138)	Loss 0.3290 (0.4019)	Prec@1 88.281 (87.835)	Prec@5 100.000 (99.442)
2022-06-17 18:05:27 - INFO - EVALUATING - Epoch: [55][30/40]	Time 0.041 (0.157)	Data 0.000 (0.107)	Loss 0.4815 (0.3948)	Prec@1 86.328 (87.941)	Prec@5 100.000 (99.483)
2022-06-17 18:05:29 - INFO - 
 Epoch: 56	Training Loss 0.1194 	Training Prec@1 95.860 	Training Prec@5 99.964 	Validation Loss 0.3896 	Validation Prec@1 87.980 	Validation Prec@5 99.560 

2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:05:29 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:05:31 - INFO - TRAINING - Epoch: [56][0/196]	Time 1.876 (1.876)	Data 1.822 (1.822)	Loss 0.1075 (0.1075)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:05:32 - INFO - TRAINING - Epoch: [56][10/196]	Time 0.112 (0.275)	Data 0.000 (0.174)	Loss 0.1659 (0.1211)	Prec@1 93.359 (95.952)	Prec@5 100.000 (99.964)
2022-06-17 18:05:33 - INFO - TRAINING - Epoch: [56][20/196]	Time 0.111 (0.197)	Data 0.000 (0.092)	Loss 0.1045 (0.1214)	Prec@1 96.484 (95.871)	Prec@5 100.000 (99.963)
2022-06-17 18:05:34 - INFO - TRAINING - Epoch: [56][30/196]	Time 0.123 (0.173)	Data 0.000 (0.062)	Loss 0.0965 (0.1165)	Prec@1 96.875 (95.943)	Prec@5 100.000 (99.962)
2022-06-17 18:05:36 - INFO - TRAINING - Epoch: [56][40/196]	Time 0.103 (0.160)	Data 0.000 (0.047)	Loss 0.0942 (0.1182)	Prec@1 96.094 (95.789)	Prec@5 100.000 (99.971)
2022-06-17 18:05:37 - INFO - TRAINING - Epoch: [56][50/196]	Time 0.106 (0.151)	Data 0.000 (0.038)	Loss 0.1037 (0.1137)	Prec@1 96.094 (95.971)	Prec@5 100.000 (99.969)
2022-06-17 18:05:38 - INFO - TRAINING - Epoch: [56][60/196]	Time 0.117 (0.145)	Data 0.000 (0.032)	Loss 0.1259 (0.1128)	Prec@1 96.875 (95.978)	Prec@5 99.609 (99.968)
2022-06-17 18:05:39 - INFO - TRAINING - Epoch: [56][70/196]	Time 0.116 (0.140)	Data 0.000 (0.027)	Loss 0.1071 (0.1121)	Prec@1 96.094 (96.033)	Prec@5 100.000 (99.967)
2022-06-17 18:05:40 - INFO - TRAINING - Epoch: [56][80/196]	Time 0.106 (0.136)	Data 0.000 (0.024)	Loss 0.1233 (0.1123)	Prec@1 96.094 (96.055)	Prec@5 100.000 (99.966)
2022-06-17 18:05:41 - INFO - TRAINING - Epoch: [56][90/196]	Time 0.108 (0.134)	Data 0.000 (0.021)	Loss 0.1589 (0.1137)	Prec@1 92.578 (95.986)	Prec@5 100.000 (99.966)
2022-06-17 18:05:42 - INFO - TRAINING - Epoch: [56][100/196]	Time 0.110 (0.133)	Data 0.000 (0.019)	Loss 0.1311 (0.1149)	Prec@1 95.312 (95.947)	Prec@5 100.000 (99.965)
2022-06-17 18:05:44 - INFO - TRAINING - Epoch: [56][110/196]	Time 0.119 (0.131)	Data 0.000 (0.018)	Loss 0.1354 (0.1147)	Prec@1 95.312 (95.960)	Prec@5 100.000 (99.968)
2022-06-17 18:05:45 - INFO - TRAINING - Epoch: [56][120/196]	Time 0.109 (0.130)	Data 0.000 (0.016)	Loss 0.1263 (0.1144)	Prec@1 96.875 (95.987)	Prec@5 100.000 (99.971)
2022-06-17 18:05:46 - INFO - TRAINING - Epoch: [56][130/196]	Time 0.135 (0.129)	Data 0.000 (0.015)	Loss 0.1170 (0.1150)	Prec@1 94.922 (95.951)	Prec@5 100.000 (99.970)
2022-06-17 18:05:47 - INFO - TRAINING - Epoch: [56][140/196]	Time 0.107 (0.128)	Data 0.000 (0.014)	Loss 0.0965 (0.1158)	Prec@1 96.875 (95.911)	Prec@5 100.000 (99.972)
2022-06-17 18:05:48 - INFO - TRAINING - Epoch: [56][150/196]	Time 0.105 (0.127)	Data 0.000 (0.013)	Loss 0.1148 (0.1169)	Prec@1 94.531 (95.879)	Prec@5 100.000 (99.974)
2022-06-17 18:05:49 - INFO - TRAINING - Epoch: [56][160/196]	Time 0.108 (0.126)	Data 0.000 (0.012)	Loss 0.1252 (0.1171)	Prec@1 96.094 (95.871)	Prec@5 100.000 (99.976)
2022-06-17 18:05:51 - INFO - TRAINING - Epoch: [56][170/196]	Time 0.129 (0.126)	Data 0.000 (0.012)	Loss 0.0802 (0.1177)	Prec@1 97.266 (95.852)	Prec@5 100.000 (99.975)
2022-06-17 18:05:52 - INFO - TRAINING - Epoch: [56][180/196]	Time 0.125 (0.125)	Data 0.000 (0.011)	Loss 0.0870 (0.1173)	Prec@1 97.656 (95.878)	Prec@5 100.000 (99.972)
2022-06-17 18:05:53 - INFO - TRAINING - Epoch: [56][190/196]	Time 0.103 (0.124)	Data 0.000 (0.010)	Loss 0.1338 (0.1172)	Prec@1 95.703 (95.887)	Prec@5 100.000 (99.967)
2022-06-17 18:05:55 - INFO - EVALUATING - Epoch: [56][0/40]	Time 2.017 (2.017)	Data 1.971 (1.971)	Loss 0.2608 (0.2608)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:05:57 - INFO - EVALUATING - Epoch: [56][10/40]	Time 0.055 (0.289)	Data 0.000 (0.241)	Loss 0.4600 (0.3995)	Prec@1 87.891 (88.139)	Prec@5 99.219 (99.432)
2022-06-17 18:05:57 - INFO - EVALUATING - Epoch: [56][20/40]	Time 0.041 (0.177)	Data 0.000 (0.129)	Loss 0.3348 (0.4036)	Prec@1 87.891 (87.853)	Prec@5 100.000 (99.386)
2022-06-17 18:05:58 - INFO - EVALUATING - Epoch: [56][30/40]	Time 0.127 (0.156)	Data 0.084 (0.109)	Loss 0.4861 (0.3964)	Prec@1 85.156 (87.916)	Prec@5 100.000 (99.446)
2022-06-17 18:06:00 - INFO - 
 Epoch: 57	Training Loss 0.1179 	Training Prec@1 95.870 	Training Prec@5 99.968 	Validation Loss 0.3912 	Validation Prec@1 87.950 	Validation Prec@5 99.530 

2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:06:00 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:06:02 - INFO - TRAINING - Epoch: [57][0/196]	Time 1.759 (1.759)	Data 1.703 (1.703)	Loss 0.0927 (0.0927)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:06:03 - INFO - TRAINING - Epoch: [57][10/196]	Time 0.120 (0.277)	Data 0.000 (0.175)	Loss 0.1133 (0.1095)	Prec@1 94.531 (96.271)	Prec@5 100.000 (100.000)
2022-06-17 18:06:04 - INFO - TRAINING - Epoch: [57][20/196]	Time 0.113 (0.202)	Data 0.000 (0.092)	Loss 0.1019 (0.1133)	Prec@1 96.875 (96.094)	Prec@5 100.000 (99.963)
2022-06-17 18:06:06 - INFO - TRAINING - Epoch: [57][30/196]	Time 0.109 (0.174)	Data 0.000 (0.062)	Loss 0.1174 (0.1127)	Prec@1 97.266 (96.232)	Prec@5 100.000 (99.962)
2022-06-17 18:06:07 - INFO - TRAINING - Epoch: [57][40/196]	Time 0.121 (0.162)	Data 0.000 (0.047)	Loss 0.1360 (0.1139)	Prec@1 96.484 (96.237)	Prec@5 99.219 (99.952)
2022-06-17 18:06:08 - INFO - TRAINING - Epoch: [57][50/196]	Time 0.109 (0.153)	Data 0.000 (0.038)	Loss 0.1062 (0.1169)	Prec@1 96.094 (96.063)	Prec@5 100.000 (99.954)
2022-06-17 18:06:09 - INFO - TRAINING - Epoch: [57][60/196]	Time 0.121 (0.148)	Data 0.000 (0.032)	Loss 0.1206 (0.1158)	Prec@1 96.484 (96.139)	Prec@5 100.000 (99.942)
2022-06-17 18:06:10 - INFO - TRAINING - Epoch: [57][70/196]	Time 0.109 (0.144)	Data 0.000 (0.027)	Loss 0.1212 (0.1176)	Prec@1 95.312 (96.072)	Prec@5 100.000 (99.945)
2022-06-17 18:06:12 - INFO - TRAINING - Epoch: [57][80/196]	Time 0.127 (0.141)	Data 0.000 (0.024)	Loss 0.1344 (0.1177)	Prec@1 96.094 (96.002)	Prec@5 99.609 (99.942)
2022-06-17 18:06:13 - INFO - TRAINING - Epoch: [57][90/196]	Time 0.104 (0.138)	Data 0.000 (0.021)	Loss 0.1731 (0.1186)	Prec@1 93.359 (95.935)	Prec@5 100.000 (99.944)
2022-06-17 18:06:14 - INFO - TRAINING - Epoch: [57][100/196]	Time 0.125 (0.136)	Data 0.001 (0.019)	Loss 0.0840 (0.1198)	Prec@1 95.703 (95.904)	Prec@5 100.000 (99.946)
2022-06-17 18:06:15 - INFO - TRAINING - Epoch: [57][110/196]	Time 0.117 (0.135)	Data 0.000 (0.018)	Loss 0.1225 (0.1205)	Prec@1 95.312 (95.865)	Prec@5 100.000 (99.947)
2022-06-17 18:06:16 - INFO - TRAINING - Epoch: [57][120/196]	Time 0.124 (0.134)	Data 0.000 (0.016)	Loss 0.0959 (0.1200)	Prec@1 96.875 (95.865)	Prec@5 100.000 (99.952)
2022-06-17 18:06:18 - INFO - TRAINING - Epoch: [57][130/196]	Time 0.098 (0.133)	Data 0.000 (0.015)	Loss 0.1040 (0.1187)	Prec@1 96.484 (95.879)	Prec@5 100.000 (99.955)
2022-06-17 18:06:19 - INFO - TRAINING - Epoch: [57][140/196]	Time 0.116 (0.132)	Data 0.000 (0.014)	Loss 0.1039 (0.1176)	Prec@1 96.875 (95.903)	Prec@5 100.000 (99.958)
2022-06-17 18:06:20 - INFO - TRAINING - Epoch: [57][150/196]	Time 0.104 (0.131)	Data 0.000 (0.013)	Loss 0.0986 (0.1172)	Prec@1 95.703 (95.920)	Prec@5 100.000 (99.961)
2022-06-17 18:06:21 - INFO - TRAINING - Epoch: [57][160/196]	Time 0.122 (0.130)	Data 0.000 (0.012)	Loss 0.1415 (0.1178)	Prec@1 94.531 (95.900)	Prec@5 99.609 (99.959)
2022-06-17 18:06:22 - INFO - TRAINING - Epoch: [57][170/196]	Time 0.101 (0.130)	Data 0.000 (0.012)	Loss 0.1233 (0.1181)	Prec@1 96.484 (95.888)	Prec@5 100.000 (99.961)
2022-06-17 18:06:24 - INFO - TRAINING - Epoch: [57][180/196]	Time 0.134 (0.129)	Data 0.000 (0.011)	Loss 0.1213 (0.1179)	Prec@1 95.703 (95.897)	Prec@5 100.000 (99.961)
2022-06-17 18:06:25 - INFO - TRAINING - Epoch: [57][190/196]	Time 0.101 (0.128)	Data 0.000 (0.010)	Loss 0.1206 (0.1175)	Prec@1 97.656 (95.920)	Prec@5 100.000 (99.961)
2022-06-17 18:06:27 - INFO - EVALUATING - Epoch: [57][0/40]	Time 2.025 (2.025)	Data 1.979 (1.979)	Loss 0.2645 (0.2645)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:06:28 - INFO - EVALUATING - Epoch: [57][10/40]	Time 0.044 (0.278)	Data 0.000 (0.231)	Loss 0.4512 (0.3964)	Prec@1 87.891 (88.317)	Prec@5 99.219 (99.396)
2022-06-17 18:06:29 - INFO - EVALUATING - Epoch: [57][20/40]	Time 0.091 (0.172)	Data 0.050 (0.124)	Loss 0.3287 (0.3993)	Prec@1 88.281 (88.002)	Prec@5 100.000 (99.386)
2022-06-17 18:06:30 - INFO - EVALUATING - Epoch: [57][30/40]	Time 0.113 (0.155)	Data 0.068 (0.109)	Loss 0.4862 (0.3921)	Prec@1 85.938 (88.067)	Prec@5 100.000 (99.446)
2022-06-17 18:06:32 - INFO - 
 Epoch: 58	Training Loss 0.1177 	Training Prec@1 95.922 	Training Prec@5 99.958 	Validation Loss 0.3870 	Validation Prec@1 88.070 	Validation Prec@5 99.530 

2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:06:32 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:06:33 - INFO - TRAINING - Epoch: [58][0/196]	Time 1.281 (1.281)	Data 1.227 (1.227)	Loss 0.1384 (0.1384)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 18:06:35 - INFO - TRAINING - Epoch: [58][10/196]	Time 0.121 (0.256)	Data 0.000 (0.159)	Loss 0.1548 (0.1269)	Prec@1 95.312 (95.526)	Prec@5 100.000 (100.000)
2022-06-17 18:06:36 - INFO - TRAINING - Epoch: [58][20/196]	Time 0.121 (0.190)	Data 0.000 (0.084)	Loss 0.1079 (0.1167)	Prec@1 95.703 (95.871)	Prec@5 100.000 (99.981)
2022-06-17 18:06:37 - INFO - TRAINING - Epoch: [58][30/196]	Time 0.111 (0.165)	Data 0.000 (0.057)	Loss 0.0938 (0.1164)	Prec@1 97.656 (95.817)	Prec@5 100.000 (99.987)
2022-06-17 18:06:38 - INFO - TRAINING - Epoch: [58][40/196]	Time 0.113 (0.154)	Data 0.000 (0.043)	Loss 0.1384 (0.1192)	Prec@1 93.359 (95.770)	Prec@5 100.000 (99.962)
2022-06-17 18:06:40 - INFO - TRAINING - Epoch: [58][50/196]	Time 0.120 (0.146)	Data 0.000 (0.035)	Loss 0.0839 (0.1177)	Prec@1 96.875 (95.864)	Prec@5 100.000 (99.954)
2022-06-17 18:06:41 - INFO - TRAINING - Epoch: [58][60/196]	Time 0.109 (0.142)	Data 0.000 (0.029)	Loss 0.1145 (0.1190)	Prec@1 94.531 (95.882)	Prec@5 100.000 (99.936)
2022-06-17 18:06:42 - INFO - TRAINING - Epoch: [58][70/196]	Time 0.116 (0.138)	Data 0.000 (0.025)	Loss 0.0908 (0.1198)	Prec@1 97.266 (95.896)	Prec@5 100.000 (99.939)
2022-06-17 18:06:43 - INFO - TRAINING - Epoch: [58][80/196]	Time 0.103 (0.134)	Data 0.000 (0.022)	Loss 0.1113 (0.1196)	Prec@1 95.703 (95.964)	Prec@5 100.000 (99.947)
2022-06-17 18:06:44 - INFO - TRAINING - Epoch: [58][90/196]	Time 0.104 (0.132)	Data 0.000 (0.020)	Loss 0.0703 (0.1183)	Prec@1 98.047 (95.969)	Prec@5 100.000 (99.948)
2022-06-17 18:06:45 - INFO - TRAINING - Epoch: [58][100/196]	Time 0.106 (0.130)	Data 0.000 (0.018)	Loss 0.1164 (0.1177)	Prec@1 96.875 (95.985)	Prec@5 99.609 (99.950)
2022-06-17 18:06:46 - INFO - TRAINING - Epoch: [58][110/196]	Time 0.109 (0.129)	Data 0.000 (0.016)	Loss 0.1073 (0.1179)	Prec@1 96.484 (95.999)	Prec@5 100.000 (99.947)
2022-06-17 18:06:48 - INFO - TRAINING - Epoch: [58][120/196]	Time 0.121 (0.128)	Data 0.000 (0.015)	Loss 0.1381 (0.1182)	Prec@1 96.094 (95.968)	Prec@5 100.000 (99.952)
2022-06-17 18:06:49 - INFO - TRAINING - Epoch: [58][130/196]	Time 0.104 (0.126)	Data 0.000 (0.014)	Loss 0.0948 (0.1169)	Prec@1 96.875 (95.995)	Prec@5 100.000 (99.955)
2022-06-17 18:06:50 - INFO - TRAINING - Epoch: [58][140/196]	Time 0.123 (0.126)	Data 0.000 (0.013)	Loss 0.1337 (0.1176)	Prec@1 96.094 (95.983)	Prec@5 100.000 (99.953)
2022-06-17 18:06:51 - INFO - TRAINING - Epoch: [58][150/196]	Time 0.111 (0.125)	Data 0.000 (0.012)	Loss 0.1185 (0.1178)	Prec@1 95.703 (95.964)	Prec@5 100.000 (99.953)
2022-06-17 18:06:52 - INFO - TRAINING - Epoch: [58][160/196]	Time 0.108 (0.124)	Data 0.000 (0.011)	Loss 0.1331 (0.1184)	Prec@1 94.531 (95.958)	Prec@5 100.000 (99.951)
2022-06-17 18:06:53 - INFO - TRAINING - Epoch: [58][170/196]	Time 0.106 (0.123)	Data 0.000 (0.011)	Loss 0.1070 (0.1185)	Prec@1 95.312 (95.945)	Prec@5 100.000 (99.952)
2022-06-17 18:06:54 - INFO - TRAINING - Epoch: [58][180/196]	Time 0.104 (0.122)	Data 0.000 (0.010)	Loss 0.1428 (0.1182)	Prec@1 94.922 (95.964)	Prec@5 100.000 (99.953)
2022-06-17 18:06:55 - INFO - TRAINING - Epoch: [58][190/196]	Time 0.102 (0.122)	Data 0.000 (0.009)	Loss 0.1312 (0.1185)	Prec@1 96.484 (95.942)	Prec@5 100.000 (99.955)
2022-06-17 18:06:58 - INFO - EVALUATING - Epoch: [58][0/40]	Time 1.964 (1.964)	Data 1.919 (1.919)	Loss 0.2651 (0.2651)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:06:59 - INFO - EVALUATING - Epoch: [58][10/40]	Time 0.065 (0.271)	Data 0.000 (0.221)	Loss 0.4561 (0.4039)	Prec@1 88.672 (87.997)	Prec@5 99.219 (99.396)
2022-06-17 18:06:59 - INFO - EVALUATING - Epoch: [58][20/40]	Time 0.044 (0.168)	Data 0.000 (0.116)	Loss 0.3271 (0.4058)	Prec@1 87.500 (87.946)	Prec@5 100.000 (99.423)
2022-06-17 18:07:01 - INFO - EVALUATING - Epoch: [58][30/40]	Time 0.041 (0.156)	Data 0.000 (0.106)	Loss 0.4916 (0.3988)	Prec@1 86.719 (88.067)	Prec@5 100.000 (99.446)
2022-06-17 18:07:03 - INFO - 
 Epoch: 59	Training Loss 0.1185 	Training Prec@1 95.930 	Training Prec@5 99.956 	Validation Loss 0.3933 	Validation Prec@1 88.150 	Validation Prec@5 99.520 

2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:07:03 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:07:04 - INFO - TRAINING - Epoch: [59][0/196]	Time 1.314 (1.314)	Data 1.262 (1.262)	Loss 0.0936 (0.0936)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:07:06 - INFO - TRAINING - Epoch: [59][10/196]	Time 0.113 (0.272)	Data 0.000 (0.175)	Loss 0.1061 (0.1120)	Prec@1 96.875 (96.236)	Prec@5 100.000 (100.000)
2022-06-17 18:07:07 - INFO - TRAINING - Epoch: [59][20/196]	Time 0.106 (0.195)	Data 0.000 (0.092)	Loss 0.1071 (0.1106)	Prec@1 95.312 (96.354)	Prec@5 100.000 (99.981)
2022-06-17 18:07:08 - INFO - TRAINING - Epoch: [59][30/196]	Time 0.108 (0.168)	Data 0.000 (0.062)	Loss 0.1213 (0.1136)	Prec@1 96.484 (96.283)	Prec@5 100.000 (99.975)
2022-06-17 18:07:09 - INFO - TRAINING - Epoch: [59][40/196]	Time 0.114 (0.154)	Data 0.000 (0.047)	Loss 0.0890 (0.1121)	Prec@1 97.656 (96.303)	Prec@5 100.000 (99.981)
2022-06-17 18:07:10 - INFO - TRAINING - Epoch: [59][50/196]	Time 0.133 (0.146)	Data 0.000 (0.038)	Loss 0.0836 (0.1118)	Prec@1 97.656 (96.339)	Prec@5 100.000 (99.985)
2022-06-17 18:07:11 - INFO - TRAINING - Epoch: [59][60/196]	Time 0.106 (0.141)	Data 0.000 (0.032)	Loss 0.0720 (0.1122)	Prec@1 96.875 (96.286)	Prec@5 100.000 (99.987)
2022-06-17 18:07:13 - INFO - TRAINING - Epoch: [59][70/196]	Time 0.132 (0.138)	Data 0.000 (0.027)	Loss 0.1962 (0.1112)	Prec@1 92.969 (96.314)	Prec@5 99.609 (99.978)
2022-06-17 18:07:14 - INFO - TRAINING - Epoch: [59][80/196]	Time 0.125 (0.135)	Data 0.000 (0.024)	Loss 0.1618 (0.1130)	Prec@1 93.750 (96.253)	Prec@5 99.609 (99.966)
2022-06-17 18:07:15 - INFO - TRAINING - Epoch: [59][90/196]	Time 0.112 (0.133)	Data 0.000 (0.021)	Loss 0.1234 (0.1134)	Prec@1 95.703 (96.210)	Prec@5 99.609 (99.966)
2022-06-17 18:07:16 - INFO - TRAINING - Epoch: [59][100/196]	Time 0.117 (0.132)	Data 0.000 (0.019)	Loss 0.1351 (0.1130)	Prec@1 92.969 (96.225)	Prec@5 100.000 (99.965)
2022-06-17 18:07:17 - INFO - TRAINING - Epoch: [59][110/196]	Time 0.138 (0.130)	Data 0.000 (0.018)	Loss 0.1310 (0.1148)	Prec@1 95.312 (96.136)	Prec@5 100.000 (99.965)
2022-06-17 18:07:18 - INFO - TRAINING - Epoch: [59][120/196]	Time 0.123 (0.129)	Data 0.000 (0.016)	Loss 0.1299 (0.1148)	Prec@1 94.922 (96.103)	Prec@5 100.000 (99.964)
2022-06-17 18:07:20 - INFO - TRAINING - Epoch: [59][130/196]	Time 0.108 (0.128)	Data 0.000 (0.015)	Loss 0.1352 (0.1141)	Prec@1 94.922 (96.150)	Prec@5 100.000 (99.967)
2022-06-17 18:07:21 - INFO - TRAINING - Epoch: [59][140/196]	Time 0.104 (0.127)	Data 0.000 (0.014)	Loss 0.0974 (0.1142)	Prec@1 97.266 (96.141)	Prec@5 100.000 (99.970)
2022-06-17 18:07:22 - INFO - TRAINING - Epoch: [59][150/196]	Time 0.109 (0.127)	Data 0.000 (0.013)	Loss 0.1215 (0.1150)	Prec@1 97.266 (96.130)	Prec@5 99.609 (99.966)
2022-06-17 18:07:23 - INFO - TRAINING - Epoch: [59][160/196]	Time 0.124 (0.127)	Data 0.000 (0.012)	Loss 0.0886 (0.1142)	Prec@1 96.484 (96.171)	Prec@5 100.000 (99.968)
2022-06-17 18:07:24 - INFO - TRAINING - Epoch: [59][170/196]	Time 0.108 (0.126)	Data 0.000 (0.012)	Loss 0.1106 (0.1141)	Prec@1 96.094 (96.158)	Prec@5 100.000 (99.970)
2022-06-17 18:07:26 - INFO - TRAINING - Epoch: [59][180/196]	Time 0.104 (0.126)	Data 0.000 (0.011)	Loss 0.0749 (0.1145)	Prec@1 97.266 (96.130)	Prec@5 100.000 (99.972)
2022-06-17 18:07:27 - INFO - TRAINING - Epoch: [59][190/196]	Time 0.103 (0.125)	Data 0.000 (0.010)	Loss 0.1462 (0.1145)	Prec@1 95.312 (96.139)	Prec@5 100.000 (99.971)
2022-06-17 18:07:29 - INFO - EVALUATING - Epoch: [59][0/40]	Time 1.480 (1.480)	Data 1.434 (1.434)	Loss 0.2620 (0.2620)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:07:30 - INFO - EVALUATING - Epoch: [59][10/40]	Time 0.081 (0.231)	Data 0.039 (0.184)	Loss 0.4582 (0.3991)	Prec@1 87.500 (88.068)	Prec@5 99.219 (99.396)
2022-06-17 18:07:31 - INFO - EVALUATING - Epoch: [59][20/40]	Time 0.129 (0.176)	Data 0.087 (0.131)	Loss 0.3331 (0.4027)	Prec@1 87.109 (87.779)	Prec@5 100.000 (99.368)
2022-06-17 18:07:32 - INFO - EVALUATING - Epoch: [59][30/40]	Time 0.089 (0.153)	Data 0.045 (0.108)	Loss 0.4895 (0.3958)	Prec@1 85.938 (87.853)	Prec@5 100.000 (99.433)
2022-06-17 18:07:34 - INFO - 
 Epoch: 60	Training Loss 0.1145 	Training Prec@1 96.130 	Training Prec@5 99.972 	Validation Loss 0.3911 	Validation Prec@1 87.890 	Validation Prec@5 99.510 

2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:07:34 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:07:36 - INFO - TRAINING - Epoch: [60][0/196]	Time 1.826 (1.826)	Data 1.773 (1.773)	Loss 0.1148 (0.1148)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 18:07:37 - INFO - TRAINING - Epoch: [60][10/196]	Time 0.119 (0.277)	Data 0.000 (0.176)	Loss 0.1274 (0.1243)	Prec@1 96.875 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:07:38 - INFO - TRAINING - Epoch: [60][20/196]	Time 0.105 (0.198)	Data 0.000 (0.092)	Loss 0.1015 (0.1177)	Prec@1 96.484 (96.001)	Prec@5 100.000 (99.981)
2022-06-17 18:07:39 - INFO - TRAINING - Epoch: [60][30/196]	Time 0.117 (0.170)	Data 0.000 (0.063)	Loss 0.1296 (0.1178)	Prec@1 95.703 (95.930)	Prec@5 100.000 (99.975)
2022-06-17 18:07:40 - INFO - TRAINING - Epoch: [60][40/196]	Time 0.114 (0.156)	Data 0.000 (0.047)	Loss 0.1400 (0.1164)	Prec@1 96.094 (96.008)	Prec@5 100.000 (99.981)
2022-06-17 18:07:41 - INFO - TRAINING - Epoch: [60][50/196]	Time 0.124 (0.148)	Data 0.000 (0.038)	Loss 0.1326 (0.1163)	Prec@1 94.922 (96.055)	Prec@5 100.000 (99.977)
2022-06-17 18:07:43 - INFO - TRAINING - Epoch: [60][60/196]	Time 0.125 (0.142)	Data 0.000 (0.032)	Loss 0.0669 (0.1150)	Prec@1 98.047 (96.107)	Prec@5 100.000 (99.981)
2022-06-17 18:07:44 - INFO - TRAINING - Epoch: [60][70/196]	Time 0.122 (0.138)	Data 0.000 (0.027)	Loss 0.1359 (0.1179)	Prec@1 94.922 (96.061)	Prec@5 100.000 (99.978)
2022-06-17 18:07:45 - INFO - TRAINING - Epoch: [60][80/196]	Time 0.119 (0.135)	Data 0.000 (0.024)	Loss 0.1098 (0.1181)	Prec@1 96.094 (96.021)	Prec@5 100.000 (99.981)
2022-06-17 18:07:46 - INFO - TRAINING - Epoch: [60][90/196]	Time 0.122 (0.133)	Data 0.000 (0.022)	Loss 0.0789 (0.1181)	Prec@1 96.875 (96.034)	Prec@5 100.000 (99.983)
2022-06-17 18:07:47 - INFO - TRAINING - Epoch: [60][100/196]	Time 0.126 (0.132)	Data 0.000 (0.019)	Loss 0.1273 (0.1182)	Prec@1 94.922 (96.067)	Prec@5 100.000 (99.985)
2022-06-17 18:07:48 - INFO - TRAINING - Epoch: [60][110/196]	Time 0.118 (0.130)	Data 0.000 (0.018)	Loss 0.1490 (0.1182)	Prec@1 96.094 (96.073)	Prec@5 100.000 (99.982)
2022-06-17 18:07:50 - INFO - TRAINING - Epoch: [60][120/196]	Time 0.119 (0.129)	Data 0.000 (0.016)	Loss 0.1432 (0.1179)	Prec@1 94.531 (96.065)	Prec@5 100.000 (99.984)
2022-06-17 18:07:51 - INFO - TRAINING - Epoch: [60][130/196]	Time 0.123 (0.128)	Data 0.000 (0.015)	Loss 0.1301 (0.1175)	Prec@1 95.703 (96.064)	Prec@5 99.609 (99.982)
2022-06-17 18:07:52 - INFO - TRAINING - Epoch: [60][140/196]	Time 0.118 (0.127)	Data 0.000 (0.014)	Loss 0.1560 (0.1181)	Prec@1 95.703 (96.052)	Prec@5 100.000 (99.975)
2022-06-17 18:07:53 - INFO - TRAINING - Epoch: [60][150/196]	Time 0.111 (0.126)	Data 0.000 (0.013)	Loss 0.1209 (0.1182)	Prec@1 95.312 (96.037)	Prec@5 100.000 (99.977)
2022-06-17 18:07:54 - INFO - TRAINING - Epoch: [60][160/196]	Time 0.127 (0.126)	Data 0.000 (0.012)	Loss 0.1189 (0.1181)	Prec@1 96.484 (95.997)	Prec@5 99.609 (99.973)
2022-06-17 18:07:55 - INFO - TRAINING - Epoch: [60][170/196]	Time 0.119 (0.125)	Data 0.000 (0.012)	Loss 0.0876 (0.1179)	Prec@1 96.875 (95.996)	Prec@5 100.000 (99.975)
2022-06-17 18:07:56 - INFO - TRAINING - Epoch: [60][180/196]	Time 0.121 (0.124)	Data 0.000 (0.011)	Loss 0.0872 (0.1179)	Prec@1 97.266 (95.982)	Prec@5 100.000 (99.974)
2022-06-17 18:07:58 - INFO - TRAINING - Epoch: [60][190/196]	Time 0.102 (0.124)	Data 0.000 (0.010)	Loss 0.0981 (0.1179)	Prec@1 96.094 (95.973)	Prec@5 100.000 (99.973)
2022-06-17 18:08:00 - INFO - EVALUATING - Epoch: [60][0/40]	Time 1.517 (1.517)	Data 1.472 (1.472)	Loss 0.2600 (0.2600)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:08:01 - INFO - EVALUATING - Epoch: [60][10/40]	Time 0.052 (0.277)	Data 0.000 (0.226)	Loss 0.4580 (0.3973)	Prec@1 88.281 (88.317)	Prec@5 99.609 (99.432)
2022-06-17 18:08:02 - INFO - EVALUATING - Epoch: [60][20/40]	Time 0.068 (0.170)	Data 0.000 (0.118)	Loss 0.3290 (0.4004)	Prec@1 87.891 (87.946)	Prec@5 100.000 (99.423)
2022-06-17 18:08:03 - INFO - EVALUATING - Epoch: [60][30/40]	Time 0.042 (0.148)	Data 0.000 (0.099)	Loss 0.4795 (0.3940)	Prec@1 86.328 (88.080)	Prec@5 100.000 (99.471)
2022-06-17 18:08:05 - INFO - 
 Epoch: 61	Training Loss 0.1180 	Training Prec@1 95.976 	Training Prec@5 99.970 	Validation Loss 0.3894 	Validation Prec@1 88.180 	Validation Prec@5 99.540 

2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:08:05 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:08:07 - INFO - TRAINING - Epoch: [61][0/196]	Time 1.808 (1.808)	Data 1.755 (1.755)	Loss 0.1410 (0.1410)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:08:08 - INFO - TRAINING - Epoch: [61][10/196]	Time 0.108 (0.267)	Data 0.000 (0.160)	Loss 0.1707 (0.1195)	Prec@1 94.141 (95.774)	Prec@5 100.000 (99.964)
2022-06-17 18:08:09 - INFO - TRAINING - Epoch: [61][20/196]	Time 0.112 (0.192)	Data 0.000 (0.084)	Loss 0.0898 (0.1175)	Prec@1 96.875 (95.852)	Prec@5 100.000 (99.981)
2022-06-17 18:08:10 - INFO - TRAINING - Epoch: [61][30/196]	Time 0.126 (0.168)	Data 0.000 (0.057)	Loss 0.1405 (0.1198)	Prec@1 93.359 (95.817)	Prec@5 100.000 (99.962)
2022-06-17 18:08:11 - INFO - TRAINING - Epoch: [61][40/196]	Time 0.101 (0.154)	Data 0.000 (0.043)	Loss 0.0845 (0.1200)	Prec@1 96.094 (95.808)	Prec@5 100.000 (99.962)
2022-06-17 18:08:12 - INFO - TRAINING - Epoch: [61][50/196]	Time 0.106 (0.146)	Data 0.000 (0.035)	Loss 0.1333 (0.1174)	Prec@1 95.312 (95.948)	Prec@5 100.000 (99.954)
2022-06-17 18:08:13 - INFO - TRAINING - Epoch: [61][60/196]	Time 0.114 (0.140)	Data 0.000 (0.029)	Loss 0.0875 (0.1164)	Prec@1 97.656 (95.985)	Prec@5 100.000 (99.962)
2022-06-17 18:08:14 - INFO - TRAINING - Epoch: [61][70/196]	Time 0.104 (0.135)	Data 0.000 (0.025)	Loss 0.1110 (0.1164)	Prec@1 96.094 (95.967)	Prec@5 100.000 (99.961)
2022-06-17 18:08:15 - INFO - TRAINING - Epoch: [61][80/196]	Time 0.105 (0.132)	Data 0.000 (0.022)	Loss 0.0934 (0.1144)	Prec@1 96.875 (96.036)	Prec@5 100.000 (99.966)
2022-06-17 18:08:17 - INFO - TRAINING - Epoch: [61][90/196]	Time 0.112 (0.130)	Data 0.000 (0.020)	Loss 0.1301 (0.1148)	Prec@1 96.875 (96.008)	Prec@5 100.000 (99.970)
2022-06-17 18:08:18 - INFO - TRAINING - Epoch: [61][100/196]	Time 0.107 (0.128)	Data 0.000 (0.018)	Loss 0.0925 (0.1142)	Prec@1 96.094 (96.013)	Prec@5 100.000 (99.969)
2022-06-17 18:08:19 - INFO - TRAINING - Epoch: [61][110/196]	Time 0.116 (0.127)	Data 0.000 (0.016)	Loss 0.0948 (0.1141)	Prec@1 96.875 (95.995)	Prec@5 100.000 (99.972)
2022-06-17 18:08:20 - INFO - TRAINING - Epoch: [61][120/196]	Time 0.116 (0.126)	Data 0.000 (0.015)	Loss 0.1059 (0.1132)	Prec@1 96.875 (96.049)	Prec@5 100.000 (99.974)
2022-06-17 18:08:21 - INFO - TRAINING - Epoch: [61][130/196]	Time 0.114 (0.125)	Data 0.000 (0.014)	Loss 0.1468 (0.1140)	Prec@1 93.750 (96.025)	Prec@5 100.000 (99.976)
2022-06-17 18:08:22 - INFO - TRAINING - Epoch: [61][140/196]	Time 0.138 (0.125)	Data 0.000 (0.013)	Loss 0.1070 (0.1144)	Prec@1 96.484 (96.019)	Prec@5 100.000 (99.978)
2022-06-17 18:08:24 - INFO - TRAINING - Epoch: [61][150/196]	Time 0.112 (0.125)	Data 0.000 (0.012)	Loss 0.0697 (0.1137)	Prec@1 98.438 (96.060)	Prec@5 100.000 (99.979)
2022-06-17 18:08:25 - INFO - TRAINING - Epoch: [61][160/196]	Time 0.117 (0.125)	Data 0.000 (0.011)	Loss 0.1097 (0.1139)	Prec@1 96.094 (96.060)	Prec@5 100.000 (99.981)
2022-06-17 18:08:26 - INFO - TRAINING - Epoch: [61][170/196]	Time 0.104 (0.124)	Data 0.000 (0.011)	Loss 0.1415 (0.1138)	Prec@1 94.141 (96.050)	Prec@5 100.000 (99.982)
2022-06-17 18:08:27 - INFO - TRAINING - Epoch: [61][180/196]	Time 0.101 (0.124)	Data 0.000 (0.010)	Loss 0.0959 (0.1136)	Prec@1 96.875 (96.066)	Prec@5 100.000 (99.983)
2022-06-17 18:08:28 - INFO - TRAINING - Epoch: [61][190/196]	Time 0.102 (0.123)	Data 0.000 (0.009)	Loss 0.1207 (0.1148)	Prec@1 96.484 (96.024)	Prec@5 99.609 (99.980)
2022-06-17 18:08:31 - INFO - EVALUATING - Epoch: [61][0/40]	Time 1.861 (1.861)	Data 1.815 (1.815)	Loss 0.2571 (0.2571)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:08:32 - INFO - EVALUATING - Epoch: [61][10/40]	Time 0.048 (0.278)	Data 0.000 (0.228)	Loss 0.4530 (0.3973)	Prec@1 88.672 (88.388)	Prec@5 99.219 (99.432)
2022-06-17 18:08:32 - INFO - EVALUATING - Epoch: [61][20/40]	Time 0.068 (0.172)	Data 0.000 (0.120)	Loss 0.3222 (0.3997)	Prec@1 87.891 (87.928)	Prec@5 100.000 (99.442)
2022-06-17 18:08:34 - INFO - EVALUATING - Epoch: [61][30/40]	Time 0.044 (0.153)	Data 0.000 (0.104)	Loss 0.4751 (0.3932)	Prec@1 86.719 (88.067)	Prec@5 100.000 (99.483)
2022-06-17 18:08:35 - INFO - 
 Epoch: 62	Training Loss 0.1148 	Training Prec@1 96.028 	Training Prec@5 99.974 	Validation Loss 0.3887 	Validation Prec@1 88.090 	Validation Prec@5 99.560 

2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:08:35 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:08:37 - INFO - TRAINING - Epoch: [62][0/196]	Time 1.750 (1.750)	Data 1.697 (1.697)	Loss 0.1387 (0.1387)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 18:08:38 - INFO - TRAINING - Epoch: [62][10/196]	Time 0.110 (0.263)	Data 0.000 (0.155)	Loss 0.1077 (0.1111)	Prec@1 96.875 (96.413)	Prec@5 100.000 (100.000)
2022-06-17 18:08:39 - INFO - TRAINING - Epoch: [62][20/196]	Time 0.106 (0.192)	Data 0.000 (0.081)	Loss 0.1395 (0.1114)	Prec@1 94.531 (96.280)	Prec@5 100.000 (100.000)
2022-06-17 18:08:41 - INFO - TRAINING - Epoch: [62][30/196]	Time 0.104 (0.163)	Data 0.000 (0.055)	Loss 0.1168 (0.1110)	Prec@1 96.484 (96.169)	Prec@5 100.000 (100.000)
2022-06-17 18:08:42 - INFO - TRAINING - Epoch: [62][40/196]	Time 0.123 (0.150)	Data 0.000 (0.042)	Loss 0.1307 (0.1104)	Prec@1 94.141 (96.218)	Prec@5 100.000 (100.000)
2022-06-17 18:08:43 - INFO - TRAINING - Epoch: [62][50/196]	Time 0.106 (0.142)	Data 0.000 (0.034)	Loss 0.0711 (0.1127)	Prec@1 97.266 (96.170)	Prec@5 100.000 (99.992)
2022-06-17 18:08:44 - INFO - TRAINING - Epoch: [62][60/196]	Time 0.103 (0.136)	Data 0.000 (0.028)	Loss 0.1067 (0.1130)	Prec@1 96.094 (96.190)	Prec@5 100.000 (99.981)
2022-06-17 18:08:45 - INFO - TRAINING - Epoch: [62][70/196]	Time 0.111 (0.132)	Data 0.000 (0.024)	Loss 0.0769 (0.1138)	Prec@1 97.266 (96.110)	Prec@5 100.000 (99.967)
2022-06-17 18:08:46 - INFO - TRAINING - Epoch: [62][80/196]	Time 0.118 (0.129)	Data 0.000 (0.021)	Loss 0.0951 (0.1121)	Prec@1 96.484 (96.156)	Prec@5 100.000 (99.971)
2022-06-17 18:08:47 - INFO - TRAINING - Epoch: [62][90/196]	Time 0.107 (0.127)	Data 0.000 (0.019)	Loss 0.1127 (0.1132)	Prec@1 96.484 (96.154)	Prec@5 100.000 (99.974)
2022-06-17 18:08:48 - INFO - TRAINING - Epoch: [62][100/196]	Time 0.103 (0.125)	Data 0.000 (0.017)	Loss 0.0786 (0.1135)	Prec@1 97.656 (96.125)	Prec@5 100.000 (99.977)
2022-06-17 18:08:49 - INFO - TRAINING - Epoch: [62][110/196]	Time 0.116 (0.124)	Data 0.000 (0.016)	Loss 0.1289 (0.1131)	Prec@1 96.094 (96.161)	Prec@5 100.000 (99.968)
2022-06-17 18:08:50 - INFO - TRAINING - Epoch: [62][120/196]	Time 0.105 (0.123)	Data 0.000 (0.014)	Loss 0.1196 (0.1127)	Prec@1 94.531 (96.149)	Prec@5 100.000 (99.971)
2022-06-17 18:08:51 - INFO - TRAINING - Epoch: [62][130/196]	Time 0.105 (0.122)	Data 0.000 (0.013)	Loss 0.1490 (0.1124)	Prec@1 94.922 (96.165)	Prec@5 100.000 (99.973)
2022-06-17 18:08:53 - INFO - TRAINING - Epoch: [62][140/196]	Time 0.103 (0.121)	Data 0.000 (0.012)	Loss 0.0634 (0.1127)	Prec@1 98.438 (96.180)	Prec@5 100.000 (99.972)
2022-06-17 18:08:54 - INFO - TRAINING - Epoch: [62][150/196]	Time 0.112 (0.120)	Data 0.000 (0.012)	Loss 0.0934 (0.1132)	Prec@1 96.484 (96.156)	Prec@5 100.000 (99.972)
2022-06-17 18:08:55 - INFO - TRAINING - Epoch: [62][160/196]	Time 0.111 (0.120)	Data 0.000 (0.011)	Loss 0.0733 (0.1123)	Prec@1 98.047 (96.196)	Prec@5 100.000 (99.973)
2022-06-17 18:08:56 - INFO - TRAINING - Epoch: [62][170/196]	Time 0.103 (0.119)	Data 0.000 (0.010)	Loss 0.1310 (0.1126)	Prec@1 94.922 (96.181)	Prec@5 100.000 (99.975)
2022-06-17 18:08:57 - INFO - TRAINING - Epoch: [62][180/196]	Time 0.104 (0.119)	Data 0.000 (0.010)	Loss 0.1121 (0.1115)	Prec@1 95.703 (96.219)	Prec@5 100.000 (99.976)
2022-06-17 18:08:58 - INFO - TRAINING - Epoch: [62][190/196]	Time 0.101 (0.118)	Data 0.000 (0.009)	Loss 0.1107 (0.1116)	Prec@1 96.094 (96.221)	Prec@5 100.000 (99.978)
2022-06-17 18:09:00 - INFO - EVALUATING - Epoch: [62][0/40]	Time 1.267 (1.267)	Data 1.221 (1.221)	Loss 0.2612 (0.2612)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:09:01 - INFO - EVALUATING - Epoch: [62][10/40]	Time 0.361 (0.252)	Data 0.320 (0.202)	Loss 0.4548 (0.3980)	Prec@1 87.891 (88.246)	Prec@5 99.609 (99.432)
2022-06-17 18:09:02 - INFO - EVALUATING - Epoch: [62][20/40]	Time 0.110 (0.166)	Data 0.070 (0.119)	Loss 0.3283 (0.4009)	Prec@1 88.281 (88.058)	Prec@5 100.000 (99.423)
2022-06-17 18:09:03 - INFO - EVALUATING - Epoch: [62][30/40]	Time 0.044 (0.147)	Data 0.000 (0.101)	Loss 0.4819 (0.3944)	Prec@1 86.719 (88.155)	Prec@5 100.000 (99.483)
2022-06-17 18:09:05 - INFO - 
 Epoch: 63	Training Loss 0.1119 	Training Prec@1 96.206 	Training Prec@5 99.976 	Validation Loss 0.3898 	Validation Prec@1 88.190 	Validation Prec@5 99.570 

2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:09:05 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:09:07 - INFO - TRAINING - Epoch: [63][0/196]	Time 1.538 (1.538)	Data 1.484 (1.484)	Loss 0.1463 (0.1463)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2022-06-17 18:09:08 - INFO - TRAINING - Epoch: [63][10/196]	Time 0.110 (0.274)	Data 0.000 (0.168)	Loss 0.1315 (0.1117)	Prec@1 94.922 (96.200)	Prec@5 100.000 (99.964)
2022-06-17 18:09:09 - INFO - TRAINING - Epoch: [63][20/196]	Time 0.123 (0.203)	Data 0.000 (0.088)	Loss 0.1348 (0.1097)	Prec@1 95.703 (96.243)	Prec@5 100.000 (99.981)
2022-06-17 18:09:11 - INFO - TRAINING - Epoch: [63][30/196]	Time 0.112 (0.175)	Data 0.000 (0.060)	Loss 0.1389 (0.1133)	Prec@1 95.703 (96.144)	Prec@5 100.000 (99.975)
2022-06-17 18:09:12 - INFO - TRAINING - Epoch: [63][40/196]	Time 0.116 (0.158)	Data 0.000 (0.045)	Loss 0.0911 (0.1075)	Prec@1 97.656 (96.322)	Prec@5 100.000 (99.981)
2022-06-17 18:09:13 - INFO - TRAINING - Epoch: [63][50/196]	Time 0.110 (0.150)	Data 0.000 (0.037)	Loss 0.1263 (0.1104)	Prec@1 94.922 (96.140)	Prec@5 100.000 (99.969)
2022-06-17 18:09:14 - INFO - TRAINING - Epoch: [63][60/196]	Time 0.123 (0.143)	Data 0.000 (0.031)	Loss 0.1254 (0.1109)	Prec@1 94.531 (96.132)	Prec@5 100.000 (99.974)
2022-06-17 18:09:15 - INFO - TRAINING - Epoch: [63][70/196]	Time 0.128 (0.139)	Data 0.000 (0.026)	Loss 0.1156 (0.1099)	Prec@1 95.703 (96.154)	Prec@5 100.000 (99.967)
2022-06-17 18:09:16 - INFO - TRAINING - Epoch: [63][80/196]	Time 0.119 (0.136)	Data 0.000 (0.023)	Loss 0.1339 (0.1098)	Prec@1 94.141 (96.161)	Prec@5 100.000 (99.971)
2022-06-17 18:09:17 - INFO - TRAINING - Epoch: [63][90/196]	Time 0.115 (0.133)	Data 0.000 (0.021)	Loss 0.1045 (0.1080)	Prec@1 96.875 (96.274)	Prec@5 100.000 (99.970)
2022-06-17 18:09:18 - INFO - TRAINING - Epoch: [63][100/196]	Time 0.102 (0.131)	Data 0.000 (0.019)	Loss 0.2077 (0.1108)	Prec@1 92.188 (96.206)	Prec@5 100.000 (99.961)
2022-06-17 18:09:19 - INFO - TRAINING - Epoch: [63][110/196]	Time 0.113 (0.129)	Data 0.000 (0.017)	Loss 0.1004 (0.1105)	Prec@1 95.312 (96.185)	Prec@5 100.000 (99.965)
2022-06-17 18:09:21 - INFO - TRAINING - Epoch: [63][120/196]	Time 0.101 (0.127)	Data 0.000 (0.016)	Loss 0.1093 (0.1105)	Prec@1 95.703 (96.174)	Prec@5 100.000 (99.964)
2022-06-17 18:09:22 - INFO - TRAINING - Epoch: [63][130/196]	Time 0.115 (0.126)	Data 0.000 (0.014)	Loss 0.1031 (0.1106)	Prec@1 95.312 (96.171)	Prec@5 100.000 (99.964)
2022-06-17 18:09:23 - INFO - TRAINING - Epoch: [63][140/196]	Time 0.122 (0.125)	Data 0.000 (0.013)	Loss 0.1043 (0.1105)	Prec@1 95.703 (96.146)	Prec@5 100.000 (99.967)
2022-06-17 18:09:24 - INFO - TRAINING - Epoch: [63][150/196]	Time 0.106 (0.124)	Data 0.000 (0.013)	Loss 0.1156 (0.1115)	Prec@1 96.484 (96.122)	Prec@5 100.000 (99.969)
2022-06-17 18:09:25 - INFO - TRAINING - Epoch: [63][160/196]	Time 0.114 (0.123)	Data 0.000 (0.012)	Loss 0.1410 (0.1117)	Prec@1 94.922 (96.123)	Prec@5 99.609 (99.961)
2022-06-17 18:09:26 - INFO - TRAINING - Epoch: [63][170/196]	Time 0.110 (0.122)	Data 0.000 (0.011)	Loss 0.0620 (0.1119)	Prec@1 97.656 (96.110)	Prec@5 100.000 (99.961)
2022-06-17 18:09:27 - INFO - TRAINING - Epoch: [63][180/196]	Time 0.116 (0.122)	Data 0.000 (0.011)	Loss 0.1018 (0.1117)	Prec@1 95.703 (96.113)	Prec@5 100.000 (99.963)
2022-06-17 18:09:28 - INFO - TRAINING - Epoch: [63][190/196]	Time 0.112 (0.121)	Data 0.000 (0.010)	Loss 0.0708 (0.1117)	Prec@1 98.047 (96.149)	Prec@5 100.000 (99.963)
2022-06-17 18:09:31 - INFO - EVALUATING - Epoch: [63][0/40]	Time 1.660 (1.660)	Data 1.614 (1.614)	Loss 0.2677 (0.2677)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:09:32 - INFO - EVALUATING - Epoch: [63][10/40]	Time 0.240 (0.268)	Data 0.197 (0.220)	Loss 0.4592 (0.4037)	Prec@1 87.109 (88.104)	Prec@5 99.609 (99.432)
2022-06-17 18:09:32 - INFO - EVALUATING - Epoch: [63][20/40]	Time 0.090 (0.167)	Data 0.047 (0.118)	Loss 0.3270 (0.4045)	Prec@1 88.281 (88.002)	Prec@5 100.000 (99.442)
2022-06-17 18:09:34 - INFO - EVALUATING - Epoch: [63][30/40]	Time 0.041 (0.150)	Data 0.000 (0.102)	Loss 0.4921 (0.3965)	Prec@1 86.328 (88.117)	Prec@5 100.000 (99.483)
2022-06-17 18:09:36 - INFO - 
 Epoch: 64	Training Loss 0.1121 	Training Prec@1 96.140 	Training Prec@5 99.964 	Validation Loss 0.3917 	Validation Prec@1 88.100 	Validation Prec@5 99.570 

2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:09:36 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:09:37 - INFO - TRAINING - Epoch: [64][0/196]	Time 1.719 (1.719)	Data 1.665 (1.665)	Loss 0.1220 (0.1220)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:09:38 - INFO - TRAINING - Epoch: [64][10/196]	Time 0.119 (0.258)	Data 0.000 (0.152)	Loss 0.0662 (0.1195)	Prec@1 98.047 (96.129)	Prec@5 100.000 (99.929)
2022-06-17 18:09:39 - INFO - TRAINING - Epoch: [64][20/196]	Time 0.113 (0.188)	Data 0.000 (0.080)	Loss 0.1518 (0.1143)	Prec@1 96.094 (96.187)	Prec@5 100.000 (99.963)
2022-06-17 18:09:41 - INFO - TRAINING - Epoch: [64][30/196]	Time 0.107 (0.164)	Data 0.000 (0.054)	Loss 0.1540 (0.1154)	Prec@1 95.703 (96.043)	Prec@5 100.000 (99.975)
2022-06-17 18:09:42 - INFO - TRAINING - Epoch: [64][40/196]	Time 0.120 (0.151)	Data 0.000 (0.041)	Loss 0.0929 (0.1129)	Prec@1 96.484 (96.160)	Prec@5 100.000 (99.981)
2022-06-17 18:09:43 - INFO - TRAINING - Epoch: [64][50/196]	Time 0.121 (0.142)	Data 0.000 (0.033)	Loss 0.1190 (0.1124)	Prec@1 96.484 (96.239)	Prec@5 100.000 (99.969)
2022-06-17 18:09:44 - INFO - TRAINING - Epoch: [64][60/196]	Time 0.120 (0.138)	Data 0.000 (0.028)	Loss 0.1303 (0.1145)	Prec@1 96.094 (96.177)	Prec@5 100.000 (99.974)
2022-06-17 18:09:45 - INFO - TRAINING - Epoch: [64][70/196]	Time 0.110 (0.135)	Data 0.000 (0.024)	Loss 0.1635 (0.1142)	Prec@1 95.312 (96.226)	Prec@5 100.000 (99.978)
2022-06-17 18:09:46 - INFO - TRAINING - Epoch: [64][80/196]	Time 0.133 (0.133)	Data 0.000 (0.021)	Loss 0.1383 (0.1156)	Prec@1 93.359 (96.132)	Prec@5 100.000 (99.981)
2022-06-17 18:09:47 - INFO - TRAINING - Epoch: [64][90/196]	Time 0.122 (0.131)	Data 0.000 (0.019)	Loss 0.0796 (0.1160)	Prec@1 97.656 (96.094)	Prec@5 100.000 (99.979)
2022-06-17 18:09:49 - INFO - TRAINING - Epoch: [64][100/196]	Time 0.102 (0.129)	Data 0.000 (0.017)	Loss 0.1090 (0.1166)	Prec@1 96.094 (96.090)	Prec@5 100.000 (99.981)
2022-06-17 18:09:50 - INFO - TRAINING - Epoch: [64][110/196]	Time 0.101 (0.128)	Data 0.000 (0.015)	Loss 0.1339 (0.1160)	Prec@1 95.312 (96.108)	Prec@5 100.000 (99.979)
2022-06-17 18:09:51 - INFO - TRAINING - Epoch: [64][120/196]	Time 0.121 (0.127)	Data 0.000 (0.014)	Loss 0.1241 (0.1160)	Prec@1 95.312 (96.097)	Prec@5 100.000 (99.974)
2022-06-17 18:09:52 - INFO - TRAINING - Epoch: [64][130/196]	Time 0.123 (0.125)	Data 0.000 (0.013)	Loss 0.1338 (0.1158)	Prec@1 95.312 (96.076)	Prec@5 100.000 (99.973)
2022-06-17 18:09:53 - INFO - TRAINING - Epoch: [64][140/196]	Time 0.102 (0.124)	Data 0.000 (0.012)	Loss 0.1819 (0.1161)	Prec@1 93.359 (96.061)	Prec@5 100.000 (99.975)
2022-06-17 18:09:54 - INFO - TRAINING - Epoch: [64][150/196]	Time 0.114 (0.123)	Data 0.000 (0.011)	Loss 0.1278 (0.1156)	Prec@1 96.094 (96.073)	Prec@5 100.000 (99.977)
2022-06-17 18:09:55 - INFO - TRAINING - Epoch: [64][160/196]	Time 0.108 (0.123)	Data 0.000 (0.011)	Loss 0.1130 (0.1155)	Prec@1 95.312 (96.082)	Prec@5 100.000 (99.978)
2022-06-17 18:09:56 - INFO - TRAINING - Epoch: [64][170/196]	Time 0.108 (0.122)	Data 0.000 (0.010)	Loss 0.1264 (0.1155)	Prec@1 95.703 (96.071)	Prec@5 100.000 (99.977)
2022-06-17 18:09:58 - INFO - TRAINING - Epoch: [64][180/196]	Time 0.115 (0.122)	Data 0.000 (0.010)	Loss 0.1156 (0.1144)	Prec@1 96.094 (96.100)	Prec@5 100.000 (99.978)
2022-06-17 18:09:59 - INFO - TRAINING - Epoch: [64][190/196]	Time 0.110 (0.121)	Data 0.000 (0.009)	Loss 0.1550 (0.1138)	Prec@1 95.312 (96.135)	Prec@5 100.000 (99.978)
2022-06-17 18:10:01 - INFO - EVALUATING - Epoch: [64][0/40]	Time 1.955 (1.955)	Data 1.910 (1.910)	Loss 0.2561 (0.2561)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:10:02 - INFO - EVALUATING - Epoch: [64][10/40]	Time 0.059 (0.269)	Data 0.000 (0.222)	Loss 0.4583 (0.4021)	Prec@1 87.500 (88.175)	Prec@5 99.609 (99.432)
2022-06-17 18:10:03 - INFO - EVALUATING - Epoch: [64][20/40]	Time 0.076 (0.179)	Data 0.000 (0.131)	Loss 0.3287 (0.4047)	Prec@1 87.891 (87.965)	Prec@5 100.000 (99.461)
2022-06-17 18:10:04 - INFO - EVALUATING - Epoch: [64][30/40]	Time 0.091 (0.146)	Data 0.049 (0.098)	Loss 0.4857 (0.3975)	Prec@1 86.328 (88.168)	Prec@5 100.000 (99.509)
2022-06-17 18:10:06 - INFO - 
 Epoch: 65	Training Loss 0.1137 	Training Prec@1 96.146 	Training Prec@5 99.976 	Validation Loss 0.3925 	Validation Prec@1 88.200 	Validation Prec@5 99.570 

2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:10:06 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:10:07 - INFO - TRAINING - Epoch: [65][0/196]	Time 1.433 (1.433)	Data 1.380 (1.380)	Loss 0.1154 (0.1154)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:10:08 - INFO - TRAINING - Epoch: [65][10/196]	Time 0.235 (0.256)	Data 0.189 (0.183)	Loss 0.1285 (0.1162)	Prec@1 96.875 (95.952)	Prec@5 100.000 (99.929)
2022-06-17 18:10:10 - INFO - TRAINING - Epoch: [65][20/196]	Time 0.116 (0.192)	Data 0.000 (0.096)	Loss 0.1007 (0.1225)	Prec@1 97.266 (95.852)	Prec@5 99.609 (99.888)
2022-06-17 18:10:11 - INFO - TRAINING - Epoch: [65][30/196]	Time 0.114 (0.165)	Data 0.000 (0.065)	Loss 0.0958 (0.1200)	Prec@1 96.484 (95.917)	Prec@5 100.000 (99.924)
2022-06-17 18:10:12 - INFO - TRAINING - Epoch: [65][40/196]	Time 0.102 (0.151)	Data 0.000 (0.049)	Loss 0.1180 (0.1185)	Prec@1 95.312 (95.979)	Prec@5 100.000 (99.914)
2022-06-17 18:10:13 - INFO - TRAINING - Epoch: [65][50/196]	Time 0.107 (0.144)	Data 0.000 (0.040)	Loss 0.1080 (0.1174)	Prec@1 96.484 (96.002)	Prec@5 100.000 (99.923)
2022-06-17 18:10:14 - INFO - TRAINING - Epoch: [65][60/196]	Time 0.113 (0.138)	Data 0.000 (0.033)	Loss 0.0918 (0.1195)	Prec@1 98.438 (95.914)	Prec@5 100.000 (99.936)
2022-06-17 18:10:15 - INFO - TRAINING - Epoch: [65][70/196]	Time 0.104 (0.134)	Data 0.000 (0.029)	Loss 0.0989 (0.1197)	Prec@1 96.094 (95.940)	Prec@5 100.000 (99.934)
2022-06-17 18:10:16 - INFO - TRAINING - Epoch: [65][80/196]	Time 0.109 (0.132)	Data 0.000 (0.025)	Loss 0.1446 (0.1194)	Prec@1 94.141 (95.925)	Prec@5 100.000 (99.942)
2022-06-17 18:10:17 - INFO - TRAINING - Epoch: [65][90/196]	Time 0.123 (0.130)	Data 0.000 (0.022)	Loss 0.1196 (0.1168)	Prec@1 95.312 (96.012)	Prec@5 100.000 (99.948)
2022-06-17 18:10:19 - INFO - TRAINING - Epoch: [65][100/196]	Time 0.108 (0.128)	Data 0.000 (0.020)	Loss 0.1043 (0.1163)	Prec@1 96.094 (96.028)	Prec@5 100.000 (99.954)
2022-06-17 18:10:20 - INFO - TRAINING - Epoch: [65][110/196]	Time 0.115 (0.127)	Data 0.000 (0.018)	Loss 0.1359 (0.1160)	Prec@1 95.703 (96.069)	Prec@5 100.000 (99.951)
2022-06-17 18:10:21 - INFO - TRAINING - Epoch: [65][120/196]	Time 0.102 (0.126)	Data 0.000 (0.017)	Loss 0.0895 (0.1153)	Prec@1 97.266 (96.113)	Prec@5 100.000 (99.955)
2022-06-17 18:10:22 - INFO - TRAINING - Epoch: [65][130/196]	Time 0.121 (0.125)	Data 0.000 (0.016)	Loss 0.0817 (0.1145)	Prec@1 97.656 (96.150)	Prec@5 100.000 (99.955)
2022-06-17 18:10:23 - INFO - TRAINING - Epoch: [65][140/196]	Time 0.103 (0.124)	Data 0.000 (0.015)	Loss 0.0949 (0.1148)	Prec@1 96.094 (96.105)	Prec@5 100.000 (99.958)
2022-06-17 18:10:24 - INFO - TRAINING - Epoch: [65][150/196]	Time 0.111 (0.124)	Data 0.000 (0.014)	Loss 0.1067 (0.1150)	Prec@1 96.484 (96.086)	Prec@5 100.000 (99.959)
2022-06-17 18:10:26 - INFO - TRAINING - Epoch: [65][160/196]	Time 0.107 (0.124)	Data 0.000 (0.013)	Loss 0.1005 (0.1146)	Prec@1 96.875 (96.086)	Prec@5 100.000 (99.959)
2022-06-17 18:10:27 - INFO - TRAINING - Epoch: [65][170/196]	Time 0.118 (0.123)	Data 0.000 (0.012)	Loss 0.0969 (0.1142)	Prec@1 96.875 (96.112)	Prec@5 100.000 (99.959)
2022-06-17 18:10:28 - INFO - TRAINING - Epoch: [65][180/196]	Time 0.108 (0.123)	Data 0.000 (0.011)	Loss 0.1659 (0.1146)	Prec@1 94.141 (96.105)	Prec@5 100.000 (99.961)
2022-06-17 18:10:29 - INFO - TRAINING - Epoch: [65][190/196]	Time 0.105 (0.122)	Data 0.000 (0.011)	Loss 0.1010 (0.1148)	Prec@1 96.094 (96.098)	Prec@5 100.000 (99.959)
2022-06-17 18:10:31 - INFO - EVALUATING - Epoch: [65][0/40]	Time 1.792 (1.792)	Data 1.744 (1.744)	Loss 0.2620 (0.2620)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:10:32 - INFO - EVALUATING - Epoch: [65][10/40]	Time 0.045 (0.254)	Data 0.001 (0.206)	Loss 0.4584 (0.3991)	Prec@1 88.281 (88.388)	Prec@5 99.609 (99.467)
2022-06-17 18:10:33 - INFO - EVALUATING - Epoch: [65][20/40]	Time 0.044 (0.159)	Data 0.000 (0.108)	Loss 0.3300 (0.4019)	Prec@1 88.281 (88.077)	Prec@5 100.000 (99.423)
2022-06-17 18:10:34 - INFO - EVALUATING - Epoch: [65][30/40]	Time 0.072 (0.152)	Data 0.000 (0.100)	Loss 0.4800 (0.3943)	Prec@1 86.328 (88.117)	Prec@5 100.000 (99.483)
2022-06-17 18:10:36 - INFO - 
 Epoch: 66	Training Loss 0.1143 	Training Prec@1 96.110 	Training Prec@5 99.960 	Validation Loss 0.3899 	Validation Prec@1 88.100 	Validation Prec@5 99.560 

2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:10:36 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:10:37 - INFO - TRAINING - Epoch: [66][0/196]	Time 1.351 (1.351)	Data 1.297 (1.297)	Loss 0.0892 (0.0892)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:10:39 - INFO - TRAINING - Epoch: [66][10/196]	Time 0.116 (0.261)	Data 0.000 (0.168)	Loss 0.0905 (0.0998)	Prec@1 97.266 (96.023)	Prec@5 100.000 (100.000)
2022-06-17 18:10:40 - INFO - TRAINING - Epoch: [66][20/196]	Time 0.113 (0.190)	Data 0.000 (0.088)	Loss 0.1055 (0.1066)	Prec@1 96.484 (95.926)	Prec@5 100.000 (100.000)
2022-06-17 18:10:41 - INFO - TRAINING - Epoch: [66][30/196]	Time 0.114 (0.165)	Data 0.000 (0.060)	Loss 0.0884 (0.1061)	Prec@1 96.875 (96.056)	Prec@5 100.000 (100.000)
2022-06-17 18:10:42 - INFO - TRAINING - Epoch: [66][40/196]	Time 0.122 (0.152)	Data 0.000 (0.045)	Loss 0.1594 (0.1092)	Prec@1 96.094 (96.151)	Prec@5 99.219 (99.981)
2022-06-17 18:10:44 - INFO - TRAINING - Epoch: [66][50/196]	Time 0.131 (0.145)	Data 0.000 (0.037)	Loss 0.0866 (0.1099)	Prec@1 96.875 (96.124)	Prec@5 100.000 (99.977)
2022-06-17 18:10:45 - INFO - TRAINING - Epoch: [66][60/196]	Time 0.110 (0.140)	Data 0.000 (0.031)	Loss 0.0816 (0.1099)	Prec@1 96.484 (96.107)	Prec@5 100.000 (99.974)
2022-06-17 18:10:46 - INFO - TRAINING - Epoch: [66][70/196]	Time 0.114 (0.136)	Data 0.000 (0.026)	Loss 0.0886 (0.1094)	Prec@1 97.656 (96.138)	Prec@5 100.000 (99.972)
2022-06-17 18:10:47 - INFO - TRAINING - Epoch: [66][80/196]	Time 0.125 (0.132)	Data 0.000 (0.023)	Loss 0.0869 (0.1083)	Prec@1 97.266 (96.219)	Prec@5 100.000 (99.976)
2022-06-17 18:10:48 - INFO - TRAINING - Epoch: [66][90/196]	Time 0.123 (0.131)	Data 0.000 (0.021)	Loss 0.1142 (0.1101)	Prec@1 95.312 (96.107)	Prec@5 100.000 (99.979)
2022-06-17 18:10:49 - INFO - TRAINING - Epoch: [66][100/196]	Time 0.107 (0.129)	Data 0.000 (0.019)	Loss 0.1549 (0.1113)	Prec@1 94.922 (96.055)	Prec@5 100.000 (99.977)
2022-06-17 18:10:50 - INFO - TRAINING - Epoch: [66][110/196]	Time 0.116 (0.127)	Data 0.000 (0.017)	Loss 0.1556 (0.1107)	Prec@1 94.922 (96.087)	Prec@5 99.609 (99.975)
2022-06-17 18:10:51 - INFO - TRAINING - Epoch: [66][120/196]	Time 0.111 (0.126)	Data 0.000 (0.016)	Loss 0.1502 (0.1118)	Prec@1 93.750 (96.045)	Prec@5 100.000 (99.974)
2022-06-17 18:10:52 - INFO - TRAINING - Epoch: [66][130/196]	Time 0.102 (0.124)	Data 0.000 (0.014)	Loss 0.1538 (0.1118)	Prec@1 94.922 (96.061)	Prec@5 100.000 (99.976)
2022-06-17 18:10:54 - INFO - TRAINING - Epoch: [66][140/196]	Time 0.111 (0.123)	Data 0.000 (0.013)	Loss 0.1192 (0.1117)	Prec@1 96.484 (96.085)	Prec@5 100.000 (99.975)
2022-06-17 18:10:55 - INFO - TRAINING - Epoch: [66][150/196]	Time 0.111 (0.122)	Data 0.000 (0.013)	Loss 0.0995 (0.1117)	Prec@1 96.875 (96.104)	Prec@5 100.000 (99.974)
2022-06-17 18:10:56 - INFO - TRAINING - Epoch: [66][160/196]	Time 0.105 (0.121)	Data 0.000 (0.012)	Loss 0.0845 (0.1117)	Prec@1 97.656 (96.123)	Prec@5 100.000 (99.971)
2022-06-17 18:10:57 - INFO - TRAINING - Epoch: [66][170/196]	Time 0.106 (0.121)	Data 0.000 (0.011)	Loss 0.0972 (0.1114)	Prec@1 96.875 (96.142)	Prec@5 100.000 (99.970)
2022-06-17 18:10:58 - INFO - TRAINING - Epoch: [66][180/196]	Time 0.106 (0.121)	Data 0.000 (0.010)	Loss 0.1660 (0.1112)	Prec@1 93.750 (96.141)	Prec@5 100.000 (99.972)
2022-06-17 18:10:59 - INFO - TRAINING - Epoch: [66][190/196]	Time 0.108 (0.120)	Data 0.000 (0.010)	Loss 0.1517 (0.1114)	Prec@1 95.312 (96.139)	Prec@5 100.000 (99.973)
2022-06-17 18:11:01 - INFO - EVALUATING - Epoch: [66][0/40]	Time 1.390 (1.390)	Data 1.344 (1.344)	Loss 0.2580 (0.2580)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:11:03 - INFO - EVALUATING - Epoch: [66][10/40]	Time 0.097 (0.260)	Data 0.053 (0.212)	Loss 0.4577 (0.3982)	Prec@1 87.891 (88.139)	Prec@5 99.219 (99.396)
2022-06-17 18:11:03 - INFO - EVALUATING - Epoch: [66][20/40]	Time 0.042 (0.163)	Data 0.000 (0.111)	Loss 0.3334 (0.4040)	Prec@1 87.891 (87.891)	Prec@5 100.000 (99.368)
2022-06-17 18:11:04 - INFO - EVALUATING - Epoch: [66][30/40]	Time 0.183 (0.147)	Data 0.141 (0.098)	Loss 0.4986 (0.3957)	Prec@1 85.938 (87.916)	Prec@5 100.000 (99.458)
2022-06-17 18:11:06 - INFO - 
 Epoch: 67	Training Loss 0.1116 	Training Prec@1 96.134 	Training Prec@5 99.972 	Validation Loss 0.3910 	Validation Prec@1 87.930 	Validation Prec@5 99.540 

2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:11:06 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:11:08 - INFO - TRAINING - Epoch: [67][0/196]	Time 1.814 (1.814)	Data 1.760 (1.760)	Loss 0.1337 (0.1337)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 18:11:09 - INFO - TRAINING - Epoch: [67][10/196]	Time 0.121 (0.281)	Data 0.000 (0.185)	Loss 0.1158 (0.1022)	Prec@1 96.875 (96.342)	Prec@5 100.000 (99.964)
2022-06-17 18:11:11 - INFO - TRAINING - Epoch: [67][20/196]	Time 0.107 (0.203)	Data 0.000 (0.097)	Loss 0.0767 (0.1065)	Prec@1 96.875 (96.094)	Prec@5 100.000 (99.981)
2022-06-17 18:11:12 - INFO - TRAINING - Epoch: [67][30/196]	Time 0.122 (0.176)	Data 0.000 (0.066)	Loss 0.0894 (0.1058)	Prec@1 96.875 (96.207)	Prec@5 100.000 (99.975)
2022-06-17 18:11:13 - INFO - TRAINING - Epoch: [67][40/196]	Time 0.117 (0.161)	Data 0.001 (0.050)	Loss 0.1206 (0.1112)	Prec@1 96.484 (96.056)	Prec@5 100.000 (99.971)
2022-06-17 18:11:14 - INFO - TRAINING - Epoch: [67][50/196]	Time 0.114 (0.152)	Data 0.000 (0.040)	Loss 0.1206 (0.1097)	Prec@1 95.312 (96.155)	Prec@5 100.000 (99.977)
2022-06-17 18:11:15 - INFO - TRAINING - Epoch: [67][60/196]	Time 0.125 (0.147)	Data 0.000 (0.034)	Loss 0.1089 (0.1100)	Prec@1 96.094 (96.126)	Prec@5 100.000 (99.974)
2022-06-17 18:11:16 - INFO - TRAINING - Epoch: [67][70/196]	Time 0.124 (0.143)	Data 0.000 (0.029)	Loss 0.1242 (0.1107)	Prec@1 95.703 (96.105)	Prec@5 100.000 (99.978)
2022-06-17 18:11:18 - INFO - TRAINING - Epoch: [67][80/196]	Time 0.124 (0.140)	Data 0.000 (0.025)	Loss 0.1255 (0.1119)	Prec@1 96.094 (96.103)	Prec@5 100.000 (99.981)
2022-06-17 18:11:19 - INFO - TRAINING - Epoch: [67][90/196]	Time 0.111 (0.138)	Data 0.000 (0.023)	Loss 0.1004 (0.1115)	Prec@1 97.266 (96.137)	Prec@5 100.000 (99.983)
2022-06-17 18:11:20 - INFO - TRAINING - Epoch: [67][100/196]	Time 0.107 (0.136)	Data 0.000 (0.020)	Loss 0.1221 (0.1118)	Prec@1 94.922 (96.159)	Prec@5 100.000 (99.977)
2022-06-17 18:11:21 - INFO - TRAINING - Epoch: [67][110/196]	Time 0.133 (0.135)	Data 0.000 (0.019)	Loss 0.0555 (0.1116)	Prec@1 98.828 (96.161)	Prec@5 100.000 (99.979)
2022-06-17 18:11:22 - INFO - TRAINING - Epoch: [67][120/196]	Time 0.108 (0.133)	Data 0.000 (0.017)	Loss 0.1217 (0.1124)	Prec@1 94.922 (96.132)	Prec@5 100.000 (99.981)
2022-06-17 18:11:24 - INFO - TRAINING - Epoch: [67][130/196]	Time 0.108 (0.132)	Data 0.000 (0.016)	Loss 0.1253 (0.1129)	Prec@1 94.531 (96.106)	Prec@5 100.000 (99.979)
2022-06-17 18:11:25 - INFO - TRAINING - Epoch: [67][140/196]	Time 0.111 (0.131)	Data 0.000 (0.015)	Loss 0.1082 (0.1118)	Prec@1 97.266 (96.155)	Prec@5 100.000 (99.981)
2022-06-17 18:11:26 - INFO - TRAINING - Epoch: [67][150/196]	Time 0.130 (0.131)	Data 0.000 (0.014)	Loss 0.1255 (0.1120)	Prec@1 96.484 (96.143)	Prec@5 100.000 (99.979)
2022-06-17 18:11:27 - INFO - TRAINING - Epoch: [67][160/196]	Time 0.107 (0.130)	Data 0.000 (0.013)	Loss 0.1461 (0.1122)	Prec@1 94.531 (96.123)	Prec@5 100.000 (99.978)
2022-06-17 18:11:28 - INFO - TRAINING - Epoch: [67][170/196]	Time 0.107 (0.129)	Data 0.000 (0.012)	Loss 0.1414 (0.1130)	Prec@1 94.531 (96.078)	Prec@5 100.000 (99.977)
2022-06-17 18:11:29 - INFO - TRAINING - Epoch: [67][180/196]	Time 0.103 (0.128)	Data 0.000 (0.012)	Loss 0.1068 (0.1135)	Prec@1 97.266 (96.076)	Prec@5 100.000 (99.972)
2022-06-17 18:11:31 - INFO - TRAINING - Epoch: [67][190/196]	Time 0.102 (0.127)	Data 0.000 (0.011)	Loss 0.1255 (0.1135)	Prec@1 95.312 (96.077)	Prec@5 100.000 (99.969)
2022-06-17 18:11:33 - INFO - EVALUATING - Epoch: [67][0/40]	Time 1.877 (1.877)	Data 1.831 (1.831)	Loss 0.2658 (0.2658)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:11:34 - INFO - EVALUATING - Epoch: [67][10/40]	Time 0.044 (0.263)	Data 0.000 (0.214)	Loss 0.4533 (0.3987)	Prec@1 88.281 (88.530)	Prec@5 99.219 (99.396)
2022-06-17 18:11:35 - INFO - EVALUATING - Epoch: [67][20/40]	Time 0.227 (0.170)	Data 0.183 (0.121)	Loss 0.3307 (0.4022)	Prec@1 87.891 (88.207)	Prec@5 100.000 (99.423)
2022-06-17 18:11:36 - INFO - EVALUATING - Epoch: [67][30/40]	Time 0.088 (0.147)	Data 0.044 (0.099)	Loss 0.4918 (0.3953)	Prec@1 86.719 (88.180)	Prec@5 100.000 (99.471)
2022-06-17 18:11:38 - INFO - 
 Epoch: 68	Training Loss 0.1133 	Training Prec@1 96.078 	Training Prec@5 99.970 	Validation Loss 0.3908 	Validation Prec@1 88.140 	Validation Prec@5 99.550 

2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:11:38 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:11:39 - INFO - TRAINING - Epoch: [68][0/196]	Time 1.876 (1.876)	Data 1.822 (1.822)	Loss 0.0811 (0.0811)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:11:41 - INFO - TRAINING - Epoch: [68][10/196]	Time 0.102 (0.269)	Data 0.000 (0.170)	Loss 0.0963 (0.1139)	Prec@1 96.875 (96.129)	Prec@5 100.000 (99.964)
2022-06-17 18:11:42 - INFO - TRAINING - Epoch: [68][20/196]	Time 0.110 (0.193)	Data 0.000 (0.089)	Loss 0.0753 (0.1141)	Prec@1 98.047 (96.298)	Prec@5 100.000 (99.963)
2022-06-17 18:11:43 - INFO - TRAINING - Epoch: [68][30/196]	Time 0.102 (0.167)	Data 0.000 (0.061)	Loss 0.1199 (0.1154)	Prec@1 96.484 (96.232)	Prec@5 100.000 (99.962)
2022-06-17 18:11:44 - INFO - TRAINING - Epoch: [68][40/196]	Time 0.108 (0.152)	Data 0.000 (0.046)	Loss 0.1777 (0.1177)	Prec@1 94.531 (95.998)	Prec@5 99.609 (99.952)
2022-06-17 18:11:45 - INFO - TRAINING - Epoch: [68][50/196]	Time 0.104 (0.145)	Data 0.000 (0.037)	Loss 0.1497 (0.1175)	Prec@1 92.969 (95.941)	Prec@5 100.000 (99.962)
2022-06-17 18:11:46 - INFO - TRAINING - Epoch: [68][60/196]	Time 0.103 (0.140)	Data 0.000 (0.031)	Loss 0.1208 (0.1179)	Prec@1 95.703 (95.934)	Prec@5 100.000 (99.962)
2022-06-17 18:11:47 - INFO - TRAINING - Epoch: [68][70/196]	Time 0.106 (0.136)	Data 0.000 (0.027)	Loss 0.1469 (0.1163)	Prec@1 94.141 (95.989)	Prec@5 100.000 (99.967)
2022-06-17 18:11:48 - INFO - TRAINING - Epoch: [68][80/196]	Time 0.106 (0.134)	Data 0.000 (0.023)	Loss 0.1138 (0.1163)	Prec@1 97.266 (96.046)	Prec@5 100.000 (99.971)
2022-06-17 18:11:50 - INFO - TRAINING - Epoch: [68][90/196]	Time 0.103 (0.132)	Data 0.001 (0.021)	Loss 0.0851 (0.1143)	Prec@1 96.484 (96.111)	Prec@5 100.000 (99.966)
2022-06-17 18:11:51 - INFO - TRAINING - Epoch: [68][100/196]	Time 0.114 (0.130)	Data 0.000 (0.019)	Loss 0.0930 (0.1140)	Prec@1 96.094 (96.078)	Prec@5 99.609 (99.961)
2022-06-17 18:11:52 - INFO - TRAINING - Epoch: [68][110/196]	Time 0.110 (0.128)	Data 0.000 (0.017)	Loss 0.0802 (0.1147)	Prec@1 96.484 (96.087)	Prec@5 100.000 (99.965)
2022-06-17 18:11:53 - INFO - TRAINING - Epoch: [68][120/196]	Time 0.104 (0.127)	Data 0.000 (0.016)	Loss 0.1022 (0.1150)	Prec@1 96.484 (96.097)	Prec@5 100.000 (99.968)
2022-06-17 18:11:54 - INFO - TRAINING - Epoch: [68][130/196]	Time 0.110 (0.126)	Data 0.000 (0.015)	Loss 0.1375 (0.1141)	Prec@1 95.312 (96.156)	Prec@5 100.000 (99.970)
2022-06-17 18:11:55 - INFO - TRAINING - Epoch: [68][140/196]	Time 0.113 (0.125)	Data 0.000 (0.014)	Loss 0.0937 (0.1140)	Prec@1 96.094 (96.146)	Prec@5 100.000 (99.970)
2022-06-17 18:11:56 - INFO - TRAINING - Epoch: [68][150/196]	Time 0.107 (0.125)	Data 0.000 (0.013)	Loss 0.1256 (0.1149)	Prec@1 95.703 (96.117)	Prec@5 100.000 (99.966)
2022-06-17 18:11:58 - INFO - TRAINING - Epoch: [68][160/196]	Time 0.108 (0.124)	Data 0.000 (0.012)	Loss 0.1226 (0.1143)	Prec@1 94.531 (96.130)	Prec@5 100.000 (99.968)
2022-06-17 18:11:59 - INFO - TRAINING - Epoch: [68][170/196]	Time 0.107 (0.123)	Data 0.000 (0.011)	Loss 0.0981 (0.1142)	Prec@1 97.266 (96.139)	Prec@5 100.000 (99.968)
2022-06-17 18:12:00 - INFO - TRAINING - Epoch: [68][180/196]	Time 0.117 (0.122)	Data 0.000 (0.011)	Loss 0.1206 (0.1141)	Prec@1 96.484 (96.141)	Prec@5 100.000 (99.970)
2022-06-17 18:12:01 - INFO - TRAINING - Epoch: [68][190/196]	Time 0.102 (0.122)	Data 0.000 (0.010)	Loss 0.1496 (0.1140)	Prec@1 94.922 (96.143)	Prec@5 99.609 (99.967)
2022-06-17 18:12:03 - INFO - EVALUATING - Epoch: [68][0/40]	Time 1.693 (1.693)	Data 1.647 (1.647)	Loss 0.2624 (0.2624)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:12:04 - INFO - EVALUATING - Epoch: [68][10/40]	Time 0.056 (0.265)	Data 0.000 (0.219)	Loss 0.4571 (0.4048)	Prec@1 88.281 (88.033)	Prec@5 99.609 (99.432)
2022-06-17 18:12:05 - INFO - EVALUATING - Epoch: [68][20/40]	Time 0.059 (0.164)	Data 0.000 (0.115)	Loss 0.3271 (0.4088)	Prec@1 88.281 (87.667)	Prec@5 100.000 (99.386)
2022-06-17 18:12:06 - INFO - EVALUATING - Epoch: [68][30/40]	Time 0.044 (0.146)	Data 0.000 (0.099)	Loss 0.5018 (0.4000)	Prec@1 85.938 (87.928)	Prec@5 100.000 (99.458)
2022-06-17 18:12:08 - INFO - 
 Epoch: 69	Training Loss 0.1136 	Training Prec@1 96.156 	Training Prec@5 99.968 	Validation Loss 0.3951 	Validation Prec@1 87.970 	Validation Prec@5 99.540 

2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:12:08 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:12:09 - INFO - TRAINING - Epoch: [69][0/196]	Time 1.479 (1.479)	Data 1.427 (1.427)	Loss 0.1375 (0.1375)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 18:12:11 - INFO - TRAINING - Epoch: [69][10/196]	Time 0.131 (0.268)	Data 0.000 (0.180)	Loss 0.0781 (0.1146)	Prec@1 98.438 (96.200)	Prec@5 100.000 (99.929)
2022-06-17 18:12:12 - INFO - TRAINING - Epoch: [69][20/196]	Time 0.122 (0.198)	Data 0.000 (0.094)	Loss 0.1122 (0.1132)	Prec@1 95.703 (96.001)	Prec@5 100.000 (99.963)
2022-06-17 18:12:13 - INFO - TRAINING - Epoch: [69][30/196]	Time 0.117 (0.172)	Data 0.000 (0.064)	Loss 0.1242 (0.1101)	Prec@1 96.484 (96.119)	Prec@5 100.000 (99.975)
2022-06-17 18:12:14 - INFO - TRAINING - Epoch: [69][40/196]	Time 0.105 (0.158)	Data 0.000 (0.048)	Loss 0.0758 (0.1094)	Prec@1 97.266 (96.056)	Prec@5 100.000 (99.981)
2022-06-17 18:12:16 - INFO - TRAINING - Epoch: [69][50/196]	Time 0.107 (0.150)	Data 0.000 (0.039)	Loss 0.0848 (0.1108)	Prec@1 97.656 (96.101)	Prec@5 100.000 (99.977)
2022-06-17 18:12:17 - INFO - TRAINING - Epoch: [69][60/196]	Time 0.122 (0.144)	Data 0.000 (0.033)	Loss 0.1055 (0.1088)	Prec@1 95.312 (96.139)	Prec@5 100.000 (99.981)
2022-06-17 18:12:18 - INFO - TRAINING - Epoch: [69][70/196]	Time 0.115 (0.139)	Data 0.000 (0.028)	Loss 0.1102 (0.1087)	Prec@1 96.875 (96.198)	Prec@5 100.000 (99.978)
2022-06-17 18:12:19 - INFO - TRAINING - Epoch: [69][80/196]	Time 0.112 (0.136)	Data 0.000 (0.025)	Loss 0.0802 (0.1109)	Prec@1 98.047 (96.108)	Prec@5 100.000 (99.981)
2022-06-17 18:12:20 - INFO - TRAINING - Epoch: [69][90/196]	Time 0.130 (0.134)	Data 0.000 (0.022)	Loss 0.1383 (0.1131)	Prec@1 92.969 (96.016)	Prec@5 100.000 (99.974)
2022-06-17 18:12:21 - INFO - TRAINING - Epoch: [69][100/196]	Time 0.111 (0.132)	Data 0.000 (0.020)	Loss 0.0804 (0.1122)	Prec@1 97.266 (96.086)	Prec@5 100.000 (99.977)
2022-06-17 18:12:22 - INFO - TRAINING - Epoch: [69][110/196]	Time 0.129 (0.130)	Data 0.000 (0.018)	Loss 0.1497 (0.1132)	Prec@1 94.922 (95.999)	Prec@5 100.000 (99.975)
2022-06-17 18:12:24 - INFO - TRAINING - Epoch: [69][120/196]	Time 0.107 (0.129)	Data 0.000 (0.017)	Loss 0.0855 (0.1127)	Prec@1 97.266 (96.045)	Prec@5 100.000 (99.977)
2022-06-17 18:12:25 - INFO - TRAINING - Epoch: [69][130/196]	Time 0.104 (0.128)	Data 0.000 (0.015)	Loss 0.1281 (0.1128)	Prec@1 94.922 (96.034)	Prec@5 100.000 (99.979)
2022-06-17 18:12:26 - INFO - TRAINING - Epoch: [69][140/196]	Time 0.128 (0.127)	Data 0.000 (0.014)	Loss 0.0970 (0.1134)	Prec@1 96.875 (96.049)	Prec@5 100.000 (99.975)
2022-06-17 18:12:27 - INFO - TRAINING - Epoch: [69][150/196]	Time 0.121 (0.126)	Data 0.000 (0.013)	Loss 0.1050 (0.1134)	Prec@1 95.703 (96.045)	Prec@5 100.000 (99.977)
2022-06-17 18:12:28 - INFO - TRAINING - Epoch: [69][160/196]	Time 0.112 (0.125)	Data 0.000 (0.013)	Loss 0.1702 (0.1143)	Prec@1 94.922 (96.028)	Prec@5 100.000 (99.978)
2022-06-17 18:12:29 - INFO - TRAINING - Epoch: [69][170/196]	Time 0.103 (0.124)	Data 0.000 (0.012)	Loss 0.0994 (0.1130)	Prec@1 96.875 (96.091)	Prec@5 100.000 (99.979)
2022-06-17 18:12:30 - INFO - TRAINING - Epoch: [69][180/196]	Time 0.113 (0.123)	Data 0.000 (0.011)	Loss 0.1112 (0.1129)	Prec@1 95.703 (96.085)	Prec@5 100.000 (99.981)
2022-06-17 18:12:31 - INFO - TRAINING - Epoch: [69][190/196]	Time 0.111 (0.123)	Data 0.000 (0.011)	Loss 0.0703 (0.1121)	Prec@1 98.438 (96.116)	Prec@5 100.000 (99.980)
2022-06-17 18:12:34 - INFO - EVALUATING - Epoch: [69][0/40]	Time 2.099 (2.099)	Data 2.054 (2.054)	Loss 0.2538 (0.2538)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:12:35 - INFO - EVALUATING - Epoch: [69][10/40]	Time 0.044 (0.278)	Data 0.001 (0.231)	Loss 0.4575 (0.3990)	Prec@1 88.672 (88.601)	Prec@5 99.609 (99.467)
2022-06-17 18:12:36 - INFO - EVALUATING - Epoch: [69][20/40]	Time 0.041 (0.169)	Data 0.000 (0.121)	Loss 0.3280 (0.4024)	Prec@1 87.500 (88.244)	Prec@5 100.000 (99.423)
2022-06-17 18:12:37 - INFO - EVALUATING - Epoch: [69][30/40]	Time 0.150 (0.153)	Data 0.109 (0.106)	Loss 0.4875 (0.3955)	Prec@1 86.328 (88.256)	Prec@5 100.000 (99.496)
2022-06-17 18:12:39 - INFO - 
 Epoch: 70	Training Loss 0.1122 	Training Prec@1 96.126 	Training Prec@5 99.980 	Validation Loss 0.3906 	Validation Prec@1 88.270 	Validation Prec@5 99.570 

2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:12:39 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:12:41 - INFO - TRAINING - Epoch: [70][0/196]	Time 1.211 (1.211)	Data 1.158 (1.158)	Loss 0.1443 (0.1443)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
2022-06-17 18:12:42 - INFO - TRAINING - Epoch: [70][10/196]	Time 0.123 (0.256)	Data 0.000 (0.166)	Loss 0.0964 (0.1072)	Prec@1 96.484 (96.271)	Prec@5 100.000 (100.000)
2022-06-17 18:12:43 - INFO - TRAINING - Epoch: [70][20/196]	Time 0.107 (0.191)	Data 0.000 (0.087)	Loss 0.0852 (0.1100)	Prec@1 96.484 (96.168)	Prec@5 100.000 (99.981)
2022-06-17 18:12:44 - INFO - TRAINING - Epoch: [70][30/196]	Time 0.123 (0.166)	Data 0.000 (0.059)	Loss 0.1455 (0.1119)	Prec@1 96.094 (96.169)	Prec@5 100.000 (99.975)
2022-06-17 18:12:46 - INFO - TRAINING - Epoch: [70][40/196]	Time 0.119 (0.154)	Data 0.000 (0.045)	Loss 0.1243 (0.1105)	Prec@1 96.484 (96.237)	Prec@5 100.000 (99.971)
2022-06-17 18:12:47 - INFO - TRAINING - Epoch: [70][50/196]	Time 0.111 (0.146)	Data 0.001 (0.036)	Loss 0.0943 (0.1094)	Prec@1 97.266 (96.293)	Prec@5 100.000 (99.977)
2022-06-17 18:12:48 - INFO - TRAINING - Epoch: [70][60/196]	Time 0.134 (0.141)	Data 0.000 (0.030)	Loss 0.0888 (0.1123)	Prec@1 96.484 (96.171)	Prec@5 100.000 (99.968)
2022-06-17 18:12:49 - INFO - TRAINING - Epoch: [70][70/196]	Time 0.138 (0.137)	Data 0.000 (0.026)	Loss 0.1714 (0.1127)	Prec@1 94.531 (96.138)	Prec@5 100.000 (99.972)
2022-06-17 18:12:50 - INFO - TRAINING - Epoch: [70][80/196]	Time 0.111 (0.134)	Data 0.000 (0.023)	Loss 0.0981 (0.1130)	Prec@1 96.484 (96.132)	Prec@5 100.000 (99.966)
2022-06-17 18:12:51 - INFO - TRAINING - Epoch: [70][90/196]	Time 0.104 (0.131)	Data 0.000 (0.020)	Loss 0.0957 (0.1138)	Prec@1 97.656 (96.154)	Prec@5 100.000 (99.957)
2022-06-17 18:12:52 - INFO - TRAINING - Epoch: [70][100/196]	Time 0.117 (0.130)	Data 0.000 (0.018)	Loss 0.1199 (0.1144)	Prec@1 94.922 (96.129)	Prec@5 100.000 (99.950)
2022-06-17 18:12:54 - INFO - TRAINING - Epoch: [70][110/196]	Time 0.107 (0.129)	Data 0.000 (0.017)	Loss 0.1249 (0.1146)	Prec@1 95.312 (96.125)	Prec@5 100.000 (99.954)
2022-06-17 18:12:55 - INFO - TRAINING - Epoch: [70][120/196]	Time 0.114 (0.127)	Data 0.000 (0.015)	Loss 0.1000 (0.1135)	Prec@1 97.266 (96.158)	Prec@5 100.000 (99.955)
2022-06-17 18:12:56 - INFO - TRAINING - Epoch: [70][130/196]	Time 0.131 (0.126)	Data 0.000 (0.014)	Loss 0.1091 (0.1123)	Prec@1 95.703 (96.207)	Prec@5 100.000 (99.955)
2022-06-17 18:12:57 - INFO - TRAINING - Epoch: [70][140/196]	Time 0.101 (0.125)	Data 0.000 (0.013)	Loss 0.1088 (0.1123)	Prec@1 96.484 (96.218)	Prec@5 100.000 (99.953)
2022-06-17 18:12:58 - INFO - TRAINING - Epoch: [70][150/196]	Time 0.126 (0.125)	Data 0.000 (0.012)	Loss 0.1353 (0.1120)	Prec@1 95.703 (96.228)	Prec@5 100.000 (99.956)
2022-06-17 18:12:59 - INFO - TRAINING - Epoch: [70][160/196]	Time 0.122 (0.124)	Data 0.000 (0.012)	Loss 0.0969 (0.1117)	Prec@1 96.484 (96.234)	Prec@5 100.000 (99.959)
2022-06-17 18:13:00 - INFO - TRAINING - Epoch: [70][170/196]	Time 0.124 (0.124)	Data 0.000 (0.011)	Loss 0.1204 (0.1114)	Prec@1 94.531 (96.231)	Prec@5 100.000 (99.959)
2022-06-17 18:13:02 - INFO - TRAINING - Epoch: [70][180/196]	Time 0.106 (0.123)	Data 0.000 (0.010)	Loss 0.0774 (0.1117)	Prec@1 97.266 (96.219)	Prec@5 100.000 (99.959)
2022-06-17 18:13:03 - INFO - TRAINING - Epoch: [70][190/196]	Time 0.100 (0.122)	Data 0.000 (0.010)	Loss 0.1243 (0.1108)	Prec@1 95.703 (96.239)	Prec@5 100.000 (99.961)
2022-06-17 18:13:05 - INFO - EVALUATING - Epoch: [70][0/40]	Time 1.225 (1.225)	Data 1.179 (1.179)	Loss 0.2578 (0.2578)	Prec@1 93.359 (93.359)	Prec@5 99.609 (99.609)
2022-06-17 18:13:06 - INFO - EVALUATING - Epoch: [70][10/40]	Time 0.044 (0.224)	Data 0.000 (0.174)	Loss 0.4569 (0.4007)	Prec@1 88.281 (88.530)	Prec@5 99.219 (99.396)
2022-06-17 18:13:07 - INFO - EVALUATING - Epoch: [70][20/40]	Time 0.044 (0.161)	Data 0.000 (0.112)	Loss 0.3285 (0.4018)	Prec@1 88.281 (88.207)	Prec@5 100.000 (99.423)
2022-06-17 18:13:08 - INFO - EVALUATING - Epoch: [70][30/40]	Time 0.044 (0.152)	Data 0.000 (0.105)	Loss 0.4879 (0.3953)	Prec@1 87.109 (88.256)	Prec@5 100.000 (99.496)
2022-06-17 18:13:10 - INFO - 
 Epoch: 71	Training Loss 0.1103 	Training Prec@1 96.266 	Training Prec@5 99.962 	Validation Loss 0.3913 	Validation Prec@1 88.240 	Validation Prec@5 99.570 

2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:13:10 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:13:12 - INFO - TRAINING - Epoch: [71][0/196]	Time 1.836 (1.836)	Data 1.781 (1.781)	Loss 0.0806 (0.0806)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:13:13 - INFO - TRAINING - Epoch: [71][10/196]	Time 0.133 (0.272)	Data 0.000 (0.166)	Loss 0.0845 (0.1056)	Prec@1 96.875 (96.129)	Prec@5 100.000 (100.000)
2022-06-17 18:13:14 - INFO - TRAINING - Epoch: [71][20/196]	Time 0.113 (0.195)	Data 0.000 (0.087)	Loss 0.1149 (0.1097)	Prec@1 96.875 (96.168)	Prec@5 100.000 (100.000)
2022-06-17 18:13:15 - INFO - TRAINING - Epoch: [71][30/196]	Time 0.115 (0.170)	Data 0.000 (0.059)	Loss 0.1147 (0.1128)	Prec@1 95.703 (96.043)	Prec@5 100.000 (99.962)
2022-06-17 18:13:16 - INFO - TRAINING - Epoch: [71][40/196]	Time 0.111 (0.155)	Data 0.000 (0.045)	Loss 0.1085 (0.1126)	Prec@1 96.094 (96.122)	Prec@5 100.000 (99.971)
2022-06-17 18:13:17 - INFO - TRAINING - Epoch: [71][50/196]	Time 0.121 (0.147)	Data 0.000 (0.036)	Loss 0.1274 (0.1114)	Prec@1 95.703 (96.132)	Prec@5 100.000 (99.977)
2022-06-17 18:13:19 - INFO - TRAINING - Epoch: [71][60/196]	Time 0.122 (0.142)	Data 0.000 (0.030)	Loss 0.1095 (0.1103)	Prec@1 96.484 (96.171)	Prec@5 100.000 (99.974)
2022-06-17 18:13:20 - INFO - TRAINING - Epoch: [71][70/196]	Time 0.114 (0.138)	Data 0.000 (0.026)	Loss 0.0973 (0.1105)	Prec@1 96.094 (96.176)	Prec@5 100.000 (99.978)
2022-06-17 18:13:21 - INFO - TRAINING - Epoch: [71][80/196]	Time 0.107 (0.134)	Data 0.001 (0.023)	Loss 0.1027 (0.1101)	Prec@1 96.875 (96.195)	Prec@5 100.000 (99.981)
2022-06-17 18:13:22 - INFO - TRAINING - Epoch: [71][90/196]	Time 0.112 (0.131)	Data 0.000 (0.020)	Loss 0.1053 (0.1106)	Prec@1 95.703 (96.120)	Prec@5 100.000 (99.979)
2022-06-17 18:13:23 - INFO - TRAINING - Epoch: [71][100/196]	Time 0.112 (0.130)	Data 0.000 (0.018)	Loss 0.1162 (0.1115)	Prec@1 95.312 (96.117)	Prec@5 100.000 (99.973)
2022-06-17 18:13:24 - INFO - TRAINING - Epoch: [71][110/196]	Time 0.105 (0.128)	Data 0.000 (0.017)	Loss 0.1312 (0.1116)	Prec@1 96.484 (96.182)	Prec@5 100.000 (99.975)
2022-06-17 18:13:25 - INFO - TRAINING - Epoch: [71][120/196]	Time 0.132 (0.127)	Data 0.000 (0.015)	Loss 0.0595 (0.1114)	Prec@1 98.047 (96.220)	Prec@5 100.000 (99.977)
2022-06-17 18:13:26 - INFO - TRAINING - Epoch: [71][130/196]	Time 0.126 (0.126)	Data 0.000 (0.014)	Loss 0.1393 (0.1115)	Prec@1 94.922 (96.210)	Prec@5 100.000 (99.976)
2022-06-17 18:13:28 - INFO - TRAINING - Epoch: [71][140/196]	Time 0.109 (0.125)	Data 0.001 (0.013)	Loss 0.1103 (0.1119)	Prec@1 96.484 (96.216)	Prec@5 100.000 (99.972)
2022-06-17 18:13:29 - INFO - TRAINING - Epoch: [71][150/196]	Time 0.111 (0.125)	Data 0.000 (0.012)	Loss 0.1013 (0.1122)	Prec@1 94.922 (96.197)	Prec@5 100.000 (99.974)
2022-06-17 18:13:30 - INFO - TRAINING - Epoch: [71][160/196]	Time 0.113 (0.124)	Data 0.000 (0.012)	Loss 0.1168 (0.1123)	Prec@1 96.484 (96.215)	Prec@5 100.000 (99.968)
2022-06-17 18:13:31 - INFO - TRAINING - Epoch: [71][170/196]	Time 0.107 (0.123)	Data 0.000 (0.011)	Loss 0.0971 (0.1123)	Prec@1 97.266 (96.213)	Prec@5 100.000 (99.970)
2022-06-17 18:13:32 - INFO - TRAINING - Epoch: [71][180/196]	Time 0.118 (0.122)	Data 0.000 (0.010)	Loss 0.1018 (0.1124)	Prec@1 96.094 (96.219)	Prec@5 100.000 (99.965)
2022-06-17 18:13:33 - INFO - TRAINING - Epoch: [71][190/196]	Time 0.101 (0.122)	Data 0.000 (0.010)	Loss 0.0882 (0.1114)	Prec@1 97.266 (96.268)	Prec@5 100.000 (99.965)
2022-06-17 18:13:35 - INFO - EVALUATING - Epoch: [71][0/40]	Time 1.277 (1.277)	Data 1.230 (1.230)	Loss 0.2562 (0.2562)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:13:37 - INFO - EVALUATING - Epoch: [71][10/40]	Time 0.057 (0.266)	Data 0.000 (0.217)	Loss 0.4632 (0.3999)	Prec@1 88.281 (88.352)	Prec@5 99.219 (99.432)
2022-06-17 18:13:37 - INFO - EVALUATING - Epoch: [71][20/40]	Time 0.123 (0.169)	Data 0.079 (0.121)	Loss 0.3305 (0.4028)	Prec@1 87.109 (87.835)	Prec@5 100.000 (99.405)
2022-06-17 18:13:39 - INFO - EVALUATING - Epoch: [71][30/40]	Time 0.056 (0.158)	Data 0.000 (0.111)	Loss 0.4911 (0.3961)	Prec@1 85.938 (88.004)	Prec@5 100.000 (99.471)
2022-06-17 18:13:40 - INFO - 
 Epoch: 72	Training Loss 0.1114 	Training Prec@1 96.268 	Training Prec@5 99.966 	Validation Loss 0.3918 	Validation Prec@1 88.070 	Validation Prec@5 99.550 

2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:13:40 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:13:43 - INFO - TRAINING - Epoch: [72][0/196]	Time 2.104 (2.104)	Data 2.050 (2.050)	Loss 0.1191 (0.1191)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2022-06-17 18:13:44 - INFO - TRAINING - Epoch: [72][10/196]	Time 0.103 (0.293)	Data 0.000 (0.193)	Loss 0.1000 (0.1168)	Prec@1 96.094 (96.165)	Prec@5 100.000 (99.929)
2022-06-17 18:13:45 - INFO - TRAINING - Epoch: [72][20/196]	Time 0.126 (0.211)	Data 0.000 (0.101)	Loss 0.0894 (0.1125)	Prec@1 97.266 (96.057)	Prec@5 100.000 (99.963)
2022-06-17 18:13:46 - INFO - TRAINING - Epoch: [72][30/196]	Time 0.124 (0.182)	Data 0.000 (0.069)	Loss 0.1066 (0.1121)	Prec@1 96.875 (96.207)	Prec@5 100.000 (99.950)
2022-06-17 18:13:47 - INFO - TRAINING - Epoch: [72][40/196]	Time 0.116 (0.167)	Data 0.000 (0.052)	Loss 0.1546 (0.1131)	Prec@1 94.531 (96.151)	Prec@5 100.000 (99.943)
2022-06-17 18:13:48 - INFO - TRAINING - Epoch: [72][50/196]	Time 0.108 (0.157)	Data 0.000 (0.042)	Loss 0.1055 (0.1129)	Prec@1 96.484 (96.101)	Prec@5 100.000 (99.954)
2022-06-17 18:13:50 - INFO - TRAINING - Epoch: [72][60/196]	Time 0.115 (0.150)	Data 0.000 (0.035)	Loss 0.0900 (0.1123)	Prec@1 96.484 (96.055)	Prec@5 100.000 (99.962)
2022-06-17 18:13:51 - INFO - TRAINING - Epoch: [72][70/196]	Time 0.105 (0.145)	Data 0.000 (0.030)	Loss 0.0805 (0.1115)	Prec@1 98.047 (96.121)	Prec@5 100.000 (99.961)
2022-06-17 18:13:52 - INFO - TRAINING - Epoch: [72][80/196]	Time 0.121 (0.142)	Data 0.000 (0.026)	Loss 0.1805 (0.1116)	Prec@1 92.188 (96.108)	Prec@5 100.000 (99.957)
2022-06-17 18:13:53 - INFO - TRAINING - Epoch: [72][90/196]	Time 0.119 (0.139)	Data 0.000 (0.024)	Loss 0.1002 (0.1117)	Prec@1 96.484 (96.107)	Prec@5 99.609 (99.957)
2022-06-17 18:13:54 - INFO - TRAINING - Epoch: [72][100/196]	Time 0.123 (0.138)	Data 0.000 (0.021)	Loss 0.0988 (0.1112)	Prec@1 97.266 (96.105)	Prec@5 100.000 (99.961)
2022-06-17 18:13:55 - INFO - TRAINING - Epoch: [72][110/196]	Time 0.104 (0.136)	Data 0.000 (0.019)	Loss 0.0752 (0.1115)	Prec@1 96.875 (96.087)	Prec@5 100.000 (99.958)
2022-06-17 18:13:57 - INFO - TRAINING - Epoch: [72][120/196]	Time 0.101 (0.134)	Data 0.000 (0.018)	Loss 0.1502 (0.1107)	Prec@1 94.922 (96.129)	Prec@5 100.000 (99.961)
2022-06-17 18:13:58 - INFO - TRAINING - Epoch: [72][130/196]	Time 0.116 (0.133)	Data 0.000 (0.016)	Loss 0.1626 (0.1103)	Prec@1 96.484 (96.195)	Prec@5 100.000 (99.961)
2022-06-17 18:13:59 - INFO - TRAINING - Epoch: [72][140/196]	Time 0.126 (0.131)	Data 0.000 (0.015)	Loss 0.0847 (0.1100)	Prec@1 97.266 (96.202)	Prec@5 100.000 (99.961)
2022-06-17 18:14:00 - INFO - TRAINING - Epoch: [72][150/196]	Time 0.132 (0.131)	Data 0.000 (0.014)	Loss 0.1121 (0.1096)	Prec@1 96.484 (96.241)	Prec@5 100.000 (99.961)
2022-06-17 18:14:01 - INFO - TRAINING - Epoch: [72][160/196]	Time 0.132 (0.130)	Data 0.000 (0.013)	Loss 0.1274 (0.1096)	Prec@1 95.703 (96.244)	Prec@5 100.000 (99.961)
2022-06-17 18:14:02 - INFO - TRAINING - Epoch: [72][170/196]	Time 0.119 (0.129)	Data 0.000 (0.013)	Loss 0.1376 (0.1099)	Prec@1 94.922 (96.219)	Prec@5 100.000 (99.961)
2022-06-17 18:14:04 - INFO - TRAINING - Epoch: [72][180/196]	Time 0.110 (0.128)	Data 0.000 (0.012)	Loss 0.1088 (0.1094)	Prec@1 97.266 (96.234)	Prec@5 100.000 (99.961)
2022-06-17 18:14:05 - INFO - TRAINING - Epoch: [72][190/196]	Time 0.102 (0.127)	Data 0.000 (0.011)	Loss 0.0917 (0.1086)	Prec@1 96.875 (96.282)	Prec@5 100.000 (99.963)
2022-06-17 18:14:07 - INFO - EVALUATING - Epoch: [72][0/40]	Time 1.998 (1.998)	Data 1.952 (1.952)	Loss 0.2508 (0.2508)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:14:08 - INFO - EVALUATING - Epoch: [72][10/40]	Time 0.071 (0.252)	Data 0.000 (0.202)	Loss 0.4480 (0.3965)	Prec@1 87.891 (88.565)	Prec@5 99.219 (99.396)
2022-06-17 18:14:09 - INFO - EVALUATING - Epoch: [72][20/40]	Time 0.060 (0.176)	Data 0.000 (0.126)	Loss 0.3310 (0.3998)	Prec@1 87.500 (88.002)	Prec@5 100.000 (99.405)
2022-06-17 18:14:10 - INFO - EVALUATING - Epoch: [72][30/40]	Time 0.057 (0.153)	Data 0.000 (0.105)	Loss 0.4935 (0.3927)	Prec@1 86.719 (88.117)	Prec@5 100.000 (99.483)
2022-06-17 18:14:12 - INFO - 
 Epoch: 73	Training Loss 0.1085 	Training Prec@1 96.276 	Training Prec@5 99.962 	Validation Loss 0.3885 	Validation Prec@1 88.140 	Validation Prec@5 99.560 

2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:14:12 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:14:14 - INFO - TRAINING - Epoch: [73][0/196]	Time 1.636 (1.636)	Data 1.584 (1.584)	Loss 0.0924 (0.0924)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:14:15 - INFO - TRAINING - Epoch: [73][10/196]	Time 0.103 (0.257)	Data 0.000 (0.166)	Loss 0.0794 (0.1060)	Prec@1 98.047 (96.626)	Prec@5 100.000 (99.929)
2022-06-17 18:14:16 - INFO - TRAINING - Epoch: [73][20/196]	Time 0.119 (0.185)	Data 0.000 (0.088)	Loss 0.1345 (0.1083)	Prec@1 95.312 (96.429)	Prec@5 100.000 (99.963)
2022-06-17 18:14:17 - INFO - TRAINING - Epoch: [73][30/196]	Time 0.102 (0.162)	Data 0.000 (0.060)	Loss 0.1780 (0.1099)	Prec@1 93.750 (96.321)	Prec@5 99.609 (99.962)
2022-06-17 18:14:18 - INFO - TRAINING - Epoch: [73][40/196]	Time 0.102 (0.150)	Data 0.000 (0.045)	Loss 0.1312 (0.1115)	Prec@1 95.703 (96.284)	Prec@5 100.000 (99.971)
2022-06-17 18:14:19 - INFO - TRAINING - Epoch: [73][50/196]	Time 0.106 (0.142)	Data 0.000 (0.037)	Loss 0.0868 (0.1099)	Prec@1 98.047 (96.362)	Prec@5 100.000 (99.977)
2022-06-17 18:14:20 - INFO - TRAINING - Epoch: [73][60/196]	Time 0.118 (0.138)	Data 0.000 (0.031)	Loss 0.0888 (0.1080)	Prec@1 98.047 (96.459)	Prec@5 100.000 (99.974)
2022-06-17 18:14:21 - INFO - TRAINING - Epoch: [73][70/196]	Time 0.109 (0.135)	Data 0.000 (0.026)	Loss 0.0962 (0.1061)	Prec@1 96.094 (96.517)	Prec@5 100.000 (99.978)
2022-06-17 18:14:23 - INFO - TRAINING - Epoch: [73][80/196]	Time 0.112 (0.131)	Data 0.000 (0.023)	Loss 0.1136 (0.1058)	Prec@1 96.875 (96.562)	Prec@5 100.000 (99.981)
2022-06-17 18:14:24 - INFO - TRAINING - Epoch: [73][90/196]	Time 0.136 (0.129)	Data 0.000 (0.021)	Loss 0.1474 (0.1073)	Prec@1 94.531 (96.467)	Prec@5 100.000 (99.983)
2022-06-17 18:14:25 - INFO - TRAINING - Epoch: [73][100/196]	Time 0.126 (0.128)	Data 0.000 (0.019)	Loss 0.1083 (0.1080)	Prec@1 96.094 (96.465)	Prec@5 100.000 (99.985)
2022-06-17 18:14:26 - INFO - TRAINING - Epoch: [73][110/196]	Time 0.105 (0.127)	Data 0.000 (0.017)	Loss 0.1059 (0.1078)	Prec@1 96.094 (96.449)	Prec@5 100.000 (99.986)
2022-06-17 18:14:27 - INFO - TRAINING - Epoch: [73][120/196]	Time 0.122 (0.126)	Data 0.000 (0.016)	Loss 0.0736 (0.1072)	Prec@1 97.266 (96.465)	Prec@5 100.000 (99.974)
2022-06-17 18:14:28 - INFO - TRAINING - Epoch: [73][130/196]	Time 0.105 (0.126)	Data 0.000 (0.014)	Loss 0.1498 (0.1082)	Prec@1 94.141 (96.428)	Prec@5 100.000 (99.976)
2022-06-17 18:14:30 - INFO - TRAINING - Epoch: [73][140/196]	Time 0.104 (0.125)	Data 0.000 (0.013)	Loss 0.0897 (0.1093)	Prec@1 96.484 (96.387)	Prec@5 100.000 (99.970)
2022-06-17 18:14:31 - INFO - TRAINING - Epoch: [73][150/196]	Time 0.113 (0.124)	Data 0.000 (0.013)	Loss 0.0920 (0.1085)	Prec@1 95.703 (96.412)	Prec@5 100.000 (99.969)
2022-06-17 18:14:32 - INFO - TRAINING - Epoch: [73][160/196]	Time 0.118 (0.123)	Data 0.000 (0.012)	Loss 0.1425 (0.1095)	Prec@1 96.094 (96.380)	Prec@5 100.000 (99.971)
2022-06-17 18:14:33 - INFO - TRAINING - Epoch: [73][170/196]	Time 0.133 (0.123)	Data 0.000 (0.011)	Loss 0.1189 (0.1094)	Prec@1 94.922 (96.366)	Prec@5 100.000 (99.970)
2022-06-17 18:14:34 - INFO - TRAINING - Epoch: [73][180/196]	Time 0.105 (0.122)	Data 0.000 (0.011)	Loss 0.0849 (0.1096)	Prec@1 98.047 (96.348)	Prec@5 100.000 (99.970)
2022-06-17 18:14:35 - INFO - TRAINING - Epoch: [73][190/196]	Time 0.113 (0.122)	Data 0.000 (0.010)	Loss 0.0801 (0.1095)	Prec@1 97.656 (96.364)	Prec@5 100.000 (99.965)
2022-06-17 18:14:37 - INFO - EVALUATING - Epoch: [73][0/40]	Time 1.518 (1.518)	Data 1.472 (1.472)	Loss 0.2555 (0.2555)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:14:39 - INFO - EVALUATING - Epoch: [73][10/40]	Time 0.476 (0.261)	Data 0.434 (0.215)	Loss 0.4617 (0.4047)	Prec@1 88.281 (88.246)	Prec@5 99.609 (99.467)
2022-06-17 18:14:40 - INFO - EVALUATING - Epoch: [73][20/40]	Time 0.107 (0.175)	Data 0.066 (0.128)	Loss 0.3315 (0.4072)	Prec@1 86.719 (87.816)	Prec@5 100.000 (99.423)
2022-06-17 18:14:41 - INFO - EVALUATING - Epoch: [73][30/40]	Time 0.088 (0.153)	Data 0.044 (0.106)	Loss 0.5018 (0.3999)	Prec@1 86.328 (88.042)	Prec@5 100.000 (99.483)
2022-06-17 18:14:42 - INFO - 
 Epoch: 74	Training Loss 0.1095 	Training Prec@1 96.364 	Training Prec@5 99.966 	Validation Loss 0.3947 	Validation Prec@1 88.070 	Validation Prec@5 99.560 

2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:14:43 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:14:45 - INFO - TRAINING - Epoch: [74][0/196]	Time 2.042 (2.042)	Data 1.990 (1.990)	Loss 0.0876 (0.0876)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:14:46 - INFO - TRAINING - Epoch: [74][10/196]	Time 0.103 (0.283)	Data 0.000 (0.181)	Loss 0.1253 (0.1013)	Prec@1 96.875 (96.662)	Prec@5 99.609 (99.964)
2022-06-17 18:14:47 - INFO - TRAINING - Epoch: [74][20/196]	Time 0.137 (0.206)	Data 0.000 (0.095)	Loss 0.0702 (0.1067)	Prec@1 98.438 (96.447)	Prec@5 100.000 (99.981)
2022-06-17 18:14:48 - INFO - TRAINING - Epoch: [74][30/196]	Time 0.107 (0.173)	Data 0.000 (0.064)	Loss 0.0813 (0.1084)	Prec@1 97.266 (96.358)	Prec@5 100.000 (99.975)
2022-06-17 18:14:49 - INFO - TRAINING - Epoch: [74][40/196]	Time 0.112 (0.158)	Data 0.000 (0.049)	Loss 0.1149 (0.1107)	Prec@1 96.484 (96.322)	Prec@5 100.000 (99.981)
2022-06-17 18:14:50 - INFO - TRAINING - Epoch: [74][50/196]	Time 0.107 (0.149)	Data 0.000 (0.039)	Loss 0.1048 (0.1110)	Prec@1 96.875 (96.285)	Prec@5 100.000 (99.985)
2022-06-17 18:14:51 - INFO - TRAINING - Epoch: [74][60/196]	Time 0.108 (0.142)	Data 0.000 (0.033)	Loss 0.1224 (0.1092)	Prec@1 95.703 (96.337)	Prec@5 100.000 (99.981)
2022-06-17 18:14:52 - INFO - TRAINING - Epoch: [74][70/196]	Time 0.111 (0.138)	Data 0.000 (0.028)	Loss 0.1458 (0.1083)	Prec@1 96.094 (96.407)	Prec@5 99.609 (99.978)
2022-06-17 18:14:53 - INFO - TRAINING - Epoch: [74][80/196]	Time 0.107 (0.134)	Data 0.000 (0.025)	Loss 0.1155 (0.1086)	Prec@1 94.922 (96.412)	Prec@5 100.000 (99.971)
2022-06-17 18:14:54 - INFO - TRAINING - Epoch: [74][90/196]	Time 0.113 (0.131)	Data 0.001 (0.022)	Loss 0.1110 (0.1089)	Prec@1 95.703 (96.381)	Prec@5 100.000 (99.974)
2022-06-17 18:14:56 - INFO - TRAINING - Epoch: [74][100/196]	Time 0.104 (0.129)	Data 0.000 (0.020)	Loss 0.0828 (0.1088)	Prec@1 96.875 (96.392)	Prec@5 100.000 (99.977)
2022-06-17 18:14:57 - INFO - TRAINING - Epoch: [74][110/196]	Time 0.105 (0.127)	Data 0.000 (0.018)	Loss 0.0803 (0.1096)	Prec@1 96.484 (96.326)	Prec@5 100.000 (99.968)
2022-06-17 18:14:58 - INFO - TRAINING - Epoch: [74][120/196]	Time 0.104 (0.126)	Data 0.000 (0.017)	Loss 0.1260 (0.1100)	Prec@1 96.875 (96.333)	Prec@5 100.000 (99.971)
2022-06-17 18:14:59 - INFO - TRAINING - Epoch: [74][130/196]	Time 0.114 (0.124)	Data 0.000 (0.016)	Loss 0.1243 (0.1101)	Prec@1 95.312 (96.299)	Prec@5 100.000 (99.973)
2022-06-17 18:15:00 - INFO - TRAINING - Epoch: [74][140/196]	Time 0.109 (0.123)	Data 0.000 (0.014)	Loss 0.1148 (0.1091)	Prec@1 96.094 (96.332)	Prec@5 100.000 (99.972)
2022-06-17 18:15:01 - INFO - TRAINING - Epoch: [74][150/196]	Time 0.111 (0.122)	Data 0.000 (0.014)	Loss 0.1196 (0.1093)	Prec@1 96.484 (96.340)	Prec@5 100.000 (99.972)
2022-06-17 18:15:02 - INFO - TRAINING - Epoch: [74][160/196]	Time 0.107 (0.121)	Data 0.000 (0.013)	Loss 0.1523 (0.1095)	Prec@1 94.141 (96.310)	Prec@5 100.000 (99.973)
2022-06-17 18:15:03 - INFO - TRAINING - Epoch: [74][170/196]	Time 0.114 (0.121)	Data 0.000 (0.012)	Loss 0.1141 (0.1090)	Prec@1 94.922 (96.322)	Prec@5 100.000 (99.975)
2022-06-17 18:15:04 - INFO - TRAINING - Epoch: [74][180/196]	Time 0.108 (0.121)	Data 0.000 (0.011)	Loss 0.0941 (0.1085)	Prec@1 96.875 (96.353)	Prec@5 100.000 (99.976)
2022-06-17 18:15:05 - INFO - TRAINING - Epoch: [74][190/196]	Time 0.102 (0.120)	Data 0.000 (0.011)	Loss 0.0738 (0.1085)	Prec@1 97.656 (96.353)	Prec@5 100.000 (99.978)
2022-06-17 18:15:08 - INFO - EVALUATING - Epoch: [74][0/40]	Time 1.780 (1.780)	Data 1.734 (1.734)	Loss 0.2612 (0.2612)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:15:08 - INFO - EVALUATING - Epoch: [74][10/40]	Time 0.041 (0.223)	Data 0.000 (0.175)	Loss 0.4563 (0.4039)	Prec@1 87.109 (88.175)	Prec@5 99.219 (99.432)
2022-06-17 18:15:10 - INFO - EVALUATING - Epoch: [74][20/40]	Time 0.109 (0.167)	Data 0.065 (0.120)	Loss 0.3240 (0.4043)	Prec@1 87.891 (87.872)	Prec@5 100.000 (99.461)
2022-06-17 18:15:11 - INFO - EVALUATING - Epoch: [74][30/40]	Time 0.096 (0.145)	Data 0.054 (0.100)	Loss 0.4901 (0.3976)	Prec@1 87.109 (88.092)	Prec@5 100.000 (99.496)
2022-06-17 18:15:12 - INFO - 
 Epoch: 75	Training Loss 0.1082 	Training Prec@1 96.374 	Training Prec@5 99.978 	Validation Loss 0.3933 	Validation Prec@1 88.200 	Validation Prec@5 99.570 

2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:15:12 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:15:14 - INFO - TRAINING - Epoch: [75][0/196]	Time 1.543 (1.543)	Data 1.489 (1.489)	Loss 0.0995 (0.0995)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:15:15 - INFO - TRAINING - Epoch: [75][10/196]	Time 0.103 (0.250)	Data 0.000 (0.154)	Loss 0.1110 (0.1025)	Prec@1 95.312 (96.236)	Prec@5 100.000 (100.000)
2022-06-17 18:15:16 - INFO - TRAINING - Epoch: [75][20/196]	Time 0.115 (0.186)	Data 0.000 (0.081)	Loss 0.0851 (0.1072)	Prec@1 95.703 (96.168)	Prec@5 100.000 (99.981)
2022-06-17 18:15:17 - INFO - TRAINING - Epoch: [75][30/196]	Time 0.106 (0.161)	Data 0.000 (0.055)	Loss 0.1291 (0.1080)	Prec@1 96.484 (96.232)	Prec@5 100.000 (99.987)
2022-06-17 18:15:18 - INFO - TRAINING - Epoch: [75][40/196]	Time 0.103 (0.148)	Data 0.000 (0.042)	Loss 0.0788 (0.1068)	Prec@1 96.875 (96.265)	Prec@5 100.000 (99.971)
2022-06-17 18:15:20 - INFO - TRAINING - Epoch: [75][50/196]	Time 0.107 (0.140)	Data 0.003 (0.034)	Loss 0.0968 (0.1079)	Prec@1 96.875 (96.247)	Prec@5 100.000 (99.977)
2022-06-17 18:15:21 - INFO - TRAINING - Epoch: [75][60/196]	Time 0.110 (0.135)	Data 0.000 (0.028)	Loss 0.1024 (0.1072)	Prec@1 95.703 (96.331)	Prec@5 100.000 (99.981)
2022-06-17 18:15:22 - INFO - TRAINING - Epoch: [75][70/196]	Time 0.106 (0.131)	Data 0.000 (0.024)	Loss 0.0870 (0.1076)	Prec@1 96.875 (96.270)	Prec@5 100.000 (99.978)
2022-06-17 18:15:23 - INFO - TRAINING - Epoch: [75][80/196]	Time 0.110 (0.129)	Data 0.000 (0.021)	Loss 0.1314 (0.1086)	Prec@1 96.094 (96.258)	Prec@5 100.000 (99.976)
2022-06-17 18:15:24 - INFO - TRAINING - Epoch: [75][90/196]	Time 0.113 (0.127)	Data 0.000 (0.019)	Loss 0.0975 (0.1087)	Prec@1 96.094 (96.235)	Prec@5 100.000 (99.979)
2022-06-17 18:15:25 - INFO - TRAINING - Epoch: [75][100/196]	Time 0.109 (0.125)	Data 0.000 (0.017)	Loss 0.1500 (0.1098)	Prec@1 95.703 (96.187)	Prec@5 99.609 (99.973)
2022-06-17 18:15:26 - INFO - TRAINING - Epoch: [75][110/196]	Time 0.118 (0.124)	Data 0.000 (0.016)	Loss 0.1085 (0.1091)	Prec@1 96.094 (96.217)	Prec@5 100.000 (99.975)
2022-06-17 18:15:27 - INFO - TRAINING - Epoch: [75][120/196]	Time 0.102 (0.123)	Data 0.000 (0.014)	Loss 0.1365 (0.1090)	Prec@1 95.312 (96.216)	Prec@5 100.000 (99.977)
2022-06-17 18:15:28 - INFO - TRAINING - Epoch: [75][130/196]	Time 0.113 (0.122)	Data 0.000 (0.013)	Loss 0.1058 (0.1087)	Prec@1 97.656 (96.225)	Prec@5 100.000 (99.979)
2022-06-17 18:15:29 - INFO - TRAINING - Epoch: [75][140/196]	Time 0.105 (0.121)	Data 0.000 (0.012)	Loss 0.1085 (0.1089)	Prec@1 96.875 (96.216)	Prec@5 100.000 (99.978)
2022-06-17 18:15:31 - INFO - TRAINING - Epoch: [75][150/196]	Time 0.107 (0.120)	Data 0.000 (0.012)	Loss 0.0564 (0.1074)	Prec@1 98.438 (96.267)	Prec@5 100.000 (99.977)
2022-06-17 18:15:32 - INFO - TRAINING - Epoch: [75][160/196]	Time 0.130 (0.120)	Data 0.000 (0.011)	Loss 0.0781 (0.1080)	Prec@1 97.656 (96.247)	Prec@5 100.000 (99.978)
2022-06-17 18:15:33 - INFO - TRAINING - Epoch: [75][170/196]	Time 0.108 (0.119)	Data 0.000 (0.010)	Loss 0.1015 (0.1079)	Prec@1 96.875 (96.254)	Prec@5 100.000 (99.979)
2022-06-17 18:15:34 - INFO - TRAINING - Epoch: [75][180/196]	Time 0.106 (0.118)	Data 0.000 (0.010)	Loss 0.1141 (0.1087)	Prec@1 96.094 (96.230)	Prec@5 100.000 (99.976)
2022-06-17 18:15:35 - INFO - TRAINING - Epoch: [75][190/196]	Time 0.111 (0.118)	Data 0.000 (0.009)	Loss 0.1142 (0.1094)	Prec@1 96.875 (96.216)	Prec@5 100.000 (99.973)
2022-06-17 18:15:38 - INFO - EVALUATING - Epoch: [75][0/40]	Time 1.944 (1.944)	Data 1.899 (1.899)	Loss 0.2568 (0.2568)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:15:39 - INFO - EVALUATING - Epoch: [75][10/40]	Time 0.044 (0.260)	Data 0.000 (0.211)	Loss 0.4690 (0.4035)	Prec@1 88.281 (88.423)	Prec@5 99.609 (99.432)
2022-06-17 18:15:39 - INFO - EVALUATING - Epoch: [75][20/40]	Time 0.042 (0.160)	Data 0.001 (0.111)	Loss 0.3247 (0.4052)	Prec@1 88.281 (87.946)	Prec@5 100.000 (99.405)
2022-06-17 18:15:40 - INFO - EVALUATING - Epoch: [75][30/40]	Time 0.096 (0.139)	Data 0.056 (0.090)	Loss 0.4880 (0.3977)	Prec@1 86.328 (88.130)	Prec@5 100.000 (99.446)
2022-06-17 18:15:42 - INFO - 
 Epoch: 76	Training Loss 0.1092 	Training Prec@1 96.230 	Training Prec@5 99.974 	Validation Loss 0.3932 	Validation Prec@1 88.140 	Validation Prec@5 99.530 

2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:15:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:15:43 - INFO - TRAINING - Epoch: [76][0/196]	Time 1.207 (1.207)	Data 1.151 (1.151)	Loss 0.1073 (0.1073)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:15:44 - INFO - TRAINING - Epoch: [76][10/196]	Time 0.105 (0.237)	Data 0.000 (0.145)	Loss 0.1066 (0.0979)	Prec@1 94.922 (96.449)	Prec@5 100.000 (100.000)
2022-06-17 18:15:45 - INFO - TRAINING - Epoch: [76][20/196]	Time 0.108 (0.178)	Data 0.000 (0.077)	Loss 0.1461 (0.1047)	Prec@1 96.484 (96.354)	Prec@5 100.000 (100.000)
2022-06-17 18:15:47 - INFO - TRAINING - Epoch: [76][30/196]	Time 0.115 (0.155)	Data 0.000 (0.052)	Loss 0.0818 (0.1031)	Prec@1 96.875 (96.510)	Prec@5 100.000 (99.975)
2022-06-17 18:15:48 - INFO - TRAINING - Epoch: [76][40/196]	Time 0.103 (0.144)	Data 0.000 (0.040)	Loss 0.1007 (0.1066)	Prec@1 96.484 (96.322)	Prec@5 100.000 (99.962)
2022-06-17 18:15:49 - INFO - TRAINING - Epoch: [76][50/196]	Time 0.115 (0.137)	Data 0.000 (0.032)	Loss 0.1505 (0.1058)	Prec@1 94.141 (96.331)	Prec@5 100.000 (99.969)
2022-06-17 18:15:50 - INFO - TRAINING - Epoch: [76][60/196]	Time 0.112 (0.132)	Data 0.000 (0.027)	Loss 0.0963 (0.1055)	Prec@1 96.875 (96.343)	Prec@5 100.000 (99.974)
2022-06-17 18:15:51 - INFO - TRAINING - Epoch: [76][70/196]	Time 0.105 (0.129)	Data 0.000 (0.023)	Loss 0.1460 (0.1075)	Prec@1 94.922 (96.292)	Prec@5 100.000 (99.978)
2022-06-17 18:15:52 - INFO - TRAINING - Epoch: [76][80/196]	Time 0.116 (0.127)	Data 0.000 (0.020)	Loss 0.0648 (0.1065)	Prec@1 98.438 (96.345)	Prec@5 100.000 (99.981)
2022-06-17 18:15:53 - INFO - TRAINING - Epoch: [76][90/196]	Time 0.102 (0.126)	Data 0.000 (0.018)	Loss 0.0774 (0.1066)	Prec@1 96.875 (96.351)	Prec@5 100.000 (99.983)
2022-06-17 18:15:54 - INFO - TRAINING - Epoch: [76][100/196]	Time 0.116 (0.125)	Data 0.000 (0.016)	Loss 0.0941 (0.1064)	Prec@1 98.438 (96.361)	Prec@5 100.000 (99.985)
2022-06-17 18:15:55 - INFO - TRAINING - Epoch: [76][110/196]	Time 0.118 (0.124)	Data 0.000 (0.015)	Loss 0.0945 (0.1070)	Prec@1 96.875 (96.330)	Prec@5 99.609 (99.979)
2022-06-17 18:15:57 - INFO - TRAINING - Epoch: [76][120/196]	Time 0.122 (0.123)	Data 0.000 (0.014)	Loss 0.0821 (0.1061)	Prec@1 98.047 (96.388)	Prec@5 100.000 (99.977)
2022-06-17 18:15:58 - INFO - TRAINING - Epoch: [76][130/196]	Time 0.112 (0.122)	Data 0.000 (0.013)	Loss 0.0859 (0.1050)	Prec@1 97.266 (96.431)	Prec@5 100.000 (99.979)
2022-06-17 18:15:59 - INFO - TRAINING - Epoch: [76][140/196]	Time 0.110 (0.122)	Data 0.000 (0.012)	Loss 0.1054 (0.1049)	Prec@1 95.703 (96.423)	Prec@5 100.000 (99.981)
2022-06-17 18:16:00 - INFO - TRAINING - Epoch: [76][150/196]	Time 0.114 (0.121)	Data 0.000 (0.011)	Loss 0.0730 (0.1043)	Prec@1 97.656 (96.464)	Prec@5 100.000 (99.979)
2022-06-17 18:16:01 - INFO - TRAINING - Epoch: [76][160/196]	Time 0.116 (0.121)	Data 0.000 (0.010)	Loss 0.0855 (0.1045)	Prec@1 96.094 (96.441)	Prec@5 100.000 (99.981)
2022-06-17 18:16:02 - INFO - TRAINING - Epoch: [76][170/196]	Time 0.108 (0.120)	Data 0.000 (0.010)	Loss 0.1349 (0.1052)	Prec@1 94.922 (96.425)	Prec@5 100.000 (99.982)
2022-06-17 18:16:03 - INFO - TRAINING - Epoch: [76][180/196]	Time 0.112 (0.120)	Data 0.000 (0.009)	Loss 0.0673 (0.1048)	Prec@1 98.438 (96.452)	Prec@5 100.000 (99.981)
2022-06-17 18:16:04 - INFO - TRAINING - Epoch: [76][190/196]	Time 0.101 (0.119)	Data 0.000 (0.009)	Loss 0.1134 (0.1050)	Prec@1 95.312 (96.448)	Prec@5 100.000 (99.982)
2022-06-17 18:16:07 - INFO - EVALUATING - Epoch: [76][0/40]	Time 1.896 (1.896)	Data 1.850 (1.850)	Loss 0.2600 (0.2600)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:16:08 - INFO - EVALUATING - Epoch: [76][10/40]	Time 0.045 (0.246)	Data 0.001 (0.197)	Loss 0.4647 (0.3996)	Prec@1 87.500 (88.352)	Prec@5 99.219 (99.432)
2022-06-17 18:16:08 - INFO - EVALUATING - Epoch: [76][20/40]	Time 0.108 (0.160)	Data 0.067 (0.110)	Loss 0.3277 (0.4029)	Prec@1 88.281 (87.891)	Prec@5 100.000 (99.442)
2022-06-17 18:16:10 - INFO - EVALUATING - Epoch: [76][30/40]	Time 0.044 (0.148)	Data 0.000 (0.099)	Loss 0.4827 (0.3953)	Prec@1 85.938 (88.080)	Prec@5 100.000 (99.509)
2022-06-17 18:16:11 - INFO - 
 Epoch: 77	Training Loss 0.1051 	Training Prec@1 96.446 	Training Prec@5 99.978 	Validation Loss 0.3910 	Validation Prec@1 88.100 	Validation Prec@5 99.580 

2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:16:11 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:16:13 - INFO - TRAINING - Epoch: [77][0/196]	Time 1.454 (1.454)	Data 1.400 (1.400)	Loss 0.1309 (0.1309)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:16:14 - INFO - TRAINING - Epoch: [77][10/196]	Time 0.102 (0.266)	Data 0.000 (0.165)	Loss 0.0894 (0.1025)	Prec@1 97.266 (96.662)	Prec@5 100.000 (100.000)
2022-06-17 18:16:15 - INFO - TRAINING - Epoch: [77][20/196]	Time 0.102 (0.190)	Data 0.000 (0.087)	Loss 0.1140 (0.1061)	Prec@1 96.875 (96.354)	Prec@5 99.609 (99.981)
2022-06-17 18:16:17 - INFO - TRAINING - Epoch: [77][30/196]	Time 0.102 (0.165)	Data 0.000 (0.059)	Loss 0.1325 (0.1051)	Prec@1 96.094 (96.459)	Prec@5 100.000 (99.987)
2022-06-17 18:16:18 - INFO - TRAINING - Epoch: [77][40/196]	Time 0.113 (0.152)	Data 0.000 (0.044)	Loss 0.1499 (0.1065)	Prec@1 94.922 (96.456)	Prec@5 100.000 (99.981)
2022-06-17 18:16:19 - INFO - TRAINING - Epoch: [77][50/196]	Time 0.108 (0.144)	Data 0.000 (0.036)	Loss 0.0983 (0.1063)	Prec@1 96.875 (96.507)	Prec@5 100.000 (99.985)
2022-06-17 18:16:20 - INFO - TRAINING - Epoch: [77][60/196]	Time 0.114 (0.139)	Data 0.000 (0.030)	Loss 0.0606 (0.1063)	Prec@1 97.656 (96.510)	Prec@5 100.000 (99.981)
2022-06-17 18:16:21 - INFO - TRAINING - Epoch: [77][70/196]	Time 0.107 (0.135)	Data 0.000 (0.026)	Loss 0.0748 (0.1055)	Prec@1 97.656 (96.545)	Prec@5 100.000 (99.978)
2022-06-17 18:16:22 - INFO - TRAINING - Epoch: [77][80/196]	Time 0.105 (0.132)	Data 0.000 (0.023)	Loss 0.1647 (0.1053)	Prec@1 94.141 (96.489)	Prec@5 100.000 (99.981)
2022-06-17 18:16:23 - INFO - TRAINING - Epoch: [77][90/196]	Time 0.127 (0.130)	Data 0.000 (0.020)	Loss 0.1277 (0.1051)	Prec@1 96.484 (96.484)	Prec@5 99.609 (99.979)
2022-06-17 18:16:25 - INFO - TRAINING - Epoch: [77][100/196]	Time 0.113 (0.129)	Data 0.000 (0.018)	Loss 0.0829 (0.1049)	Prec@1 97.656 (96.500)	Prec@5 100.000 (99.977)
2022-06-17 18:16:26 - INFO - TRAINING - Epoch: [77][110/196]	Time 0.102 (0.127)	Data 0.000 (0.017)	Loss 0.2020 (0.1060)	Prec@1 92.969 (96.495)	Prec@5 99.609 (99.972)
2022-06-17 18:16:27 - INFO - TRAINING - Epoch: [77][120/196]	Time 0.116 (0.126)	Data 0.000 (0.015)	Loss 0.1448 (0.1064)	Prec@1 94.922 (96.452)	Prec@5 100.000 (99.974)
2022-06-17 18:16:28 - INFO - TRAINING - Epoch: [77][130/196]	Time 0.102 (0.125)	Data 0.000 (0.014)	Loss 0.1231 (0.1070)	Prec@1 96.094 (96.419)	Prec@5 100.000 (99.976)
2022-06-17 18:16:29 - INFO - TRAINING - Epoch: [77][140/196]	Time 0.115 (0.124)	Data 0.000 (0.013)	Loss 0.1408 (0.1076)	Prec@1 95.312 (96.393)	Prec@5 100.000 (99.975)
2022-06-17 18:16:30 - INFO - TRAINING - Epoch: [77][150/196]	Time 0.102 (0.123)	Data 0.000 (0.012)	Loss 0.1179 (0.1074)	Prec@1 96.094 (96.404)	Prec@5 100.000 (99.969)
2022-06-17 18:16:31 - INFO - TRAINING - Epoch: [77][160/196]	Time 0.113 (0.122)	Data 0.000 (0.012)	Loss 0.0938 (0.1075)	Prec@1 96.484 (96.397)	Prec@5 100.000 (99.971)
2022-06-17 18:16:32 - INFO - TRAINING - Epoch: [77][170/196]	Time 0.131 (0.122)	Data 0.000 (0.011)	Loss 0.0816 (0.1074)	Prec@1 97.656 (96.409)	Prec@5 100.000 (99.973)
2022-06-17 18:16:34 - INFO - TRAINING - Epoch: [77][180/196]	Time 0.120 (0.122)	Data 0.000 (0.010)	Loss 0.0950 (0.1085)	Prec@1 97.656 (96.381)	Prec@5 100.000 (99.970)
2022-06-17 18:16:35 - INFO - TRAINING - Epoch: [77][190/196]	Time 0.101 (0.121)	Data 0.000 (0.010)	Loss 0.1765 (0.1089)	Prec@1 93.359 (96.374)	Prec@5 100.000 (99.971)
2022-06-17 18:16:37 - INFO - EVALUATING - Epoch: [77][0/40]	Time 1.627 (1.627)	Data 1.580 (1.580)	Loss 0.2588 (0.2588)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:16:38 - INFO - EVALUATING - Epoch: [77][10/40]	Time 0.059 (0.227)	Data 0.000 (0.177)	Loss 0.4603 (0.4033)	Prec@1 87.891 (88.317)	Prec@5 99.609 (99.432)
2022-06-17 18:16:39 - INFO - EVALUATING - Epoch: [77][20/40]	Time 0.109 (0.169)	Data 0.065 (0.121)	Loss 0.3269 (0.4047)	Prec@1 87.891 (88.002)	Prec@5 100.000 (99.442)
2022-06-17 18:16:40 - INFO - EVALUATING - Epoch: [77][30/40]	Time 0.050 (0.150)	Data 0.000 (0.104)	Loss 0.4867 (0.3974)	Prec@1 85.938 (88.067)	Prec@5 100.000 (99.496)
2022-06-17 18:16:42 - INFO - 
 Epoch: 78	Training Loss 0.1094 	Training Prec@1 96.350 	Training Prec@5 99.972 	Validation Loss 0.3928 	Validation Prec@1 88.090 	Validation Prec@5 99.570 

2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:16:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:16:43 - INFO - TRAINING - Epoch: [78][0/196]	Time 1.243 (1.243)	Data 1.191 (1.191)	Loss 0.0809 (0.0809)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:16:45 - INFO - TRAINING - Epoch: [78][10/196]	Time 0.118 (0.268)	Data 0.000 (0.167)	Loss 0.0937 (0.0913)	Prec@1 97.656 (97.479)	Prec@5 100.000 (100.000)
2022-06-17 18:16:46 - INFO - TRAINING - Epoch: [78][20/196]	Time 0.130 (0.196)	Data 0.000 (0.088)	Loss 0.1605 (0.0964)	Prec@1 94.141 (97.042)	Prec@5 100.000 (99.981)
2022-06-17 18:16:47 - INFO - TRAINING - Epoch: [78][30/196]	Time 0.113 (0.171)	Data 0.000 (0.060)	Loss 0.1141 (0.0981)	Prec@1 95.703 (96.875)	Prec@5 100.000 (99.975)
2022-06-17 18:16:48 - INFO - TRAINING - Epoch: [78][40/196]	Time 0.118 (0.159)	Data 0.000 (0.045)	Loss 0.0750 (0.0994)	Prec@1 97.656 (96.799)	Prec@5 100.000 (99.981)
2022-06-17 18:16:49 - INFO - TRAINING - Epoch: [78][50/196]	Time 0.118 (0.151)	Data 0.000 (0.036)	Loss 0.1023 (0.1007)	Prec@1 96.484 (96.722)	Prec@5 100.000 (99.977)
2022-06-17 18:16:51 - INFO - TRAINING - Epoch: [78][60/196]	Time 0.134 (0.146)	Data 0.000 (0.031)	Loss 0.1152 (0.1027)	Prec@1 96.484 (96.670)	Prec@5 100.000 (99.968)
2022-06-17 18:16:52 - INFO - TRAINING - Epoch: [78][70/196]	Time 0.101 (0.142)	Data 0.000 (0.026)	Loss 0.1400 (0.1024)	Prec@1 94.922 (96.633)	Prec@5 100.000 (99.972)
2022-06-17 18:16:53 - INFO - TRAINING - Epoch: [78][80/196]	Time 0.126 (0.139)	Data 0.000 (0.023)	Loss 0.1070 (0.1041)	Prec@1 96.875 (96.586)	Prec@5 100.000 (99.961)
2022-06-17 18:16:54 - INFO - TRAINING - Epoch: [78][90/196]	Time 0.116 (0.137)	Data 0.000 (0.021)	Loss 0.0873 (0.1035)	Prec@1 97.656 (96.583)	Prec@5 100.000 (99.961)
2022-06-17 18:16:55 - INFO - TRAINING - Epoch: [78][100/196]	Time 0.108 (0.135)	Data 0.000 (0.019)	Loss 0.0938 (0.1052)	Prec@1 96.875 (96.500)	Prec@5 100.000 (99.957)
2022-06-17 18:16:57 - INFO - TRAINING - Epoch: [78][110/196]	Time 0.107 (0.133)	Data 0.000 (0.017)	Loss 0.0859 (0.1049)	Prec@1 98.438 (96.509)	Prec@5 100.000 (99.958)
2022-06-17 18:16:58 - INFO - TRAINING - Epoch: [78][120/196]	Time 0.128 (0.133)	Data 0.000 (0.016)	Loss 0.0898 (0.1046)	Prec@1 96.875 (96.484)	Prec@5 100.000 (99.961)
2022-06-17 18:16:59 - INFO - TRAINING - Epoch: [78][130/196]	Time 0.125 (0.132)	Data 0.000 (0.014)	Loss 0.1807 (0.1053)	Prec@1 94.531 (96.446)	Prec@5 100.000 (99.958)
2022-06-17 18:17:00 - INFO - TRAINING - Epoch: [78][140/196]	Time 0.112 (0.131)	Data 0.000 (0.013)	Loss 0.0980 (0.1052)	Prec@1 97.266 (96.473)	Prec@5 100.000 (99.961)
2022-06-17 18:17:01 - INFO - TRAINING - Epoch: [78][150/196]	Time 0.104 (0.130)	Data 0.000 (0.012)	Loss 0.1109 (0.1056)	Prec@1 96.094 (96.459)	Prec@5 100.000 (99.961)
2022-06-17 18:17:03 - INFO - TRAINING - Epoch: [78][160/196]	Time 0.109 (0.129)	Data 0.000 (0.012)	Loss 0.1142 (0.1059)	Prec@1 95.312 (96.448)	Prec@5 100.000 (99.961)
2022-06-17 18:17:04 - INFO - TRAINING - Epoch: [78][170/196]	Time 0.119 (0.129)	Data 0.000 (0.011)	Loss 0.1039 (0.1051)	Prec@1 96.094 (96.455)	Prec@5 100.000 (99.961)
2022-06-17 18:17:05 - INFO - TRAINING - Epoch: [78][180/196]	Time 0.104 (0.128)	Data 0.000 (0.010)	Loss 0.0870 (0.1047)	Prec@1 96.484 (96.474)	Prec@5 100.000 (99.963)
2022-06-17 18:17:06 - INFO - TRAINING - Epoch: [78][190/196]	Time 0.102 (0.127)	Data 0.000 (0.010)	Loss 0.1102 (0.1043)	Prec@1 96.484 (96.493)	Prec@5 100.000 (99.965)
2022-06-17 18:17:08 - INFO - EVALUATING - Epoch: [78][0/40]	Time 1.692 (1.692)	Data 1.645 (1.645)	Loss 0.2625 (0.2625)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:17:10 - INFO - EVALUATING - Epoch: [78][10/40]	Time 0.059 (0.267)	Data 0.000 (0.216)	Loss 0.4721 (0.4040)	Prec@1 87.500 (88.317)	Prec@5 99.609 (99.396)
2022-06-17 18:17:10 - INFO - EVALUATING - Epoch: [78][20/40]	Time 0.113 (0.167)	Data 0.072 (0.117)	Loss 0.3200 (0.4052)	Prec@1 88.281 (87.928)	Prec@5 100.000 (99.442)
2022-06-17 18:17:11 - INFO - EVALUATING - Epoch: [78][30/40]	Time 0.083 (0.146)	Data 0.042 (0.098)	Loss 0.4924 (0.3978)	Prec@1 85.547 (88.054)	Prec@5 100.000 (99.471)
2022-06-17 18:17:13 - INFO - 
 Epoch: 79	Training Loss 0.1041 	Training Prec@1 96.492 	Training Prec@5 99.966 	Validation Loss 0.3934 	Validation Prec@1 88.070 	Validation Prec@5 99.550 

2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:17:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:17:15 - INFO - TRAINING - Epoch: [79][0/196]	Time 1.630 (1.630)	Data 1.575 (1.575)	Loss 0.1183 (0.1183)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:17:16 - INFO - TRAINING - Epoch: [79][10/196]	Time 0.111 (0.281)	Data 0.000 (0.180)	Loss 0.0968 (0.0969)	Prec@1 96.484 (96.768)	Prec@5 100.000 (99.893)
2022-06-17 18:17:17 - INFO - TRAINING - Epoch: [79][20/196]	Time 0.111 (0.203)	Data 0.000 (0.095)	Loss 0.1233 (0.0993)	Prec@1 96.094 (96.708)	Prec@5 100.000 (99.944)
2022-06-17 18:17:19 - INFO - TRAINING - Epoch: [79][30/196]	Time 0.122 (0.176)	Data 0.000 (0.064)	Loss 0.0976 (0.0984)	Prec@1 97.656 (96.724)	Prec@5 100.000 (99.950)
2022-06-17 18:17:20 - INFO - TRAINING - Epoch: [79][40/196]	Time 0.120 (0.160)	Data 0.000 (0.049)	Loss 0.1234 (0.1025)	Prec@1 96.484 (96.618)	Prec@5 100.000 (99.952)
2022-06-17 18:17:21 - INFO - TRAINING - Epoch: [79][50/196]	Time 0.113 (0.150)	Data 0.000 (0.039)	Loss 0.0947 (0.1020)	Prec@1 96.484 (96.638)	Prec@5 100.000 (99.946)
2022-06-17 18:17:22 - INFO - TRAINING - Epoch: [79][60/196]	Time 0.111 (0.144)	Data 0.000 (0.033)	Loss 0.0947 (0.1012)	Prec@1 96.094 (96.619)	Prec@5 99.609 (99.936)
2022-06-17 18:17:23 - INFO - TRAINING - Epoch: [79][70/196]	Time 0.111 (0.139)	Data 0.000 (0.028)	Loss 0.1221 (0.1029)	Prec@1 95.312 (96.451)	Prec@5 100.000 (99.945)
2022-06-17 18:17:24 - INFO - TRAINING - Epoch: [79][80/196]	Time 0.115 (0.136)	Data 0.000 (0.025)	Loss 0.0815 (0.1033)	Prec@1 97.266 (96.388)	Prec@5 100.000 (99.947)
2022-06-17 18:17:25 - INFO - TRAINING - Epoch: [79][90/196]	Time 0.123 (0.134)	Data 0.000 (0.022)	Loss 0.1516 (0.1021)	Prec@1 94.531 (96.420)	Prec@5 100.000 (99.944)
2022-06-17 18:17:26 - INFO - TRAINING - Epoch: [79][100/196]	Time 0.109 (0.132)	Data 0.000 (0.020)	Loss 0.0709 (0.1009)	Prec@1 98.047 (96.473)	Prec@5 100.000 (99.950)
2022-06-17 18:17:28 - INFO - TRAINING - Epoch: [79][110/196]	Time 0.121 (0.131)	Data 0.000 (0.018)	Loss 0.1133 (0.1015)	Prec@1 96.094 (96.498)	Prec@5 99.609 (99.944)
2022-06-17 18:17:29 - INFO - TRAINING - Epoch: [79][120/196]	Time 0.116 (0.129)	Data 0.000 (0.017)	Loss 0.0822 (0.1023)	Prec@1 96.875 (96.488)	Prec@5 100.000 (99.945)
2022-06-17 18:17:30 - INFO - TRAINING - Epoch: [79][130/196]	Time 0.121 (0.128)	Data 0.000 (0.015)	Loss 0.1008 (0.1029)	Prec@1 96.875 (96.455)	Prec@5 100.000 (99.946)
2022-06-17 18:17:31 - INFO - TRAINING - Epoch: [79][140/196]	Time 0.123 (0.127)	Data 0.000 (0.014)	Loss 0.1299 (0.1032)	Prec@1 95.703 (96.448)	Prec@5 100.000 (99.950)
2022-06-17 18:17:32 - INFO - TRAINING - Epoch: [79][150/196]	Time 0.109 (0.126)	Data 0.000 (0.013)	Loss 0.1084 (0.1035)	Prec@1 96.875 (96.448)	Prec@5 100.000 (99.951)
2022-06-17 18:17:33 - INFO - TRAINING - Epoch: [79][160/196]	Time 0.124 (0.125)	Data 0.000 (0.013)	Loss 0.0907 (0.1034)	Prec@1 96.875 (96.429)	Prec@5 100.000 (99.954)
2022-06-17 18:17:34 - INFO - TRAINING - Epoch: [79][170/196]	Time 0.126 (0.125)	Data 0.000 (0.012)	Loss 0.0963 (0.1033)	Prec@1 96.094 (96.434)	Prec@5 100.000 (99.954)
2022-06-17 18:17:36 - INFO - TRAINING - Epoch: [79][180/196]	Time 0.106 (0.124)	Data 0.000 (0.011)	Loss 0.0942 (0.1033)	Prec@1 97.266 (96.428)	Prec@5 100.000 (99.955)
2022-06-17 18:17:37 - INFO - TRAINING - Epoch: [79][190/196]	Time 0.102 (0.123)	Data 0.000 (0.011)	Loss 0.1308 (0.1033)	Prec@1 94.531 (96.419)	Prec@5 100.000 (99.955)
2022-06-17 18:17:39 - INFO - EVALUATING - Epoch: [79][0/40]	Time 2.081 (2.081)	Data 2.036 (2.036)	Loss 0.2584 (0.2584)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:17:40 - INFO - EVALUATING - Epoch: [79][10/40]	Time 0.044 (0.276)	Data 0.000 (0.229)	Loss 0.4676 (0.4035)	Prec@1 87.891 (88.139)	Prec@5 99.609 (99.432)
2022-06-17 18:17:41 - INFO - EVALUATING - Epoch: [79][20/40]	Time 0.069 (0.170)	Data 0.000 (0.120)	Loss 0.3310 (0.4061)	Prec@1 87.891 (87.853)	Prec@5 100.000 (99.405)
2022-06-17 18:17:42 - INFO - EVALUATING - Epoch: [79][30/40]	Time 0.096 (0.150)	Data 0.056 (0.103)	Loss 0.4949 (0.3981)	Prec@1 86.328 (88.004)	Prec@5 100.000 (99.471)
2022-06-17 18:17:44 - INFO - 
 Epoch: 80	Training Loss 0.1034 	Training Prec@1 96.418 	Training Prec@5 99.956 	Validation Loss 0.3938 	Validation Prec@1 88.040 	Validation Prec@5 99.550 

2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:17:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:17:45 - INFO - TRAINING - Epoch: [80][0/196]	Time 1.406 (1.406)	Data 1.352 (1.352)	Loss 0.1026 (0.1026)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:17:47 - INFO - TRAINING - Epoch: [80][10/196]	Time 0.103 (0.257)	Data 0.000 (0.160)	Loss 0.0901 (0.1107)	Prec@1 97.266 (96.591)	Prec@5 100.000 (100.000)
2022-06-17 18:17:48 - INFO - TRAINING - Epoch: [80][20/196]	Time 0.102 (0.185)	Data 0.000 (0.084)	Loss 0.0861 (0.1025)	Prec@1 97.656 (96.689)	Prec@5 100.000 (99.981)
2022-06-17 18:17:49 - INFO - TRAINING - Epoch: [80][30/196]	Time 0.115 (0.161)	Data 0.000 (0.057)	Loss 0.1047 (0.0996)	Prec@1 97.266 (96.749)	Prec@5 100.000 (99.975)
2022-06-17 18:17:50 - INFO - TRAINING - Epoch: [80][40/196]	Time 0.112 (0.148)	Data 0.000 (0.043)	Loss 0.1398 (0.1027)	Prec@1 96.875 (96.684)	Prec@5 100.000 (99.981)
2022-06-17 18:17:51 - INFO - TRAINING - Epoch: [80][50/196]	Time 0.109 (0.141)	Data 0.000 (0.035)	Loss 0.0770 (0.1041)	Prec@1 97.266 (96.553)	Prec@5 100.000 (99.977)
2022-06-17 18:17:52 - INFO - TRAINING - Epoch: [80][60/196]	Time 0.108 (0.135)	Data 0.000 (0.029)	Loss 0.0844 (0.1043)	Prec@1 97.266 (96.587)	Prec@5 100.000 (99.981)
2022-06-17 18:17:53 - INFO - TRAINING - Epoch: [80][70/196]	Time 0.116 (0.132)	Data 0.000 (0.025)	Loss 0.0862 (0.1046)	Prec@1 97.266 (96.545)	Prec@5 100.000 (99.978)
2022-06-17 18:17:54 - INFO - TRAINING - Epoch: [80][80/196]	Time 0.108 (0.129)	Data 0.000 (0.022)	Loss 0.0805 (0.1039)	Prec@1 97.266 (96.557)	Prec@5 100.000 (99.971)
2022-06-17 18:17:55 - INFO - TRAINING - Epoch: [80][90/196]	Time 0.103 (0.127)	Data 0.000 (0.020)	Loss 0.1223 (0.1043)	Prec@1 95.312 (96.532)	Prec@5 100.000 (99.974)
2022-06-17 18:17:56 - INFO - TRAINING - Epoch: [80][100/196]	Time 0.102 (0.125)	Data 0.000 (0.018)	Loss 0.1109 (0.1050)	Prec@1 94.141 (96.481)	Prec@5 100.000 (99.977)
2022-06-17 18:17:58 - INFO - TRAINING - Epoch: [80][110/196]	Time 0.109 (0.124)	Data 0.000 (0.016)	Loss 0.0753 (0.1044)	Prec@1 96.875 (96.534)	Prec@5 100.000 (99.975)
2022-06-17 18:17:59 - INFO - TRAINING - Epoch: [80][120/196]	Time 0.107 (0.122)	Data 0.000 (0.015)	Loss 0.1031 (0.1036)	Prec@1 96.484 (96.542)	Prec@5 100.000 (99.974)
2022-06-17 18:18:00 - INFO - TRAINING - Epoch: [80][130/196]	Time 0.103 (0.121)	Data 0.000 (0.014)	Loss 0.0866 (0.1035)	Prec@1 96.875 (96.547)	Prec@5 100.000 (99.973)
2022-06-17 18:18:01 - INFO - TRAINING - Epoch: [80][140/196]	Time 0.124 (0.121)	Data 0.000 (0.013)	Loss 0.0716 (0.1031)	Prec@1 97.266 (96.562)	Prec@5 100.000 (99.972)
2022-06-17 18:18:02 - INFO - TRAINING - Epoch: [80][150/196]	Time 0.110 (0.121)	Data 0.000 (0.012)	Loss 0.0965 (0.1043)	Prec@1 96.875 (96.523)	Prec@5 100.000 (99.969)
2022-06-17 18:18:03 - INFO - TRAINING - Epoch: [80][160/196]	Time 0.104 (0.120)	Data 0.000 (0.011)	Loss 0.1246 (0.1037)	Prec@1 95.312 (96.552)	Prec@5 100.000 (99.971)
2022-06-17 18:18:04 - INFO - TRAINING - Epoch: [80][170/196]	Time 0.127 (0.119)	Data 0.000 (0.011)	Loss 0.1186 (0.1037)	Prec@1 96.094 (96.560)	Prec@5 100.000 (99.970)
2022-06-17 18:18:05 - INFO - TRAINING - Epoch: [80][180/196]	Time 0.119 (0.119)	Data 0.000 (0.010)	Loss 0.1346 (0.1040)	Prec@1 96.875 (96.562)	Prec@5 100.000 (99.970)
2022-06-17 18:18:06 - INFO - TRAINING - Epoch: [80][190/196]	Time 0.106 (0.118)	Data 0.000 (0.010)	Loss 0.1309 (0.1047)	Prec@1 95.703 (96.554)	Prec@5 100.000 (99.969)
2022-06-17 18:18:09 - INFO - EVALUATING - Epoch: [80][0/40]	Time 1.682 (1.682)	Data 1.635 (1.635)	Loss 0.2621 (0.2621)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:18:10 - INFO - EVALUATING - Epoch: [80][10/40]	Time 0.044 (0.253)	Data 0.001 (0.205)	Loss 0.4674 (0.4062)	Prec@1 87.891 (88.033)	Prec@5 99.609 (99.432)
2022-06-17 18:18:10 - INFO - EVALUATING - Epoch: [80][20/40]	Time 0.043 (0.157)	Data 0.000 (0.108)	Loss 0.3312 (0.4061)	Prec@1 88.281 (87.891)	Prec@5 100.000 (99.423)
2022-06-17 18:18:11 - INFO - EVALUATING - Epoch: [80][30/40]	Time 0.047 (0.142)	Data 0.000 (0.094)	Loss 0.4812 (0.3978)	Prec@1 85.938 (88.155)	Prec@5 100.000 (99.458)
2022-06-17 18:18:13 - INFO - 
 Epoch: 81	Training Loss 0.1049 	Training Prec@1 96.552 	Training Prec@5 99.970 	Validation Loss 0.3933 	Validation Prec@1 88.180 	Validation Prec@5 99.540 

2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:18:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:18:15 - INFO - TRAINING - Epoch: [81][0/196]	Time 1.805 (1.805)	Data 1.750 (1.750)	Loss 0.0932 (0.0932)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:18:16 - INFO - TRAINING - Epoch: [81][10/196]	Time 0.120 (0.276)	Data 0.000 (0.171)	Loss 0.0860 (0.1020)	Prec@1 98.438 (96.591)	Prec@5 100.000 (99.964)
2022-06-17 18:18:18 - INFO - TRAINING - Epoch: [81][20/196]	Time 0.121 (0.199)	Data 0.000 (0.090)	Loss 0.0815 (0.1033)	Prec@1 96.875 (96.484)	Prec@5 100.000 (99.963)
2022-06-17 18:18:19 - INFO - TRAINING - Epoch: [81][30/196]	Time 0.103 (0.170)	Data 0.000 (0.061)	Loss 0.0747 (0.1027)	Prec@1 96.484 (96.434)	Prec@5 100.000 (99.962)
2022-06-17 18:18:20 - INFO - TRAINING - Epoch: [81][40/196]	Time 0.123 (0.157)	Data 0.000 (0.046)	Loss 0.1604 (0.1040)	Prec@1 93.359 (96.389)	Prec@5 100.000 (99.971)
2022-06-17 18:18:21 - INFO - TRAINING - Epoch: [81][50/196]	Time 0.136 (0.148)	Data 0.000 (0.037)	Loss 0.1470 (0.1078)	Prec@1 94.531 (96.209)	Prec@5 100.000 (99.969)
2022-06-17 18:18:22 - INFO - TRAINING - Epoch: [81][60/196]	Time 0.108 (0.142)	Data 0.000 (0.031)	Loss 0.0989 (0.1076)	Prec@1 96.875 (96.203)	Prec@5 100.000 (99.974)
2022-06-17 18:18:23 - INFO - TRAINING - Epoch: [81][70/196]	Time 0.121 (0.138)	Data 0.000 (0.027)	Loss 0.0648 (0.1071)	Prec@1 97.266 (96.242)	Prec@5 100.000 (99.972)
2022-06-17 18:18:24 - INFO - TRAINING - Epoch: [81][80/196]	Time 0.109 (0.136)	Data 0.000 (0.024)	Loss 0.0696 (0.1061)	Prec@1 97.656 (96.354)	Prec@5 100.000 (99.976)
2022-06-17 18:18:25 - INFO - TRAINING - Epoch: [81][90/196]	Time 0.121 (0.134)	Data 0.000 (0.021)	Loss 0.0695 (0.1062)	Prec@1 97.266 (96.368)	Prec@5 100.000 (99.979)
2022-06-17 18:18:27 - INFO - TRAINING - Epoch: [81][100/196]	Time 0.115 (0.131)	Data 0.000 (0.019)	Loss 0.1006 (0.1062)	Prec@1 96.875 (96.407)	Prec@5 100.000 (99.981)
2022-06-17 18:18:28 - INFO - TRAINING - Epoch: [81][110/196]	Time 0.127 (0.130)	Data 0.000 (0.017)	Loss 0.0925 (0.1056)	Prec@1 96.875 (96.428)	Prec@5 100.000 (99.982)
2022-06-17 18:18:29 - INFO - TRAINING - Epoch: [81][120/196]	Time 0.113 (0.128)	Data 0.000 (0.016)	Loss 0.1121 (0.1062)	Prec@1 96.094 (96.423)	Prec@5 100.000 (99.984)
2022-06-17 18:18:30 - INFO - TRAINING - Epoch: [81][130/196]	Time 0.106 (0.127)	Data 0.000 (0.015)	Loss 0.1307 (0.1057)	Prec@1 96.094 (96.416)	Prec@5 100.000 (99.979)
2022-06-17 18:18:31 - INFO - TRAINING - Epoch: [81][140/196]	Time 0.115 (0.126)	Data 0.000 (0.014)	Loss 0.1262 (0.1055)	Prec@1 96.094 (96.435)	Prec@5 100.000 (99.978)
2022-06-17 18:18:32 - INFO - TRAINING - Epoch: [81][150/196]	Time 0.113 (0.125)	Data 0.000 (0.013)	Loss 0.1064 (0.1056)	Prec@1 97.266 (96.451)	Prec@5 100.000 (99.974)
2022-06-17 18:18:33 - INFO - TRAINING - Epoch: [81][160/196]	Time 0.110 (0.124)	Data 0.000 (0.012)	Loss 0.1114 (0.1052)	Prec@1 96.875 (96.467)	Prec@5 100.000 (99.976)
2022-06-17 18:18:34 - INFO - TRAINING - Epoch: [81][170/196]	Time 0.106 (0.123)	Data 0.000 (0.011)	Loss 0.1379 (0.1058)	Prec@1 96.484 (96.441)	Prec@5 100.000 (99.975)
2022-06-17 18:18:36 - INFO - TRAINING - Epoch: [81][180/196]	Time 0.121 (0.122)	Data 0.000 (0.011)	Loss 0.1470 (0.1055)	Prec@1 94.531 (96.461)	Prec@5 100.000 (99.972)
2022-06-17 18:18:37 - INFO - TRAINING - Epoch: [81][190/196]	Time 0.101 (0.122)	Data 0.000 (0.010)	Loss 0.0565 (0.1057)	Prec@1 97.656 (96.427)	Prec@5 100.000 (99.971)
2022-06-17 18:18:39 - INFO - EVALUATING - Epoch: [81][0/40]	Time 1.932 (1.932)	Data 1.887 (1.887)	Loss 0.2615 (0.2615)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:18:40 - INFO - EVALUATING - Epoch: [81][10/40]	Time 0.044 (0.260)	Data 0.000 (0.213)	Loss 0.4657 (0.4049)	Prec@1 87.500 (88.246)	Prec@5 99.609 (99.467)
2022-06-17 18:18:41 - INFO - EVALUATING - Epoch: [81][20/40]	Time 0.041 (0.165)	Data 0.000 (0.116)	Loss 0.3354 (0.4061)	Prec@1 87.891 (87.891)	Prec@5 100.000 (99.423)
2022-06-17 18:18:42 - INFO - EVALUATING - Epoch: [81][30/40]	Time 0.043 (0.147)	Data 0.000 (0.099)	Loss 0.4887 (0.3983)	Prec@1 86.328 (88.004)	Prec@5 100.000 (99.471)
2022-06-17 18:18:44 - INFO - 
 Epoch: 82	Training Loss 0.1053 	Training Prec@1 96.444 	Training Prec@5 99.972 	Validation Loss 0.3934 	Validation Prec@1 88.080 	Validation Prec@5 99.550 

2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:18:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:18:45 - INFO - TRAINING - Epoch: [82][0/196]	Time 1.528 (1.528)	Data 1.477 (1.477)	Loss 0.1288 (0.1288)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:18:47 - INFO - TRAINING - Epoch: [82][10/196]	Time 0.105 (0.256)	Data 0.000 (0.163)	Loss 0.0787 (0.1082)	Prec@1 96.875 (96.413)	Prec@5 100.000 (99.964)
2022-06-17 18:18:48 - INFO - TRAINING - Epoch: [82][20/196]	Time 0.121 (0.186)	Data 0.000 (0.086)	Loss 0.1004 (0.1051)	Prec@1 96.875 (96.484)	Prec@5 100.000 (99.981)
2022-06-17 18:18:49 - INFO - TRAINING - Epoch: [82][30/196]	Time 0.116 (0.162)	Data 0.000 (0.058)	Loss 0.0927 (0.1033)	Prec@1 97.266 (96.535)	Prec@5 100.000 (99.987)
2022-06-17 18:18:50 - INFO - TRAINING - Epoch: [82][40/196]	Time 0.111 (0.150)	Data 0.000 (0.044)	Loss 0.0802 (0.1045)	Prec@1 98.438 (96.456)	Prec@5 100.000 (99.981)
2022-06-17 18:18:51 - INFO - TRAINING - Epoch: [82][50/196]	Time 0.104 (0.143)	Data 0.000 (0.035)	Loss 0.1390 (0.1043)	Prec@1 94.922 (96.469)	Prec@5 100.000 (99.962)
2022-06-17 18:18:52 - INFO - TRAINING - Epoch: [82][60/196]	Time 0.107 (0.137)	Data 0.000 (0.030)	Loss 0.1492 (0.1083)	Prec@1 94.531 (96.305)	Prec@5 100.000 (99.949)
2022-06-17 18:18:53 - INFO - TRAINING - Epoch: [82][70/196]	Time 0.115 (0.134)	Data 0.000 (0.025)	Loss 0.0831 (0.1074)	Prec@1 96.094 (96.297)	Prec@5 100.000 (99.956)
2022-06-17 18:18:55 - INFO - TRAINING - Epoch: [82][80/196]	Time 0.124 (0.132)	Data 0.000 (0.022)	Loss 0.1213 (0.1076)	Prec@1 96.484 (96.306)	Prec@5 100.000 (99.957)
2022-06-17 18:18:56 - INFO - TRAINING - Epoch: [82][90/196]	Time 0.102 (0.129)	Data 0.000 (0.020)	Loss 0.1249 (0.1065)	Prec@1 95.312 (96.364)	Prec@5 100.000 (99.961)
2022-06-17 18:18:57 - INFO - TRAINING - Epoch: [82][100/196]	Time 0.109 (0.128)	Data 0.000 (0.018)	Loss 0.1504 (0.1062)	Prec@1 94.922 (96.372)	Prec@5 100.000 (99.961)
2022-06-17 18:18:58 - INFO - TRAINING - Epoch: [82][110/196]	Time 0.103 (0.126)	Data 0.000 (0.016)	Loss 0.0945 (0.1061)	Prec@1 96.875 (96.375)	Prec@5 100.000 (99.961)
2022-06-17 18:18:59 - INFO - TRAINING - Epoch: [82][120/196]	Time 0.112 (0.125)	Data 0.000 (0.015)	Loss 0.0840 (0.1057)	Prec@1 98.047 (96.404)	Prec@5 100.000 (99.964)
2022-06-17 18:19:00 - INFO - TRAINING - Epoch: [82][130/196]	Time 0.105 (0.124)	Data 0.000 (0.014)	Loss 0.0783 (0.1062)	Prec@1 96.875 (96.383)	Prec@5 100.000 (99.961)
2022-06-17 18:19:01 - INFO - TRAINING - Epoch: [82][140/196]	Time 0.111 (0.123)	Data 0.000 (0.013)	Loss 0.1364 (0.1073)	Prec@1 94.141 (96.349)	Prec@5 100.000 (99.961)
2022-06-17 18:19:02 - INFO - TRAINING - Epoch: [82][150/196]	Time 0.102 (0.122)	Data 0.000 (0.012)	Loss 0.0941 (0.1070)	Prec@1 97.656 (96.360)	Prec@5 100.000 (99.961)
2022-06-17 18:19:03 - INFO - TRAINING - Epoch: [82][160/196]	Time 0.110 (0.121)	Data 0.000 (0.011)	Loss 0.1054 (0.1066)	Prec@1 95.703 (96.368)	Prec@5 100.000 (99.964)
2022-06-17 18:19:04 - INFO - TRAINING - Epoch: [82][170/196]	Time 0.103 (0.120)	Data 0.000 (0.011)	Loss 0.1045 (0.1064)	Prec@1 95.312 (96.361)	Prec@5 100.000 (99.966)
2022-06-17 18:19:06 - INFO - TRAINING - Epoch: [82][180/196]	Time 0.107 (0.120)	Data 0.000 (0.010)	Loss 0.0696 (0.1060)	Prec@1 98.047 (96.379)	Prec@5 100.000 (99.968)
2022-06-17 18:19:07 - INFO - TRAINING - Epoch: [82][190/196]	Time 0.101 (0.119)	Data 0.000 (0.010)	Loss 0.1181 (0.1060)	Prec@1 96.094 (96.368)	Prec@5 100.000 (99.969)
2022-06-17 18:19:09 - INFO - EVALUATING - Epoch: [82][0/40]	Time 1.787 (1.787)	Data 1.742 (1.742)	Loss 0.2640 (0.2640)	Prec@1 92.969 (92.969)	Prec@5 99.609 (99.609)
2022-06-17 18:19:10 - INFO - EVALUATING - Epoch: [82][10/40]	Time 0.045 (0.249)	Data 0.001 (0.200)	Loss 0.4695 (0.4116)	Prec@1 87.500 (87.926)	Prec@5 99.219 (99.432)
2022-06-17 18:19:11 - INFO - EVALUATING - Epoch: [82][20/40]	Time 0.116 (0.164)	Data 0.074 (0.117)	Loss 0.3277 (0.4098)	Prec@1 87.891 (87.705)	Prec@5 100.000 (99.479)
2022-06-17 18:19:12 - INFO - EVALUATING - Epoch: [82][30/40]	Time 0.168 (0.148)	Data 0.124 (0.102)	Loss 0.4865 (0.4019)	Prec@1 86.719 (88.042)	Prec@5 100.000 (99.509)
2022-06-17 18:19:14 - INFO - 
 Epoch: 83	Training Loss 0.1063 	Training Prec@1 96.364 	Training Prec@5 99.970 	Validation Loss 0.3972 	Validation Prec@1 88.090 	Validation Prec@5 99.570 

2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:19:14 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:19:15 - INFO - TRAINING - Epoch: [83][0/196]	Time 1.646 (1.646)	Data 1.595 (1.595)	Loss 0.0726 (0.0726)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:19:16 - INFO - TRAINING - Epoch: [83][10/196]	Time 0.114 (0.254)	Data 0.000 (0.145)	Loss 0.0991 (0.1008)	Prec@1 96.875 (96.626)	Prec@5 100.000 (99.929)
2022-06-17 18:19:17 - INFO - TRAINING - Epoch: [83][20/196]	Time 0.119 (0.187)	Data 0.000 (0.076)	Loss 0.0990 (0.0977)	Prec@1 96.875 (96.782)	Prec@5 100.000 (99.963)
2022-06-17 18:19:19 - INFO - TRAINING - Epoch: [83][30/196]	Time 0.101 (0.163)	Data 0.000 (0.052)	Loss 0.1284 (0.1015)	Prec@1 95.312 (96.673)	Prec@5 100.000 (99.962)
2022-06-17 18:19:20 - INFO - TRAINING - Epoch: [83][40/196]	Time 0.103 (0.149)	Data 0.000 (0.039)	Loss 0.1063 (0.1045)	Prec@1 96.094 (96.475)	Prec@5 100.000 (99.971)
2022-06-17 18:19:21 - INFO - TRAINING - Epoch: [83][50/196]	Time 0.106 (0.141)	Data 0.000 (0.032)	Loss 0.1190 (0.1035)	Prec@1 95.703 (96.500)	Prec@5 100.000 (99.962)
2022-06-17 18:19:22 - INFO - TRAINING - Epoch: [83][60/196]	Time 0.110 (0.136)	Data 0.000 (0.026)	Loss 0.0780 (0.1054)	Prec@1 97.656 (96.401)	Prec@5 100.000 (99.968)
2022-06-17 18:19:23 - INFO - TRAINING - Epoch: [83][70/196]	Time 0.104 (0.132)	Data 0.000 (0.023)	Loss 0.0744 (0.1055)	Prec@1 97.266 (96.407)	Prec@5 100.000 (99.967)
2022-06-17 18:19:24 - INFO - TRAINING - Epoch: [83][80/196]	Time 0.110 (0.129)	Data 0.000 (0.020)	Loss 0.1201 (0.1050)	Prec@1 96.094 (96.431)	Prec@5 100.000 (99.966)
2022-06-17 18:19:25 - INFO - TRAINING - Epoch: [83][90/196]	Time 0.102 (0.127)	Data 0.000 (0.018)	Loss 0.1355 (0.1053)	Prec@1 95.703 (96.390)	Prec@5 99.609 (99.966)
2022-06-17 18:19:26 - INFO - TRAINING - Epoch: [83][100/196]	Time 0.107 (0.125)	Data 0.000 (0.016)	Loss 0.1073 (0.1038)	Prec@1 96.875 (96.450)	Prec@5 100.000 (99.969)
2022-06-17 18:19:27 - INFO - TRAINING - Epoch: [83][110/196]	Time 0.103 (0.124)	Data 0.000 (0.015)	Loss 0.0923 (0.1035)	Prec@1 96.875 (96.435)	Prec@5 100.000 (99.972)
2022-06-17 18:19:28 - INFO - TRAINING - Epoch: [83][120/196]	Time 0.105 (0.123)	Data 0.000 (0.013)	Loss 0.1154 (0.1045)	Prec@1 96.484 (96.400)	Prec@5 100.000 (99.974)
2022-06-17 18:19:30 - INFO - TRAINING - Epoch: [83][130/196]	Time 0.109 (0.122)	Data 0.000 (0.012)	Loss 0.0649 (0.1046)	Prec@1 98.047 (96.353)	Prec@5 100.000 (99.976)
2022-06-17 18:19:31 - INFO - TRAINING - Epoch: [83][140/196]	Time 0.116 (0.121)	Data 0.000 (0.012)	Loss 0.1024 (0.1048)	Prec@1 96.094 (96.362)	Prec@5 100.000 (99.975)
2022-06-17 18:19:32 - INFO - TRAINING - Epoch: [83][150/196]	Time 0.105 (0.121)	Data 0.000 (0.011)	Loss 0.1100 (0.1043)	Prec@1 96.484 (96.383)	Prec@5 100.000 (99.974)
2022-06-17 18:19:33 - INFO - TRAINING - Epoch: [83][160/196]	Time 0.106 (0.120)	Data 0.000 (0.010)	Loss 0.0821 (0.1046)	Prec@1 97.266 (96.387)	Prec@5 100.000 (99.973)
2022-06-17 18:19:34 - INFO - TRAINING - Epoch: [83][170/196]	Time 0.101 (0.119)	Data 0.000 (0.010)	Loss 0.1113 (0.1049)	Prec@1 96.875 (96.398)	Prec@5 100.000 (99.975)
2022-06-17 18:19:35 - INFO - TRAINING - Epoch: [83][180/196]	Time 0.108 (0.119)	Data 0.000 (0.009)	Loss 0.1138 (0.1049)	Prec@1 96.875 (96.435)	Prec@5 100.000 (99.974)
2022-06-17 18:19:36 - INFO - TRAINING - Epoch: [83][190/196]	Time 0.102 (0.118)	Data 0.000 (0.009)	Loss 0.0808 (0.1048)	Prec@1 97.656 (96.443)	Prec@5 100.000 (99.973)
2022-06-17 18:19:38 - INFO - EVALUATING - Epoch: [83][0/40]	Time 1.512 (1.512)	Data 1.465 (1.465)	Loss 0.2624 (0.2624)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:19:40 - INFO - EVALUATING - Epoch: [83][10/40]	Time 0.078 (0.246)	Data 0.033 (0.197)	Loss 0.4605 (0.4112)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.467)
2022-06-17 18:19:41 - INFO - EVALUATING - Epoch: [83][20/40]	Time 0.341 (0.179)	Data 0.299 (0.130)	Loss 0.3341 (0.4114)	Prec@1 87.891 (87.928)	Prec@5 100.000 (99.442)
2022-06-17 18:19:41 - INFO - EVALUATING - Epoch: [83][30/40]	Time 0.041 (0.151)	Data 0.000 (0.103)	Loss 0.5027 (0.4035)	Prec@1 85.156 (88.080)	Prec@5 100.000 (99.483)
2022-06-17 18:19:43 - INFO - 
 Epoch: 84	Training Loss 0.1049 	Training Prec@1 96.434 	Training Prec@5 99.974 	Validation Loss 0.3986 	Validation Prec@1 88.100 	Validation Prec@5 99.560 

2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:19:43 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:19:45 - INFO - TRAINING - Epoch: [84][0/196]	Time 1.505 (1.505)	Data 1.452 (1.452)	Loss 0.0751 (0.0751)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:19:46 - INFO - TRAINING - Epoch: [84][10/196]	Time 0.107 (0.265)	Data 0.053 (0.179)	Loss 0.0991 (0.0928)	Prec@1 96.094 (96.733)	Prec@5 100.000 (99.964)
2022-06-17 18:19:47 - INFO - TRAINING - Epoch: [84][20/196]	Time 0.115 (0.190)	Data 0.000 (0.094)	Loss 0.1096 (0.0960)	Prec@1 96.094 (96.856)	Prec@5 100.000 (99.944)
2022-06-17 18:19:48 - INFO - TRAINING - Epoch: [84][30/196]	Time 0.123 (0.166)	Data 0.000 (0.064)	Loss 0.1356 (0.1002)	Prec@1 94.531 (96.598)	Prec@5 100.000 (99.962)
2022-06-17 18:19:50 - INFO - TRAINING - Epoch: [84][40/196]	Time 0.133 (0.154)	Data 0.000 (0.048)	Loss 0.1320 (0.1057)	Prec@1 96.484 (96.370)	Prec@5 100.000 (99.962)
2022-06-17 18:19:51 - INFO - TRAINING - Epoch: [84][50/196]	Time 0.125 (0.148)	Data 0.000 (0.039)	Loss 0.0785 (0.1024)	Prec@1 98.438 (96.515)	Prec@5 100.000 (99.962)
2022-06-17 18:19:52 - INFO - TRAINING - Epoch: [84][60/196]	Time 0.111 (0.143)	Data 0.000 (0.032)	Loss 0.0978 (0.1029)	Prec@1 96.875 (96.491)	Prec@5 100.000 (99.968)
2022-06-17 18:19:53 - INFO - TRAINING - Epoch: [84][70/196]	Time 0.112 (0.139)	Data 0.000 (0.028)	Loss 0.0955 (0.1024)	Prec@1 96.875 (96.506)	Prec@5 100.000 (99.972)
2022-06-17 18:19:54 - INFO - TRAINING - Epoch: [84][80/196]	Time 0.114 (0.135)	Data 0.000 (0.025)	Loss 0.0880 (0.1038)	Prec@1 96.484 (96.446)	Prec@5 100.000 (99.976)
2022-06-17 18:19:55 - INFO - TRAINING - Epoch: [84][90/196]	Time 0.127 (0.133)	Data 0.000 (0.022)	Loss 0.1189 (0.1048)	Prec@1 94.922 (96.403)	Prec@5 100.000 (99.974)
2022-06-17 18:19:57 - INFO - TRAINING - Epoch: [84][100/196]	Time 0.113 (0.132)	Data 0.000 (0.020)	Loss 0.1230 (0.1052)	Prec@1 96.094 (96.372)	Prec@5 100.000 (99.977)
2022-06-17 18:19:58 - INFO - TRAINING - Epoch: [84][110/196]	Time 0.119 (0.131)	Data 0.000 (0.018)	Loss 0.1032 (0.1038)	Prec@1 96.484 (96.435)	Prec@5 100.000 (99.979)
2022-06-17 18:19:59 - INFO - TRAINING - Epoch: [84][120/196]	Time 0.106 (0.129)	Data 0.000 (0.017)	Loss 0.0623 (0.1033)	Prec@1 98.438 (96.471)	Prec@5 100.000 (99.977)
2022-06-17 18:20:00 - INFO - TRAINING - Epoch: [84][130/196]	Time 0.128 (0.128)	Data 0.000 (0.015)	Loss 0.1265 (0.1028)	Prec@1 96.484 (96.526)	Prec@5 100.000 (99.976)
2022-06-17 18:20:01 - INFO - TRAINING - Epoch: [84][140/196]	Time 0.103 (0.127)	Data 0.000 (0.014)	Loss 0.0964 (0.1027)	Prec@1 96.875 (96.548)	Prec@5 99.609 (99.970)
2022-06-17 18:20:02 - INFO - TRAINING - Epoch: [84][150/196]	Time 0.120 (0.127)	Data 0.000 (0.013)	Loss 0.1003 (0.1035)	Prec@1 96.484 (96.495)	Prec@5 100.000 (99.969)
2022-06-17 18:20:04 - INFO - TRAINING - Epoch: [84][160/196]	Time 0.115 (0.126)	Data 0.000 (0.013)	Loss 0.0960 (0.1028)	Prec@1 96.484 (96.521)	Prec@5 100.000 (99.968)
2022-06-17 18:20:05 - INFO - TRAINING - Epoch: [84][170/196]	Time 0.123 (0.126)	Data 0.000 (0.012)	Loss 0.1098 (0.1029)	Prec@1 94.922 (96.519)	Prec@5 100.000 (99.970)
2022-06-17 18:20:06 - INFO - TRAINING - Epoch: [84][180/196]	Time 0.113 (0.126)	Data 0.000 (0.011)	Loss 0.0867 (0.1030)	Prec@1 96.094 (96.508)	Prec@5 100.000 (99.972)
2022-06-17 18:20:07 - INFO - TRAINING - Epoch: [84][190/196]	Time 0.110 (0.125)	Data 0.000 (0.011)	Loss 0.1214 (0.1029)	Prec@1 95.703 (96.493)	Prec@5 100.000 (99.971)
2022-06-17 18:20:09 - INFO - EVALUATING - Epoch: [84][0/40]	Time 1.356 (1.356)	Data 1.311 (1.311)	Loss 0.2598 (0.2598)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:20:11 - INFO - EVALUATING - Epoch: [84][10/40]	Time 0.058 (0.276)	Data 0.000 (0.227)	Loss 0.4591 (0.4033)	Prec@1 87.109 (88.352)	Prec@5 99.219 (99.467)
2022-06-17 18:20:11 - INFO - EVALUATING - Epoch: [84][20/40]	Time 0.120 (0.170)	Data 0.076 (0.123)	Loss 0.3419 (0.4070)	Prec@1 87.500 (88.077)	Prec@5 100.000 (99.442)
2022-06-17 18:20:12 - INFO - EVALUATING - Epoch: [84][30/40]	Time 0.057 (0.150)	Data 0.000 (0.104)	Loss 0.4977 (0.4000)	Prec@1 85.938 (88.206)	Prec@5 100.000 (99.496)
2022-06-17 18:20:14 - INFO - 
 Epoch: 85	Training Loss 0.1029 	Training Prec@1 96.480 	Training Prec@5 99.972 	Validation Loss 0.3959 	Validation Prec@1 88.250 	Validation Prec@5 99.570 

2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:20:14 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:20:15 - INFO - TRAINING - Epoch: [85][0/196]	Time 1.222 (1.222)	Data 1.168 (1.168)	Loss 0.0860 (0.0860)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:20:17 - INFO - TRAINING - Epoch: [85][10/196]	Time 0.106 (0.249)	Data 0.000 (0.155)	Loss 0.0612 (0.0949)	Prec@1 98.438 (96.911)	Prec@5 100.000 (100.000)
2022-06-17 18:20:18 - INFO - TRAINING - Epoch: [85][20/196]	Time 0.102 (0.184)	Data 0.000 (0.081)	Loss 0.0756 (0.1008)	Prec@1 97.266 (96.559)	Prec@5 100.000 (100.000)
2022-06-17 18:20:19 - INFO - TRAINING - Epoch: [85][30/196]	Time 0.117 (0.161)	Data 0.000 (0.055)	Loss 0.0940 (0.1011)	Prec@1 96.875 (96.522)	Prec@5 100.000 (99.987)
2022-06-17 18:20:20 - INFO - TRAINING - Epoch: [85][40/196]	Time 0.111 (0.148)	Data 0.000 (0.042)	Loss 0.1040 (0.1022)	Prec@1 96.484 (96.494)	Prec@5 100.000 (99.981)
2022-06-17 18:20:21 - INFO - TRAINING - Epoch: [85][50/196]	Time 0.103 (0.140)	Data 0.000 (0.034)	Loss 0.0966 (0.1020)	Prec@1 96.875 (96.500)	Prec@5 100.000 (99.985)
2022-06-17 18:20:22 - INFO - TRAINING - Epoch: [85][60/196]	Time 0.106 (0.135)	Data 0.000 (0.028)	Loss 0.0962 (0.1031)	Prec@1 96.094 (96.459)	Prec@5 100.000 (99.987)
2022-06-17 18:20:24 - INFO - TRAINING - Epoch: [85][70/196]	Time 0.116 (0.131)	Data 0.000 (0.024)	Loss 0.1090 (0.1034)	Prec@1 96.875 (96.451)	Prec@5 100.000 (99.983)
2022-06-17 18:20:25 - INFO - TRAINING - Epoch: [85][80/196]	Time 0.120 (0.129)	Data 0.000 (0.021)	Loss 0.1287 (0.1034)	Prec@1 95.312 (96.465)	Prec@5 99.609 (99.976)
2022-06-17 18:20:26 - INFO - TRAINING - Epoch: [85][90/196]	Time 0.102 (0.127)	Data 0.000 (0.019)	Loss 0.0590 (0.1014)	Prec@1 97.656 (96.536)	Prec@5 100.000 (99.979)
2022-06-17 18:20:27 - INFO - TRAINING - Epoch: [85][100/196]	Time 0.104 (0.125)	Data 0.000 (0.017)	Loss 0.1188 (0.1014)	Prec@1 94.922 (96.546)	Prec@5 99.609 (99.977)
2022-06-17 18:20:28 - INFO - TRAINING - Epoch: [85][110/196]	Time 0.104 (0.123)	Data 0.000 (0.016)	Loss 0.0659 (0.1007)	Prec@1 98.047 (96.586)	Prec@5 100.000 (99.979)
2022-06-17 18:20:29 - INFO - TRAINING - Epoch: [85][120/196]	Time 0.114 (0.122)	Data 0.000 (0.014)	Loss 0.1149 (0.1013)	Prec@1 96.094 (96.578)	Prec@5 100.000 (99.977)
2022-06-17 18:20:30 - INFO - TRAINING - Epoch: [85][130/196]	Time 0.129 (0.121)	Data 0.000 (0.013)	Loss 0.0772 (0.1018)	Prec@1 96.875 (96.526)	Prec@5 100.000 (99.979)
2022-06-17 18:20:31 - INFO - TRAINING - Epoch: [85][140/196]	Time 0.110 (0.121)	Data 0.000 (0.012)	Loss 0.1282 (0.1024)	Prec@1 96.094 (96.537)	Prec@5 100.000 (99.981)
2022-06-17 18:20:32 - INFO - TRAINING - Epoch: [85][150/196]	Time 0.112 (0.120)	Data 0.000 (0.012)	Loss 0.0814 (0.1020)	Prec@1 96.875 (96.541)	Prec@5 100.000 (99.982)
2022-06-17 18:20:34 - INFO - TRAINING - Epoch: [85][160/196]	Time 0.122 (0.120)	Data 0.000 (0.011)	Loss 0.0928 (0.1023)	Prec@1 96.875 (96.528)	Prec@5 100.000 (99.981)
2022-06-17 18:20:35 - INFO - TRAINING - Epoch: [85][170/196]	Time 0.109 (0.119)	Data 0.000 (0.010)	Loss 0.1107 (0.1031)	Prec@1 96.484 (96.503)	Prec@5 100.000 (99.979)
2022-06-17 18:20:36 - INFO - TRAINING - Epoch: [85][180/196]	Time 0.113 (0.119)	Data 0.000 (0.010)	Loss 0.0914 (0.1025)	Prec@1 97.656 (96.510)	Prec@5 100.000 (99.981)
2022-06-17 18:20:37 - INFO - TRAINING - Epoch: [85][190/196]	Time 0.101 (0.118)	Data 0.000 (0.009)	Loss 0.1107 (0.1022)	Prec@1 96.094 (96.531)	Prec@5 99.609 (99.980)
2022-06-17 18:20:39 - INFO - EVALUATING - Epoch: [85][0/40]	Time 1.576 (1.576)	Data 1.531 (1.531)	Loss 0.2606 (0.2606)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:20:40 - INFO - EVALUATING - Epoch: [85][10/40]	Time 0.044 (0.268)	Data 0.000 (0.220)	Loss 0.4625 (0.4058)	Prec@1 88.672 (88.388)	Prec@5 99.609 (99.503)
2022-06-17 18:20:41 - INFO - EVALUATING - Epoch: [85][20/40]	Time 0.042 (0.165)	Data 0.000 (0.117)	Loss 0.3298 (0.4066)	Prec@1 87.891 (88.114)	Prec@5 100.000 (99.423)
2022-06-17 18:20:42 - INFO - EVALUATING - Epoch: [85][30/40]	Time 0.099 (0.148)	Data 0.055 (0.101)	Loss 0.4922 (0.3994)	Prec@1 86.328 (88.193)	Prec@5 100.000 (99.471)
2022-06-17 18:20:44 - INFO - 
 Epoch: 86	Training Loss 0.1026 	Training Prec@1 96.514 	Training Prec@5 99.980 	Validation Loss 0.3955 	Validation Prec@1 88.170 	Validation Prec@5 99.540 

2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:20:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:20:45 - INFO - TRAINING - Epoch: [86][0/196]	Time 1.183 (1.183)	Data 1.130 (1.130)	Loss 0.0859 (0.0859)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:20:47 - INFO - TRAINING - Epoch: [86][10/196]	Time 0.102 (0.255)	Data 0.000 (0.155)	Loss 0.0819 (0.1150)	Prec@1 96.875 (96.058)	Prec@5 100.000 (99.964)
2022-06-17 18:20:48 - INFO - TRAINING - Epoch: [86][20/196]	Time 0.136 (0.187)	Data 0.000 (0.081)	Loss 0.1325 (0.1088)	Prec@1 96.094 (96.317)	Prec@5 99.609 (99.963)
2022-06-17 18:20:49 - INFO - TRAINING - Epoch: [86][30/196]	Time 0.107 (0.163)	Data 0.000 (0.055)	Loss 0.1062 (0.1074)	Prec@1 96.875 (96.358)	Prec@5 100.000 (99.962)
2022-06-17 18:20:50 - INFO - TRAINING - Epoch: [86][40/196]	Time 0.103 (0.149)	Data 0.000 (0.042)	Loss 0.0773 (0.1033)	Prec@1 96.484 (96.446)	Prec@5 100.000 (99.971)
2022-06-17 18:20:51 - INFO - TRAINING - Epoch: [86][50/196]	Time 0.113 (0.141)	Data 0.000 (0.034)	Loss 0.1136 (0.1049)	Prec@1 96.875 (96.454)	Prec@5 100.000 (99.969)
2022-06-17 18:20:52 - INFO - TRAINING - Epoch: [86][60/196]	Time 0.104 (0.135)	Data 0.000 (0.028)	Loss 0.1117 (0.1037)	Prec@1 96.484 (96.555)	Prec@5 100.000 (99.974)
2022-06-17 18:20:53 - INFO - TRAINING - Epoch: [86][70/196]	Time 0.108 (0.132)	Data 0.000 (0.024)	Loss 0.0953 (0.1042)	Prec@1 96.484 (96.545)	Prec@5 100.000 (99.978)
2022-06-17 18:20:54 - INFO - TRAINING - Epoch: [86][80/196]	Time 0.108 (0.130)	Data 0.000 (0.021)	Loss 0.0624 (0.1032)	Prec@1 98.047 (96.547)	Prec@5 100.000 (99.971)
2022-06-17 18:20:56 - INFO - TRAINING - Epoch: [86][90/196]	Time 0.106 (0.128)	Data 0.000 (0.019)	Loss 0.0994 (0.1040)	Prec@1 96.094 (96.484)	Prec@5 100.000 (99.974)
2022-06-17 18:20:57 - INFO - TRAINING - Epoch: [86][100/196]	Time 0.114 (0.126)	Data 0.000 (0.017)	Loss 0.1331 (0.1046)	Prec@1 94.922 (96.473)	Prec@5 100.000 (99.973)
2022-06-17 18:20:58 - INFO - TRAINING - Epoch: [86][110/196]	Time 0.108 (0.125)	Data 0.000 (0.016)	Loss 0.1169 (0.1042)	Prec@1 96.094 (96.495)	Prec@5 100.000 (99.975)
2022-06-17 18:20:59 - INFO - TRAINING - Epoch: [86][120/196]	Time 0.108 (0.124)	Data 0.000 (0.014)	Loss 0.1342 (0.1047)	Prec@1 94.922 (96.468)	Prec@5 100.000 (99.974)
2022-06-17 18:21:00 - INFO - TRAINING - Epoch: [86][130/196]	Time 0.109 (0.123)	Data 0.000 (0.013)	Loss 0.1558 (0.1043)	Prec@1 94.141 (96.484)	Prec@5 100.000 (99.973)
2022-06-17 18:21:01 - INFO - TRAINING - Epoch: [86][140/196]	Time 0.115 (0.122)	Data 0.000 (0.012)	Loss 0.1145 (0.1039)	Prec@1 95.703 (96.498)	Prec@5 100.000 (99.975)
2022-06-17 18:21:02 - INFO - TRAINING - Epoch: [86][150/196]	Time 0.104 (0.121)	Data 0.000 (0.012)	Loss 0.0751 (0.1034)	Prec@1 98.438 (96.526)	Prec@5 100.000 (99.977)
2022-06-17 18:21:03 - INFO - TRAINING - Epoch: [86][160/196]	Time 0.107 (0.121)	Data 0.000 (0.011)	Loss 0.1458 (0.1044)	Prec@1 96.094 (96.480)	Prec@5 100.000 (99.978)
2022-06-17 18:21:05 - INFO - TRAINING - Epoch: [86][170/196]	Time 0.112 (0.120)	Data 0.000 (0.010)	Loss 0.0988 (0.1050)	Prec@1 96.484 (96.452)	Prec@5 100.000 (99.979)
2022-06-17 18:21:06 - INFO - TRAINING - Epoch: [86][180/196]	Time 0.118 (0.120)	Data 0.000 (0.010)	Loss 0.1340 (0.1047)	Prec@1 94.531 (96.443)	Prec@5 100.000 (99.978)
2022-06-17 18:21:07 - INFO - TRAINING - Epoch: [86][190/196]	Time 0.102 (0.119)	Data 0.000 (0.009)	Loss 0.0762 (0.1041)	Prec@1 98.438 (96.462)	Prec@5 100.000 (99.980)
2022-06-17 18:21:09 - INFO - EVALUATING - Epoch: [86][0/40]	Time 1.926 (1.926)	Data 1.881 (1.881)	Loss 0.2695 (0.2695)	Prec@1 92.578 (92.578)	Prec@5 99.609 (99.609)
2022-06-17 18:21:10 - INFO - EVALUATING - Epoch: [86][10/40]	Time 0.044 (0.262)	Data 0.000 (0.215)	Loss 0.4655 (0.4100)	Prec@1 87.891 (87.997)	Prec@5 99.609 (99.396)
2022-06-17 18:21:11 - INFO - EVALUATING - Epoch: [86][20/40]	Time 0.131 (0.165)	Data 0.089 (0.117)	Loss 0.3329 (0.4098)	Prec@1 87.500 (87.946)	Prec@5 100.000 (99.423)
2022-06-17 18:21:12 - INFO - EVALUATING - Epoch: [86][30/40]	Time 0.300 (0.153)	Data 0.256 (0.106)	Loss 0.4989 (0.4019)	Prec@1 85.938 (88.117)	Prec@5 100.000 (99.458)
2022-06-17 18:21:14 - INFO - 
 Epoch: 87	Training Loss 0.1043 	Training Prec@1 96.446 	Training Prec@5 99.980 	Validation Loss 0.3974 	Validation Prec@1 88.150 	Validation Prec@5 99.540 

2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:21:14 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:21:15 - INFO - TRAINING - Epoch: [87][0/196]	Time 1.555 (1.555)	Data 1.501 (1.501)	Loss 0.1361 (0.1361)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2022-06-17 18:21:17 - INFO - TRAINING - Epoch: [87][10/196]	Time 0.111 (0.242)	Data 0.000 (0.142)	Loss 0.1068 (0.1032)	Prec@1 96.484 (96.591)	Prec@5 100.000 (100.000)
2022-06-17 18:21:18 - INFO - TRAINING - Epoch: [87][20/196]	Time 0.104 (0.183)	Data 0.000 (0.075)	Loss 0.0965 (0.1023)	Prec@1 97.266 (96.466)	Prec@5 100.000 (99.981)
2022-06-17 18:21:19 - INFO - TRAINING - Epoch: [87][30/196]	Time 0.120 (0.160)	Data 0.000 (0.051)	Loss 0.1048 (0.1009)	Prec@1 96.094 (96.636)	Prec@5 100.000 (99.987)
2022-06-17 18:21:20 - INFO - TRAINING - Epoch: [87][40/196]	Time 0.120 (0.149)	Data 0.000 (0.038)	Loss 0.0736 (0.0986)	Prec@1 97.266 (96.618)	Prec@5 100.000 (99.981)
2022-06-17 18:21:21 - INFO - TRAINING - Epoch: [87][50/196]	Time 0.118 (0.142)	Data 0.000 (0.031)	Loss 0.1297 (0.1010)	Prec@1 95.312 (96.477)	Prec@5 100.000 (99.985)
2022-06-17 18:21:22 - INFO - TRAINING - Epoch: [87][60/196]	Time 0.103 (0.137)	Data 0.000 (0.026)	Loss 0.1187 (0.1016)	Prec@1 95.312 (96.427)	Prec@5 100.000 (99.987)
2022-06-17 18:21:23 - INFO - TRAINING - Epoch: [87][70/196]	Time 0.125 (0.134)	Data 0.000 (0.022)	Loss 0.0979 (0.1016)	Prec@1 96.484 (96.468)	Prec@5 100.000 (99.983)
2022-06-17 18:21:24 - INFO - TRAINING - Epoch: [87][80/196]	Time 0.102 (0.131)	Data 0.000 (0.020)	Loss 0.0847 (0.1006)	Prec@1 97.656 (96.489)	Prec@5 100.000 (99.981)
2022-06-17 18:21:26 - INFO - TRAINING - Epoch: [87][90/196]	Time 0.104 (0.129)	Data 0.000 (0.017)	Loss 0.1076 (0.1011)	Prec@1 95.703 (96.463)	Prec@5 100.000 (99.983)
2022-06-17 18:21:27 - INFO - TRAINING - Epoch: [87][100/196]	Time 0.108 (0.127)	Data 0.000 (0.016)	Loss 0.1349 (0.1015)	Prec@1 94.922 (96.422)	Prec@5 100.000 (99.985)
2022-06-17 18:21:28 - INFO - TRAINING - Epoch: [87][110/196]	Time 0.126 (0.126)	Data 0.000 (0.014)	Loss 0.1103 (0.1009)	Prec@1 95.312 (96.442)	Prec@5 100.000 (99.982)
2022-06-17 18:21:29 - INFO - TRAINING - Epoch: [87][120/196]	Time 0.125 (0.125)	Data 0.000 (0.013)	Loss 0.1223 (0.1010)	Prec@1 97.266 (96.491)	Prec@5 100.000 (99.984)
2022-06-17 18:21:30 - INFO - TRAINING - Epoch: [87][130/196]	Time 0.103 (0.124)	Data 0.000 (0.012)	Loss 0.0841 (0.1001)	Prec@1 98.047 (96.550)	Prec@5 100.000 (99.985)
2022-06-17 18:21:31 - INFO - TRAINING - Epoch: [87][140/196]	Time 0.112 (0.123)	Data 0.000 (0.011)	Loss 0.1065 (0.1006)	Prec@1 96.484 (96.548)	Prec@5 100.000 (99.983)
2022-06-17 18:21:32 - INFO - TRAINING - Epoch: [87][150/196]	Time 0.101 (0.122)	Data 0.000 (0.011)	Loss 0.1045 (0.1008)	Prec@1 97.266 (96.544)	Prec@5 100.000 (99.982)
2022-06-17 18:21:33 - INFO - TRAINING - Epoch: [87][160/196]	Time 0.108 (0.122)	Data 0.000 (0.010)	Loss 0.0975 (0.1006)	Prec@1 97.656 (96.555)	Prec@5 100.000 (99.978)
2022-06-17 18:21:34 - INFO - TRAINING - Epoch: [87][170/196]	Time 0.111 (0.121)	Data 0.000 (0.009)	Loss 0.1495 (0.1015)	Prec@1 94.922 (96.507)	Prec@5 99.609 (99.977)
2022-06-17 18:21:36 - INFO - TRAINING - Epoch: [87][180/196]	Time 0.117 (0.120)	Data 0.000 (0.009)	Loss 0.1040 (0.1013)	Prec@1 96.484 (96.506)	Prec@5 100.000 (99.976)
2022-06-17 18:21:37 - INFO - TRAINING - Epoch: [87][190/196]	Time 0.101 (0.120)	Data 0.000 (0.008)	Loss 0.0900 (0.1013)	Prec@1 96.875 (96.517)	Prec@5 100.000 (99.975)
2022-06-17 18:21:39 - INFO - EVALUATING - Epoch: [87][0/40]	Time 1.564 (1.564)	Data 1.518 (1.518)	Loss 0.2680 (0.2680)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:21:40 - INFO - EVALUATING - Epoch: [87][10/40]	Time 0.044 (0.230)	Data 0.000 (0.181)	Loss 0.4653 (0.4089)	Prec@1 87.891 (87.962)	Prec@5 99.219 (99.432)
2022-06-17 18:21:41 - INFO - EVALUATING - Epoch: [87][20/40]	Time 0.335 (0.167)	Data 0.291 (0.118)	Loss 0.3302 (0.4105)	Prec@1 87.500 (87.779)	Prec@5 100.000 (99.423)
2022-06-17 18:21:42 - INFO - EVALUATING - Epoch: [87][30/40]	Time 0.046 (0.143)	Data 0.000 (0.093)	Loss 0.4972 (0.4032)	Prec@1 85.938 (88.004)	Prec@5 100.000 (99.483)
2022-06-17 18:21:44 - INFO - 
 Epoch: 88	Training Loss 0.1013 	Training Prec@1 96.514 	Training Prec@5 99.976 	Validation Loss 0.3984 	Validation Prec@1 88.100 	Validation Prec@5 99.550 

2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:21:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:21:46 - INFO - TRAINING - Epoch: [88][0/196]	Time 1.860 (1.860)	Data 1.806 (1.806)	Loss 0.1082 (0.1082)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:21:47 - INFO - TRAINING - Epoch: [88][10/196]	Time 0.112 (0.273)	Data 0.000 (0.165)	Loss 0.0922 (0.1050)	Prec@1 97.266 (96.342)	Prec@5 100.000 (100.000)
2022-06-17 18:21:48 - INFO - TRAINING - Epoch: [88][20/196]	Time 0.113 (0.200)	Data 0.000 (0.086)	Loss 0.0578 (0.0992)	Prec@1 98.828 (96.633)	Prec@5 100.000 (100.000)
2022-06-17 18:21:49 - INFO - TRAINING - Epoch: [88][30/196]	Time 0.103 (0.171)	Data 0.000 (0.059)	Loss 0.1093 (0.0981)	Prec@1 95.312 (96.610)	Prec@5 100.000 (99.987)
2022-06-17 18:21:50 - INFO - TRAINING - Epoch: [88][40/196]	Time 0.110 (0.158)	Data 0.000 (0.044)	Loss 0.0769 (0.1002)	Prec@1 96.875 (96.465)	Prec@5 100.000 (99.990)
2022-06-17 18:21:51 - INFO - TRAINING - Epoch: [88][50/196]	Time 0.111 (0.150)	Data 0.000 (0.036)	Loss 0.0687 (0.0986)	Prec@1 97.266 (96.515)	Prec@5 100.000 (99.992)
2022-06-17 18:21:52 - INFO - TRAINING - Epoch: [88][60/196]	Time 0.123 (0.143)	Data 0.000 (0.030)	Loss 0.1121 (0.1005)	Prec@1 95.703 (96.472)	Prec@5 100.000 (99.987)
2022-06-17 18:21:54 - INFO - TRAINING - Epoch: [88][70/196]	Time 0.106 (0.139)	Data 0.000 (0.026)	Loss 0.0901 (0.1018)	Prec@1 97.266 (96.424)	Prec@5 100.000 (99.983)
2022-06-17 18:21:55 - INFO - TRAINING - Epoch: [88][80/196]	Time 0.109 (0.136)	Data 0.000 (0.023)	Loss 0.1618 (0.1036)	Prec@1 94.531 (96.383)	Prec@5 100.000 (99.981)
2022-06-17 18:21:56 - INFO - TRAINING - Epoch: [88][90/196]	Time 0.133 (0.134)	Data 0.000 (0.020)	Loss 0.1143 (0.1045)	Prec@1 95.703 (96.360)	Prec@5 100.000 (99.979)
2022-06-17 18:21:57 - INFO - TRAINING - Epoch: [88][100/196]	Time 0.120 (0.132)	Data 0.000 (0.018)	Loss 0.0907 (0.1058)	Prec@1 97.266 (96.314)	Prec@5 100.000 (99.973)
2022-06-17 18:21:58 - INFO - TRAINING - Epoch: [88][110/196]	Time 0.104 (0.131)	Data 0.000 (0.017)	Loss 0.0627 (0.1053)	Prec@1 97.656 (96.344)	Prec@5 100.000 (99.975)
2022-06-17 18:21:59 - INFO - TRAINING - Epoch: [88][120/196]	Time 0.101 (0.129)	Data 0.000 (0.015)	Loss 0.0856 (0.1040)	Prec@1 96.094 (96.388)	Prec@5 100.000 (99.977)
2022-06-17 18:22:00 - INFO - TRAINING - Epoch: [88][130/196]	Time 0.111 (0.128)	Data 0.000 (0.014)	Loss 0.0814 (0.1031)	Prec@1 97.656 (96.434)	Prec@5 100.000 (99.979)
2022-06-17 18:22:02 - INFO - TRAINING - Epoch: [88][140/196]	Time 0.126 (0.127)	Data 0.000 (0.013)	Loss 0.0617 (0.1028)	Prec@1 97.656 (96.448)	Prec@5 100.000 (99.978)
2022-06-17 18:22:03 - INFO - TRAINING - Epoch: [88][150/196]	Time 0.118 (0.126)	Data 0.000 (0.012)	Loss 0.0752 (0.1027)	Prec@1 96.875 (96.446)	Prec@5 100.000 (99.977)
2022-06-17 18:22:04 - INFO - TRAINING - Epoch: [88][160/196]	Time 0.120 (0.126)	Data 0.000 (0.012)	Loss 0.1151 (0.1021)	Prec@1 96.094 (96.477)	Prec@5 100.000 (99.978)
2022-06-17 18:22:05 - INFO - TRAINING - Epoch: [88][170/196]	Time 0.106 (0.125)	Data 0.000 (0.011)	Loss 0.1607 (0.1022)	Prec@1 94.141 (96.468)	Prec@5 100.000 (99.979)
2022-06-17 18:22:06 - INFO - TRAINING - Epoch: [88][180/196]	Time 0.123 (0.124)	Data 0.000 (0.010)	Loss 0.1223 (0.1020)	Prec@1 96.094 (96.482)	Prec@5 100.000 (99.981)
2022-06-17 18:22:07 - INFO - TRAINING - Epoch: [88][190/196]	Time 0.102 (0.124)	Data 0.000 (0.010)	Loss 0.0881 (0.1023)	Prec@1 96.484 (96.478)	Prec@5 100.000 (99.980)
2022-06-17 18:22:09 - INFO - EVALUATING - Epoch: [88][0/40]	Time 1.366 (1.366)	Data 1.320 (1.320)	Loss 0.2734 (0.2734)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:22:11 - INFO - EVALUATING - Epoch: [88][10/40]	Time 0.069 (0.268)	Data 0.000 (0.219)	Loss 0.4673 (0.4094)	Prec@1 87.109 (87.784)	Prec@5 99.219 (99.432)
2022-06-17 18:22:11 - INFO - EVALUATING - Epoch: [88][20/40]	Time 0.043 (0.165)	Data 0.000 (0.115)	Loss 0.3376 (0.4110)	Prec@1 87.500 (87.853)	Prec@5 100.000 (99.423)
2022-06-17 18:22:12 - INFO - EVALUATING - Epoch: [88][30/40]	Time 0.047 (0.149)	Data 0.000 (0.100)	Loss 0.5030 (0.4034)	Prec@1 86.328 (88.067)	Prec@5 100.000 (99.496)
2022-06-17 18:22:14 - INFO - 
 Epoch: 89	Training Loss 0.1024 	Training Prec@1 96.474 	Training Prec@5 99.980 	Validation Loss 0.3991 	Validation Prec@1 88.120 	Validation Prec@5 99.570 

2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:22:14 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:22:16 - INFO - TRAINING - Epoch: [89][0/196]	Time 1.438 (1.438)	Data 1.383 (1.383)	Loss 0.1280 (0.1280)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 18:22:17 - INFO - TRAINING - Epoch: [89][10/196]	Time 0.104 (0.232)	Data 0.000 (0.149)	Loss 0.0818 (0.1097)	Prec@1 97.266 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:22:18 - INFO - TRAINING - Epoch: [89][20/196]	Time 0.123 (0.176)	Data 0.000 (0.084)	Loss 0.0835 (0.1020)	Prec@1 96.875 (96.317)	Prec@5 100.000 (100.000)
2022-06-17 18:22:19 - INFO - TRAINING - Epoch: [89][30/196]	Time 0.102 (0.155)	Data 0.000 (0.057)	Loss 0.1493 (0.1056)	Prec@1 94.141 (96.132)	Prec@5 100.000 (100.000)
2022-06-17 18:22:20 - INFO - TRAINING - Epoch: [89][40/196]	Time 0.102 (0.143)	Data 0.000 (0.043)	Loss 0.0731 (0.1030)	Prec@1 98.438 (96.246)	Prec@5 100.000 (99.981)
2022-06-17 18:22:21 - INFO - TRAINING - Epoch: [89][50/196]	Time 0.108 (0.137)	Data 0.000 (0.035)	Loss 0.1264 (0.1048)	Prec@1 96.094 (96.255)	Prec@5 100.000 (99.985)
2022-06-17 18:22:22 - INFO - TRAINING - Epoch: [89][60/196]	Time 0.110 (0.132)	Data 0.000 (0.029)	Loss 0.1270 (0.1023)	Prec@1 95.312 (96.369)	Prec@5 100.000 (99.987)
2022-06-17 18:22:24 - INFO - TRAINING - Epoch: [89][70/196]	Time 0.102 (0.130)	Data 0.000 (0.025)	Loss 0.0885 (0.1037)	Prec@1 96.094 (96.352)	Prec@5 100.000 (99.983)
2022-06-17 18:22:25 - INFO - TRAINING - Epoch: [89][80/196]	Time 0.106 (0.127)	Data 0.000 (0.022)	Loss 0.1362 (0.1038)	Prec@1 95.312 (96.383)	Prec@5 100.000 (99.986)
2022-06-17 18:22:26 - INFO - TRAINING - Epoch: [89][90/196]	Time 0.106 (0.125)	Data 0.000 (0.020)	Loss 0.1260 (0.1034)	Prec@1 94.531 (96.373)	Prec@5 100.000 (99.987)
2022-06-17 18:22:27 - INFO - TRAINING - Epoch: [89][100/196]	Time 0.119 (0.124)	Data 0.000 (0.018)	Loss 0.0943 (0.1028)	Prec@1 96.875 (96.384)	Prec@5 100.000 (99.985)
2022-06-17 18:22:28 - INFO - TRAINING - Epoch: [89][110/196]	Time 0.127 (0.123)	Data 0.000 (0.016)	Loss 0.1037 (0.1019)	Prec@1 96.875 (96.453)	Prec@5 100.000 (99.982)
2022-06-17 18:22:29 - INFO - TRAINING - Epoch: [89][120/196]	Time 0.109 (0.122)	Data 0.000 (0.015)	Loss 0.1185 (0.1020)	Prec@1 95.703 (96.436)	Prec@5 100.000 (99.984)
2022-06-17 18:22:30 - INFO - TRAINING - Epoch: [89][130/196]	Time 0.102 (0.121)	Data 0.000 (0.014)	Loss 0.1337 (0.1024)	Prec@1 95.703 (96.449)	Prec@5 100.000 (99.982)
2022-06-17 18:22:31 - INFO - TRAINING - Epoch: [89][140/196]	Time 0.131 (0.121)	Data 0.000 (0.013)	Loss 0.0947 (0.1030)	Prec@1 96.875 (96.443)	Prec@5 100.000 (99.978)
2022-06-17 18:22:33 - INFO - TRAINING - Epoch: [89][150/196]	Time 0.110 (0.121)	Data 0.000 (0.012)	Loss 0.0876 (0.1023)	Prec@1 97.266 (96.456)	Prec@5 100.000 (99.979)
2022-06-17 18:22:34 - INFO - TRAINING - Epoch: [89][160/196]	Time 0.107 (0.120)	Data 0.000 (0.011)	Loss 0.0984 (0.1021)	Prec@1 96.484 (96.477)	Prec@5 100.000 (99.978)
2022-06-17 18:22:35 - INFO - TRAINING - Epoch: [89][170/196]	Time 0.118 (0.119)	Data 0.000 (0.011)	Loss 0.1371 (0.1020)	Prec@1 95.312 (96.480)	Prec@5 100.000 (99.979)
2022-06-17 18:22:36 - INFO - TRAINING - Epoch: [89][180/196]	Time 0.124 (0.119)	Data 0.000 (0.010)	Loss 0.1385 (0.1019)	Prec@1 96.484 (96.497)	Prec@5 100.000 (99.981)
2022-06-17 18:22:37 - INFO - TRAINING - Epoch: [89][190/196]	Time 0.103 (0.118)	Data 0.000 (0.010)	Loss 0.0793 (0.1020)	Prec@1 97.656 (96.493)	Prec@5 100.000 (99.982)
2022-06-17 18:22:39 - INFO - EVALUATING - Epoch: [89][0/40]	Time 1.513 (1.513)	Data 1.467 (1.467)	Loss 0.2640 (0.2640)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:22:40 - INFO - EVALUATING - Epoch: [89][10/40]	Time 0.054 (0.240)	Data 0.000 (0.193)	Loss 0.4626 (0.4029)	Prec@1 88.281 (88.246)	Prec@5 99.609 (99.503)
2022-06-17 18:22:41 - INFO - EVALUATING - Epoch: [89][20/40]	Time 0.071 (0.180)	Data 0.000 (0.131)	Loss 0.3305 (0.4064)	Prec@1 87.109 (87.872)	Prec@5 100.000 (99.461)
2022-06-17 18:22:42 - INFO - EVALUATING - Epoch: [89][30/40]	Time 0.096 (0.151)	Data 0.054 (0.104)	Loss 0.4914 (0.3991)	Prec@1 85.938 (88.067)	Prec@5 100.000 (99.496)
2022-06-17 18:22:44 - INFO - 
 Epoch: 90	Training Loss 0.1018 	Training Prec@1 96.500 	Training Prec@5 99.982 	Validation Loss 0.3943 	Validation Prec@1 88.140 	Validation Prec@5 99.570 

2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:22:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:22:46 - INFO - TRAINING - Epoch: [90][0/196]	Time 1.354 (1.354)	Data 1.301 (1.301)	Loss 0.1033 (0.1033)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:22:47 - INFO - TRAINING - Epoch: [90][10/196]	Time 0.105 (0.272)	Data 0.000 (0.174)	Loss 0.0988 (0.0943)	Prec@1 96.094 (96.946)	Prec@5 100.000 (99.964)
2022-06-17 18:22:48 - INFO - TRAINING - Epoch: [90][20/196]	Time 0.127 (0.195)	Data 0.000 (0.091)	Loss 0.1165 (0.1002)	Prec@1 96.875 (96.522)	Prec@5 99.609 (99.963)
2022-06-17 18:22:50 - INFO - TRAINING - Epoch: [90][30/196]	Time 0.105 (0.168)	Data 0.000 (0.062)	Loss 0.1099 (0.0987)	Prec@1 96.484 (96.686)	Prec@5 100.000 (99.975)
2022-06-17 18:22:51 - INFO - TRAINING - Epoch: [90][40/196]	Time 0.111 (0.154)	Data 0.000 (0.047)	Loss 0.1184 (0.0996)	Prec@1 94.922 (96.589)	Prec@5 100.000 (99.971)
2022-06-17 18:22:52 - INFO - TRAINING - Epoch: [90][50/196]	Time 0.109 (0.146)	Data 0.000 (0.038)	Loss 0.0956 (0.0971)	Prec@1 96.875 (96.699)	Prec@5 100.000 (99.977)
2022-06-17 18:22:53 - INFO - TRAINING - Epoch: [90][60/196]	Time 0.102 (0.140)	Data 0.000 (0.032)	Loss 0.1335 (0.0993)	Prec@1 96.094 (96.657)	Prec@5 100.000 (99.974)
2022-06-17 18:22:54 - INFO - TRAINING - Epoch: [90][70/196]	Time 0.102 (0.135)	Data 0.000 (0.027)	Loss 0.1045 (0.0990)	Prec@1 95.703 (96.644)	Prec@5 100.000 (99.978)
2022-06-17 18:22:55 - INFO - TRAINING - Epoch: [90][80/196]	Time 0.113 (0.133)	Data 0.000 (0.024)	Loss 0.1022 (0.0977)	Prec@1 97.656 (96.677)	Prec@5 100.000 (99.981)
2022-06-17 18:22:56 - INFO - TRAINING - Epoch: [90][90/196]	Time 0.108 (0.131)	Data 0.000 (0.021)	Loss 0.1420 (0.0976)	Prec@1 94.141 (96.682)	Prec@5 100.000 (99.974)
2022-06-17 18:22:57 - INFO - TRAINING - Epoch: [90][100/196]	Time 0.108 (0.129)	Data 0.000 (0.019)	Loss 0.1268 (0.0977)	Prec@1 95.312 (96.693)	Prec@5 100.000 (99.977)
2022-06-17 18:22:59 - INFO - TRAINING - Epoch: [90][110/196]	Time 0.141 (0.128)	Data 0.000 (0.018)	Loss 0.0780 (0.0982)	Prec@1 97.266 (96.678)	Prec@5 100.000 (99.979)
2022-06-17 18:23:00 - INFO - TRAINING - Epoch: [90][120/196]	Time 0.103 (0.127)	Data 0.000 (0.016)	Loss 0.1509 (0.0988)	Prec@1 94.922 (96.681)	Prec@5 100.000 (99.977)
2022-06-17 18:23:01 - INFO - TRAINING - Epoch: [90][130/196]	Time 0.103 (0.126)	Data 0.000 (0.015)	Loss 0.0587 (0.0990)	Prec@1 98.828 (96.666)	Prec@5 100.000 (99.979)
2022-06-17 18:23:02 - INFO - TRAINING - Epoch: [90][140/196]	Time 0.111 (0.125)	Data 0.000 (0.014)	Loss 0.1273 (0.0993)	Prec@1 96.094 (96.676)	Prec@5 99.609 (99.978)
2022-06-17 18:23:03 - INFO - TRAINING - Epoch: [90][150/196]	Time 0.107 (0.125)	Data 0.000 (0.013)	Loss 0.1304 (0.0992)	Prec@1 95.703 (96.663)	Prec@5 100.000 (99.979)
2022-06-17 18:23:04 - INFO - TRAINING - Epoch: [90][160/196]	Time 0.104 (0.124)	Data 0.000 (0.012)	Loss 0.1710 (0.1002)	Prec@1 93.750 (96.618)	Prec@5 100.000 (99.981)
2022-06-17 18:23:05 - INFO - TRAINING - Epoch: [90][170/196]	Time 0.103 (0.123)	Data 0.000 (0.011)	Loss 0.0750 (0.0997)	Prec@1 96.094 (96.631)	Prec@5 100.000 (99.975)
2022-06-17 18:23:07 - INFO - TRAINING - Epoch: [90][180/196]	Time 0.104 (0.123)	Data 0.000 (0.011)	Loss 0.0959 (0.1000)	Prec@1 96.484 (96.622)	Prec@5 100.000 (99.976)
2022-06-17 18:23:08 - INFO - TRAINING - Epoch: [90][190/196]	Time 0.101 (0.122)	Data 0.000 (0.010)	Loss 0.0809 (0.1001)	Prec@1 98.047 (96.638)	Prec@5 100.000 (99.978)
2022-06-17 18:23:10 - INFO - EVALUATING - Epoch: [90][0/40]	Time 1.818 (1.818)	Data 1.770 (1.770)	Loss 0.2668 (0.2668)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:23:11 - INFO - EVALUATING - Epoch: [90][10/40]	Time 0.067 (0.234)	Data 0.000 (0.186)	Loss 0.4736 (0.4126)	Prec@1 88.672 (88.210)	Prec@5 99.219 (99.467)
2022-06-17 18:23:12 - INFO - EVALUATING - Epoch: [90][20/40]	Time 0.107 (0.165)	Data 0.063 (0.119)	Loss 0.3367 (0.4149)	Prec@1 87.109 (87.816)	Prec@5 100.000 (99.442)
2022-06-17 18:23:13 - INFO - EVALUATING - Epoch: [90][30/40]	Time 0.177 (0.149)	Data 0.133 (0.104)	Loss 0.5057 (0.4067)	Prec@1 85.156 (88.017)	Prec@5 100.000 (99.483)
2022-06-17 18:23:15 - INFO - 
 Epoch: 91	Training Loss 0.1001 	Training Prec@1 96.652 	Training Prec@5 99.978 	Validation Loss 0.4022 	Validation Prec@1 88.100 	Validation Prec@5 99.550 

2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:23:15 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:23:16 - INFO - TRAINING - Epoch: [91][0/196]	Time 1.299 (1.299)	Data 1.246 (1.246)	Loss 0.0774 (0.0774)	Prec@1 98.047 (98.047)	Prec@5 99.609 (99.609)
2022-06-17 18:23:18 - INFO - TRAINING - Epoch: [91][10/196]	Time 0.105 (0.268)	Data 0.000 (0.196)	Loss 0.0786 (0.0893)	Prec@1 97.656 (96.946)	Prec@5 100.000 (99.964)
2022-06-17 18:23:19 - INFO - TRAINING - Epoch: [91][20/196]	Time 0.106 (0.193)	Data 0.000 (0.103)	Loss 0.0861 (0.0905)	Prec@1 96.484 (96.912)	Prec@5 100.000 (99.981)
2022-06-17 18:23:20 - INFO - TRAINING - Epoch: [91][30/196]	Time 0.101 (0.166)	Data 0.000 (0.070)	Loss 0.0983 (0.0901)	Prec@1 96.875 (96.900)	Prec@5 100.000 (99.987)
2022-06-17 18:23:21 - INFO - TRAINING - Epoch: [91][40/196]	Time 0.116 (0.153)	Data 0.000 (0.053)	Loss 0.1642 (0.0922)	Prec@1 95.312 (96.923)	Prec@5 100.000 (99.990)
2022-06-17 18:23:22 - INFO - TRAINING - Epoch: [91][50/196]	Time 0.113 (0.145)	Data 0.000 (0.042)	Loss 0.0850 (0.0945)	Prec@1 96.875 (96.768)	Prec@5 100.000 (99.992)
2022-06-17 18:23:23 - INFO - TRAINING - Epoch: [91][60/196]	Time 0.116 (0.140)	Data 0.000 (0.036)	Loss 0.0626 (0.0945)	Prec@1 98.047 (96.760)	Prec@5 100.000 (99.994)
2022-06-17 18:23:24 - INFO - TRAINING - Epoch: [91][70/196]	Time 0.125 (0.136)	Data 0.000 (0.031)	Loss 0.1239 (0.0956)	Prec@1 95.703 (96.732)	Prec@5 100.000 (99.994)
2022-06-17 18:23:25 - INFO - TRAINING - Epoch: [91][80/196]	Time 0.139 (0.134)	Data 0.000 (0.027)	Loss 0.1334 (0.0975)	Prec@1 95.312 (96.639)	Prec@5 100.000 (99.990)
2022-06-17 18:23:27 - INFO - TRAINING - Epoch: [91][90/196]	Time 0.121 (0.132)	Data 0.000 (0.024)	Loss 0.1550 (0.0988)	Prec@1 95.703 (96.557)	Prec@5 100.000 (99.991)
2022-06-17 18:23:28 - INFO - TRAINING - Epoch: [91][100/196]	Time 0.103 (0.130)	Data 0.000 (0.022)	Loss 0.1337 (0.0984)	Prec@1 95.703 (96.600)	Prec@5 100.000 (99.992)
2022-06-17 18:23:29 - INFO - TRAINING - Epoch: [91][110/196]	Time 0.102 (0.128)	Data 0.000 (0.020)	Loss 0.0857 (0.0981)	Prec@1 97.656 (96.590)	Prec@5 100.000 (99.993)
2022-06-17 18:23:30 - INFO - TRAINING - Epoch: [91][120/196]	Time 0.122 (0.127)	Data 0.000 (0.018)	Loss 0.1280 (0.0984)	Prec@1 96.484 (96.578)	Prec@5 100.000 (99.990)
2022-06-17 18:23:31 - INFO - TRAINING - Epoch: [91][130/196]	Time 0.108 (0.125)	Data 0.000 (0.017)	Loss 0.1123 (0.0992)	Prec@1 95.703 (96.559)	Prec@5 100.000 (99.991)
2022-06-17 18:23:32 - INFO - TRAINING - Epoch: [91][140/196]	Time 0.107 (0.125)	Data 0.000 (0.016)	Loss 0.0964 (0.0988)	Prec@1 96.875 (96.565)	Prec@5 100.000 (99.992)
2022-06-17 18:23:33 - INFO - TRAINING - Epoch: [91][150/196]	Time 0.116 (0.124)	Data 0.000 (0.015)	Loss 0.0776 (0.0982)	Prec@1 97.266 (96.596)	Prec@5 100.000 (99.992)
2022-06-17 18:23:34 - INFO - TRAINING - Epoch: [91][160/196]	Time 0.112 (0.123)	Data 0.000 (0.014)	Loss 0.1049 (0.0981)	Prec@1 96.875 (96.613)	Prec@5 100.000 (99.993)
2022-06-17 18:23:36 - INFO - TRAINING - Epoch: [91][170/196]	Time 0.122 (0.123)	Data 0.000 (0.013)	Loss 0.1364 (0.0983)	Prec@1 94.922 (96.612)	Prec@5 100.000 (99.993)
2022-06-17 18:23:37 - INFO - TRAINING - Epoch: [91][180/196]	Time 0.103 (0.122)	Data 0.000 (0.012)	Loss 0.0657 (0.0986)	Prec@1 98.047 (96.607)	Prec@5 100.000 (99.991)
2022-06-17 18:23:38 - INFO - TRAINING - Epoch: [91][190/196]	Time 0.103 (0.121)	Data 0.000 (0.012)	Loss 0.0904 (0.0989)	Prec@1 96.484 (96.599)	Prec@5 100.000 (99.992)
2022-06-17 18:23:40 - INFO - EVALUATING - Epoch: [91][0/40]	Time 1.837 (1.837)	Data 1.787 (1.787)	Loss 0.2665 (0.2665)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:23:41 - INFO - EVALUATING - Epoch: [91][10/40]	Time 0.044 (0.255)	Data 0.000 (0.205)	Loss 0.4683 (0.4088)	Prec@1 87.500 (88.246)	Prec@5 99.219 (99.396)
2022-06-17 18:23:42 - INFO - EVALUATING - Epoch: [91][20/40]	Time 0.044 (0.173)	Data 0.001 (0.122)	Loss 0.3317 (0.4106)	Prec@1 88.281 (87.891)	Prec@5 100.000 (99.442)
2022-06-17 18:23:43 - INFO - EVALUATING - Epoch: [91][30/40]	Time 0.091 (0.149)	Data 0.049 (0.100)	Loss 0.5017 (0.4029)	Prec@1 85.938 (88.080)	Prec@5 100.000 (99.458)
2022-06-17 18:23:45 - INFO - 
 Epoch: 92	Training Loss 0.0993 	Training Prec@1 96.580 	Training Prec@5 99.992 	Validation Loss 0.3982 	Validation Prec@1 88.090 	Validation Prec@5 99.540 

2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:23:45 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:23:47 - INFO - TRAINING - Epoch: [92][0/196]	Time 1.928 (1.928)	Data 1.875 (1.875)	Loss 0.0936 (0.0936)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:23:48 - INFO - TRAINING - Epoch: [92][10/196]	Time 0.122 (0.276)	Data 0.000 (0.171)	Loss 0.1107 (0.0996)	Prec@1 96.484 (96.733)	Prec@5 100.000 (100.000)
2022-06-17 18:23:49 - INFO - TRAINING - Epoch: [92][20/196]	Time 0.105 (0.195)	Data 0.000 (0.090)	Loss 0.0995 (0.1063)	Prec@1 95.703 (96.336)	Prec@5 100.000 (99.963)
2022-06-17 18:23:50 - INFO - TRAINING - Epoch: [92][30/196]	Time 0.109 (0.168)	Data 0.000 (0.061)	Loss 0.0999 (0.1015)	Prec@1 96.484 (96.447)	Prec@5 100.000 (99.962)
2022-06-17 18:23:51 - INFO - TRAINING - Epoch: [92][40/196]	Time 0.109 (0.155)	Data 0.000 (0.046)	Loss 0.1318 (0.1027)	Prec@1 95.312 (96.380)	Prec@5 100.000 (99.971)
2022-06-17 18:23:52 - INFO - TRAINING - Epoch: [92][50/196]	Time 0.114 (0.147)	Data 0.000 (0.037)	Loss 0.0894 (0.1036)	Prec@1 97.266 (96.385)	Prec@5 100.000 (99.977)
2022-06-17 18:23:53 - INFO - TRAINING - Epoch: [92][60/196]	Time 0.125 (0.142)	Data 0.000 (0.031)	Loss 0.0963 (0.1013)	Prec@1 97.266 (96.504)	Prec@5 100.000 (99.981)
2022-06-17 18:23:55 - INFO - TRAINING - Epoch: [92][70/196]	Time 0.111 (0.137)	Data 0.000 (0.027)	Loss 0.0918 (0.1023)	Prec@1 97.266 (96.473)	Prec@5 100.000 (99.983)
2022-06-17 18:23:56 - INFO - TRAINING - Epoch: [92][80/196]	Time 0.108 (0.134)	Data 0.000 (0.023)	Loss 0.1108 (0.1021)	Prec@1 95.703 (96.484)	Prec@5 100.000 (99.986)
2022-06-17 18:23:57 - INFO - TRAINING - Epoch: [92][90/196]	Time 0.117 (0.132)	Data 0.000 (0.021)	Loss 0.1048 (0.1031)	Prec@1 95.312 (96.463)	Prec@5 100.000 (99.983)
2022-06-17 18:23:58 - INFO - TRAINING - Epoch: [92][100/196]	Time 0.110 (0.129)	Data 0.000 (0.019)	Loss 0.1264 (0.1029)	Prec@1 95.703 (96.477)	Prec@5 100.000 (99.985)
2022-06-17 18:23:59 - INFO - TRAINING - Epoch: [92][110/196]	Time 0.108 (0.127)	Data 0.000 (0.017)	Loss 0.1238 (0.1036)	Prec@1 96.094 (96.474)	Prec@5 100.000 (99.975)
2022-06-17 18:24:00 - INFO - TRAINING - Epoch: [92][120/196]	Time 0.120 (0.126)	Data 0.000 (0.016)	Loss 0.1193 (0.1028)	Prec@1 95.312 (96.484)	Prec@5 100.000 (99.974)
2022-06-17 18:24:01 - INFO - TRAINING - Epoch: [92][130/196]	Time 0.114 (0.124)	Data 0.000 (0.015)	Loss 0.0867 (0.1027)	Prec@1 96.875 (96.493)	Prec@5 100.000 (99.976)
2022-06-17 18:24:02 - INFO - TRAINING - Epoch: [92][140/196]	Time 0.122 (0.123)	Data 0.000 (0.014)	Loss 0.1070 (0.1030)	Prec@1 96.484 (96.493)	Prec@5 100.000 (99.975)
2022-06-17 18:24:03 - INFO - TRAINING - Epoch: [92][150/196]	Time 0.111 (0.123)	Data 0.000 (0.013)	Loss 0.0706 (0.1025)	Prec@1 98.438 (96.500)	Prec@5 100.000 (99.977)
2022-06-17 18:24:04 - INFO - TRAINING - Epoch: [92][160/196]	Time 0.108 (0.122)	Data 0.000 (0.012)	Loss 0.0941 (0.1025)	Prec@1 96.484 (96.480)	Prec@5 100.000 (99.976)
2022-06-17 18:24:06 - INFO - TRAINING - Epoch: [92][170/196]	Time 0.109 (0.121)	Data 0.000 (0.011)	Loss 0.0574 (0.1016)	Prec@1 98.047 (96.507)	Prec@5 100.000 (99.975)
2022-06-17 18:24:07 - INFO - TRAINING - Epoch: [92][180/196]	Time 0.116 (0.120)	Data 0.000 (0.011)	Loss 0.0951 (0.1011)	Prec@1 95.703 (96.519)	Prec@5 99.609 (99.972)
2022-06-17 18:24:08 - INFO - TRAINING - Epoch: [92][190/196]	Time 0.108 (0.120)	Data 0.000 (0.010)	Loss 0.0867 (0.1014)	Prec@1 96.484 (96.517)	Prec@5 100.000 (99.971)
2022-06-17 18:24:10 - INFO - EVALUATING - Epoch: [92][0/40]	Time 2.068 (2.068)	Data 2.022 (2.022)	Loss 0.2766 (0.2766)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
2022-06-17 18:24:11 - INFO - EVALUATING - Epoch: [92][10/40]	Time 0.044 (0.237)	Data 0.000 (0.185)	Loss 0.4656 (0.4099)	Prec@1 87.891 (87.962)	Prec@5 99.219 (99.432)
2022-06-17 18:24:12 - INFO - EVALUATING - Epoch: [92][20/40]	Time 0.065 (0.168)	Data 0.000 (0.116)	Loss 0.3269 (0.4101)	Prec@1 87.891 (87.891)	Prec@5 100.000 (99.461)
2022-06-17 18:24:13 - INFO - EVALUATING - Epoch: [92][30/40]	Time 0.065 (0.154)	Data 0.000 (0.103)	Loss 0.4925 (0.4014)	Prec@1 86.328 (88.029)	Prec@5 100.000 (99.509)
2022-06-17 18:24:15 - INFO - 
 Epoch: 93	Training Loss 0.1018 	Training Prec@1 96.492 	Training Prec@5 99.972 	Validation Loss 0.3970 	Validation Prec@1 88.070 	Validation Prec@5 99.580 

2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:24:15 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:24:17 - INFO - TRAINING - Epoch: [93][0/196]	Time 1.668 (1.668)	Data 1.613 (1.613)	Loss 0.0933 (0.0933)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:24:18 - INFO - TRAINING - Epoch: [93][10/196]	Time 0.110 (0.279)	Data 0.000 (0.179)	Loss 0.0478 (0.0902)	Prec@1 98.828 (96.839)	Prec@5 100.000 (99.964)
2022-06-17 18:24:19 - INFO - TRAINING - Epoch: [93][20/196]	Time 0.109 (0.200)	Data 0.000 (0.094)	Loss 0.0752 (0.1003)	Prec@1 97.656 (96.447)	Prec@5 100.000 (99.944)
2022-06-17 18:24:20 - INFO - TRAINING - Epoch: [93][30/196]	Time 0.117 (0.172)	Data 0.000 (0.064)	Loss 0.0937 (0.1008)	Prec@1 96.484 (96.333)	Prec@5 100.000 (99.950)
2022-06-17 18:24:21 - INFO - TRAINING - Epoch: [93][40/196]	Time 0.108 (0.157)	Data 0.000 (0.048)	Loss 0.0803 (0.1011)	Prec@1 97.656 (96.427)	Prec@5 100.000 (99.962)
2022-06-17 18:24:23 - INFO - TRAINING - Epoch: [93][50/196]	Time 0.107 (0.148)	Data 0.000 (0.039)	Loss 0.0400 (0.0963)	Prec@1 98.828 (96.592)	Prec@5 100.000 (99.969)
2022-06-17 18:24:24 - INFO - TRAINING - Epoch: [93][60/196]	Time 0.111 (0.143)	Data 0.000 (0.032)	Loss 0.0655 (0.0951)	Prec@1 97.656 (96.676)	Prec@5 100.000 (99.974)
2022-06-17 18:24:25 - INFO - TRAINING - Epoch: [93][70/196]	Time 0.102 (0.139)	Data 0.000 (0.028)	Loss 0.1248 (0.0952)	Prec@1 96.094 (96.710)	Prec@5 100.000 (99.967)
2022-06-17 18:24:26 - INFO - TRAINING - Epoch: [93][80/196]	Time 0.116 (0.135)	Data 0.000 (0.025)	Loss 0.0745 (0.0969)	Prec@1 98.047 (96.634)	Prec@5 100.000 (99.971)
2022-06-17 18:24:27 - INFO - TRAINING - Epoch: [93][90/196]	Time 0.110 (0.133)	Data 0.000 (0.022)	Loss 0.0997 (0.0969)	Prec@1 96.094 (96.617)	Prec@5 100.000 (99.974)
2022-06-17 18:24:28 - INFO - TRAINING - Epoch: [93][100/196]	Time 0.107 (0.131)	Data 0.000 (0.020)	Loss 0.0911 (0.0969)	Prec@1 97.266 (96.643)	Prec@5 100.000 (99.977)
2022-06-17 18:24:29 - INFO - TRAINING - Epoch: [93][110/196]	Time 0.128 (0.129)	Data 0.000 (0.018)	Loss 0.1194 (0.0976)	Prec@1 96.484 (96.650)	Prec@5 100.000 (99.979)
2022-06-17 18:24:30 - INFO - TRAINING - Epoch: [93][120/196]	Time 0.110 (0.128)	Data 0.000 (0.017)	Loss 0.0781 (0.0984)	Prec@1 96.875 (96.614)	Prec@5 100.000 (99.981)
2022-06-17 18:24:32 - INFO - TRAINING - Epoch: [93][130/196]	Time 0.115 (0.126)	Data 0.000 (0.015)	Loss 0.1227 (0.0988)	Prec@1 95.703 (96.604)	Prec@5 100.000 (99.982)
2022-06-17 18:24:33 - INFO - TRAINING - Epoch: [93][140/196]	Time 0.118 (0.125)	Data 0.000 (0.014)	Loss 0.1032 (0.0992)	Prec@1 96.094 (96.581)	Prec@5 100.000 (99.983)
2022-06-17 18:24:34 - INFO - TRAINING - Epoch: [93][150/196]	Time 0.121 (0.125)	Data 0.000 (0.013)	Loss 0.1185 (0.1000)	Prec@1 95.312 (96.559)	Prec@5 100.000 (99.984)
2022-06-17 18:24:35 - INFO - TRAINING - Epoch: [93][160/196]	Time 0.111 (0.124)	Data 0.000 (0.012)	Loss 0.0900 (0.0994)	Prec@1 98.047 (96.596)	Prec@5 100.000 (99.983)
2022-06-17 18:24:36 - INFO - TRAINING - Epoch: [93][170/196]	Time 0.130 (0.123)	Data 0.000 (0.012)	Loss 0.1176 (0.0995)	Prec@1 96.484 (96.587)	Prec@5 100.000 (99.982)
2022-06-17 18:24:37 - INFO - TRAINING - Epoch: [93][180/196]	Time 0.110 (0.123)	Data 0.000 (0.011)	Loss 0.1452 (0.1006)	Prec@1 95.312 (96.540)	Prec@5 100.000 (99.983)
2022-06-17 18:24:38 - INFO - TRAINING - Epoch: [93][190/196]	Time 0.103 (0.122)	Data 0.000 (0.011)	Loss 0.0645 (0.0997)	Prec@1 97.656 (96.578)	Prec@5 100.000 (99.984)
2022-06-17 18:24:41 - INFO - EVALUATING - Epoch: [93][0/40]	Time 1.897 (1.897)	Data 1.852 (1.852)	Loss 0.2640 (0.2640)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:24:42 - INFO - EVALUATING - Epoch: [93][10/40]	Time 0.044 (0.275)	Data 0.001 (0.225)	Loss 0.4625 (0.4085)	Prec@1 88.281 (88.175)	Prec@5 99.609 (99.467)
2022-06-17 18:24:43 - INFO - EVALUATING - Epoch: [93][20/40]	Time 0.072 (0.171)	Data 0.000 (0.120)	Loss 0.3287 (0.4098)	Prec@1 86.719 (87.705)	Prec@5 100.000 (99.442)
2022-06-17 18:24:44 - INFO - EVALUATING - Epoch: [93][30/40]	Time 0.087 (0.150)	Data 0.047 (0.101)	Loss 0.5019 (0.4018)	Prec@1 85.156 (87.954)	Prec@5 100.000 (99.471)
2022-06-17 18:24:45 - INFO - 
 Epoch: 94	Training Loss 0.0999 	Training Prec@1 96.564 	Training Prec@5 99.984 	Validation Loss 0.3969 	Validation Prec@1 88.040 	Validation Prec@5 99.540 

2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:24:45 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:24:47 - INFO - TRAINING - Epoch: [94][0/196]	Time 1.318 (1.318)	Data 1.265 (1.265)	Loss 0.1008 (0.1008)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:24:48 - INFO - TRAINING - Epoch: [94][10/196]	Time 0.111 (0.268)	Data 0.000 (0.181)	Loss 0.1269 (0.1039)	Prec@1 96.094 (95.987)	Prec@5 100.000 (99.964)
2022-06-17 18:24:50 - INFO - TRAINING - Epoch: [94][20/196]	Time 0.110 (0.197)	Data 0.000 (0.095)	Loss 0.0574 (0.0905)	Prec@1 98.828 (96.745)	Prec@5 100.000 (99.981)
2022-06-17 18:24:51 - INFO - TRAINING - Epoch: [94][30/196]	Time 0.119 (0.171)	Data 0.000 (0.064)	Loss 0.1160 (0.0940)	Prec@1 96.094 (96.850)	Prec@5 100.000 (99.987)
2022-06-17 18:24:52 - INFO - TRAINING - Epoch: [94][40/196]	Time 0.130 (0.157)	Data 0.000 (0.049)	Loss 0.0650 (0.0975)	Prec@1 98.828 (96.770)	Prec@5 100.000 (99.971)
2022-06-17 18:24:53 - INFO - TRAINING - Epoch: [94][50/196]	Time 0.107 (0.149)	Data 0.000 (0.039)	Loss 0.1139 (0.0983)	Prec@1 95.703 (96.714)	Prec@5 100.000 (99.969)
2022-06-17 18:24:54 - INFO - TRAINING - Epoch: [94][60/196]	Time 0.108 (0.143)	Data 0.000 (0.033)	Loss 0.0875 (0.0958)	Prec@1 96.875 (96.798)	Prec@5 100.000 (99.968)
2022-06-17 18:24:55 - INFO - TRAINING - Epoch: [94][70/196]	Time 0.115 (0.138)	Data 0.000 (0.028)	Loss 0.0520 (0.0970)	Prec@1 98.828 (96.737)	Prec@5 100.000 (99.961)
2022-06-17 18:24:56 - INFO - TRAINING - Epoch: [94][80/196]	Time 0.105 (0.135)	Data 0.000 (0.025)	Loss 0.1161 (0.0976)	Prec@1 97.656 (96.687)	Prec@5 100.000 (99.961)
2022-06-17 18:24:57 - INFO - TRAINING - Epoch: [94][90/196]	Time 0.102 (0.132)	Data 0.000 (0.022)	Loss 0.1180 (0.0984)	Prec@1 98.438 (96.678)	Prec@5 100.000 (99.966)
2022-06-17 18:24:59 - INFO - TRAINING - Epoch: [94][100/196]	Time 0.112 (0.130)	Data 0.000 (0.020)	Loss 0.0966 (0.0990)	Prec@1 96.484 (96.631)	Prec@5 100.000 (99.969)
2022-06-17 18:25:00 - INFO - TRAINING - Epoch: [94][110/196]	Time 0.113 (0.129)	Data 0.000 (0.018)	Loss 0.1097 (0.0984)	Prec@1 97.266 (96.681)	Prec@5 100.000 (99.972)
2022-06-17 18:25:01 - INFO - TRAINING - Epoch: [94][120/196]	Time 0.102 (0.127)	Data 0.000 (0.017)	Loss 0.1160 (0.0979)	Prec@1 95.703 (96.668)	Prec@5 100.000 (99.971)
2022-06-17 18:25:02 - INFO - TRAINING - Epoch: [94][130/196]	Time 0.101 (0.126)	Data 0.000 (0.015)	Loss 0.1052 (0.0979)	Prec@1 95.703 (96.687)	Prec@5 100.000 (99.970)
2022-06-17 18:25:03 - INFO - TRAINING - Epoch: [94][140/196]	Time 0.119 (0.125)	Data 0.000 (0.014)	Loss 0.1235 (0.0977)	Prec@1 95.312 (96.684)	Prec@5 100.000 (99.972)
2022-06-17 18:25:04 - INFO - TRAINING - Epoch: [94][150/196]	Time 0.109 (0.124)	Data 0.000 (0.013)	Loss 0.1071 (0.0979)	Prec@1 96.094 (96.658)	Prec@5 100.000 (99.972)
2022-06-17 18:25:05 - INFO - TRAINING - Epoch: [94][160/196]	Time 0.110 (0.124)	Data 0.000 (0.013)	Loss 0.1041 (0.0984)	Prec@1 96.875 (96.637)	Prec@5 100.000 (99.973)
2022-06-17 18:25:06 - INFO - TRAINING - Epoch: [94][170/196]	Time 0.102 (0.123)	Data 0.000 (0.012)	Loss 0.1326 (0.0986)	Prec@1 94.531 (96.621)	Prec@5 100.000 (99.973)
2022-06-17 18:25:08 - INFO - TRAINING - Epoch: [94][180/196]	Time 0.121 (0.122)	Data 0.000 (0.011)	Loss 0.0513 (0.0987)	Prec@1 99.219 (96.603)	Prec@5 100.000 (99.972)
2022-06-17 18:25:09 - INFO - TRAINING - Epoch: [94][190/196]	Time 0.104 (0.122)	Data 0.000 (0.011)	Loss 0.1133 (0.0990)	Prec@1 96.094 (96.601)	Prec@5 100.000 (99.973)
2022-06-17 18:25:11 - INFO - EVALUATING - Epoch: [94][0/40]	Time 1.860 (1.860)	Data 1.814 (1.814)	Loss 0.2640 (0.2640)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:25:12 - INFO - EVALUATING - Epoch: [94][10/40]	Time 0.047 (0.254)	Data 0.003 (0.204)	Loss 0.4732 (0.4116)	Prec@1 87.891 (88.139)	Prec@5 99.219 (99.361)
2022-06-17 18:25:13 - INFO - EVALUATING - Epoch: [94][20/40]	Time 0.041 (0.171)	Data 0.000 (0.122)	Loss 0.3252 (0.4126)	Prec@1 87.500 (87.872)	Prec@5 100.000 (99.386)
2022-06-17 18:25:14 - INFO - EVALUATING - Epoch: [94][30/40]	Time 0.061 (0.150)	Data 0.000 (0.102)	Loss 0.5120 (0.4040)	Prec@1 85.938 (88.155)	Prec@5 100.000 (99.458)
2022-06-17 18:25:16 - INFO - 
 Epoch: 95	Training Loss 0.0990 	Training Prec@1 96.600 	Training Prec@5 99.974 	Validation Loss 0.3990 	Validation Prec@1 88.180 	Validation Prec@5 99.540 

2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:25:16 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:25:17 - INFO - TRAINING - Epoch: [95][0/196]	Time 1.449 (1.449)	Data 1.395 (1.395)	Loss 0.0657 (0.0657)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:25:19 - INFO - TRAINING - Epoch: [95][10/196]	Time 0.124 (0.259)	Data 0.000 (0.161)	Loss 0.1355 (0.0929)	Prec@1 95.312 (97.088)	Prec@5 100.000 (99.964)
2022-06-17 18:25:20 - INFO - TRAINING - Epoch: [95][20/196]	Time 0.111 (0.192)	Data 0.000 (0.085)	Loss 0.1162 (0.0919)	Prec@1 96.484 (97.024)	Prec@5 100.000 (99.981)
2022-06-17 18:25:21 - INFO - TRAINING - Epoch: [95][30/196]	Time 0.106 (0.167)	Data 0.000 (0.057)	Loss 0.1081 (0.0998)	Prec@1 96.094 (96.673)	Prec@5 100.000 (99.987)
2022-06-17 18:25:22 - INFO - TRAINING - Epoch: [95][40/196]	Time 0.114 (0.153)	Data 0.000 (0.043)	Loss 0.1158 (0.0983)	Prec@1 96.094 (96.751)	Prec@5 100.000 (99.990)
2022-06-17 18:25:23 - INFO - TRAINING - Epoch: [95][50/196]	Time 0.106 (0.145)	Data 0.000 (0.035)	Loss 0.1092 (0.0962)	Prec@1 94.922 (96.722)	Prec@5 100.000 (99.992)
2022-06-17 18:25:24 - INFO - TRAINING - Epoch: [95][60/196]	Time 0.118 (0.139)	Data 0.000 (0.029)	Loss 0.0881 (0.0970)	Prec@1 97.656 (96.664)	Prec@5 100.000 (99.987)
2022-06-17 18:25:25 - INFO - TRAINING - Epoch: [95][70/196]	Time 0.126 (0.135)	Data 0.000 (0.025)	Loss 0.0922 (0.0971)	Prec@1 96.875 (96.644)	Prec@5 100.000 (99.989)
2022-06-17 18:25:27 - INFO - TRAINING - Epoch: [95][80/196]	Time 0.106 (0.133)	Data 0.000 (0.022)	Loss 0.0844 (0.0973)	Prec@1 96.484 (96.624)	Prec@5 100.000 (99.990)
2022-06-17 18:25:28 - INFO - TRAINING - Epoch: [95][90/196]	Time 0.120 (0.130)	Data 0.000 (0.020)	Loss 0.1245 (0.0998)	Prec@1 94.922 (96.510)	Prec@5 100.000 (99.991)
2022-06-17 18:25:29 - INFO - TRAINING - Epoch: [95][100/196]	Time 0.116 (0.129)	Data 0.000 (0.018)	Loss 0.1090 (0.1007)	Prec@1 96.875 (96.477)	Prec@5 100.000 (99.988)
2022-06-17 18:25:30 - INFO - TRAINING - Epoch: [95][110/196]	Time 0.116 (0.127)	Data 0.000 (0.016)	Loss 0.0933 (0.1019)	Prec@1 96.875 (96.425)	Prec@5 100.000 (99.986)
2022-06-17 18:25:31 - INFO - TRAINING - Epoch: [95][120/196]	Time 0.106 (0.125)	Data 0.000 (0.015)	Loss 0.0630 (0.1012)	Prec@1 97.656 (96.449)	Prec@5 100.000 (99.987)
2022-06-17 18:25:32 - INFO - TRAINING - Epoch: [95][130/196]	Time 0.104 (0.124)	Data 0.000 (0.014)	Loss 0.0925 (0.1000)	Prec@1 96.875 (96.481)	Prec@5 100.000 (99.988)
2022-06-17 18:25:33 - INFO - TRAINING - Epoch: [95][140/196]	Time 0.122 (0.124)	Data 0.000 (0.013)	Loss 0.0965 (0.0997)	Prec@1 96.484 (96.512)	Prec@5 100.000 (99.989)
2022-06-17 18:25:34 - INFO - TRAINING - Epoch: [95][150/196]	Time 0.111 (0.123)	Data 0.000 (0.012)	Loss 0.0961 (0.1000)	Prec@1 96.875 (96.528)	Prec@5 100.000 (99.984)
2022-06-17 18:25:36 - INFO - TRAINING - Epoch: [95][160/196]	Time 0.107 (0.122)	Data 0.000 (0.011)	Loss 0.1008 (0.0994)	Prec@1 97.656 (96.550)	Prec@5 100.000 (99.985)
2022-06-17 18:25:37 - INFO - TRAINING - Epoch: [95][170/196]	Time 0.109 (0.122)	Data 0.000 (0.011)	Loss 0.0795 (0.0997)	Prec@1 97.656 (96.541)	Prec@5 100.000 (99.986)
2022-06-17 18:25:38 - INFO - TRAINING - Epoch: [95][180/196]	Time 0.135 (0.121)	Data 0.000 (0.010)	Loss 0.0783 (0.0994)	Prec@1 97.656 (96.562)	Prec@5 100.000 (99.987)
2022-06-17 18:25:39 - INFO - TRAINING - Epoch: [95][190/196]	Time 0.109 (0.121)	Data 0.000 (0.010)	Loss 0.1107 (0.0997)	Prec@1 96.484 (96.562)	Prec@5 100.000 (99.988)
2022-06-17 18:25:41 - INFO - EVALUATING - Epoch: [95][0/40]	Time 1.803 (1.803)	Data 1.757 (1.757)	Loss 0.2585 (0.2585)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:25:42 - INFO - EVALUATING - Epoch: [95][10/40]	Time 0.065 (0.256)	Data 0.000 (0.205)	Loss 0.4686 (0.4066)	Prec@1 87.891 (88.210)	Prec@5 99.219 (99.432)
2022-06-17 18:25:43 - INFO - EVALUATING - Epoch: [95][20/40]	Time 0.044 (0.168)	Data 0.000 (0.117)	Loss 0.3388 (0.4102)	Prec@1 87.109 (87.760)	Prec@5 100.000 (99.386)
2022-06-17 18:25:44 - INFO - EVALUATING - Epoch: [95][30/40]	Time 0.091 (0.142)	Data 0.048 (0.092)	Loss 0.4971 (0.4022)	Prec@1 86.328 (88.054)	Prec@5 100.000 (99.446)
2022-06-17 18:25:46 - INFO - 
 Epoch: 96	Training Loss 0.0997 	Training Prec@1 96.562 	Training Prec@5 99.986 	Validation Loss 0.3967 	Validation Prec@1 88.140 	Validation Prec@5 99.530 

2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:25:46 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:25:48 - INFO - TRAINING - Epoch: [96][0/196]	Time 1.638 (1.638)	Data 1.586 (1.586)	Loss 0.0934 (0.0934)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:25:49 - INFO - TRAINING - Epoch: [96][10/196]	Time 0.111 (0.261)	Data 0.000 (0.166)	Loss 0.0692 (0.1082)	Prec@1 96.875 (96.626)	Prec@5 100.000 (99.929)
2022-06-17 18:25:50 - INFO - TRAINING - Epoch: [96][20/196]	Time 0.107 (0.191)	Data 0.000 (0.087)	Loss 0.0360 (0.1002)	Prec@1 99.219 (96.689)	Prec@5 100.000 (99.963)
2022-06-17 18:25:51 - INFO - TRAINING - Epoch: [96][30/196]	Time 0.129 (0.168)	Data 0.000 (0.059)	Loss 0.1662 (0.1020)	Prec@1 92.578 (96.434)	Prec@5 100.000 (99.975)
2022-06-17 18:25:52 - INFO - TRAINING - Epoch: [96][40/196]	Time 0.109 (0.155)	Data 0.000 (0.045)	Loss 0.0517 (0.0971)	Prec@1 98.047 (96.694)	Prec@5 100.000 (99.981)
2022-06-17 18:25:53 - INFO - TRAINING - Epoch: [96][50/196]	Time 0.115 (0.148)	Data 0.000 (0.036)	Loss 0.0856 (0.0985)	Prec@1 96.094 (96.691)	Prec@5 100.000 (99.977)
2022-06-17 18:25:55 - INFO - TRAINING - Epoch: [96][60/196]	Time 0.125 (0.144)	Data 0.000 (0.030)	Loss 0.0869 (0.0986)	Prec@1 96.875 (96.721)	Prec@5 100.000 (99.981)
2022-06-17 18:25:56 - INFO - TRAINING - Epoch: [96][70/196]	Time 0.108 (0.141)	Data 0.000 (0.026)	Loss 0.1096 (0.0977)	Prec@1 96.484 (96.770)	Prec@5 99.609 (99.972)
2022-06-17 18:25:57 - INFO - TRAINING - Epoch: [96][80/196]	Time 0.108 (0.137)	Data 0.000 (0.023)	Loss 0.1404 (0.0982)	Prec@1 95.312 (96.721)	Prec@5 100.000 (99.976)
2022-06-17 18:25:58 - INFO - TRAINING - Epoch: [96][90/196]	Time 0.106 (0.135)	Data 0.000 (0.020)	Loss 0.0753 (0.0968)	Prec@1 96.484 (96.789)	Prec@5 100.000 (99.974)
2022-06-17 18:25:59 - INFO - TRAINING - Epoch: [96][100/196]	Time 0.107 (0.134)	Data 0.000 (0.018)	Loss 0.0909 (0.0976)	Prec@1 96.875 (96.709)	Prec@5 100.000 (99.977)
2022-06-17 18:26:01 - INFO - TRAINING - Epoch: [96][110/196]	Time 0.107 (0.132)	Data 0.000 (0.017)	Loss 0.0808 (0.0980)	Prec@1 96.875 (96.678)	Prec@5 100.000 (99.975)
2022-06-17 18:26:02 - INFO - TRAINING - Epoch: [96][120/196]	Time 0.119 (0.131)	Data 0.000 (0.015)	Loss 0.0771 (0.0977)	Prec@1 97.266 (96.681)	Prec@5 100.000 (99.974)
2022-06-17 18:26:03 - INFO - TRAINING - Epoch: [96][130/196]	Time 0.107 (0.130)	Data 0.000 (0.014)	Loss 0.0934 (0.0976)	Prec@1 96.484 (96.678)	Prec@5 100.000 (99.973)
2022-06-17 18:26:04 - INFO - TRAINING - Epoch: [96][140/196]	Time 0.125 (0.129)	Data 0.000 (0.013)	Loss 0.0704 (0.0966)	Prec@1 97.656 (96.723)	Prec@5 100.000 (99.972)
2022-06-17 18:26:05 - INFO - TRAINING - Epoch: [96][150/196]	Time 0.110 (0.128)	Data 0.000 (0.012)	Loss 0.0568 (0.0965)	Prec@1 98.047 (96.715)	Prec@5 100.000 (99.972)
2022-06-17 18:26:06 - INFO - TRAINING - Epoch: [96][160/196]	Time 0.116 (0.128)	Data 0.000 (0.012)	Loss 0.0697 (0.0965)	Prec@1 98.438 (96.725)	Prec@5 100.000 (99.973)
2022-06-17 18:26:08 - INFO - TRAINING - Epoch: [96][170/196]	Time 0.117 (0.127)	Data 0.000 (0.011)	Loss 0.0830 (0.0962)	Prec@1 97.656 (96.761)	Prec@5 100.000 (99.973)
2022-06-17 18:26:09 - INFO - TRAINING - Epoch: [96][180/196]	Time 0.132 (0.127)	Data 0.000 (0.010)	Loss 0.0959 (0.0967)	Prec@1 96.875 (96.730)	Prec@5 100.000 (99.972)
2022-06-17 18:26:10 - INFO - TRAINING - Epoch: [96][190/196]	Time 0.103 (0.126)	Data 0.000 (0.010)	Loss 0.1357 (0.0969)	Prec@1 93.359 (96.699)	Prec@5 100.000 (99.971)
2022-06-17 18:26:13 - INFO - EVALUATING - Epoch: [96][0/40]	Time 2.063 (2.063)	Data 2.016 (2.016)	Loss 0.2661 (0.2661)	Prec@1 92.578 (92.578)	Prec@5 99.609 (99.609)
2022-06-17 18:26:13 - INFO - EVALUATING - Epoch: [96][10/40]	Time 0.059 (0.265)	Data 0.000 (0.213)	Loss 0.4754 (0.4102)	Prec@1 87.891 (88.033)	Prec@5 99.609 (99.396)
2022-06-17 18:26:14 - INFO - EVALUATING - Epoch: [96][20/40]	Time 0.112 (0.176)	Data 0.069 (0.127)	Loss 0.3384 (0.4126)	Prec@1 88.281 (87.946)	Prec@5 100.000 (99.423)
2022-06-17 18:26:15 - INFO - EVALUATING - Epoch: [96][30/40]	Time 0.048 (0.156)	Data 0.000 (0.108)	Loss 0.4990 (0.4036)	Prec@1 86.328 (88.168)	Prec@5 100.000 (99.496)
2022-06-17 18:26:17 - INFO - 
 Epoch: 97	Training Loss 0.0964 	Training Prec@1 96.720 	Training Prec@5 99.972 	Validation Loss 0.3986 	Validation Prec@1 88.240 	Validation Prec@5 99.570 

2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:26:17 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:26:18 - INFO - TRAINING - Epoch: [97][0/196]	Time 1.227 (1.227)	Data 1.172 (1.172)	Loss 0.0682 (0.0682)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:26:20 - INFO - TRAINING - Epoch: [97][10/196]	Time 0.111 (0.257)	Data 0.000 (0.167)	Loss 0.1521 (0.0972)	Prec@1 94.141 (96.555)	Prec@5 100.000 (100.000)
2022-06-17 18:26:21 - INFO - TRAINING - Epoch: [97][20/196]	Time 0.114 (0.190)	Data 0.000 (0.088)	Loss 0.0968 (0.0989)	Prec@1 96.875 (96.577)	Prec@5 99.609 (99.963)
2022-06-17 18:26:22 - INFO - TRAINING - Epoch: [97][30/196]	Time 0.120 (0.166)	Data 0.000 (0.060)	Loss 0.1251 (0.1029)	Prec@1 95.703 (96.358)	Prec@5 100.000 (99.975)
2022-06-17 18:26:23 - INFO - TRAINING - Epoch: [97][40/196]	Time 0.115 (0.153)	Data 0.000 (0.045)	Loss 0.1373 (0.1044)	Prec@1 94.531 (96.265)	Prec@5 100.000 (99.981)
2022-06-17 18:26:25 - INFO - TRAINING - Epoch: [97][50/196]	Time 0.133 (0.146)	Data 0.000 (0.036)	Loss 0.1024 (0.1041)	Prec@1 95.703 (96.278)	Prec@5 100.000 (99.985)
2022-06-17 18:26:26 - INFO - TRAINING - Epoch: [97][60/196]	Time 0.117 (0.141)	Data 0.000 (0.030)	Loss 0.0710 (0.1043)	Prec@1 97.266 (96.318)	Prec@5 100.000 (99.987)
2022-06-17 18:26:27 - INFO - TRAINING - Epoch: [97][70/196]	Time 0.117 (0.138)	Data 0.000 (0.026)	Loss 0.0751 (0.1042)	Prec@1 98.438 (96.308)	Prec@5 100.000 (99.989)
2022-06-17 18:26:28 - INFO - TRAINING - Epoch: [97][80/196]	Time 0.111 (0.136)	Data 0.000 (0.023)	Loss 0.0909 (0.1019)	Prec@1 96.094 (96.393)	Prec@5 100.000 (99.986)
2022-06-17 18:26:29 - INFO - TRAINING - Epoch: [97][90/196]	Time 0.113 (0.134)	Data 0.000 (0.020)	Loss 0.1157 (0.1025)	Prec@1 96.094 (96.381)	Prec@5 100.000 (99.983)
2022-06-17 18:26:30 - INFO - TRAINING - Epoch: [97][100/196]	Time 0.118 (0.132)	Data 0.000 (0.018)	Loss 0.0608 (0.1013)	Prec@1 98.047 (96.446)	Prec@5 100.000 (99.981)
2022-06-17 18:26:32 - INFO - TRAINING - Epoch: [97][110/196]	Time 0.135 (0.131)	Data 0.000 (0.017)	Loss 0.0687 (0.1014)	Prec@1 98.047 (96.428)	Prec@5 100.000 (99.982)
2022-06-17 18:26:33 - INFO - TRAINING - Epoch: [97][120/196]	Time 0.103 (0.130)	Data 0.000 (0.015)	Loss 0.0711 (0.1000)	Prec@1 97.266 (96.471)	Prec@5 100.000 (99.984)
2022-06-17 18:26:34 - INFO - TRAINING - Epoch: [97][130/196]	Time 0.111 (0.129)	Data 0.000 (0.014)	Loss 0.1060 (0.0985)	Prec@1 96.094 (96.532)	Prec@5 100.000 (99.985)
2022-06-17 18:26:35 - INFO - TRAINING - Epoch: [97][140/196]	Time 0.124 (0.128)	Data 0.000 (0.013)	Loss 0.0940 (0.0978)	Prec@1 97.656 (96.573)	Prec@5 100.000 (99.983)
2022-06-17 18:26:36 - INFO - TRAINING - Epoch: [97][150/196]	Time 0.122 (0.128)	Data 0.000 (0.012)	Loss 0.0742 (0.0985)	Prec@1 97.656 (96.526)	Prec@5 100.000 (99.984)
2022-06-17 18:26:38 - INFO - TRAINING - Epoch: [97][160/196]	Time 0.119 (0.128)	Data 0.000 (0.012)	Loss 0.0770 (0.0989)	Prec@1 98.828 (96.513)	Prec@5 100.000 (99.983)
2022-06-17 18:26:39 - INFO - TRAINING - Epoch: [97][170/196]	Time 0.107 (0.127)	Data 0.000 (0.011)	Loss 0.1058 (0.0990)	Prec@1 96.484 (96.505)	Prec@5 100.000 (99.982)
2022-06-17 18:26:40 - INFO - TRAINING - Epoch: [97][180/196]	Time 0.120 (0.127)	Data 0.000 (0.010)	Loss 0.0967 (0.0994)	Prec@1 96.484 (96.495)	Prec@5 100.000 (99.983)
2022-06-17 18:26:41 - INFO - TRAINING - Epoch: [97][190/196]	Time 0.102 (0.126)	Data 0.000 (0.010)	Loss 0.0462 (0.0997)	Prec@1 98.828 (96.497)	Prec@5 100.000 (99.982)
2022-06-17 18:26:43 - INFO - EVALUATING - Epoch: [97][0/40]	Time 1.391 (1.391)	Data 1.346 (1.346)	Loss 0.2518 (0.2518)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:26:45 - INFO - EVALUATING - Epoch: [97][10/40]	Time 0.055 (0.252)	Data 0.000 (0.203)	Loss 0.4721 (0.4083)	Prec@1 89.062 (88.388)	Prec@5 99.219 (99.396)
2022-06-17 18:26:45 - INFO - EVALUATING - Epoch: [97][20/40]	Time 0.056 (0.167)	Data 0.000 (0.118)	Loss 0.3404 (0.4122)	Prec@1 87.500 (88.002)	Prec@5 100.000 (99.386)
2022-06-17 18:26:46 - INFO - EVALUATING - Epoch: [97][30/40]	Time 0.102 (0.144)	Data 0.058 (0.097)	Loss 0.5059 (0.4048)	Prec@1 85.938 (88.168)	Prec@5 100.000 (99.458)
2022-06-17 18:26:48 - INFO - 
 Epoch: 98	Training Loss 0.0995 	Training Prec@1 96.512 	Training Prec@5 99.982 	Validation Loss 0.3996 	Validation Prec@1 88.170 	Validation Prec@5 99.540 

2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:26:48 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:26:50 - INFO - TRAINING - Epoch: [98][0/196]	Time 1.445 (1.445)	Data 1.392 (1.392)	Loss 0.0879 (0.0879)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:26:51 - INFO - TRAINING - Epoch: [98][10/196]	Time 0.106 (0.259)	Data 0.000 (0.159)	Loss 0.0767 (0.0828)	Prec@1 96.875 (97.372)	Prec@5 100.000 (100.000)
2022-06-17 18:26:52 - INFO - TRAINING - Epoch: [98][20/196]	Time 0.121 (0.191)	Data 0.000 (0.084)	Loss 0.0921 (0.0898)	Prec@1 96.484 (96.856)	Prec@5 100.000 (100.000)
2022-06-17 18:26:53 - INFO - TRAINING - Epoch: [98][30/196]	Time 0.118 (0.166)	Data 0.000 (0.057)	Loss 0.0846 (0.0934)	Prec@1 96.094 (96.673)	Prec@5 100.000 (100.000)
2022-06-17 18:26:54 - INFO - TRAINING - Epoch: [98][40/196]	Time 0.104 (0.153)	Data 0.000 (0.043)	Loss 0.0595 (0.0923)	Prec@1 98.828 (96.770)	Prec@5 100.000 (99.990)
2022-06-17 18:26:56 - INFO - TRAINING - Epoch: [98][50/196]	Time 0.120 (0.146)	Data 0.000 (0.035)	Loss 0.0932 (0.0934)	Prec@1 96.875 (96.699)	Prec@5 100.000 (99.992)
2022-06-17 18:26:57 - INFO - TRAINING - Epoch: [98][60/196]	Time 0.118 (0.141)	Data 0.000 (0.029)	Loss 0.0718 (0.0935)	Prec@1 97.266 (96.715)	Prec@5 100.000 (99.994)
2022-06-17 18:26:58 - INFO - TRAINING - Epoch: [98][70/196]	Time 0.130 (0.138)	Data 0.000 (0.025)	Loss 0.1242 (0.0948)	Prec@1 94.531 (96.638)	Prec@5 100.000 (99.994)
2022-06-17 18:26:59 - INFO - TRAINING - Epoch: [98][80/196]	Time 0.106 (0.135)	Data 0.000 (0.022)	Loss 0.0607 (0.0942)	Prec@1 98.828 (96.706)	Prec@5 100.000 (99.990)
2022-06-17 18:27:00 - INFO - TRAINING - Epoch: [98][90/196]	Time 0.112 (0.133)	Data 0.000 (0.019)	Loss 0.1078 (0.0958)	Prec@1 95.703 (96.712)	Prec@5 100.000 (99.979)
2022-06-17 18:27:01 - INFO - TRAINING - Epoch: [98][100/196]	Time 0.119 (0.132)	Data 0.000 (0.018)	Loss 0.0824 (0.0961)	Prec@1 96.484 (96.662)	Prec@5 100.000 (99.981)
2022-06-17 18:27:03 - INFO - TRAINING - Epoch: [98][110/196]	Time 0.133 (0.131)	Data 0.000 (0.016)	Loss 0.0765 (0.0951)	Prec@1 97.656 (96.692)	Prec@5 100.000 (99.982)
2022-06-17 18:27:04 - INFO - TRAINING - Epoch: [98][120/196]	Time 0.104 (0.130)	Data 0.000 (0.015)	Loss 0.0787 (0.0947)	Prec@1 97.656 (96.710)	Prec@5 100.000 (99.984)
2022-06-17 18:27:05 - INFO - TRAINING - Epoch: [98][130/196]	Time 0.126 (0.129)	Data 0.000 (0.014)	Loss 0.1053 (0.0944)	Prec@1 96.484 (96.726)	Prec@5 100.000 (99.985)
2022-06-17 18:27:06 - INFO - TRAINING - Epoch: [98][140/196]	Time 0.119 (0.128)	Data 0.000 (0.013)	Loss 0.0948 (0.0946)	Prec@1 96.875 (96.731)	Prec@5 100.000 (99.983)
2022-06-17 18:27:07 - INFO - TRAINING - Epoch: [98][150/196]	Time 0.127 (0.127)	Data 0.000 (0.012)	Loss 0.0957 (0.0943)	Prec@1 96.094 (96.722)	Prec@5 100.000 (99.984)
2022-06-17 18:27:08 - INFO - TRAINING - Epoch: [98][160/196]	Time 0.125 (0.126)	Data 0.000 (0.011)	Loss 0.1028 (0.0946)	Prec@1 96.484 (96.725)	Prec@5 99.609 (99.983)
2022-06-17 18:27:10 - INFO - TRAINING - Epoch: [98][170/196]	Time 0.107 (0.126)	Data 0.000 (0.011)	Loss 0.1019 (0.0953)	Prec@1 96.094 (96.688)	Prec@5 100.000 (99.977)
2022-06-17 18:27:11 - INFO - TRAINING - Epoch: [98][180/196]	Time 0.126 (0.125)	Data 0.000 (0.010)	Loss 0.0799 (0.0955)	Prec@1 97.266 (96.674)	Prec@5 100.000 (99.976)
2022-06-17 18:27:12 - INFO - TRAINING - Epoch: [98][190/196]	Time 0.118 (0.124)	Data 0.000 (0.009)	Loss 0.1397 (0.0959)	Prec@1 94.531 (96.679)	Prec@5 100.000 (99.978)
2022-06-17 18:27:14 - INFO - EVALUATING - Epoch: [98][0/40]	Time 1.331 (1.331)	Data 1.286 (1.286)	Loss 0.2590 (0.2590)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:27:15 - INFO - EVALUATING - Epoch: [98][10/40]	Time 0.042 (0.233)	Data 0.001 (0.183)	Loss 0.4747 (0.4123)	Prec@1 87.891 (88.317)	Prec@5 99.219 (99.396)
2022-06-17 18:27:16 - INFO - EVALUATING - Epoch: [98][20/40]	Time 0.058 (0.167)	Data 0.000 (0.120)	Loss 0.3300 (0.4141)	Prec@1 87.891 (88.058)	Prec@5 100.000 (99.386)
2022-06-17 18:27:17 - INFO - EVALUATING - Epoch: [98][30/40]	Time 0.102 (0.149)	Data 0.058 (0.103)	Loss 0.5160 (0.4065)	Prec@1 85.938 (88.206)	Prec@5 100.000 (99.471)
2022-06-17 18:27:19 - INFO - 
 Epoch: 99	Training Loss 0.0960 	Training Prec@1 96.680 	Training Prec@5 99.976 	Validation Loss 0.4005 	Validation Prec@1 88.240 	Validation Prec@5 99.550 

2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:27:19 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:27:21 - INFO - TRAINING - Epoch: [99][0/196]	Time 1.973 (1.973)	Data 1.920 (1.920)	Loss 0.1011 (0.1011)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:27:22 - INFO - TRAINING - Epoch: [99][10/196]	Time 0.110 (0.286)	Data 0.000 (0.175)	Loss 0.0975 (0.0979)	Prec@1 98.047 (96.662)	Prec@5 100.000 (99.964)
2022-06-17 18:27:23 - INFO - TRAINING - Epoch: [99][20/196]	Time 0.109 (0.202)	Data 0.000 (0.092)	Loss 0.1363 (0.0997)	Prec@1 95.312 (96.670)	Prec@5 99.609 (99.963)
2022-06-17 18:27:24 - INFO - TRAINING - Epoch: [99][30/196]	Time 0.120 (0.174)	Data 0.000 (0.062)	Loss 0.0846 (0.0977)	Prec@1 97.656 (96.774)	Prec@5 100.000 (99.962)
2022-06-17 18:27:25 - INFO - TRAINING - Epoch: [99][40/196]	Time 0.112 (0.159)	Data 0.000 (0.047)	Loss 0.1034 (0.0978)	Prec@1 95.703 (96.665)	Prec@5 100.000 (99.971)
2022-06-17 18:27:27 - INFO - TRAINING - Epoch: [99][50/196]	Time 0.134 (0.151)	Data 0.000 (0.038)	Loss 0.0725 (0.0948)	Prec@1 98.438 (96.791)	Prec@5 100.000 (99.977)
2022-06-17 18:27:28 - INFO - TRAINING - Epoch: [99][60/196]	Time 0.132 (0.145)	Data 0.001 (0.032)	Loss 0.1253 (0.0950)	Prec@1 95.703 (96.798)	Prec@5 100.000 (99.981)
2022-06-17 18:27:29 - INFO - TRAINING - Epoch: [99][70/196]	Time 0.103 (0.141)	Data 0.000 (0.027)	Loss 0.0898 (0.0950)	Prec@1 96.875 (96.781)	Prec@5 100.000 (99.978)
2022-06-17 18:27:30 - INFO - TRAINING - Epoch: [99][80/196]	Time 0.123 (0.138)	Data 0.000 (0.024)	Loss 0.1008 (0.0941)	Prec@1 96.875 (96.807)	Prec@5 99.609 (99.976)
2022-06-17 18:27:31 - INFO - TRAINING - Epoch: [99][90/196]	Time 0.134 (0.136)	Data 0.000 (0.021)	Loss 0.1060 (0.0938)	Prec@1 95.703 (96.806)	Prec@5 100.000 (99.979)
2022-06-17 18:27:32 - INFO - TRAINING - Epoch: [99][100/196]	Time 0.108 (0.132)	Data 0.000 (0.019)	Loss 0.1089 (0.0944)	Prec@1 96.875 (96.794)	Prec@5 99.609 (99.977)
2022-06-17 18:27:33 - INFO - TRAINING - Epoch: [99][110/196]	Time 0.132 (0.131)	Data 0.000 (0.018)	Loss 0.0988 (0.0952)	Prec@1 97.266 (96.766)	Prec@5 100.000 (99.979)
2022-06-17 18:27:35 - INFO - TRAINING - Epoch: [99][120/196]	Time 0.113 (0.129)	Data 0.000 (0.016)	Loss 0.0715 (0.0956)	Prec@1 97.266 (96.756)	Prec@5 100.000 (99.977)
2022-06-17 18:27:36 - INFO - TRAINING - Epoch: [99][130/196]	Time 0.124 (0.128)	Data 0.000 (0.015)	Loss 0.0916 (0.0962)	Prec@1 96.875 (96.717)	Prec@5 100.000 (99.979)
2022-06-17 18:27:37 - INFO - TRAINING - Epoch: [99][140/196]	Time 0.117 (0.127)	Data 0.000 (0.014)	Loss 0.1331 (0.0969)	Prec@1 96.484 (96.695)	Prec@5 100.000 (99.981)
2022-06-17 18:27:38 - INFO - TRAINING - Epoch: [99][150/196]	Time 0.103 (0.126)	Data 0.000 (0.013)	Loss 0.1300 (0.0971)	Prec@1 95.703 (96.689)	Prec@5 100.000 (99.982)
2022-06-17 18:27:39 - INFO - TRAINING - Epoch: [99][160/196]	Time 0.113 (0.125)	Data 0.000 (0.012)	Loss 0.0790 (0.0974)	Prec@1 97.656 (96.674)	Prec@5 100.000 (99.981)
2022-06-17 18:27:40 - INFO - TRAINING - Epoch: [99][170/196]	Time 0.118 (0.124)	Data 0.000 (0.012)	Loss 0.0887 (0.0970)	Prec@1 96.875 (96.667)	Prec@5 100.000 (99.979)
2022-06-17 18:27:41 - INFO - TRAINING - Epoch: [99][180/196]	Time 0.130 (0.123)	Data 0.000 (0.011)	Loss 0.0970 (0.0981)	Prec@1 97.266 (96.618)	Prec@5 100.000 (99.974)
2022-06-17 18:27:42 - INFO - TRAINING - Epoch: [99][190/196]	Time 0.104 (0.123)	Data 0.000 (0.010)	Loss 0.0787 (0.0988)	Prec@1 97.656 (96.605)	Prec@5 100.000 (99.971)
2022-06-17 18:27:45 - INFO - EVALUATING - Epoch: [99][0/40]	Time 1.974 (1.974)	Data 1.929 (1.929)	Loss 0.2598 (0.2598)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:27:46 - INFO - EVALUATING - Epoch: [99][10/40]	Time 0.111 (0.239)	Data 0.070 (0.190)	Loss 0.4686 (0.4092)	Prec@1 88.281 (88.565)	Prec@5 99.219 (99.467)
2022-06-17 18:27:47 - INFO - EVALUATING - Epoch: [99][20/40]	Time 0.104 (0.176)	Data 0.060 (0.128)	Loss 0.3339 (0.4122)	Prec@1 87.500 (87.946)	Prec@5 100.000 (99.461)
2022-06-17 18:27:48 - INFO - EVALUATING - Epoch: [99][30/40]	Time 0.265 (0.159)	Data 0.222 (0.113)	Loss 0.5051 (0.4042)	Prec@1 86.328 (88.130)	Prec@5 100.000 (99.496)
2022-06-17 18:27:50 - INFO - 
 Epoch: 100	Training Loss 0.0990 	Training Prec@1 96.596 	Training Prec@5 99.972 	Validation Loss 0.3987 	Validation Prec@1 88.200 	Validation Prec@5 99.570 

2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:27:50 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:27:51 - INFO - TRAINING - Epoch: [100][0/196]	Time 1.233 (1.233)	Data 1.180 (1.180)	Loss 0.1831 (0.1831)	Prec@1 94.531 (94.531)	Prec@5 99.609 (99.609)
2022-06-17 18:27:53 - INFO - TRAINING - Epoch: [100][10/196]	Time 0.120 (0.270)	Data 0.000 (0.177)	Loss 0.1144 (0.1029)	Prec@1 97.266 (96.946)	Prec@5 100.000 (99.964)
2022-06-17 18:27:54 - INFO - TRAINING - Epoch: [100][20/196]	Time 0.122 (0.194)	Data 0.000 (0.093)	Loss 0.1045 (0.0954)	Prec@1 96.484 (96.931)	Prec@5 100.000 (99.981)
2022-06-17 18:27:55 - INFO - TRAINING - Epoch: [100][30/196]	Time 0.135 (0.170)	Data 0.000 (0.063)	Loss 0.0777 (0.0961)	Prec@1 96.875 (96.724)	Prec@5 100.000 (99.987)
2022-06-17 18:27:56 - INFO - TRAINING - Epoch: [100][40/196]	Time 0.126 (0.157)	Data 0.000 (0.048)	Loss 0.1181 (0.0974)	Prec@1 96.094 (96.665)	Prec@5 100.000 (99.990)
2022-06-17 18:27:57 - INFO - TRAINING - Epoch: [100][50/196]	Time 0.104 (0.148)	Data 0.000 (0.038)	Loss 0.0771 (0.0952)	Prec@1 98.047 (96.768)	Prec@5 100.000 (99.985)
2022-06-17 18:27:58 - INFO - TRAINING - Epoch: [100][60/196]	Time 0.108 (0.141)	Data 0.000 (0.032)	Loss 0.1088 (0.0975)	Prec@1 98.047 (96.670)	Prec@5 100.000 (99.974)
2022-06-17 18:27:59 - INFO - TRAINING - Epoch: [100][70/196]	Time 0.103 (0.137)	Data 0.000 (0.028)	Loss 0.0506 (0.0978)	Prec@1 98.828 (96.622)	Prec@5 100.000 (99.978)
2022-06-17 18:28:00 - INFO - TRAINING - Epoch: [100][80/196]	Time 0.111 (0.133)	Data 0.000 (0.024)	Loss 0.0799 (0.0970)	Prec@1 97.266 (96.663)	Prec@5 100.000 (99.976)
2022-06-17 18:28:02 - INFO - TRAINING - Epoch: [100][90/196]	Time 0.130 (0.131)	Data 0.000 (0.022)	Loss 0.1522 (0.0973)	Prec@1 95.312 (96.669)	Prec@5 100.000 (99.979)
2022-06-17 18:28:03 - INFO - TRAINING - Epoch: [100][100/196]	Time 0.107 (0.129)	Data 0.000 (0.020)	Loss 0.1153 (0.0975)	Prec@1 96.484 (96.666)	Prec@5 100.000 (99.977)
2022-06-17 18:28:04 - INFO - TRAINING - Epoch: [100][110/196]	Time 0.104 (0.127)	Data 0.000 (0.018)	Loss 0.0812 (0.0965)	Prec@1 97.656 (96.724)	Prec@5 100.000 (99.975)
2022-06-17 18:28:05 - INFO - TRAINING - Epoch: [100][120/196]	Time 0.107 (0.125)	Data 0.000 (0.016)	Loss 0.1127 (0.0965)	Prec@1 96.484 (96.707)	Prec@5 100.000 (99.977)
2022-06-17 18:28:06 - INFO - TRAINING - Epoch: [100][130/196]	Time 0.112 (0.124)	Data 0.000 (0.015)	Loss 0.1124 (0.0968)	Prec@1 97.656 (96.705)	Prec@5 100.000 (99.979)
2022-06-17 18:28:07 - INFO - TRAINING - Epoch: [100][140/196]	Time 0.109 (0.123)	Data 0.000 (0.014)	Loss 0.0662 (0.0970)	Prec@1 98.047 (96.717)	Prec@5 100.000 (99.981)
2022-06-17 18:28:08 - INFO - TRAINING - Epoch: [100][150/196]	Time 0.105 (0.122)	Data 0.000 (0.013)	Loss 0.0883 (0.0965)	Prec@1 96.875 (96.730)	Prec@5 100.000 (99.979)
2022-06-17 18:28:09 - INFO - TRAINING - Epoch: [100][160/196]	Time 0.103 (0.121)	Data 0.000 (0.012)	Loss 0.0692 (0.0960)	Prec@1 97.266 (96.732)	Prec@5 100.000 (99.978)
2022-06-17 18:28:10 - INFO - TRAINING - Epoch: [100][170/196]	Time 0.116 (0.121)	Data 0.000 (0.012)	Loss 0.0795 (0.0957)	Prec@1 96.875 (96.749)	Prec@5 100.000 (99.979)
2022-06-17 18:28:12 - INFO - TRAINING - Epoch: [100][180/196]	Time 0.124 (0.121)	Data 0.000 (0.011)	Loss 0.0808 (0.0956)	Prec@1 98.047 (96.771)	Prec@5 100.000 (99.976)
2022-06-17 18:28:13 - INFO - TRAINING - Epoch: [100][190/196]	Time 0.101 (0.120)	Data 0.000 (0.010)	Loss 0.0995 (0.0961)	Prec@1 95.703 (96.750)	Prec@5 100.000 (99.978)
2022-06-17 18:28:15 - INFO - EVALUATING - Epoch: [100][0/40]	Time 1.610 (1.610)	Data 1.565 (1.565)	Loss 0.2649 (0.2649)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:28:16 - INFO - EVALUATING - Epoch: [100][10/40]	Time 0.044 (0.229)	Data 0.000 (0.181)	Loss 0.4759 (0.4146)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.432)
2022-06-17 18:28:17 - INFO - EVALUATING - Epoch: [100][20/40]	Time 0.065 (0.183)	Data 0.000 (0.134)	Loss 0.3387 (0.4154)	Prec@1 87.500 (87.946)	Prec@5 100.000 (99.405)
2022-06-17 18:28:18 - INFO - EVALUATING - Epoch: [100][30/40]	Time 0.106 (0.150)	Data 0.065 (0.102)	Loss 0.5123 (0.4073)	Prec@1 85.156 (88.092)	Prec@5 100.000 (99.471)
2022-06-17 18:28:20 - INFO - 
 Epoch: 101	Training Loss 0.0958 	Training Prec@1 96.772 	Training Prec@5 99.978 	Validation Loss 0.4023 	Validation Prec@1 88.120 	Validation Prec@5 99.540 

2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:28:20 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:28:22 - INFO - TRAINING - Epoch: [101][0/196]	Time 2.134 (2.134)	Data 2.082 (2.082)	Loss 0.0951 (0.0951)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 18:28:23 - INFO - TRAINING - Epoch: [101][10/196]	Time 0.111 (0.303)	Data 0.000 (0.190)	Loss 0.1107 (0.1068)	Prec@1 95.312 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:28:24 - INFO - TRAINING - Epoch: [101][20/196]	Time 0.132 (0.213)	Data 0.000 (0.099)	Loss 0.1228 (0.1025)	Prec@1 95.312 (96.298)	Prec@5 100.000 (100.000)
2022-06-17 18:28:25 - INFO - TRAINING - Epoch: [101][30/196]	Time 0.137 (0.182)	Data 0.000 (0.067)	Loss 0.0748 (0.0986)	Prec@1 97.266 (96.510)	Prec@5 100.000 (99.987)
2022-06-17 18:28:27 - INFO - TRAINING - Epoch: [101][40/196]	Time 0.108 (0.166)	Data 0.000 (0.051)	Loss 0.1150 (0.0968)	Prec@1 96.875 (96.599)	Prec@5 100.000 (99.981)
2022-06-17 18:28:28 - INFO - TRAINING - Epoch: [101][50/196]	Time 0.129 (0.157)	Data 0.000 (0.041)	Loss 0.0564 (0.0945)	Prec@1 98.438 (96.729)	Prec@5 100.000 (99.977)
2022-06-17 18:28:29 - INFO - TRAINING - Epoch: [101][60/196]	Time 0.120 (0.150)	Data 0.000 (0.034)	Loss 0.0787 (0.0949)	Prec@1 97.266 (96.734)	Prec@5 100.000 (99.981)
2022-06-17 18:28:30 - INFO - TRAINING - Epoch: [101][70/196]	Time 0.122 (0.145)	Data 0.000 (0.030)	Loss 0.0860 (0.0955)	Prec@1 96.875 (96.715)	Prec@5 100.000 (99.972)
2022-06-17 18:28:31 - INFO - TRAINING - Epoch: [101][80/196]	Time 0.105 (0.142)	Data 0.000 (0.026)	Loss 0.1010 (0.0948)	Prec@1 96.484 (96.750)	Prec@5 100.000 (99.976)
2022-06-17 18:28:32 - INFO - TRAINING - Epoch: [101][90/196]	Time 0.134 (0.139)	Data 0.000 (0.023)	Loss 0.1099 (0.0956)	Prec@1 95.703 (96.716)	Prec@5 100.000 (99.979)
2022-06-17 18:28:34 - INFO - TRAINING - Epoch: [101][100/196]	Time 0.118 (0.137)	Data 0.000 (0.021)	Loss 0.0971 (0.0934)	Prec@1 96.484 (96.821)	Prec@5 100.000 (99.981)
2022-06-17 18:28:35 - INFO - TRAINING - Epoch: [101][110/196]	Time 0.126 (0.135)	Data 0.000 (0.019)	Loss 0.0980 (0.0934)	Prec@1 97.656 (96.815)	Prec@5 99.609 (99.975)
2022-06-17 18:28:36 - INFO - TRAINING - Epoch: [101][120/196]	Time 0.116 (0.133)	Data 0.000 (0.018)	Loss 0.0817 (0.0942)	Prec@1 96.484 (96.778)	Prec@5 100.000 (99.974)
2022-06-17 18:28:37 - INFO - TRAINING - Epoch: [101][130/196]	Time 0.106 (0.132)	Data 0.000 (0.016)	Loss 0.1156 (0.0953)	Prec@1 95.703 (96.723)	Prec@5 100.000 (99.973)
2022-06-17 18:28:38 - INFO - TRAINING - Epoch: [101][140/196]	Time 0.112 (0.131)	Data 0.000 (0.015)	Loss 0.0595 (0.0953)	Prec@1 98.438 (96.745)	Prec@5 100.000 (99.972)
2022-06-17 18:28:39 - INFO - TRAINING - Epoch: [101][150/196]	Time 0.114 (0.130)	Data 0.000 (0.014)	Loss 0.1123 (0.0953)	Prec@1 94.922 (96.725)	Prec@5 100.000 (99.972)
2022-06-17 18:28:40 - INFO - TRAINING - Epoch: [101][160/196]	Time 0.121 (0.129)	Data 0.000 (0.013)	Loss 0.1193 (0.0954)	Prec@1 95.312 (96.712)	Prec@5 100.000 (99.973)
2022-06-17 18:28:42 - INFO - TRAINING - Epoch: [101][170/196]	Time 0.111 (0.128)	Data 0.000 (0.013)	Loss 0.0973 (0.0963)	Prec@1 96.484 (96.656)	Prec@5 100.000 (99.975)
2022-06-17 18:28:43 - INFO - TRAINING - Epoch: [101][180/196]	Time 0.125 (0.127)	Data 0.000 (0.012)	Loss 0.0991 (0.0960)	Prec@1 96.094 (96.668)	Prec@5 100.000 (99.974)
2022-06-17 18:28:44 - INFO - TRAINING - Epoch: [101][190/196]	Time 0.102 (0.126)	Data 0.000 (0.011)	Loss 0.0624 (0.0959)	Prec@1 97.266 (96.675)	Prec@5 100.000 (99.975)
2022-06-17 18:28:46 - INFO - EVALUATING - Epoch: [101][0/40]	Time 1.605 (1.605)	Data 1.559 (1.559)	Loss 0.2629 (0.2629)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:28:47 - INFO - EVALUATING - Epoch: [101][10/40]	Time 0.070 (0.239)	Data 0.000 (0.190)	Loss 0.4719 (0.4099)	Prec@1 87.891 (88.423)	Prec@5 99.219 (99.396)
2022-06-17 18:28:48 - INFO - EVALUATING - Epoch: [101][20/40]	Time 0.046 (0.171)	Data 0.003 (0.123)	Loss 0.3503 (0.4143)	Prec@1 87.109 (87.965)	Prec@5 100.000 (99.386)
2022-06-17 18:28:49 - INFO - EVALUATING - Epoch: [101][30/40]	Time 0.041 (0.150)	Data 0.000 (0.104)	Loss 0.5085 (0.4064)	Prec@1 84.766 (88.193)	Prec@5 100.000 (99.471)
2022-06-17 18:28:51 - INFO - 
 Epoch: 102	Training Loss 0.0956 	Training Prec@1 96.696 	Training Prec@5 99.974 	Validation Loss 0.4020 	Validation Prec@1 88.230 	Validation Prec@5 99.550 

2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:28:51 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:28:52 - INFO - TRAINING - Epoch: [102][0/196]	Time 1.336 (1.336)	Data 1.283 (1.283)	Loss 0.1115 (0.1115)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:28:54 - INFO - TRAINING - Epoch: [102][10/196]	Time 0.111 (0.261)	Data 0.062 (0.170)	Loss 0.0854 (0.0952)	Prec@1 96.875 (96.875)	Prec@5 100.000 (99.964)
2022-06-17 18:28:55 - INFO - TRAINING - Epoch: [102][20/196]	Time 0.115 (0.189)	Data 0.000 (0.089)	Loss 0.0827 (0.0914)	Prec@1 98.438 (97.061)	Prec@5 100.000 (99.963)
2022-06-17 18:28:56 - INFO - TRAINING - Epoch: [102][30/196]	Time 0.105 (0.168)	Data 0.000 (0.061)	Loss 0.0448 (0.0894)	Prec@1 99.219 (97.177)	Prec@5 100.000 (99.975)
2022-06-17 18:28:57 - INFO - TRAINING - Epoch: [102][40/196]	Time 0.101 (0.154)	Data 0.000 (0.046)	Loss 0.0795 (0.0912)	Prec@1 97.266 (97.056)	Prec@5 100.000 (99.962)
2022-06-17 18:28:59 - INFO - TRAINING - Epoch: [102][50/196]	Time 0.126 (0.147)	Data 0.000 (0.037)	Loss 0.0788 (0.0904)	Prec@1 98.438 (97.151)	Prec@5 100.000 (99.969)
2022-06-17 18:29:00 - INFO - TRAINING - Epoch: [102][60/196]	Time 0.109 (0.143)	Data 0.000 (0.031)	Loss 0.0904 (0.0890)	Prec@1 96.094 (97.138)	Prec@5 100.000 (99.974)
2022-06-17 18:29:01 - INFO - TRAINING - Epoch: [102][70/196]	Time 0.111 (0.139)	Data 0.000 (0.027)	Loss 0.0942 (0.0910)	Prec@1 95.703 (97.024)	Prec@5 100.000 (99.978)
2022-06-17 18:29:02 - INFO - TRAINING - Epoch: [102][80/196]	Time 0.107 (0.137)	Data 0.000 (0.023)	Loss 0.0867 (0.0917)	Prec@1 97.266 (96.957)	Prec@5 100.000 (99.971)
2022-06-17 18:29:03 - INFO - TRAINING - Epoch: [102][90/196]	Time 0.129 (0.135)	Data 0.000 (0.021)	Loss 0.0698 (0.0925)	Prec@1 96.875 (96.905)	Prec@5 100.000 (99.974)
2022-06-17 18:29:04 - INFO - TRAINING - Epoch: [102][100/196]	Time 0.123 (0.133)	Data 0.000 (0.019)	Loss 0.1148 (0.0929)	Prec@1 96.094 (96.918)	Prec@5 100.000 (99.973)
2022-06-17 18:29:06 - INFO - TRAINING - Epoch: [102][110/196]	Time 0.126 (0.131)	Data 0.000 (0.017)	Loss 0.1199 (0.0935)	Prec@1 96.094 (96.889)	Prec@5 100.000 (99.975)
2022-06-17 18:29:07 - INFO - TRAINING - Epoch: [102][120/196]	Time 0.125 (0.130)	Data 0.000 (0.016)	Loss 0.0881 (0.0927)	Prec@1 96.484 (96.959)	Prec@5 100.000 (99.977)
2022-06-17 18:29:08 - INFO - TRAINING - Epoch: [102][130/196]	Time 0.129 (0.129)	Data 0.000 (0.015)	Loss 0.1031 (0.0933)	Prec@1 95.312 (96.923)	Prec@5 100.000 (99.973)
2022-06-17 18:29:09 - INFO - TRAINING - Epoch: [102][140/196]	Time 0.124 (0.128)	Data 0.000 (0.014)	Loss 0.0806 (0.0935)	Prec@1 97.656 (96.900)	Prec@5 100.000 (99.975)
2022-06-17 18:29:10 - INFO - TRAINING - Epoch: [102][150/196]	Time 0.125 (0.128)	Data 0.000 (0.013)	Loss 0.0654 (0.0939)	Prec@1 98.047 (96.875)	Prec@5 100.000 (99.977)
2022-06-17 18:29:11 - INFO - TRAINING - Epoch: [102][160/196]	Time 0.128 (0.127)	Data 0.000 (0.012)	Loss 0.0831 (0.0939)	Prec@1 97.656 (96.875)	Prec@5 100.000 (99.978)
2022-06-17 18:29:13 - INFO - TRAINING - Epoch: [102][170/196]	Time 0.126 (0.126)	Data 0.000 (0.011)	Loss 0.1201 (0.0936)	Prec@1 95.703 (96.880)	Prec@5 100.000 (99.979)
2022-06-17 18:29:14 - INFO - TRAINING - Epoch: [102][180/196]	Time 0.123 (0.126)	Data 0.000 (0.011)	Loss 0.0639 (0.0935)	Prec@1 98.047 (96.890)	Prec@5 100.000 (99.981)
2022-06-17 18:29:15 - INFO - TRAINING - Epoch: [102][190/196]	Time 0.111 (0.125)	Data 0.000 (0.010)	Loss 0.0913 (0.0940)	Prec@1 95.703 (96.863)	Prec@5 100.000 (99.982)
2022-06-17 18:29:18 - INFO - EVALUATING - Epoch: [102][0/40]	Time 2.173 (2.173)	Data 2.127 (2.127)	Loss 0.2636 (0.2636)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:29:18 - INFO - EVALUATING - Epoch: [102][10/40]	Time 0.044 (0.271)	Data 0.000 (0.221)	Loss 0.4797 (0.4166)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.432)
2022-06-17 18:29:19 - INFO - EVALUATING - Epoch: [102][20/40]	Time 0.128 (0.176)	Data 0.086 (0.127)	Loss 0.3401 (0.4174)	Prec@1 87.500 (87.835)	Prec@5 100.000 (99.442)
2022-06-17 18:29:20 - INFO - EVALUATING - Epoch: [102][30/40]	Time 0.104 (0.155)	Data 0.063 (0.109)	Loss 0.5107 (0.4087)	Prec@1 85.938 (88.105)	Prec@5 100.000 (99.483)
2022-06-17 18:29:22 - INFO - 
 Epoch: 103	Training Loss 0.0936 	Training Prec@1 96.878 	Training Prec@5 99.982 	Validation Loss 0.4039 	Validation Prec@1 88.160 	Validation Prec@5 99.560 

2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:29:22 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:29:24 - INFO - TRAINING - Epoch: [103][0/196]	Time 1.990 (1.990)	Data 1.937 (1.937)	Loss 0.0637 (0.0637)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:29:25 - INFO - TRAINING - Epoch: [103][10/196]	Time 0.107 (0.278)	Data 0.000 (0.190)	Loss 0.0780 (0.0856)	Prec@1 97.656 (97.301)	Prec@5 100.000 (100.000)
2022-06-17 18:29:26 - INFO - TRAINING - Epoch: [103][20/196]	Time 0.104 (0.197)	Data 0.001 (0.100)	Loss 0.0958 (0.0853)	Prec@1 98.047 (97.396)	Prec@5 100.000 (100.000)
2022-06-17 18:29:28 - INFO - TRAINING - Epoch: [103][30/196]	Time 0.128 (0.171)	Data 0.000 (0.068)	Loss 0.1235 (0.0876)	Prec@1 95.312 (97.253)	Prec@5 99.609 (99.975)
2022-06-17 18:29:29 - INFO - TRAINING - Epoch: [103][40/196]	Time 0.109 (0.157)	Data 0.000 (0.051)	Loss 0.1006 (0.0915)	Prec@1 96.875 (97.027)	Prec@5 100.000 (99.971)
2022-06-17 18:29:30 - INFO - TRAINING - Epoch: [103][50/196]	Time 0.120 (0.148)	Data 0.000 (0.041)	Loss 0.1033 (0.0912)	Prec@1 97.266 (97.082)	Prec@5 100.000 (99.962)
2022-06-17 18:29:31 - INFO - TRAINING - Epoch: [103][60/196]	Time 0.105 (0.143)	Data 0.000 (0.035)	Loss 0.1143 (0.0924)	Prec@1 96.094 (97.009)	Prec@5 100.000 (99.968)
2022-06-17 18:29:32 - INFO - TRAINING - Epoch: [103][70/196]	Time 0.106 (0.138)	Data 0.000 (0.030)	Loss 0.0781 (0.0914)	Prec@1 97.656 (97.062)	Prec@5 100.000 (99.972)
2022-06-17 18:29:33 - INFO - TRAINING - Epoch: [103][80/196]	Time 0.110 (0.134)	Data 0.000 (0.026)	Loss 0.1521 (0.0934)	Prec@1 94.922 (96.976)	Prec@5 100.000 (99.976)
2022-06-17 18:29:34 - INFO - TRAINING - Epoch: [103][90/196]	Time 0.120 (0.132)	Data 0.000 (0.023)	Loss 0.0386 (0.0927)	Prec@1 98.828 (96.969)	Prec@5 100.000 (99.979)
2022-06-17 18:29:35 - INFO - TRAINING - Epoch: [103][100/196]	Time 0.119 (0.131)	Data 0.000 (0.021)	Loss 0.1143 (0.0929)	Prec@1 96.484 (96.945)	Prec@5 100.000 (99.973)
2022-06-17 18:29:37 - INFO - TRAINING - Epoch: [103][110/196]	Time 0.128 (0.130)	Data 0.000 (0.019)	Loss 0.0900 (0.0932)	Prec@1 96.875 (96.931)	Prec@5 100.000 (99.975)
2022-06-17 18:29:38 - INFO - TRAINING - Epoch: [103][120/196]	Time 0.106 (0.128)	Data 0.000 (0.018)	Loss 0.1348 (0.0925)	Prec@1 96.875 (96.962)	Prec@5 100.000 (99.977)
2022-06-17 18:29:39 - INFO - TRAINING - Epoch: [103][130/196]	Time 0.127 (0.127)	Data 0.000 (0.016)	Loss 0.0786 (0.0935)	Prec@1 98.047 (96.938)	Prec@5 100.000 (99.979)
2022-06-17 18:29:40 - INFO - TRAINING - Epoch: [103][140/196]	Time 0.103 (0.126)	Data 0.000 (0.015)	Loss 0.0848 (0.0940)	Prec@1 97.266 (96.908)	Prec@5 100.000 (99.975)
2022-06-17 18:29:41 - INFO - TRAINING - Epoch: [103][150/196]	Time 0.127 (0.126)	Data 0.000 (0.014)	Loss 0.0755 (0.0933)	Prec@1 97.656 (96.940)	Prec@5 100.000 (99.977)
2022-06-17 18:29:42 - INFO - TRAINING - Epoch: [103][160/196]	Time 0.107 (0.125)	Data 0.000 (0.013)	Loss 0.0797 (0.0934)	Prec@1 96.875 (96.911)	Prec@5 100.000 (99.978)
2022-06-17 18:29:43 - INFO - TRAINING - Epoch: [103][170/196]	Time 0.127 (0.124)	Data 0.000 (0.013)	Loss 0.1128 (0.0928)	Prec@1 94.531 (96.930)	Prec@5 100.000 (99.979)
2022-06-17 18:29:45 - INFO - TRAINING - Epoch: [103][180/196]	Time 0.122 (0.124)	Data 0.000 (0.012)	Loss 0.0644 (0.0926)	Prec@1 98.438 (96.935)	Prec@5 100.000 (99.981)
2022-06-17 18:29:46 - INFO - TRAINING - Epoch: [103][190/196]	Time 0.101 (0.123)	Data 0.000 (0.011)	Loss 0.0906 (0.0925)	Prec@1 97.656 (96.930)	Prec@5 100.000 (99.982)
2022-06-17 18:29:48 - INFO - EVALUATING - Epoch: [103][0/40]	Time 1.306 (1.306)	Data 1.261 (1.261)	Loss 0.2648 (0.2648)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:29:49 - INFO - EVALUATING - Epoch: [103][10/40]	Time 0.060 (0.219)	Data 0.000 (0.171)	Loss 0.4738 (0.4178)	Prec@1 88.281 (88.175)	Prec@5 99.219 (99.432)
2022-06-17 18:29:50 - INFO - EVALUATING - Epoch: [103][20/40]	Time 0.067 (0.166)	Data 0.000 (0.117)	Loss 0.3307 (0.4185)	Prec@1 87.500 (87.816)	Prec@5 100.000 (99.423)
2022-06-17 18:29:51 - INFO - EVALUATING - Epoch: [103][30/40]	Time 0.047 (0.145)	Data 0.000 (0.097)	Loss 0.5209 (0.4104)	Prec@1 86.328 (88.130)	Prec@5 100.000 (99.496)
2022-06-17 18:29:53 - INFO - 
 Epoch: 104	Training Loss 0.0929 	Training Prec@1 96.902 	Training Prec@5 99.982 	Validation Loss 0.4054 	Validation Prec@1 88.170 	Validation Prec@5 99.550 

2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:29:53 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:29:54 - INFO - TRAINING - Epoch: [104][0/196]	Time 1.428 (1.428)	Data 1.375 (1.375)	Loss 0.1038 (0.1038)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:29:56 - INFO - TRAINING - Epoch: [104][10/196]	Time 0.104 (0.286)	Data 0.000 (0.197)	Loss 0.0936 (0.1021)	Prec@1 96.875 (96.520)	Prec@5 100.000 (100.000)
2022-06-17 18:29:57 - INFO - TRAINING - Epoch: [104][20/196]	Time 0.134 (0.204)	Data 0.000 (0.104)	Loss 0.1166 (0.0955)	Prec@1 96.094 (96.763)	Prec@5 100.000 (100.000)
2022-06-17 18:29:58 - INFO - TRAINING - Epoch: [104][30/196]	Time 0.104 (0.175)	Data 0.000 (0.070)	Loss 0.0822 (0.0958)	Prec@1 97.266 (96.699)	Prec@5 100.000 (100.000)
2022-06-17 18:29:59 - INFO - TRAINING - Epoch: [104][40/196]	Time 0.137 (0.161)	Data 0.000 (0.053)	Loss 0.0997 (0.0929)	Prec@1 96.484 (96.885)	Prec@5 100.000 (99.990)
2022-06-17 18:30:00 - INFO - TRAINING - Epoch: [104][50/196]	Time 0.107 (0.153)	Data 0.000 (0.043)	Loss 0.0811 (0.0940)	Prec@1 96.875 (96.752)	Prec@5 100.000 (99.985)
2022-06-17 18:30:02 - INFO - TRAINING - Epoch: [104][60/196]	Time 0.125 (0.147)	Data 0.000 (0.036)	Loss 0.1146 (0.0957)	Prec@1 96.875 (96.747)	Prec@5 99.609 (99.968)
2022-06-17 18:30:03 - INFO - TRAINING - Epoch: [104][70/196]	Time 0.110 (0.142)	Data 0.000 (0.031)	Loss 0.1135 (0.0952)	Prec@1 95.312 (96.776)	Prec@5 99.609 (99.967)
2022-06-17 18:30:04 - INFO - TRAINING - Epoch: [104][80/196]	Time 0.119 (0.138)	Data 0.000 (0.027)	Loss 0.0875 (0.0945)	Prec@1 97.266 (96.769)	Prec@5 100.000 (99.971)
2022-06-17 18:30:05 - INFO - TRAINING - Epoch: [104][90/196]	Time 0.108 (0.136)	Data 0.000 (0.024)	Loss 0.1578 (0.0940)	Prec@1 94.531 (96.793)	Prec@5 99.609 (99.970)
2022-06-17 18:30:06 - INFO - TRAINING - Epoch: [104][100/196]	Time 0.103 (0.134)	Data 0.000 (0.022)	Loss 0.1241 (0.0943)	Prec@1 96.094 (96.740)	Prec@5 100.000 (99.973)
2022-06-17 18:30:07 - INFO - TRAINING - Epoch: [104][110/196]	Time 0.133 (0.132)	Data 0.000 (0.020)	Loss 0.0761 (0.0941)	Prec@1 98.828 (96.741)	Prec@5 100.000 (99.975)
2022-06-17 18:30:08 - INFO - TRAINING - Epoch: [104][120/196]	Time 0.106 (0.130)	Data 0.000 (0.018)	Loss 0.1002 (0.0945)	Prec@1 96.875 (96.730)	Prec@5 100.000 (99.974)
2022-06-17 18:30:10 - INFO - TRAINING - Epoch: [104][130/196]	Time 0.114 (0.129)	Data 0.000 (0.017)	Loss 0.1062 (0.0956)	Prec@1 95.312 (96.675)	Prec@5 100.000 (99.976)
2022-06-17 18:30:11 - INFO - TRAINING - Epoch: [104][140/196]	Time 0.120 (0.128)	Data 0.000 (0.016)	Loss 0.0599 (0.0959)	Prec@1 98.438 (96.645)	Prec@5 100.000 (99.978)
2022-06-17 18:30:12 - INFO - TRAINING - Epoch: [104][150/196]	Time 0.105 (0.127)	Data 0.000 (0.015)	Loss 0.0891 (0.0958)	Prec@1 97.266 (96.655)	Prec@5 100.000 (99.977)
2022-06-17 18:30:13 - INFO - TRAINING - Epoch: [104][160/196]	Time 0.125 (0.127)	Data 0.000 (0.014)	Loss 0.1070 (0.0957)	Prec@1 96.094 (96.661)	Prec@5 99.609 (99.976)
2022-06-17 18:30:14 - INFO - TRAINING - Epoch: [104][170/196]	Time 0.105 (0.126)	Data 0.000 (0.013)	Loss 0.0514 (0.0954)	Prec@1 98.828 (96.697)	Prec@5 100.000 (99.977)
2022-06-17 18:30:15 - INFO - TRAINING - Epoch: [104][180/196]	Time 0.109 (0.125)	Data 0.000 (0.012)	Loss 0.0965 (0.0959)	Prec@1 96.094 (96.674)	Prec@5 100.000 (99.978)
2022-06-17 18:30:16 - INFO - TRAINING - Epoch: [104][190/196]	Time 0.108 (0.124)	Data 0.000 (0.012)	Loss 0.0884 (0.0957)	Prec@1 96.484 (96.670)	Prec@5 100.000 (99.980)
2022-06-17 18:30:19 - INFO - EVALUATING - Epoch: [104][0/40]	Time 1.955 (1.955)	Data 1.909 (1.909)	Loss 0.2598 (0.2598)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:30:20 - INFO - EVALUATING - Epoch: [104][10/40]	Time 0.042 (0.280)	Data 0.000 (0.233)	Loss 0.4651 (0.4075)	Prec@1 88.672 (88.565)	Prec@5 99.219 (99.432)
2022-06-17 18:30:21 - INFO - EVALUATING - Epoch: [104][20/40]	Time 0.078 (0.172)	Data 0.037 (0.124)	Loss 0.3442 (0.4113)	Prec@1 86.719 (88.132)	Prec@5 100.000 (99.405)
2022-06-17 18:30:22 - INFO - EVALUATING - Epoch: [104][30/40]	Time 0.186 (0.157)	Data 0.142 (0.111)	Loss 0.5146 (0.4041)	Prec@1 85.938 (88.218)	Prec@5 100.000 (99.471)
2022-06-17 18:30:24 - INFO - 
 Epoch: 105	Training Loss 0.0954 	Training Prec@1 96.692 	Training Prec@5 99.980 	Validation Loss 0.3994 	Validation Prec@1 88.280 	Validation Prec@5 99.550 

2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:30:24 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:30:26 - INFO - TRAINING - Epoch: [105][0/196]	Time 2.014 (2.014)	Data 1.961 (1.961)	Loss 0.0757 (0.0757)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:30:28 - INFO - TRAINING - Epoch: [105][10/196]	Time 0.111 (0.293)	Data 0.000 (0.194)	Loss 0.0941 (0.0897)	Prec@1 97.656 (96.946)	Prec@5 100.000 (100.000)
2022-06-17 18:30:29 - INFO - TRAINING - Epoch: [105][20/196]	Time 0.113 (0.207)	Data 0.000 (0.102)	Loss 0.0999 (0.0928)	Prec@1 95.312 (96.633)	Prec@5 100.000 (100.000)
2022-06-17 18:30:30 - INFO - TRAINING - Epoch: [105][30/196]	Time 0.119 (0.179)	Data 0.000 (0.069)	Loss 0.1316 (0.0959)	Prec@1 96.484 (96.636)	Prec@5 100.000 (99.987)
2022-06-17 18:30:31 - INFO - TRAINING - Epoch: [105][40/196]	Time 0.106 (0.162)	Data 0.000 (0.052)	Loss 0.1379 (0.0978)	Prec@1 94.922 (96.475)	Prec@5 100.000 (99.981)
2022-06-17 18:30:32 - INFO - TRAINING - Epoch: [105][50/196]	Time 0.103 (0.153)	Data 0.000 (0.042)	Loss 0.1069 (0.0978)	Prec@1 96.094 (96.400)	Prec@5 100.000 (99.985)
2022-06-17 18:30:33 - INFO - TRAINING - Epoch: [105][60/196]	Time 0.130 (0.148)	Data 0.000 (0.035)	Loss 0.0994 (0.0974)	Prec@1 97.266 (96.420)	Prec@5 100.000 (99.987)
2022-06-17 18:30:34 - INFO - TRAINING - Epoch: [105][70/196]	Time 0.121 (0.143)	Data 0.000 (0.030)	Loss 0.0924 (0.0975)	Prec@1 96.875 (96.468)	Prec@5 100.000 (99.989)
2022-06-17 18:30:36 - INFO - TRAINING - Epoch: [105][80/196]	Time 0.103 (0.139)	Data 0.000 (0.027)	Loss 0.1060 (0.0972)	Prec@1 95.312 (96.465)	Prec@5 100.000 (99.986)
2022-06-17 18:30:37 - INFO - TRAINING - Epoch: [105][90/196]	Time 0.103 (0.137)	Data 0.000 (0.024)	Loss 0.1384 (0.0988)	Prec@1 94.922 (96.463)	Prec@5 100.000 (99.987)
2022-06-17 18:30:38 - INFO - TRAINING - Epoch: [105][100/196]	Time 0.117 (0.134)	Data 0.000 (0.021)	Loss 0.0821 (0.0984)	Prec@1 97.266 (96.508)	Prec@5 100.000 (99.985)
2022-06-17 18:30:39 - INFO - TRAINING - Epoch: [105][110/196]	Time 0.121 (0.133)	Data 0.000 (0.019)	Loss 0.0759 (0.0994)	Prec@1 98.047 (96.460)	Prec@5 99.609 (99.982)
2022-06-17 18:30:40 - INFO - TRAINING - Epoch: [105][120/196]	Time 0.105 (0.131)	Data 0.000 (0.018)	Loss 0.0765 (0.1002)	Prec@1 97.656 (96.436)	Prec@5 100.000 (99.981)
2022-06-17 18:30:41 - INFO - TRAINING - Epoch: [105][130/196]	Time 0.104 (0.129)	Data 0.000 (0.017)	Loss 0.0632 (0.0995)	Prec@1 98.438 (96.475)	Prec@5 100.000 (99.982)
2022-06-17 18:30:42 - INFO - TRAINING - Epoch: [105][140/196]	Time 0.112 (0.128)	Data 0.000 (0.015)	Loss 0.0876 (0.0984)	Prec@1 97.266 (96.537)	Prec@5 100.000 (99.983)
2022-06-17 18:30:44 - INFO - TRAINING - Epoch: [105][150/196]	Time 0.118 (0.127)	Data 0.000 (0.014)	Loss 0.1072 (0.0969)	Prec@1 95.312 (96.580)	Prec@5 100.000 (99.984)
2022-06-17 18:30:45 - INFO - TRAINING - Epoch: [105][160/196]	Time 0.103 (0.126)	Data 0.000 (0.014)	Loss 0.1147 (0.0974)	Prec@1 95.312 (96.572)	Prec@5 100.000 (99.985)
2022-06-17 18:30:46 - INFO - TRAINING - Epoch: [105][170/196]	Time 0.112 (0.126)	Data 0.000 (0.013)	Loss 0.0965 (0.0974)	Prec@1 94.922 (96.567)	Prec@5 100.000 (99.986)
2022-06-17 18:30:47 - INFO - TRAINING - Epoch: [105][180/196]	Time 0.111 (0.125)	Data 0.000 (0.012)	Loss 0.0684 (0.0973)	Prec@1 98.047 (96.558)	Prec@5 100.000 (99.987)
2022-06-17 18:30:48 - INFO - TRAINING - Epoch: [105][190/196]	Time 0.106 (0.124)	Data 0.000 (0.011)	Loss 0.0665 (0.0967)	Prec@1 97.656 (96.578)	Prec@5 100.000 (99.986)
2022-06-17 18:30:50 - INFO - EVALUATING - Epoch: [105][0/40]	Time 1.631 (1.631)	Data 1.586 (1.586)	Loss 0.2659 (0.2659)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:30:51 - INFO - EVALUATING - Epoch: [105][10/40]	Time 0.296 (0.252)	Data 0.252 (0.205)	Loss 0.4704 (0.4124)	Prec@1 87.109 (88.423)	Prec@5 99.219 (99.432)
2022-06-17 18:30:52 - INFO - EVALUATING - Epoch: [105][20/40]	Time 0.235 (0.178)	Data 0.190 (0.131)	Loss 0.3472 (0.4154)	Prec@1 87.109 (87.928)	Prec@5 100.000 (99.442)
2022-06-17 18:30:53 - INFO - EVALUATING - Epoch: [105][30/40]	Time 0.105 (0.153)	Data 0.063 (0.108)	Loss 0.5034 (0.4073)	Prec@1 86.328 (88.155)	Prec@5 100.000 (99.496)
2022-06-17 18:30:56 - INFO - 
 Epoch: 106	Training Loss 0.0969 	Training Prec@1 96.582 	Training Prec@5 99.984 	Validation Loss 0.4026 	Validation Prec@1 88.180 	Validation Prec@5 99.570 

2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:30:56 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:30:57 - INFO - TRAINING - Epoch: [106][0/196]	Time 1.763 (1.763)	Data 1.710 (1.710)	Loss 0.0465 (0.0465)	Prec@1 99.609 (99.609)	Prec@5 100.000 (100.000)
2022-06-17 18:30:59 - INFO - TRAINING - Epoch: [106][10/196]	Time 0.132 (0.271)	Data 0.000 (0.176)	Loss 0.0776 (0.0910)	Prec@1 97.656 (96.768)	Prec@5 100.000 (99.964)
2022-06-17 18:31:00 - INFO - TRAINING - Epoch: [106][20/196]	Time 0.103 (0.195)	Data 0.000 (0.092)	Loss 0.0813 (0.0882)	Prec@1 98.438 (96.838)	Prec@5 100.000 (99.981)
2022-06-17 18:31:01 - INFO - TRAINING - Epoch: [106][30/196]	Time 0.114 (0.168)	Data 0.000 (0.063)	Loss 0.1317 (0.0918)	Prec@1 96.484 (96.812)	Prec@5 99.609 (99.950)
2022-06-17 18:31:02 - INFO - TRAINING - Epoch: [106][40/196]	Time 0.108 (0.153)	Data 0.000 (0.047)	Loss 0.1163 (0.0932)	Prec@1 96.484 (96.799)	Prec@5 100.000 (99.943)
2022-06-17 18:31:03 - INFO - TRAINING - Epoch: [106][50/196]	Time 0.107 (0.145)	Data 0.000 (0.038)	Loss 0.0740 (0.0919)	Prec@1 97.656 (96.829)	Prec@5 100.000 (99.946)
2022-06-17 18:31:04 - INFO - TRAINING - Epoch: [106][60/196]	Time 0.107 (0.139)	Data 0.000 (0.032)	Loss 0.1547 (0.0936)	Prec@1 94.531 (96.766)	Prec@5 100.000 (99.955)
2022-06-17 18:31:05 - INFO - TRAINING - Epoch: [106][70/196]	Time 0.102 (0.134)	Data 0.000 (0.027)	Loss 0.1077 (0.0944)	Prec@1 95.312 (96.704)	Prec@5 100.000 (99.961)
2022-06-17 18:31:06 - INFO - TRAINING - Epoch: [106][80/196]	Time 0.109 (0.131)	Data 0.000 (0.024)	Loss 0.0688 (0.0948)	Prec@1 97.656 (96.682)	Prec@5 100.000 (99.966)
2022-06-17 18:31:07 - INFO - TRAINING - Epoch: [106][90/196]	Time 0.105 (0.129)	Data 0.000 (0.021)	Loss 0.0978 (0.0939)	Prec@1 96.484 (96.729)	Prec@5 100.000 (99.970)
2022-06-17 18:31:08 - INFO - TRAINING - Epoch: [106][100/196]	Time 0.102 (0.127)	Data 0.000 (0.019)	Loss 0.1100 (0.0929)	Prec@1 96.484 (96.774)	Prec@5 99.609 (99.969)
2022-06-17 18:31:10 - INFO - TRAINING - Epoch: [106][110/196]	Time 0.115 (0.126)	Data 0.000 (0.018)	Loss 0.1033 (0.0936)	Prec@1 95.703 (96.713)	Prec@5 100.000 (99.972)
2022-06-17 18:31:11 - INFO - TRAINING - Epoch: [106][120/196]	Time 0.109 (0.125)	Data 0.000 (0.016)	Loss 0.1132 (0.0942)	Prec@1 97.266 (96.726)	Prec@5 100.000 (99.971)
2022-06-17 18:31:12 - INFO - TRAINING - Epoch: [106][130/196]	Time 0.109 (0.123)	Data 0.000 (0.015)	Loss 0.0755 (0.0943)	Prec@1 96.875 (96.711)	Prec@5 100.000 (99.973)
2022-06-17 18:31:13 - INFO - TRAINING - Epoch: [106][140/196]	Time 0.102 (0.122)	Data 0.000 (0.014)	Loss 0.0982 (0.0950)	Prec@1 96.484 (96.673)	Prec@5 100.000 (99.975)
2022-06-17 18:31:14 - INFO - TRAINING - Epoch: [106][150/196]	Time 0.111 (0.121)	Data 0.000 (0.013)	Loss 0.0798 (0.0948)	Prec@1 98.047 (96.686)	Prec@5 100.000 (99.974)
2022-06-17 18:31:15 - INFO - TRAINING - Epoch: [106][160/196]	Time 0.119 (0.121)	Data 0.000 (0.012)	Loss 0.0881 (0.0943)	Prec@1 97.266 (96.720)	Prec@5 100.000 (99.976)
2022-06-17 18:31:16 - INFO - TRAINING - Epoch: [106][170/196]	Time 0.126 (0.120)	Data 0.000 (0.012)	Loss 0.0917 (0.0941)	Prec@1 96.875 (96.729)	Prec@5 99.609 (99.973)
2022-06-17 18:31:17 - INFO - TRAINING - Epoch: [106][180/196]	Time 0.115 (0.120)	Data 0.000 (0.011)	Loss 0.0887 (0.0937)	Prec@1 96.484 (96.739)	Prec@5 100.000 (99.972)
2022-06-17 18:31:18 - INFO - TRAINING - Epoch: [106][190/196]	Time 0.103 (0.120)	Data 0.000 (0.010)	Loss 0.0597 (0.0927)	Prec@1 98.438 (96.781)	Prec@5 100.000 (99.973)
2022-06-17 18:31:21 - INFO - EVALUATING - Epoch: [106][0/40]	Time 1.675 (1.675)	Data 1.629 (1.629)	Loss 0.2648 (0.2648)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:31:22 - INFO - EVALUATING - Epoch: [106][10/40]	Time 0.045 (0.226)	Data 0.000 (0.176)	Loss 0.4759 (0.4103)	Prec@1 86.719 (88.175)	Prec@5 99.219 (99.432)
2022-06-17 18:31:23 - INFO - EVALUATING - Epoch: [106][20/40]	Time 0.042 (0.163)	Data 0.001 (0.112)	Loss 0.3407 (0.4129)	Prec@1 87.500 (87.891)	Prec@5 100.000 (99.423)
2022-06-17 18:31:24 - INFO - EVALUATING - Epoch: [106][30/40]	Time 0.091 (0.143)	Data 0.047 (0.094)	Loss 0.4981 (0.4046)	Prec@1 85.938 (88.080)	Prec@5 100.000 (99.483)
2022-06-17 18:31:26 - INFO - 
 Epoch: 107	Training Loss 0.0931 	Training Prec@1 96.770 	Training Prec@5 99.974 	Validation Loss 0.4008 	Validation Prec@1 88.110 	Validation Prec@5 99.560 

2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:31:26 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:31:27 - INFO - TRAINING - Epoch: [107][0/196]	Time 1.524 (1.524)	Data 1.470 (1.470)	Loss 0.0794 (0.0794)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:31:29 - INFO - TRAINING - Epoch: [107][10/196]	Time 0.132 (0.283)	Data 0.000 (0.187)	Loss 0.0964 (0.0840)	Prec@1 96.875 (97.195)	Prec@5 100.000 (100.000)
2022-06-17 18:31:30 - INFO - TRAINING - Epoch: [107][20/196]	Time 0.133 (0.206)	Data 0.000 (0.098)	Loss 0.0792 (0.0895)	Prec@1 97.656 (96.875)	Prec@5 100.000 (99.963)
2022-06-17 18:31:31 - INFO - TRAINING - Epoch: [107][30/196]	Time 0.106 (0.177)	Data 0.000 (0.067)	Loss 0.0665 (0.0930)	Prec@1 97.656 (96.799)	Prec@5 100.000 (99.962)
2022-06-17 18:31:32 - INFO - TRAINING - Epoch: [107][40/196]	Time 0.129 (0.162)	Data 0.000 (0.051)	Loss 0.0857 (0.0920)	Prec@1 97.266 (96.770)	Prec@5 100.000 (99.971)
2022-06-17 18:31:33 - INFO - TRAINING - Epoch: [107][50/196]	Time 0.124 (0.154)	Data 0.000 (0.041)	Loss 0.1152 (0.0960)	Prec@1 94.922 (96.599)	Prec@5 100.000 (99.969)
2022-06-17 18:31:35 - INFO - TRAINING - Epoch: [107][60/196]	Time 0.115 (0.148)	Data 0.000 (0.034)	Loss 0.0931 (0.0949)	Prec@1 97.266 (96.632)	Prec@5 100.000 (99.974)
2022-06-17 18:31:36 - INFO - TRAINING - Epoch: [107][70/196]	Time 0.105 (0.143)	Data 0.000 (0.029)	Loss 0.1282 (0.0942)	Prec@1 96.094 (96.649)	Prec@5 100.000 (99.978)
2022-06-17 18:31:37 - INFO - TRAINING - Epoch: [107][80/196]	Time 0.121 (0.140)	Data 0.000 (0.026)	Loss 0.0972 (0.0938)	Prec@1 96.875 (96.721)	Prec@5 100.000 (99.981)
2022-06-17 18:31:38 - INFO - TRAINING - Epoch: [107][90/196]	Time 0.109 (0.138)	Data 0.000 (0.023)	Loss 0.1077 (0.0929)	Prec@1 96.484 (96.772)	Prec@5 100.000 (99.983)
2022-06-17 18:31:39 - INFO - TRAINING - Epoch: [107][100/196]	Time 0.119 (0.136)	Data 0.000 (0.021)	Loss 0.1181 (0.0926)	Prec@1 95.703 (96.774)	Prec@5 100.000 (99.981)
2022-06-17 18:31:41 - INFO - TRAINING - Epoch: [107][110/196]	Time 0.106 (0.135)	Data 0.000 (0.019)	Loss 0.0983 (0.0919)	Prec@1 96.094 (96.784)	Prec@5 100.000 (99.982)
2022-06-17 18:31:42 - INFO - TRAINING - Epoch: [107][120/196]	Time 0.132 (0.134)	Data 0.000 (0.017)	Loss 0.0944 (0.0923)	Prec@1 96.484 (96.756)	Prec@5 100.000 (99.984)
2022-06-17 18:31:43 - INFO - TRAINING - Epoch: [107][130/196]	Time 0.127 (0.133)	Data 0.000 (0.016)	Loss 0.1073 (0.0937)	Prec@1 96.875 (96.702)	Prec@5 100.000 (99.982)
2022-06-17 18:31:44 - INFO - TRAINING - Epoch: [107][140/196]	Time 0.119 (0.132)	Data 0.000 (0.015)	Loss 0.0873 (0.0936)	Prec@1 96.875 (96.709)	Prec@5 100.000 (99.981)
2022-06-17 18:31:45 - INFO - TRAINING - Epoch: [107][150/196]	Time 0.106 (0.131)	Data 0.000 (0.014)	Loss 0.0961 (0.0928)	Prec@1 97.266 (96.746)	Prec@5 100.000 (99.982)
2022-06-17 18:31:47 - INFO - TRAINING - Epoch: [107][160/196]	Time 0.124 (0.130)	Data 0.000 (0.013)	Loss 0.0857 (0.0921)	Prec@1 97.266 (96.763)	Prec@5 99.609 (99.981)
2022-06-17 18:31:48 - INFO - TRAINING - Epoch: [107][170/196]	Time 0.120 (0.129)	Data 0.000 (0.012)	Loss 0.1021 (0.0920)	Prec@1 94.922 (96.774)	Prec@5 100.000 (99.979)
2022-06-17 18:31:49 - INFO - TRAINING - Epoch: [107][180/196]	Time 0.114 (0.129)	Data 0.000 (0.012)	Loss 0.1086 (0.0930)	Prec@1 95.312 (96.733)	Prec@5 100.000 (99.976)
2022-06-17 18:31:50 - INFO - TRAINING - Epoch: [107][190/196]	Time 0.102 (0.128)	Data 0.000 (0.011)	Loss 0.1106 (0.0923)	Prec@1 96.094 (96.760)	Prec@5 100.000 (99.978)
2022-06-17 18:31:52 - INFO - EVALUATING - Epoch: [107][0/40]	Time 1.526 (1.526)	Data 1.480 (1.480)	Loss 0.2670 (0.2670)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:31:54 - INFO - EVALUATING - Epoch: [107][10/40]	Time 0.065 (0.266)	Data 0.000 (0.216)	Loss 0.4688 (0.4128)	Prec@1 88.281 (88.317)	Prec@5 99.219 (99.432)
2022-06-17 18:31:54 - INFO - EVALUATING - Epoch: [107][20/40]	Time 0.114 (0.169)	Data 0.072 (0.120)	Loss 0.3382 (0.4156)	Prec@1 87.500 (88.039)	Prec@5 100.000 (99.442)
2022-06-17 18:31:55 - INFO - EVALUATING - Epoch: [107][30/40]	Time 0.057 (0.151)	Data 0.000 (0.103)	Loss 0.5127 (0.4083)	Prec@1 85.156 (88.155)	Prec@5 100.000 (99.496)
2022-06-17 18:31:57 - INFO - 
 Epoch: 108	Training Loss 0.0922 	Training Prec@1 96.768 	Training Prec@5 99.976 	Validation Loss 0.4039 	Validation Prec@1 88.170 	Validation Prec@5 99.570 

2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:31:57 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:31:59 - INFO - TRAINING - Epoch: [108][0/196]	Time 1.709 (1.709)	Data 1.652 (1.652)	Loss 0.1003 (0.1003)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:32:00 - INFO - TRAINING - Epoch: [108][10/196]	Time 0.114 (0.258)	Data 0.000 (0.166)	Loss 0.0976 (0.0876)	Prec@1 96.875 (96.911)	Prec@5 100.000 (100.000)
2022-06-17 18:32:01 - INFO - TRAINING - Epoch: [108][20/196]	Time 0.123 (0.189)	Data 0.000 (0.087)	Loss 0.0574 (0.0867)	Prec@1 99.219 (97.024)	Prec@5 100.000 (100.000)
2022-06-17 18:32:02 - INFO - TRAINING - Epoch: [108][30/196]	Time 0.119 (0.166)	Data 0.000 (0.059)	Loss 0.0814 (0.0870)	Prec@1 97.266 (97.064)	Prec@5 100.000 (100.000)
2022-06-17 18:32:04 - INFO - TRAINING - Epoch: [108][40/196]	Time 0.112 (0.154)	Data 0.000 (0.045)	Loss 0.0751 (0.0860)	Prec@1 97.656 (97.170)	Prec@5 99.609 (99.990)
2022-06-17 18:32:05 - INFO - TRAINING - Epoch: [108][50/196]	Time 0.120 (0.147)	Data 0.000 (0.036)	Loss 0.0813 (0.0873)	Prec@1 96.875 (97.112)	Prec@5 100.000 (99.985)
2022-06-17 18:32:06 - INFO - TRAINING - Epoch: [108][60/196]	Time 0.123 (0.143)	Data 0.000 (0.030)	Loss 0.0828 (0.0874)	Prec@1 96.484 (97.125)	Prec@5 100.000 (99.987)
2022-06-17 18:32:07 - INFO - TRAINING - Epoch: [108][70/196]	Time 0.124 (0.140)	Data 0.000 (0.026)	Loss 0.0738 (0.0880)	Prec@1 96.875 (97.095)	Prec@5 100.000 (99.983)
2022-06-17 18:32:08 - INFO - TRAINING - Epoch: [108][80/196]	Time 0.105 (0.137)	Data 0.000 (0.023)	Loss 0.0985 (0.0880)	Prec@1 96.484 (97.078)	Prec@5 100.000 (99.986)
2022-06-17 18:32:10 - INFO - TRAINING - Epoch: [108][90/196]	Time 0.115 (0.135)	Data 0.000 (0.020)	Loss 0.0804 (0.0884)	Prec@1 97.656 (97.094)	Prec@5 100.000 (99.983)
2022-06-17 18:32:11 - INFO - TRAINING - Epoch: [108][100/196]	Time 0.112 (0.133)	Data 0.000 (0.018)	Loss 0.0998 (0.0900)	Prec@1 96.484 (97.026)	Prec@5 100.000 (99.981)
2022-06-17 18:32:12 - INFO - TRAINING - Epoch: [108][110/196]	Time 0.124 (0.132)	Data 0.000 (0.017)	Loss 0.1594 (0.0911)	Prec@1 94.922 (96.949)	Prec@5 100.000 (99.982)
2022-06-17 18:32:13 - INFO - TRAINING - Epoch: [108][120/196]	Time 0.129 (0.131)	Data 0.000 (0.015)	Loss 0.1568 (0.0915)	Prec@1 95.312 (96.933)	Prec@5 100.000 (99.984)
2022-06-17 18:32:14 - INFO - TRAINING - Epoch: [108][130/196]	Time 0.127 (0.130)	Data 0.000 (0.014)	Loss 0.0810 (0.0909)	Prec@1 96.484 (96.964)	Prec@5 100.000 (99.982)
2022-06-17 18:32:15 - INFO - TRAINING - Epoch: [108][140/196]	Time 0.120 (0.129)	Data 0.000 (0.013)	Loss 0.0731 (0.0905)	Prec@1 96.484 (96.947)	Prec@5 100.000 (99.983)
2022-06-17 18:32:17 - INFO - TRAINING - Epoch: [108][150/196]	Time 0.115 (0.128)	Data 0.000 (0.012)	Loss 0.1108 (0.0901)	Prec@1 96.094 (96.955)	Prec@5 100.000 (99.982)
2022-06-17 18:32:18 - INFO - TRAINING - Epoch: [108][160/196]	Time 0.120 (0.128)	Data 0.000 (0.012)	Loss 0.0922 (0.0913)	Prec@1 96.875 (96.894)	Prec@5 100.000 (99.983)
2022-06-17 18:32:19 - INFO - TRAINING - Epoch: [108][170/196]	Time 0.128 (0.128)	Data 0.000 (0.011)	Loss 0.1337 (0.0921)	Prec@1 95.703 (96.868)	Prec@5 100.000 (99.984)
2022-06-17 18:32:20 - INFO - TRAINING - Epoch: [108][180/196]	Time 0.103 (0.127)	Data 0.000 (0.010)	Loss 0.0715 (0.0920)	Prec@1 98.047 (96.858)	Prec@5 100.000 (99.985)
2022-06-17 18:32:21 - INFO - TRAINING - Epoch: [108][190/196]	Time 0.105 (0.126)	Data 0.000 (0.010)	Loss 0.0984 (0.0924)	Prec@1 96.875 (96.846)	Prec@5 100.000 (99.986)
2022-06-17 18:32:24 - INFO - EVALUATING - Epoch: [108][0/40]	Time 1.655 (1.655)	Data 1.609 (1.609)	Loss 0.2601 (0.2601)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:32:25 - INFO - EVALUATING - Epoch: [108][10/40]	Time 0.043 (0.263)	Data 0.000 (0.217)	Loss 0.4718 (0.4124)	Prec@1 88.281 (88.033)	Prec@5 99.219 (99.467)
2022-06-17 18:32:26 - INFO - EVALUATING - Epoch: [108][20/40]	Time 0.132 (0.169)	Data 0.091 (0.122)	Loss 0.3394 (0.4148)	Prec@1 87.109 (87.760)	Prec@5 100.000 (99.423)
2022-06-17 18:32:27 - INFO - EVALUATING - Epoch: [108][30/40]	Time 0.092 (0.149)	Data 0.049 (0.103)	Loss 0.4949 (0.4065)	Prec@1 85.547 (88.017)	Prec@5 100.000 (99.471)
2022-06-17 18:32:29 - INFO - 
 Epoch: 109	Training Loss 0.0921 	Training Prec@1 96.852 	Training Prec@5 99.986 	Validation Loss 0.4016 	Validation Prec@1 88.070 	Validation Prec@5 99.540 

2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:32:29 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:32:30 - INFO - TRAINING - Epoch: [109][0/196]	Time 1.827 (1.827)	Data 1.774 (1.774)	Loss 0.0892 (0.0892)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:32:32 - INFO - TRAINING - Epoch: [109][10/196]	Time 0.109 (0.280)	Data 0.000 (0.179)	Loss 0.0836 (0.0949)	Prec@1 96.484 (96.839)	Prec@5 100.000 (99.929)
2022-06-17 18:32:33 - INFO - TRAINING - Epoch: [109][20/196]	Time 0.104 (0.200)	Data 0.000 (0.094)	Loss 0.0905 (0.0928)	Prec@1 96.875 (96.745)	Prec@5 100.000 (99.963)
2022-06-17 18:32:34 - INFO - TRAINING - Epoch: [109][30/196]	Time 0.126 (0.174)	Data 0.000 (0.064)	Loss 0.0746 (0.0943)	Prec@1 98.047 (96.623)	Prec@5 100.000 (99.962)
2022-06-17 18:32:35 - INFO - TRAINING - Epoch: [109][40/196]	Time 0.119 (0.160)	Data 0.000 (0.048)	Loss 0.1224 (0.0932)	Prec@1 96.484 (96.656)	Prec@5 100.000 (99.971)
2022-06-17 18:32:36 - INFO - TRAINING - Epoch: [109][50/196]	Time 0.126 (0.153)	Data 0.000 (0.039)	Loss 0.0759 (0.0915)	Prec@1 98.438 (96.745)	Prec@5 100.000 (99.969)
2022-06-17 18:32:38 - INFO - TRAINING - Epoch: [109][60/196]	Time 0.125 (0.148)	Data 0.000 (0.033)	Loss 0.1348 (0.0932)	Prec@1 94.922 (96.696)	Prec@5 100.000 (99.968)
2022-06-17 18:32:39 - INFO - TRAINING - Epoch: [109][70/196]	Time 0.125 (0.144)	Data 0.000 (0.028)	Loss 0.0877 (0.0924)	Prec@1 96.094 (96.759)	Prec@5 100.000 (99.972)
2022-06-17 18:32:40 - INFO - TRAINING - Epoch: [109][80/196]	Time 0.104 (0.141)	Data 0.000 (0.025)	Loss 0.1012 (0.0924)	Prec@1 96.875 (96.788)	Prec@5 100.000 (99.976)
2022-06-17 18:32:41 - INFO - TRAINING - Epoch: [109][90/196]	Time 0.128 (0.139)	Data 0.000 (0.022)	Loss 0.1289 (0.0929)	Prec@1 94.141 (96.763)	Prec@5 100.000 (99.979)
2022-06-17 18:32:42 - INFO - TRAINING - Epoch: [109][100/196]	Time 0.110 (0.137)	Data 0.000 (0.020)	Loss 0.1092 (0.0922)	Prec@1 95.703 (96.840)	Prec@5 100.000 (99.973)
2022-06-17 18:32:44 - INFO - TRAINING - Epoch: [109][110/196]	Time 0.124 (0.136)	Data 0.000 (0.018)	Loss 0.1161 (0.0908)	Prec@1 95.312 (96.882)	Prec@5 100.000 (99.975)
2022-06-17 18:32:45 - INFO - TRAINING - Epoch: [109][120/196]	Time 0.130 (0.135)	Data 0.000 (0.017)	Loss 0.0722 (0.0899)	Prec@1 97.656 (96.917)	Prec@5 100.000 (99.977)
2022-06-17 18:32:46 - INFO - TRAINING - Epoch: [109][130/196]	Time 0.123 (0.133)	Data 0.000 (0.015)	Loss 0.0902 (0.0903)	Prec@1 96.094 (96.890)	Prec@5 100.000 (99.979)
2022-06-17 18:32:47 - INFO - TRAINING - Epoch: [109][140/196]	Time 0.111 (0.133)	Data 0.000 (0.014)	Loss 0.0714 (0.0909)	Prec@1 97.266 (96.847)	Prec@5 100.000 (99.975)
2022-06-17 18:32:48 - INFO - TRAINING - Epoch: [109][150/196]	Time 0.105 (0.132)	Data 0.000 (0.013)	Loss 0.0909 (0.0914)	Prec@1 96.484 (96.849)	Prec@5 100.000 (99.977)
2022-06-17 18:32:50 - INFO - TRAINING - Epoch: [109][160/196]	Time 0.136 (0.131)	Data 0.000 (0.013)	Loss 0.1577 (0.0918)	Prec@1 94.141 (96.846)	Prec@5 100.000 (99.978)
2022-06-17 18:32:51 - INFO - TRAINING - Epoch: [109][170/196]	Time 0.131 (0.130)	Data 0.000 (0.012)	Loss 0.0769 (0.0914)	Prec@1 98.047 (96.877)	Prec@5 100.000 (99.979)
2022-06-17 18:32:52 - INFO - TRAINING - Epoch: [109][180/196]	Time 0.120 (0.130)	Data 0.000 (0.011)	Loss 0.0775 (0.0903)	Prec@1 97.266 (96.929)	Prec@5 100.000 (99.981)
2022-06-17 18:32:53 - INFO - TRAINING - Epoch: [109][190/196]	Time 0.102 (0.129)	Data 0.000 (0.011)	Loss 0.0775 (0.0905)	Prec@1 97.266 (96.926)	Prec@5 100.000 (99.980)
2022-06-17 18:32:56 - INFO - EVALUATING - Epoch: [109][0/40]	Time 1.693 (1.693)	Data 1.648 (1.648)	Loss 0.2615 (0.2615)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:32:57 - INFO - EVALUATING - Epoch: [109][10/40]	Time 0.263 (0.258)	Data 0.218 (0.213)	Loss 0.4755 (0.4115)	Prec@1 87.891 (88.494)	Prec@5 99.219 (99.396)
2022-06-17 18:32:57 - INFO - EVALUATING - Epoch: [109][20/40]	Time 0.107 (0.171)	Data 0.067 (0.124)	Loss 0.3456 (0.4140)	Prec@1 87.109 (88.039)	Prec@5 100.000 (99.368)
2022-06-17 18:32:59 - INFO - EVALUATING - Epoch: [109][30/40]	Time 0.176 (0.153)	Data 0.133 (0.107)	Loss 0.4973 (0.4060)	Prec@1 86.328 (88.269)	Prec@5 100.000 (99.446)
2022-06-17 18:33:01 - INFO - 
 Epoch: 110	Training Loss 0.0907 	Training Prec@1 96.912 	Training Prec@5 99.980 	Validation Loss 0.4009 	Validation Prec@1 88.330 	Validation Prec@5 99.530 

2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:33:01 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:33:03 - INFO - TRAINING - Epoch: [110][0/196]	Time 1.724 (1.724)	Data 1.670 (1.670)	Loss 0.1051 (0.1051)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2022-06-17 18:33:04 - INFO - TRAINING - Epoch: [110][10/196]	Time 0.101 (0.262)	Data 0.000 (0.158)	Loss 0.0741 (0.0819)	Prec@1 98.047 (97.088)	Prec@5 100.000 (99.964)
2022-06-17 18:33:05 - INFO - TRAINING - Epoch: [110][20/196]	Time 0.113 (0.193)	Data 0.000 (0.083)	Loss 0.0855 (0.0845)	Prec@1 96.875 (97.154)	Prec@5 100.000 (99.981)
2022-06-17 18:33:06 - INFO - TRAINING - Epoch: [110][30/196]	Time 0.109 (0.168)	Data 0.000 (0.056)	Loss 0.0945 (0.0807)	Prec@1 97.656 (97.366)	Prec@5 100.000 (99.987)
2022-06-17 18:33:07 - INFO - TRAINING - Epoch: [110][40/196]	Time 0.119 (0.154)	Data 0.000 (0.043)	Loss 0.0681 (0.0802)	Prec@1 97.266 (97.418)	Prec@5 100.000 (99.981)
2022-06-17 18:33:08 - INFO - TRAINING - Epoch: [110][50/196]	Time 0.116 (0.146)	Data 0.000 (0.034)	Loss 0.0864 (0.0821)	Prec@1 97.266 (97.312)	Prec@5 100.000 (99.985)
2022-06-17 18:33:10 - INFO - TRAINING - Epoch: [110][60/196]	Time 0.107 (0.140)	Data 0.000 (0.029)	Loss 0.1213 (0.0852)	Prec@1 95.703 (97.195)	Prec@5 100.000 (99.981)
2022-06-17 18:33:11 - INFO - TRAINING - Epoch: [110][70/196]	Time 0.106 (0.136)	Data 0.000 (0.025)	Loss 0.1054 (0.0867)	Prec@1 96.484 (97.095)	Prec@5 100.000 (99.978)
2022-06-17 18:33:12 - INFO - TRAINING - Epoch: [110][80/196]	Time 0.121 (0.133)	Data 0.000 (0.022)	Loss 0.1234 (0.0892)	Prec@1 96.094 (96.962)	Prec@5 100.000 (99.971)
2022-06-17 18:33:13 - INFO - TRAINING - Epoch: [110][90/196]	Time 0.103 (0.131)	Data 0.000 (0.019)	Loss 0.1382 (0.0884)	Prec@1 95.312 (96.995)	Prec@5 99.609 (99.970)
2022-06-17 18:33:14 - INFO - TRAINING - Epoch: [110][100/196]	Time 0.108 (0.129)	Data 0.000 (0.018)	Loss 0.1058 (0.0881)	Prec@1 96.484 (96.995)	Prec@5 100.000 (99.973)
2022-06-17 18:33:15 - INFO - TRAINING - Epoch: [110][110/196]	Time 0.125 (0.127)	Data 0.000 (0.016)	Loss 0.0806 (0.0888)	Prec@1 97.656 (96.963)	Prec@5 100.000 (99.975)
2022-06-17 18:33:16 - INFO - TRAINING - Epoch: [110][120/196]	Time 0.102 (0.126)	Data 0.000 (0.015)	Loss 0.1393 (0.0902)	Prec@1 94.141 (96.914)	Prec@5 100.000 (99.977)
2022-06-17 18:33:17 - INFO - TRAINING - Epoch: [110][130/196]	Time 0.109 (0.126)	Data 0.000 (0.014)	Loss 0.0822 (0.0905)	Prec@1 97.266 (96.908)	Prec@5 100.000 (99.979)
2022-06-17 18:33:19 - INFO - TRAINING - Epoch: [110][140/196]	Time 0.111 (0.125)	Data 0.000 (0.013)	Loss 0.0782 (0.0907)	Prec@1 97.656 (96.914)	Prec@5 100.000 (99.981)
2022-06-17 18:33:20 - INFO - TRAINING - Epoch: [110][150/196]	Time 0.104 (0.124)	Data 0.000 (0.012)	Loss 0.0715 (0.0908)	Prec@1 97.266 (96.888)	Prec@5 100.000 (99.982)
2022-06-17 18:33:21 - INFO - TRAINING - Epoch: [110][160/196]	Time 0.126 (0.124)	Data 0.000 (0.011)	Loss 0.0815 (0.0910)	Prec@1 97.656 (96.899)	Prec@5 100.000 (99.981)
2022-06-17 18:33:22 - INFO - TRAINING - Epoch: [110][170/196]	Time 0.120 (0.123)	Data 0.000 (0.010)	Loss 0.0887 (0.0909)	Prec@1 96.875 (96.891)	Prec@5 100.000 (99.982)
2022-06-17 18:33:23 - INFO - TRAINING - Epoch: [110][180/196]	Time 0.114 (0.123)	Data 0.000 (0.010)	Loss 0.0832 (0.0909)	Prec@1 98.047 (96.905)	Prec@5 100.000 (99.981)
2022-06-17 18:33:24 - INFO - TRAINING - Epoch: [110][190/196]	Time 0.101 (0.122)	Data 0.000 (0.009)	Loss 0.0954 (0.0913)	Prec@1 95.703 (96.887)	Prec@5 100.000 (99.982)
2022-06-17 18:33:27 - INFO - EVALUATING - Epoch: [110][0/40]	Time 1.671 (1.671)	Data 1.625 (1.625)	Loss 0.2594 (0.2594)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:33:28 - INFO - EVALUATING - Epoch: [110][10/40]	Time 0.059 (0.260)	Data 0.000 (0.210)	Loss 0.4752 (0.4145)	Prec@1 87.500 (88.175)	Prec@5 99.219 (99.467)
2022-06-17 18:33:29 - INFO - EVALUATING - Epoch: [110][20/40]	Time 0.123 (0.173)	Data 0.080 (0.123)	Loss 0.3386 (0.4161)	Prec@1 87.500 (87.909)	Prec@5 100.000 (99.442)
2022-06-17 18:33:30 - INFO - EVALUATING - Epoch: [110][30/40]	Time 0.044 (0.156)	Data 0.000 (0.108)	Loss 0.5071 (0.4079)	Prec@1 85.938 (88.143)	Prec@5 100.000 (99.483)
2022-06-17 18:33:32 - INFO - 
 Epoch: 111	Training Loss 0.0913 	Training Prec@1 96.892 	Training Prec@5 99.982 	Validation Loss 0.4027 	Validation Prec@1 88.200 	Validation Prec@5 99.560 

2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:33:32 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:33:33 - INFO - TRAINING - Epoch: [111][0/196]	Time 1.488 (1.488)	Data 1.433 (1.433)	Loss 0.0884 (0.0884)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:33:34 - INFO - TRAINING - Epoch: [111][10/196]	Time 0.113 (0.241)	Data 0.066 (0.149)	Loss 0.1167 (0.0957)	Prec@1 96.094 (96.520)	Prec@5 100.000 (99.964)
2022-06-17 18:33:35 - INFO - TRAINING - Epoch: [111][20/196]	Time 0.124 (0.180)	Data 0.000 (0.080)	Loss 0.0992 (0.0914)	Prec@1 96.484 (96.782)	Prec@5 100.000 (99.963)
2022-06-17 18:33:37 - INFO - TRAINING - Epoch: [111][30/196]	Time 0.104 (0.158)	Data 0.000 (0.054)	Loss 0.0897 (0.0920)	Prec@1 97.266 (96.837)	Prec@5 100.000 (99.975)
2022-06-17 18:33:38 - INFO - TRAINING - Epoch: [111][40/196]	Time 0.110 (0.147)	Data 0.000 (0.041)	Loss 0.0735 (0.0928)	Prec@1 97.266 (96.865)	Prec@5 100.000 (99.971)
2022-06-17 18:33:39 - INFO - TRAINING - Epoch: [111][50/196]	Time 0.103 (0.140)	Data 0.000 (0.033)	Loss 0.0755 (0.0917)	Prec@1 97.656 (96.890)	Prec@5 100.000 (99.977)
2022-06-17 18:33:40 - INFO - TRAINING - Epoch: [111][60/196]	Time 0.121 (0.136)	Data 0.000 (0.028)	Loss 0.0691 (0.0933)	Prec@1 97.656 (96.766)	Prec@5 100.000 (99.974)
2022-06-17 18:33:41 - INFO - TRAINING - Epoch: [111][70/196]	Time 0.108 (0.133)	Data 0.000 (0.024)	Loss 0.0823 (0.0928)	Prec@1 97.656 (96.820)	Prec@5 100.000 (99.978)
2022-06-17 18:33:42 - INFO - TRAINING - Epoch: [111][80/196]	Time 0.118 (0.130)	Data 0.000 (0.021)	Loss 0.0659 (0.0915)	Prec@1 98.047 (96.938)	Prec@5 100.000 (99.981)
2022-06-17 18:33:43 - INFO - TRAINING - Epoch: [111][90/196]	Time 0.117 (0.129)	Data 0.000 (0.019)	Loss 0.1138 (0.0918)	Prec@1 96.875 (96.939)	Prec@5 100.000 (99.983)
2022-06-17 18:33:44 - INFO - TRAINING - Epoch: [111][100/196]	Time 0.131 (0.127)	Data 0.000 (0.017)	Loss 0.0975 (0.0922)	Prec@1 96.875 (96.887)	Prec@5 100.000 (99.985)
2022-06-17 18:33:46 - INFO - TRAINING - Epoch: [111][110/196]	Time 0.107 (0.126)	Data 0.000 (0.015)	Loss 0.0853 (0.0920)	Prec@1 98.047 (96.914)	Prec@5 100.000 (99.986)
2022-06-17 18:33:47 - INFO - TRAINING - Epoch: [111][120/196]	Time 0.107 (0.125)	Data 0.000 (0.014)	Loss 0.1169 (0.0921)	Prec@1 94.922 (96.907)	Prec@5 100.000 (99.987)
2022-06-17 18:33:48 - INFO - TRAINING - Epoch: [111][130/196]	Time 0.103 (0.123)	Data 0.000 (0.013)	Loss 0.1153 (0.0912)	Prec@1 97.656 (96.941)	Prec@5 100.000 (99.988)
2022-06-17 18:33:49 - INFO - TRAINING - Epoch: [111][140/196]	Time 0.131 (0.123)	Data 0.000 (0.012)	Loss 0.1042 (0.0911)	Prec@1 96.094 (96.953)	Prec@5 99.609 (99.986)
2022-06-17 18:33:50 - INFO - TRAINING - Epoch: [111][150/196]	Time 0.111 (0.123)	Data 0.000 (0.011)	Loss 0.1067 (0.0912)	Prec@1 96.484 (96.940)	Prec@5 100.000 (99.987)
2022-06-17 18:33:51 - INFO - TRAINING - Epoch: [111][160/196]	Time 0.117 (0.122)	Data 0.000 (0.011)	Loss 0.1029 (0.0913)	Prec@1 96.484 (96.941)	Prec@5 99.609 (99.985)
2022-06-17 18:33:52 - INFO - TRAINING - Epoch: [111][170/196]	Time 0.106 (0.121)	Data 0.000 (0.010)	Loss 0.0877 (0.0907)	Prec@1 96.875 (96.953)	Prec@5 100.000 (99.986)
2022-06-17 18:33:54 - INFO - TRAINING - Epoch: [111][180/196]	Time 0.118 (0.121)	Data 0.000 (0.010)	Loss 0.0752 (0.0907)	Prec@1 96.484 (96.940)	Prec@5 100.000 (99.985)
2022-06-17 18:33:55 - INFO - TRAINING - Epoch: [111][190/196]	Time 0.120 (0.120)	Data 0.000 (0.009)	Loss 0.0880 (0.0908)	Prec@1 97.266 (96.938)	Prec@5 100.000 (99.986)
2022-06-17 18:33:57 - INFO - EVALUATING - Epoch: [111][0/40]	Time 1.854 (1.854)	Data 1.809 (1.809)	Loss 0.2607 (0.2607)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:33:58 - INFO - EVALUATING - Epoch: [111][10/40]	Time 0.044 (0.264)	Data 0.000 (0.216)	Loss 0.4744 (0.4159)	Prec@1 87.891 (88.281)	Prec@5 99.219 (99.467)
2022-06-17 18:33:59 - INFO - EVALUATING - Epoch: [111][20/40]	Time 0.043 (0.168)	Data 0.001 (0.118)	Loss 0.3482 (0.4181)	Prec@1 87.891 (87.835)	Prec@5 100.000 (99.461)
2022-06-17 18:34:00 - INFO - EVALUATING - Epoch: [111][30/40]	Time 0.102 (0.150)	Data 0.060 (0.103)	Loss 0.5052 (0.4094)	Prec@1 86.328 (88.067)	Prec@5 100.000 (99.496)
2022-06-17 18:34:02 - INFO - 
 Epoch: 112	Training Loss 0.0909 	Training Prec@1 96.942 	Training Prec@5 99.986 	Validation Loss 0.4038 	Validation Prec@1 88.120 	Validation Prec@5 99.570 

2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:34:02 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:34:03 - INFO - TRAINING - Epoch: [112][0/196]	Time 1.363 (1.363)	Data 1.311 (1.311)	Loss 0.1212 (0.1212)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:34:04 - INFO - TRAINING - Epoch: [112][10/196]	Time 0.112 (0.239)	Data 0.000 (0.141)	Loss 0.1148 (0.1031)	Prec@1 96.094 (96.342)	Prec@5 100.000 (100.000)
2022-06-17 18:34:06 - INFO - TRAINING - Epoch: [112][20/196]	Time 0.107 (0.182)	Data 0.000 (0.081)	Loss 0.0935 (0.0978)	Prec@1 97.266 (96.763)	Prec@5 100.000 (99.981)
2022-06-17 18:34:07 - INFO - TRAINING - Epoch: [112][30/196]	Time 0.104 (0.161)	Data 0.000 (0.055)	Loss 0.0820 (0.0941)	Prec@1 97.266 (96.913)	Prec@5 100.000 (99.987)
2022-06-17 18:34:08 - INFO - TRAINING - Epoch: [112][40/196]	Time 0.132 (0.150)	Data 0.000 (0.042)	Loss 0.0643 (0.0931)	Prec@1 98.047 (96.942)	Prec@5 100.000 (99.981)
2022-06-17 18:34:09 - INFO - TRAINING - Epoch: [112][50/196]	Time 0.125 (0.144)	Data 0.000 (0.034)	Loss 0.0918 (0.0947)	Prec@1 98.828 (96.867)	Prec@5 100.000 (99.985)
2022-06-17 18:34:10 - INFO - TRAINING - Epoch: [112][60/196]	Time 0.110 (0.139)	Data 0.000 (0.028)	Loss 0.0993 (0.0963)	Prec@1 96.484 (96.856)	Prec@5 100.000 (99.981)
2022-06-17 18:34:11 - INFO - TRAINING - Epoch: [112][70/196]	Time 0.109 (0.135)	Data 0.000 (0.024)	Loss 0.1045 (0.0981)	Prec@1 95.703 (96.787)	Prec@5 100.000 (99.978)
2022-06-17 18:34:13 - INFO - TRAINING - Epoch: [112][80/196]	Time 0.113 (0.132)	Data 0.000 (0.021)	Loss 0.1001 (0.0971)	Prec@1 97.266 (96.793)	Prec@5 100.000 (99.976)
2022-06-17 18:34:14 - INFO - TRAINING - Epoch: [112][90/196]	Time 0.121 (0.130)	Data 0.000 (0.019)	Loss 0.0869 (0.0948)	Prec@1 96.875 (96.832)	Prec@5 100.000 (99.979)
2022-06-17 18:34:15 - INFO - TRAINING - Epoch: [112][100/196]	Time 0.108 (0.129)	Data 0.000 (0.017)	Loss 0.0742 (0.0932)	Prec@1 97.656 (96.883)	Prec@5 100.000 (99.981)
2022-06-17 18:34:16 - INFO - TRAINING - Epoch: [112][110/196]	Time 0.107 (0.128)	Data 0.000 (0.016)	Loss 0.1001 (0.0930)	Prec@1 97.266 (96.886)	Prec@5 100.000 (99.982)
2022-06-17 18:34:17 - INFO - TRAINING - Epoch: [112][120/196]	Time 0.114 (0.127)	Data 0.000 (0.014)	Loss 0.0581 (0.0920)	Prec@1 99.219 (96.936)	Prec@5 99.609 (99.977)
2022-06-17 18:34:18 - INFO - TRAINING - Epoch: [112][130/196]	Time 0.140 (0.126)	Data 0.000 (0.013)	Loss 0.1482 (0.0924)	Prec@1 93.359 (96.860)	Prec@5 100.000 (99.979)
2022-06-17 18:34:19 - INFO - TRAINING - Epoch: [112][140/196]	Time 0.103 (0.125)	Data 0.000 (0.012)	Loss 0.0768 (0.0928)	Prec@1 96.484 (96.822)	Prec@5 100.000 (99.981)
2022-06-17 18:34:21 - INFO - TRAINING - Epoch: [112][150/196]	Time 0.114 (0.124)	Data 0.000 (0.012)	Loss 0.1201 (0.0925)	Prec@1 95.312 (96.821)	Prec@5 100.000 (99.982)
2022-06-17 18:34:22 - INFO - TRAINING - Epoch: [112][160/196]	Time 0.106 (0.124)	Data 0.000 (0.011)	Loss 0.0604 (0.0914)	Prec@1 98.828 (96.856)	Prec@5 100.000 (99.983)
2022-06-17 18:34:23 - INFO - TRAINING - Epoch: [112][170/196]	Time 0.119 (0.123)	Data 0.000 (0.010)	Loss 0.0870 (0.0908)	Prec@1 97.656 (96.902)	Prec@5 100.000 (99.984)
2022-06-17 18:34:24 - INFO - TRAINING - Epoch: [112][180/196]	Time 0.107 (0.122)	Data 0.000 (0.010)	Loss 0.0612 (0.0913)	Prec@1 98.438 (96.881)	Prec@5 100.000 (99.985)
2022-06-17 18:34:25 - INFO - TRAINING - Epoch: [112][190/196]	Time 0.102 (0.121)	Data 0.000 (0.009)	Loss 0.0714 (0.0911)	Prec@1 96.875 (96.885)	Prec@5 100.000 (99.984)
2022-06-17 18:34:27 - INFO - EVALUATING - Epoch: [112][0/40]	Time 1.391 (1.391)	Data 1.345 (1.345)	Loss 0.2629 (0.2629)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:34:28 - INFO - EVALUATING - Epoch: [112][10/40]	Time 0.068 (0.228)	Data 0.000 (0.175)	Loss 0.4762 (0.4135)	Prec@1 86.719 (88.246)	Prec@5 99.219 (99.574)
2022-06-17 18:34:29 - INFO - EVALUATING - Epoch: [112][20/40]	Time 0.113 (0.168)	Data 0.071 (0.117)	Loss 0.3415 (0.4167)	Prec@1 87.500 (87.909)	Prec@5 100.000 (99.498)
2022-06-17 18:34:30 - INFO - EVALUATING - Epoch: [112][30/40]	Time 0.193 (0.155)	Data 0.149 (0.107)	Loss 0.5072 (0.4079)	Prec@1 86.328 (88.143)	Prec@5 100.000 (99.534)
2022-06-17 18:34:32 - INFO - 
 Epoch: 113	Training Loss 0.0908 	Training Prec@1 96.900 	Training Prec@5 99.984 	Validation Loss 0.4033 	Validation Prec@1 88.130 	Validation Prec@5 99.600 

2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:34:32 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:34:34 - INFO - TRAINING - Epoch: [113][0/196]	Time 1.532 (1.532)	Data 1.478 (1.478)	Loss 0.0948 (0.0948)	Prec@1 95.703 (95.703)	Prec@5 99.609 (99.609)
2022-06-17 18:34:35 - INFO - TRAINING - Epoch: [113][10/196]	Time 0.104 (0.270)	Data 0.000 (0.174)	Loss 0.1177 (0.0889)	Prec@1 94.922 (96.697)	Prec@5 100.000 (99.964)
2022-06-17 18:34:36 - INFO - TRAINING - Epoch: [113][20/196]	Time 0.102 (0.190)	Data 0.000 (0.091)	Loss 0.0917 (0.0817)	Prec@1 96.875 (97.080)	Prec@5 100.000 (99.981)
2022-06-17 18:34:37 - INFO - TRAINING - Epoch: [113][30/196]	Time 0.113 (0.163)	Data 0.000 (0.062)	Loss 0.0955 (0.0905)	Prec@1 97.266 (96.963)	Prec@5 100.000 (99.975)
2022-06-17 18:34:38 - INFO - TRAINING - Epoch: [113][40/196]	Time 0.106 (0.150)	Data 0.000 (0.047)	Loss 0.0950 (0.0901)	Prec@1 96.484 (96.951)	Prec@5 100.000 (99.981)
2022-06-17 18:34:39 - INFO - TRAINING - Epoch: [113][50/196]	Time 0.138 (0.143)	Data 0.000 (0.038)	Loss 0.0953 (0.0891)	Prec@1 96.484 (96.982)	Prec@5 100.000 (99.985)
2022-06-17 18:34:41 - INFO - TRAINING - Epoch: [113][60/196]	Time 0.111 (0.137)	Data 0.000 (0.032)	Loss 0.0570 (0.0891)	Prec@1 98.438 (97.003)	Prec@5 100.000 (99.974)
2022-06-17 18:34:42 - INFO - TRAINING - Epoch: [113][70/196]	Time 0.106 (0.133)	Data 0.000 (0.027)	Loss 0.1240 (0.0903)	Prec@1 94.922 (96.952)	Prec@5 100.000 (99.972)
2022-06-17 18:34:43 - INFO - TRAINING - Epoch: [113][80/196]	Time 0.103 (0.130)	Data 0.000 (0.024)	Loss 0.1815 (0.0918)	Prec@1 94.141 (96.899)	Prec@5 100.000 (99.976)
2022-06-17 18:34:44 - INFO - TRAINING - Epoch: [113][90/196]	Time 0.114 (0.127)	Data 0.000 (0.021)	Loss 0.0812 (0.0907)	Prec@1 96.094 (96.927)	Prec@5 100.000 (99.979)
2022-06-17 18:34:45 - INFO - TRAINING - Epoch: [113][100/196]	Time 0.108 (0.125)	Data 0.000 (0.019)	Loss 0.0653 (0.0910)	Prec@1 98.047 (96.937)	Prec@5 100.000 (99.981)
2022-06-17 18:34:46 - INFO - TRAINING - Epoch: [113][110/196]	Time 0.103 (0.124)	Data 0.000 (0.018)	Loss 0.0583 (0.0907)	Prec@1 98.047 (96.938)	Prec@5 100.000 (99.982)
2022-06-17 18:34:47 - INFO - TRAINING - Epoch: [113][120/196]	Time 0.102 (0.122)	Data 0.000 (0.016)	Loss 0.0691 (0.0912)	Prec@1 96.875 (96.917)	Prec@5 100.000 (99.984)
2022-06-17 18:34:48 - INFO - TRAINING - Epoch: [113][130/196]	Time 0.103 (0.121)	Data 0.000 (0.015)	Loss 0.0880 (0.0910)	Prec@1 98.438 (96.911)	Prec@5 100.000 (99.985)
2022-06-17 18:34:49 - INFO - TRAINING - Epoch: [113][140/196]	Time 0.110 (0.120)	Data 0.000 (0.014)	Loss 0.0848 (0.0916)	Prec@1 97.656 (96.911)	Prec@5 100.000 (99.986)
2022-06-17 18:34:50 - INFO - TRAINING - Epoch: [113][150/196]	Time 0.107 (0.119)	Data 0.000 (0.013)	Loss 0.0847 (0.0918)	Prec@1 96.875 (96.919)	Prec@5 100.000 (99.987)
2022-06-17 18:34:51 - INFO - TRAINING - Epoch: [113][160/196]	Time 0.125 (0.118)	Data 0.000 (0.012)	Loss 0.1000 (0.0912)	Prec@1 97.266 (96.924)	Prec@5 100.000 (99.988)
2022-06-17 18:34:52 - INFO - TRAINING - Epoch: [113][170/196]	Time 0.115 (0.118)	Data 0.000 (0.011)	Loss 0.0868 (0.0912)	Prec@1 97.266 (96.928)	Prec@5 100.000 (99.986)
2022-06-17 18:34:54 - INFO - TRAINING - Epoch: [113][180/196]	Time 0.111 (0.118)	Data 0.000 (0.011)	Loss 0.0631 (0.0907)	Prec@1 97.656 (96.953)	Prec@5 100.000 (99.985)
2022-06-17 18:34:55 - INFO - TRAINING - Epoch: [113][190/196]	Time 0.102 (0.117)	Data 0.000 (0.010)	Loss 0.0980 (0.0906)	Prec@1 98.438 (96.975)	Prec@5 99.609 (99.984)
2022-06-17 18:34:57 - INFO - EVALUATING - Epoch: [113][0/40]	Time 1.816 (1.816)	Data 1.770 (1.770)	Loss 0.2546 (0.2546)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:34:58 - INFO - EVALUATING - Epoch: [113][10/40]	Time 0.042 (0.233)	Data 0.000 (0.184)	Loss 0.4758 (0.4127)	Prec@1 87.891 (88.388)	Prec@5 99.219 (99.432)
2022-06-17 18:34:59 - INFO - EVALUATING - Epoch: [113][20/40]	Time 0.042 (0.176)	Data 0.000 (0.128)	Loss 0.3452 (0.4174)	Prec@1 87.500 (88.002)	Prec@5 100.000 (99.442)
2022-06-17 18:35:00 - INFO - EVALUATING - Epoch: [113][30/40]	Time 0.103 (0.153)	Data 0.059 (0.106)	Loss 0.5028 (0.4100)	Prec@1 85.938 (88.143)	Prec@5 100.000 (99.509)
2022-06-17 18:35:02 - INFO - 
 Epoch: 114	Training Loss 0.0906 	Training Prec@1 96.976 	Training Prec@5 99.984 	Validation Loss 0.4053 	Validation Prec@1 88.220 	Validation Prec@5 99.580 

2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:35:02 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:35:03 - INFO - TRAINING - Epoch: [114][0/196]	Time 1.520 (1.520)	Data 1.466 (1.466)	Loss 0.1031 (0.1031)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:35:05 - INFO - TRAINING - Epoch: [114][10/196]	Time 0.106 (0.259)	Data 0.000 (0.166)	Loss 0.1121 (0.0979)	Prec@1 96.094 (96.555)	Prec@5 100.000 (99.964)
2022-06-17 18:35:06 - INFO - TRAINING - Epoch: [114][20/196]	Time 0.113 (0.189)	Data 0.000 (0.087)	Loss 0.0838 (0.0917)	Prec@1 96.484 (96.801)	Prec@5 100.000 (99.981)
2022-06-17 18:35:07 - INFO - TRAINING - Epoch: [114][30/196]	Time 0.102 (0.162)	Data 0.000 (0.059)	Loss 0.0635 (0.0907)	Prec@1 97.656 (96.862)	Prec@5 100.000 (99.975)
2022-06-17 18:35:08 - INFO - TRAINING - Epoch: [114][40/196]	Time 0.111 (0.148)	Data 0.000 (0.045)	Loss 0.0827 (0.0914)	Prec@1 97.266 (96.827)	Prec@5 100.000 (99.981)
2022-06-17 18:35:09 - INFO - TRAINING - Epoch: [114][50/196]	Time 0.108 (0.140)	Data 0.000 (0.036)	Loss 0.0931 (0.0903)	Prec@1 97.266 (96.867)	Prec@5 100.000 (99.977)
2022-06-17 18:35:10 - INFO - TRAINING - Epoch: [114][60/196]	Time 0.113 (0.135)	Data 0.000 (0.030)	Loss 0.0844 (0.0887)	Prec@1 98.047 (96.965)	Prec@5 100.000 (99.981)
2022-06-17 18:35:11 - INFO - TRAINING - Epoch: [114][70/196]	Time 0.102 (0.131)	Data 0.000 (0.026)	Loss 0.0771 (0.0866)	Prec@1 96.875 (97.007)	Prec@5 100.000 (99.983)
2022-06-17 18:35:12 - INFO - TRAINING - Epoch: [114][80/196]	Time 0.111 (0.128)	Data 0.000 (0.023)	Loss 0.0649 (0.0868)	Prec@1 98.047 (97.024)	Prec@5 100.000 (99.986)
2022-06-17 18:35:13 - INFO - TRAINING - Epoch: [114][90/196]	Time 0.110 (0.126)	Data 0.000 (0.020)	Loss 0.1192 (0.0871)	Prec@1 95.312 (97.012)	Prec@5 100.000 (99.987)
2022-06-17 18:35:14 - INFO - TRAINING - Epoch: [114][100/196]	Time 0.103 (0.125)	Data 0.000 (0.018)	Loss 0.0869 (0.0866)	Prec@1 98.047 (97.006)	Prec@5 100.000 (99.988)
2022-06-17 18:35:16 - INFO - TRAINING - Epoch: [114][110/196]	Time 0.104 (0.123)	Data 0.000 (0.017)	Loss 0.1015 (0.0860)	Prec@1 96.094 (97.040)	Prec@5 100.000 (99.989)
2022-06-17 18:35:17 - INFO - TRAINING - Epoch: [114][120/196]	Time 0.103 (0.122)	Data 0.000 (0.015)	Loss 0.0702 (0.0858)	Prec@1 98.047 (97.046)	Prec@5 100.000 (99.990)
2022-06-17 18:35:18 - INFO - TRAINING - Epoch: [114][130/196]	Time 0.109 (0.121)	Data 0.000 (0.014)	Loss 0.0830 (0.0848)	Prec@1 97.266 (97.111)	Prec@5 100.000 (99.991)
2022-06-17 18:35:19 - INFO - TRAINING - Epoch: [114][140/196]	Time 0.104 (0.121)	Data 0.000 (0.013)	Loss 0.0716 (0.0862)	Prec@1 96.875 (97.052)	Prec@5 100.000 (99.989)
2022-06-17 18:35:20 - INFO - TRAINING - Epoch: [114][150/196]	Time 0.119 (0.120)	Data 0.000 (0.012)	Loss 0.1097 (0.0856)	Prec@1 96.484 (97.074)	Prec@5 100.000 (99.987)
2022-06-17 18:35:21 - INFO - TRAINING - Epoch: [114][160/196]	Time 0.104 (0.120)	Data 0.000 (0.012)	Loss 0.1214 (0.0866)	Prec@1 96.875 (97.038)	Prec@5 100.000 (99.985)
2022-06-17 18:35:22 - INFO - TRAINING - Epoch: [114][170/196]	Time 0.109 (0.119)	Data 0.000 (0.011)	Loss 0.0877 (0.0868)	Prec@1 96.484 (97.017)	Prec@5 100.000 (99.984)
2022-06-17 18:35:23 - INFO - TRAINING - Epoch: [114][180/196]	Time 0.110 (0.119)	Data 0.000 (0.010)	Loss 0.0864 (0.0868)	Prec@1 97.266 (97.015)	Prec@5 100.000 (99.985)
2022-06-17 18:35:24 - INFO - TRAINING - Epoch: [114][190/196]	Time 0.104 (0.118)	Data 0.000 (0.010)	Loss 0.0832 (0.0867)	Prec@1 98.047 (97.024)	Prec@5 100.000 (99.986)
2022-06-17 18:35:27 - INFO - EVALUATING - Epoch: [114][0/40]	Time 1.590 (1.590)	Data 1.544 (1.544)	Loss 0.2672 (0.2672)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:35:28 - INFO - EVALUATING - Epoch: [114][10/40]	Time 0.254 (0.250)	Data 0.211 (0.199)	Loss 0.4727 (0.4151)	Prec@1 88.281 (88.423)	Prec@5 99.219 (99.503)
2022-06-17 18:35:29 - INFO - EVALUATING - Epoch: [114][20/40]	Time 0.110 (0.173)	Data 0.066 (0.123)	Loss 0.3386 (0.4158)	Prec@1 87.109 (88.021)	Prec@5 100.000 (99.442)
2022-06-17 18:35:30 - INFO - EVALUATING - Epoch: [114][30/40]	Time 0.091 (0.152)	Data 0.049 (0.102)	Loss 0.5017 (0.4071)	Prec@1 85.938 (88.105)	Prec@5 100.000 (99.471)
2022-06-17 18:35:32 - INFO - 
 Epoch: 115	Training Loss 0.0869 	Training Prec@1 97.018 	Training Prec@5 99.982 	Validation Loss 0.4024 	Validation Prec@1 88.160 	Validation Prec@5 99.550 

2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:35:32 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:35:33 - INFO - TRAINING - Epoch: [115][0/196]	Time 1.785 (1.785)	Data 1.733 (1.733)	Loss 0.0963 (0.0963)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:35:35 - INFO - TRAINING - Epoch: [115][10/196]	Time 0.115 (0.287)	Data 0.000 (0.180)	Loss 0.0883 (0.0897)	Prec@1 96.094 (96.733)	Prec@5 100.000 (100.000)
2022-06-17 18:35:36 - INFO - TRAINING - Epoch: [115][20/196]	Time 0.112 (0.202)	Data 0.000 (0.095)	Loss 0.0813 (0.0867)	Prec@1 97.266 (96.968)	Prec@5 100.000 (99.963)
2022-06-17 18:35:37 - INFO - TRAINING - Epoch: [115][30/196]	Time 0.107 (0.173)	Data 0.000 (0.064)	Loss 0.0720 (0.0872)	Prec@1 97.656 (96.951)	Prec@5 100.000 (99.975)
2022-06-17 18:35:38 - INFO - TRAINING - Epoch: [115][40/196]	Time 0.112 (0.157)	Data 0.000 (0.049)	Loss 0.0779 (0.0877)	Prec@1 97.656 (96.999)	Prec@5 100.000 (99.971)
2022-06-17 18:35:39 - INFO - TRAINING - Epoch: [115][50/196]	Time 0.104 (0.148)	Data 0.000 (0.039)	Loss 0.0998 (0.0874)	Prec@1 97.266 (97.082)	Prec@5 100.000 (99.962)
2022-06-17 18:35:40 - INFO - TRAINING - Epoch: [115][60/196]	Time 0.109 (0.143)	Data 0.000 (0.033)	Loss 0.0890 (0.0880)	Prec@1 96.484 (97.074)	Prec@5 100.000 (99.968)
2022-06-17 18:35:41 - INFO - TRAINING - Epoch: [115][70/196]	Time 0.128 (0.138)	Data 0.000 (0.028)	Loss 0.1236 (0.0905)	Prec@1 95.703 (97.002)	Prec@5 99.609 (99.961)
2022-06-17 18:35:43 - INFO - TRAINING - Epoch: [115][80/196]	Time 0.106 (0.135)	Data 0.000 (0.025)	Loss 0.1270 (0.0913)	Prec@1 93.750 (96.976)	Prec@5 100.000 (99.966)
2022-06-17 18:35:44 - INFO - TRAINING - Epoch: [115][90/196]	Time 0.111 (0.133)	Data 0.000 (0.022)	Loss 0.0854 (0.0915)	Prec@1 97.656 (96.957)	Prec@5 100.000 (99.970)
2022-06-17 18:35:45 - INFO - TRAINING - Epoch: [115][100/196]	Time 0.102 (0.131)	Data 0.000 (0.020)	Loss 0.0969 (0.0926)	Prec@1 96.484 (96.883)	Prec@5 100.000 (99.973)
2022-06-17 18:35:46 - INFO - TRAINING - Epoch: [115][110/196]	Time 0.103 (0.129)	Data 0.000 (0.018)	Loss 0.1065 (0.0922)	Prec@1 96.094 (96.903)	Prec@5 100.000 (99.968)
2022-06-17 18:35:47 - INFO - TRAINING - Epoch: [115][120/196]	Time 0.102 (0.128)	Data 0.000 (0.017)	Loss 0.0778 (0.0916)	Prec@1 98.047 (96.936)	Prec@5 100.000 (99.968)
2022-06-17 18:35:48 - INFO - TRAINING - Epoch: [115][130/196]	Time 0.103 (0.126)	Data 0.000 (0.015)	Loss 0.0922 (0.0928)	Prec@1 96.484 (96.866)	Prec@5 100.000 (99.967)
2022-06-17 18:35:49 - INFO - TRAINING - Epoch: [115][140/196]	Time 0.111 (0.125)	Data 0.000 (0.014)	Loss 0.0634 (0.0921)	Prec@1 97.656 (96.875)	Prec@5 100.000 (99.970)
2022-06-17 18:35:50 - INFO - TRAINING - Epoch: [115][150/196]	Time 0.102 (0.124)	Data 0.000 (0.013)	Loss 0.0770 (0.0913)	Prec@1 98.438 (96.901)	Prec@5 100.000 (99.972)
2022-06-17 18:35:51 - INFO - TRAINING - Epoch: [115][160/196]	Time 0.116 (0.123)	Data 0.000 (0.013)	Loss 0.0725 (0.0910)	Prec@1 98.438 (96.899)	Prec@5 100.000 (99.973)
2022-06-17 18:35:52 - INFO - TRAINING - Epoch: [115][170/196]	Time 0.106 (0.122)	Data 0.000 (0.012)	Loss 0.1329 (0.0918)	Prec@1 94.141 (96.854)	Prec@5 100.000 (99.973)
2022-06-17 18:35:54 - INFO - TRAINING - Epoch: [115][180/196]	Time 0.112 (0.121)	Data 0.000 (0.011)	Loss 0.1269 (0.0919)	Prec@1 94.922 (96.845)	Prec@5 100.000 (99.974)
2022-06-17 18:35:55 - INFO - TRAINING - Epoch: [115][190/196]	Time 0.102 (0.121)	Data 0.000 (0.011)	Loss 0.0904 (0.0914)	Prec@1 96.875 (96.865)	Prec@5 100.000 (99.975)
2022-06-17 18:35:57 - INFO - EVALUATING - Epoch: [115][0/40]	Time 2.034 (2.034)	Data 1.988 (1.988)	Loss 0.2588 (0.2588)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:35:58 - INFO - EVALUATING - Epoch: [115][10/40]	Time 0.043 (0.256)	Data 0.000 (0.208)	Loss 0.4707 (0.4127)	Prec@1 87.109 (88.459)	Prec@5 99.219 (99.467)
2022-06-17 18:35:59 - INFO - EVALUATING - Epoch: [115][20/40]	Time 0.151 (0.164)	Data 0.109 (0.114)	Loss 0.3421 (0.4167)	Prec@1 87.109 (87.909)	Prec@5 100.000 (99.423)
2022-06-17 18:36:00 - INFO - EVALUATING - Epoch: [115][30/40]	Time 0.149 (0.147)	Data 0.107 (0.098)	Loss 0.5117 (0.4095)	Prec@1 86.328 (88.117)	Prec@5 100.000 (99.483)
2022-06-17 18:36:02 - INFO - 
 Epoch: 116	Training Loss 0.0917 	Training Prec@1 96.860 	Training Prec@5 99.976 	Validation Loss 0.4047 	Validation Prec@1 88.090 	Validation Prec@5 99.560 

2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:36:02 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:36:03 - INFO - TRAINING - Epoch: [116][0/196]	Time 1.243 (1.243)	Data 1.190 (1.190)	Loss 0.0710 (0.0710)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:36:05 - INFO - TRAINING - Epoch: [116][10/196]	Time 0.102 (0.245)	Data 0.000 (0.159)	Loss 0.0824 (0.0879)	Prec@1 97.656 (97.443)	Prec@5 100.000 (99.964)
2022-06-17 18:36:06 - INFO - TRAINING - Epoch: [116][20/196]	Time 0.109 (0.181)	Data 0.000 (0.089)	Loss 0.1362 (0.0960)	Prec@1 94.531 (96.856)	Prec@5 100.000 (99.981)
2022-06-17 18:36:07 - INFO - TRAINING - Epoch: [116][30/196]	Time 0.124 (0.158)	Data 0.000 (0.061)	Loss 0.1149 (0.0981)	Prec@1 95.312 (96.736)	Prec@5 100.000 (99.962)
2022-06-17 18:36:08 - INFO - TRAINING - Epoch: [116][40/196]	Time 0.119 (0.147)	Data 0.000 (0.046)	Loss 0.0731 (0.0955)	Prec@1 98.047 (96.837)	Prec@5 100.000 (99.971)
2022-06-17 18:36:09 - INFO - TRAINING - Epoch: [116][50/196]	Time 0.121 (0.140)	Data 0.000 (0.037)	Loss 0.0895 (0.0932)	Prec@1 96.875 (96.929)	Prec@5 100.000 (99.977)
2022-06-17 18:36:10 - INFO - TRAINING - Epoch: [116][60/196]	Time 0.103 (0.136)	Data 0.000 (0.031)	Loss 0.0545 (0.0922)	Prec@1 98.047 (96.920)	Prec@5 100.000 (99.981)
2022-06-17 18:36:11 - INFO - TRAINING - Epoch: [116][70/196]	Time 0.109 (0.133)	Data 0.000 (0.027)	Loss 0.0318 (0.0901)	Prec@1 99.609 (96.996)	Prec@5 100.000 (99.978)
2022-06-17 18:36:13 - INFO - TRAINING - Epoch: [116][80/196]	Time 0.126 (0.131)	Data 0.000 (0.023)	Loss 0.0879 (0.0914)	Prec@1 98.047 (96.928)	Prec@5 100.000 (99.981)
2022-06-17 18:36:14 - INFO - TRAINING - Epoch: [116][90/196]	Time 0.116 (0.129)	Data 0.000 (0.021)	Loss 0.0834 (0.0914)	Prec@1 97.656 (96.896)	Prec@5 100.000 (99.983)
2022-06-17 18:36:15 - INFO - TRAINING - Epoch: [116][100/196]	Time 0.101 (0.127)	Data 0.000 (0.019)	Loss 0.1006 (0.0905)	Prec@1 96.094 (96.910)	Prec@5 100.000 (99.985)
2022-06-17 18:36:16 - INFO - TRAINING - Epoch: [116][110/196]	Time 0.132 (0.126)	Data 0.000 (0.017)	Loss 0.0834 (0.0901)	Prec@1 96.875 (96.942)	Prec@5 100.000 (99.986)
2022-06-17 18:36:17 - INFO - TRAINING - Epoch: [116][120/196]	Time 0.118 (0.126)	Data 0.000 (0.016)	Loss 0.0913 (0.0902)	Prec@1 97.266 (96.959)	Prec@5 100.000 (99.984)
2022-06-17 18:36:18 - INFO - TRAINING - Epoch: [116][130/196]	Time 0.132 (0.125)	Data 0.000 (0.015)	Loss 0.0733 (0.0905)	Prec@1 98.438 (96.929)	Prec@5 100.000 (99.985)
2022-06-17 18:36:19 - INFO - TRAINING - Epoch: [116][140/196]	Time 0.111 (0.125)	Data 0.000 (0.014)	Loss 0.0724 (0.0899)	Prec@1 98.047 (96.947)	Prec@5 100.000 (99.983)
2022-06-17 18:36:21 - INFO - TRAINING - Epoch: [116][150/196]	Time 0.131 (0.124)	Data 0.000 (0.013)	Loss 0.1181 (0.0901)	Prec@1 95.703 (96.914)	Prec@5 100.000 (99.984)
2022-06-17 18:36:22 - INFO - TRAINING - Epoch: [116][160/196]	Time 0.120 (0.124)	Data 0.000 (0.012)	Loss 0.0736 (0.0896)	Prec@1 97.656 (96.933)	Prec@5 100.000 (99.985)
2022-06-17 18:36:23 - INFO - TRAINING - Epoch: [116][170/196]	Time 0.124 (0.123)	Data 0.000 (0.011)	Loss 0.0614 (0.0889)	Prec@1 98.047 (96.948)	Prec@5 100.000 (99.984)
2022-06-17 18:36:24 - INFO - TRAINING - Epoch: [116][180/196]	Time 0.103 (0.122)	Data 0.000 (0.011)	Loss 0.0763 (0.0891)	Prec@1 96.875 (96.938)	Prec@5 100.000 (99.985)
2022-06-17 18:36:25 - INFO - TRAINING - Epoch: [116][190/196]	Time 0.102 (0.121)	Data 0.000 (0.010)	Loss 0.0987 (0.0884)	Prec@1 96.484 (96.963)	Prec@5 100.000 (99.986)
2022-06-17 18:36:27 - INFO - EVALUATING - Epoch: [116][0/40]	Time 1.739 (1.739)	Data 1.693 (1.693)	Loss 0.2551 (0.2551)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:36:28 - INFO - EVALUATING - Epoch: [116][10/40]	Time 0.054 (0.253)	Data 0.000 (0.205)	Loss 0.4766 (0.4154)	Prec@1 87.891 (88.707)	Prec@5 98.828 (99.503)
2022-06-17 18:36:29 - INFO - EVALUATING - Epoch: [116][20/40]	Time 0.110 (0.168)	Data 0.069 (0.121)	Loss 0.3430 (0.4187)	Prec@1 87.109 (88.058)	Prec@5 99.609 (99.423)
2022-06-17 18:36:30 - INFO - EVALUATING - Epoch: [116][30/40]	Time 0.055 (0.153)	Data 0.000 (0.107)	Loss 0.5145 (0.4127)	Prec@1 86.328 (88.231)	Prec@5 100.000 (99.471)
2022-06-17 18:36:32 - INFO - 
 Epoch: 117	Training Loss 0.0885 	Training Prec@1 96.956 	Training Prec@5 99.986 	Validation Loss 0.4081 	Validation Prec@1 88.210 	Validation Prec@5 99.530 

2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:36:32 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:36:34 - INFO - TRAINING - Epoch: [117][0/196]	Time 1.573 (1.573)	Data 1.520 (1.520)	Loss 0.0736 (0.0736)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:36:35 - INFO - TRAINING - Epoch: [117][10/196]	Time 0.112 (0.275)	Data 0.000 (0.173)	Loss 0.1322 (0.0803)	Prec@1 94.922 (97.301)	Prec@5 100.000 (100.000)
2022-06-17 18:36:37 - INFO - TRAINING - Epoch: [117][20/196]	Time 0.116 (0.199)	Data 0.000 (0.091)	Loss 0.0742 (0.0859)	Prec@1 98.047 (97.042)	Prec@5 100.000 (100.000)
2022-06-17 18:36:38 - INFO - TRAINING - Epoch: [117][30/196]	Time 0.129 (0.173)	Data 0.000 (0.061)	Loss 0.0742 (0.0907)	Prec@1 97.656 (96.837)	Prec@5 100.000 (99.975)
2022-06-17 18:36:39 - INFO - TRAINING - Epoch: [117][40/196]	Time 0.119 (0.159)	Data 0.000 (0.047)	Loss 0.0883 (0.0887)	Prec@1 96.484 (96.904)	Prec@5 100.000 (99.981)
2022-06-17 18:36:40 - INFO - TRAINING - Epoch: [117][50/196]	Time 0.103 (0.150)	Data 0.000 (0.037)	Loss 0.1107 (0.0914)	Prec@1 95.703 (96.760)	Prec@5 100.000 (99.977)
2022-06-17 18:36:41 - INFO - TRAINING - Epoch: [117][60/196]	Time 0.110 (0.144)	Data 0.000 (0.031)	Loss 0.0810 (0.0917)	Prec@1 98.047 (96.811)	Prec@5 100.000 (99.981)
2022-06-17 18:36:42 - INFO - TRAINING - Epoch: [117][70/196]	Time 0.105 (0.140)	Data 0.000 (0.027)	Loss 0.0847 (0.0905)	Prec@1 98.047 (96.919)	Prec@5 100.000 (99.983)
2022-06-17 18:36:43 - INFO - TRAINING - Epoch: [117][80/196]	Time 0.119 (0.137)	Data 0.000 (0.024)	Loss 0.0794 (0.0891)	Prec@1 98.047 (96.943)	Prec@5 100.000 (99.986)
2022-06-17 18:36:45 - INFO - TRAINING - Epoch: [117][90/196]	Time 0.117 (0.134)	Data 0.000 (0.021)	Loss 0.0949 (0.0899)	Prec@1 97.266 (96.901)	Prec@5 100.000 (99.987)
2022-06-17 18:36:46 - INFO - TRAINING - Epoch: [117][100/196]	Time 0.113 (0.132)	Data 0.000 (0.019)	Loss 0.0753 (0.0894)	Prec@1 97.656 (96.902)	Prec@5 100.000 (99.985)
2022-06-17 18:36:47 - INFO - TRAINING - Epoch: [117][110/196]	Time 0.126 (0.131)	Data 0.000 (0.017)	Loss 0.0528 (0.0883)	Prec@1 98.438 (96.974)	Prec@5 100.000 (99.982)
2022-06-17 18:36:48 - INFO - TRAINING - Epoch: [117][120/196]	Time 0.121 (0.130)	Data 0.000 (0.016)	Loss 0.0866 (0.0885)	Prec@1 97.656 (96.998)	Prec@5 100.000 (99.977)
2022-06-17 18:36:49 - INFO - TRAINING - Epoch: [117][130/196]	Time 0.111 (0.129)	Data 0.000 (0.015)	Loss 0.0559 (0.0881)	Prec@1 98.047 (97.003)	Prec@5 100.000 (99.979)
2022-06-17 18:36:50 - INFO - TRAINING - Epoch: [117][140/196]	Time 0.106 (0.128)	Data 0.000 (0.014)	Loss 0.0909 (0.0872)	Prec@1 96.094 (97.011)	Prec@5 100.000 (99.981)
2022-06-17 18:36:51 - INFO - TRAINING - Epoch: [117][150/196]	Time 0.105 (0.127)	Data 0.000 (0.013)	Loss 0.1097 (0.0878)	Prec@1 95.312 (96.968)	Prec@5 100.000 (99.982)
2022-06-17 18:36:53 - INFO - TRAINING - Epoch: [117][160/196]	Time 0.124 (0.126)	Data 0.000 (0.012)	Loss 0.0806 (0.0876)	Prec@1 97.266 (96.955)	Prec@5 100.000 (99.983)
2022-06-17 18:36:54 - INFO - TRAINING - Epoch: [117][170/196]	Time 0.102 (0.126)	Data 0.000 (0.011)	Loss 0.0546 (0.0867)	Prec@1 98.828 (97.017)	Prec@5 100.000 (99.984)
2022-06-17 18:36:55 - INFO - TRAINING - Epoch: [117][180/196]	Time 0.107 (0.125)	Data 0.000 (0.011)	Loss 0.0917 (0.0870)	Prec@1 96.484 (96.989)	Prec@5 100.000 (99.985)
2022-06-17 18:36:56 - INFO - TRAINING - Epoch: [117][190/196]	Time 0.112 (0.124)	Data 0.000 (0.010)	Loss 0.1052 (0.0871)	Prec@1 95.703 (96.979)	Prec@5 100.000 (99.986)
2022-06-17 18:36:59 - INFO - EVALUATING - Epoch: [117][0/40]	Time 1.902 (1.902)	Data 1.857 (1.857)	Loss 0.2632 (0.2632)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:37:00 - INFO - EVALUATING - Epoch: [117][10/40]	Time 0.045 (0.256)	Data 0.000 (0.209)	Loss 0.4866 (0.4169)	Prec@1 87.500 (88.388)	Prec@5 99.219 (99.396)
2022-06-17 18:37:00 - INFO - EVALUATING - Epoch: [117][20/40]	Time 0.160 (0.172)	Data 0.116 (0.124)	Loss 0.3509 (0.4213)	Prec@1 87.109 (87.835)	Prec@5 100.000 (99.386)
2022-06-17 18:37:02 - INFO - EVALUATING - Epoch: [117][30/40]	Time 0.244 (0.158)	Data 0.200 (0.110)	Loss 0.5158 (0.4122)	Prec@1 85.938 (88.117)	Prec@5 100.000 (99.458)
2022-06-17 18:37:03 - INFO - 
 Epoch: 118	Training Loss 0.0869 	Training Prec@1 96.982 	Training Prec@5 99.986 	Validation Loss 0.4076 	Validation Prec@1 88.130 	Validation Prec@5 99.540 

2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:37:03 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:37:05 - INFO - TRAINING - Epoch: [118][0/196]	Time 1.788 (1.788)	Data 1.734 (1.734)	Loss 0.0379 (0.0379)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
2022-06-17 18:37:06 - INFO - TRAINING - Epoch: [118][10/196]	Time 0.115 (0.267)	Data 0.000 (0.158)	Loss 0.0696 (0.0872)	Prec@1 98.438 (97.230)	Prec@5 100.000 (100.000)
2022-06-17 18:37:07 - INFO - TRAINING - Epoch: [118][20/196]	Time 0.128 (0.194)	Data 0.000 (0.083)	Loss 0.0739 (0.0891)	Prec@1 96.875 (97.173)	Prec@5 100.000 (100.000)
2022-06-17 18:37:09 - INFO - TRAINING - Epoch: [118][30/196]	Time 0.105 (0.170)	Data 0.000 (0.056)	Loss 0.0651 (0.0901)	Prec@1 97.266 (97.001)	Prec@5 100.000 (100.000)
2022-06-17 18:37:10 - INFO - TRAINING - Epoch: [118][40/196]	Time 0.121 (0.157)	Data 0.000 (0.043)	Loss 0.1111 (0.0933)	Prec@1 96.484 (96.846)	Prec@5 100.000 (100.000)
2022-06-17 18:37:11 - INFO - TRAINING - Epoch: [118][50/196]	Time 0.119 (0.149)	Data 0.000 (0.034)	Loss 0.0712 (0.0925)	Prec@1 97.266 (96.837)	Prec@5 100.000 (100.000)
2022-06-17 18:37:12 - INFO - TRAINING - Epoch: [118][60/196]	Time 0.116 (0.144)	Data 0.000 (0.029)	Loss 0.1198 (0.0915)	Prec@1 95.312 (96.843)	Prec@5 100.000 (100.000)
2022-06-17 18:37:13 - INFO - TRAINING - Epoch: [118][70/196]	Time 0.103 (0.140)	Data 0.000 (0.025)	Loss 0.1050 (0.0890)	Prec@1 95.703 (96.925)	Prec@5 100.000 (100.000)
2022-06-17 18:37:15 - INFO - TRAINING - Epoch: [118][80/196]	Time 0.129 (0.137)	Data 0.000 (0.022)	Loss 0.1205 (0.0881)	Prec@1 96.094 (97.024)	Prec@5 100.000 (100.000)
2022-06-17 18:37:16 - INFO - TRAINING - Epoch: [118][90/196]	Time 0.116 (0.135)	Data 0.000 (0.019)	Loss 0.0767 (0.0885)	Prec@1 96.875 (97.038)	Prec@5 100.000 (100.000)
2022-06-17 18:37:17 - INFO - TRAINING - Epoch: [118][100/196]	Time 0.112 (0.134)	Data 0.000 (0.017)	Loss 0.0831 (0.0874)	Prec@1 95.703 (97.045)	Prec@5 100.000 (99.996)
2022-06-17 18:37:18 - INFO - TRAINING - Epoch: [118][110/196]	Time 0.108 (0.132)	Data 0.000 (0.016)	Loss 0.0917 (0.0868)	Prec@1 96.484 (97.062)	Prec@5 100.000 (99.996)
2022-06-17 18:37:19 - INFO - TRAINING - Epoch: [118][120/196]	Time 0.118 (0.131)	Data 0.000 (0.015)	Loss 0.1264 (0.0876)	Prec@1 95.703 (97.024)	Prec@5 99.609 (99.994)
2022-06-17 18:37:20 - INFO - TRAINING - Epoch: [118][130/196]	Time 0.115 (0.130)	Data 0.000 (0.014)	Loss 0.0511 (0.0877)	Prec@1 98.047 (97.021)	Prec@5 100.000 (99.994)
2022-06-17 18:37:22 - INFO - TRAINING - Epoch: [118][140/196]	Time 0.114 (0.129)	Data 0.000 (0.013)	Loss 0.0993 (0.0876)	Prec@1 96.484 (97.025)	Prec@5 99.609 (99.992)
2022-06-17 18:37:23 - INFO - TRAINING - Epoch: [118][150/196]	Time 0.106 (0.128)	Data 0.000 (0.012)	Loss 0.1267 (0.0876)	Prec@1 94.922 (96.991)	Prec@5 100.000 (99.992)
2022-06-17 18:37:24 - INFO - TRAINING - Epoch: [118][160/196]	Time 0.120 (0.127)	Data 0.000 (0.011)	Loss 0.1127 (0.0876)	Prec@1 96.875 (97.013)	Prec@5 100.000 (99.993)
2022-06-17 18:37:25 - INFO - TRAINING - Epoch: [118][170/196]	Time 0.110 (0.127)	Data 0.000 (0.010)	Loss 0.1373 (0.0871)	Prec@1 94.531 (97.030)	Prec@5 100.000 (99.993)
2022-06-17 18:37:26 - INFO - TRAINING - Epoch: [118][180/196]	Time 0.114 (0.126)	Data 0.000 (0.010)	Loss 0.1074 (0.0872)	Prec@1 96.094 (97.026)	Prec@5 100.000 (99.994)
2022-06-17 18:37:27 - INFO - TRAINING - Epoch: [118][190/196]	Time 0.102 (0.125)	Data 0.000 (0.009)	Loss 0.0776 (0.0869)	Prec@1 97.656 (97.039)	Prec@5 100.000 (99.994)
2022-06-17 18:37:30 - INFO - EVALUATING - Epoch: [118][0/40]	Time 1.958 (1.958)	Data 1.912 (1.912)	Loss 0.2537 (0.2537)	Prec@1 94.141 (94.141)	Prec@5 99.609 (99.609)
2022-06-17 18:37:31 - INFO - EVALUATING - Epoch: [118][10/40]	Time 0.066 (0.281)	Data 0.000 (0.233)	Loss 0.4879 (0.4160)	Prec@1 86.719 (88.494)	Prec@5 99.219 (99.432)
2022-06-17 18:37:32 - INFO - EVALUATING - Epoch: [118][20/40]	Time 0.079 (0.171)	Data 0.037 (0.124)	Loss 0.3421 (0.4197)	Prec@1 87.109 (87.928)	Prec@5 100.000 (99.423)
2022-06-17 18:37:33 - INFO - EVALUATING - Epoch: [118][30/40]	Time 0.044 (0.152)	Data 0.000 (0.107)	Loss 0.5189 (0.4121)	Prec@1 86.328 (88.130)	Prec@5 100.000 (99.483)
2022-06-17 18:37:35 - INFO - 
 Epoch: 119	Training Loss 0.0873 	Training Prec@1 97.026 	Training Prec@5 99.990 	Validation Loss 0.4074 	Validation Prec@1 88.180 	Validation Prec@5 99.560 

2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:37:35 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:37:36 - INFO - TRAINING - Epoch: [119][0/196]	Time 1.294 (1.294)	Data 1.241 (1.241)	Loss 0.0644 (0.0644)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:37:38 - INFO - TRAINING - Epoch: [119][10/196]	Time 0.119 (0.248)	Data 0.000 (0.157)	Loss 0.0730 (0.0781)	Prec@1 97.266 (97.763)	Prec@5 100.000 (100.000)
2022-06-17 18:37:39 - INFO - TRAINING - Epoch: [119][20/196]	Time 0.112 (0.186)	Data 0.000 (0.086)	Loss 0.0601 (0.0800)	Prec@1 96.875 (97.470)	Prec@5 100.000 (99.981)
2022-06-17 18:37:40 - INFO - TRAINING - Epoch: [119][30/196]	Time 0.102 (0.163)	Data 0.000 (0.058)	Loss 0.1307 (0.0823)	Prec@1 95.703 (97.341)	Prec@5 100.000 (99.987)
2022-06-17 18:37:41 - INFO - TRAINING - Epoch: [119][40/196]	Time 0.107 (0.152)	Data 0.000 (0.044)	Loss 0.0946 (0.0833)	Prec@1 96.484 (97.304)	Prec@5 100.000 (99.990)
2022-06-17 18:37:42 - INFO - TRAINING - Epoch: [119][50/196]	Time 0.119 (0.145)	Data 0.000 (0.035)	Loss 0.0852 (0.0829)	Prec@1 96.094 (97.243)	Prec@5 100.000 (99.992)
2022-06-17 18:37:43 - INFO - TRAINING - Epoch: [119][60/196]	Time 0.109 (0.141)	Data 0.000 (0.030)	Loss 0.0544 (0.0848)	Prec@1 98.438 (97.163)	Prec@5 100.000 (99.994)
2022-06-17 18:37:45 - INFO - TRAINING - Epoch: [119][70/196]	Time 0.118 (0.138)	Data 0.000 (0.025)	Loss 0.1199 (0.0844)	Prec@1 95.312 (97.183)	Prec@5 100.000 (99.989)
2022-06-17 18:37:46 - INFO - TRAINING - Epoch: [119][80/196]	Time 0.123 (0.136)	Data 0.000 (0.022)	Loss 0.1266 (0.0838)	Prec@1 95.703 (97.203)	Prec@5 100.000 (99.986)
2022-06-17 18:37:47 - INFO - TRAINING - Epoch: [119][90/196]	Time 0.109 (0.134)	Data 0.000 (0.020)	Loss 0.0837 (0.0851)	Prec@1 96.875 (97.184)	Prec@5 100.000 (99.987)
2022-06-17 18:37:48 - INFO - TRAINING - Epoch: [119][100/196]	Time 0.122 (0.132)	Data 0.000 (0.018)	Loss 0.0758 (0.0846)	Prec@1 96.484 (97.181)	Prec@5 100.000 (99.988)
2022-06-17 18:37:49 - INFO - TRAINING - Epoch: [119][110/196]	Time 0.110 (0.130)	Data 0.000 (0.016)	Loss 0.0621 (0.0850)	Prec@1 98.438 (97.153)	Prec@5 100.000 (99.989)
2022-06-17 18:37:50 - INFO - TRAINING - Epoch: [119][120/196]	Time 0.119 (0.129)	Data 0.000 (0.015)	Loss 0.0604 (0.0863)	Prec@1 98.828 (97.114)	Prec@5 100.000 (99.981)
2022-06-17 18:37:52 - INFO - TRAINING - Epoch: [119][130/196]	Time 0.110 (0.128)	Data 0.000 (0.014)	Loss 0.0933 (0.0863)	Prec@1 96.484 (97.120)	Prec@5 100.000 (99.979)
2022-06-17 18:37:53 - INFO - TRAINING - Epoch: [119][140/196]	Time 0.126 (0.127)	Data 0.000 (0.013)	Loss 0.0788 (0.0864)	Prec@1 98.438 (97.088)	Prec@5 100.000 (99.981)
2022-06-17 18:37:54 - INFO - TRAINING - Epoch: [119][150/196]	Time 0.106 (0.126)	Data 0.000 (0.012)	Loss 0.0633 (0.0858)	Prec@1 98.438 (97.121)	Prec@5 100.000 (99.982)
2022-06-17 18:37:55 - INFO - TRAINING - Epoch: [119][160/196]	Time 0.121 (0.126)	Data 0.000 (0.012)	Loss 0.0763 (0.0856)	Prec@1 96.875 (97.130)	Prec@5 100.000 (99.983)
2022-06-17 18:37:56 - INFO - TRAINING - Epoch: [119][170/196]	Time 0.106 (0.125)	Data 0.000 (0.011)	Loss 0.0891 (0.0869)	Prec@1 97.266 (97.071)	Prec@5 100.000 (99.984)
2022-06-17 18:37:57 - INFO - TRAINING - Epoch: [119][180/196]	Time 0.121 (0.125)	Data 0.000 (0.010)	Loss 0.0652 (0.0875)	Prec@1 97.656 (97.039)	Prec@5 100.000 (99.985)
2022-06-17 18:37:59 - INFO - TRAINING - Epoch: [119][190/196]	Time 0.101 (0.124)	Data 0.000 (0.010)	Loss 0.0799 (0.0880)	Prec@1 96.875 (97.016)	Prec@5 100.000 (99.984)
2022-06-17 18:38:01 - INFO - EVALUATING - Epoch: [119][0/40]	Time 1.868 (1.868)	Data 1.821 (1.821)	Loss 0.2620 (0.2620)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:38:02 - INFO - EVALUATING - Epoch: [119][10/40]	Time 0.045 (0.244)	Data 0.000 (0.195)	Loss 0.4779 (0.4165)	Prec@1 87.891 (88.352)	Prec@5 99.219 (99.538)
2022-06-17 18:38:03 - INFO - EVALUATING - Epoch: [119][20/40]	Time 0.457 (0.188)	Data 0.415 (0.140)	Loss 0.3419 (0.4208)	Prec@1 88.281 (87.965)	Prec@5 100.000 (99.516)
2022-06-17 18:38:04 - INFO - EVALUATING - Epoch: [119][30/40]	Time 0.101 (0.153)	Data 0.060 (0.105)	Loss 0.5168 (0.4128)	Prec@1 86.719 (88.168)	Prec@5 100.000 (99.559)
2022-06-17 18:38:06 - INFO - 
 Epoch: 120	Training Loss 0.0886 	Training Prec@1 96.988 	Training Prec@5 99.982 	Validation Loss 0.4074 	Validation Prec@1 88.270 	Validation Prec@5 99.600 

2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:38:06 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:38:08 - INFO - TRAINING - Epoch: [120][0/196]	Time 1.668 (1.668)	Data 1.615 (1.615)	Loss 0.1063 (0.1063)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:38:09 - INFO - TRAINING - Epoch: [120][10/196]	Time 0.111 (0.278)	Data 0.000 (0.186)	Loss 0.0858 (0.0940)	Prec@1 96.484 (96.662)	Prec@5 100.000 (100.000)
2022-06-17 18:38:10 - INFO - TRAINING - Epoch: [120][20/196]	Time 0.103 (0.198)	Data 0.000 (0.098)	Loss 0.1082 (0.0913)	Prec@1 96.484 (97.005)	Prec@5 100.000 (100.000)
2022-06-17 18:38:12 - INFO - TRAINING - Epoch: [120][30/196]	Time 0.131 (0.173)	Data 0.000 (0.066)	Loss 0.0961 (0.0915)	Prec@1 96.484 (96.913)	Prec@5 100.000 (100.000)
2022-06-17 18:38:13 - INFO - TRAINING - Epoch: [120][40/196]	Time 0.114 (0.159)	Data 0.000 (0.050)	Loss 0.0759 (0.0910)	Prec@1 97.656 (96.932)	Prec@5 100.000 (99.981)
2022-06-17 18:38:14 - INFO - TRAINING - Epoch: [120][50/196]	Time 0.126 (0.150)	Data 0.000 (0.040)	Loss 0.0883 (0.0902)	Prec@1 96.875 (96.875)	Prec@5 100.000 (99.985)
2022-06-17 18:38:15 - INFO - TRAINING - Epoch: [120][60/196]	Time 0.103 (0.144)	Data 0.000 (0.034)	Loss 0.1160 (0.0883)	Prec@1 95.312 (96.977)	Prec@5 100.000 (99.981)
2022-06-17 18:38:16 - INFO - TRAINING - Epoch: [120][70/196]	Time 0.128 (0.140)	Data 0.000 (0.029)	Loss 0.0857 (0.0890)	Prec@1 97.656 (96.980)	Prec@5 100.000 (99.978)
2022-06-17 18:38:17 - INFO - TRAINING - Epoch: [120][80/196]	Time 0.114 (0.137)	Data 0.000 (0.026)	Loss 0.0691 (0.0887)	Prec@1 98.047 (97.015)	Prec@5 100.000 (99.981)
2022-06-17 18:38:18 - INFO - TRAINING - Epoch: [120][90/196]	Time 0.121 (0.135)	Data 0.000 (0.023)	Loss 0.0712 (0.0896)	Prec@1 98.438 (97.017)	Prec@5 100.000 (99.983)
2022-06-17 18:38:20 - INFO - TRAINING - Epoch: [120][100/196]	Time 0.103 (0.132)	Data 0.000 (0.021)	Loss 0.0913 (0.0895)	Prec@1 96.484 (97.003)	Prec@5 100.000 (99.985)
2022-06-17 18:38:21 - INFO - TRAINING - Epoch: [120][110/196]	Time 0.119 (0.131)	Data 0.000 (0.019)	Loss 0.0985 (0.0887)	Prec@1 97.266 (97.040)	Prec@5 100.000 (99.982)
2022-06-17 18:38:22 - INFO - TRAINING - Epoch: [120][120/196]	Time 0.119 (0.130)	Data 0.000 (0.017)	Loss 0.1234 (0.0881)	Prec@1 95.312 (97.030)	Prec@5 100.000 (99.984)
2022-06-17 18:38:23 - INFO - TRAINING - Epoch: [120][130/196]	Time 0.123 (0.129)	Data 0.000 (0.016)	Loss 0.0956 (0.0885)	Prec@1 97.656 (97.030)	Prec@5 100.000 (99.982)
2022-06-17 18:38:24 - INFO - TRAINING - Epoch: [120][140/196]	Time 0.101 (0.127)	Data 0.000 (0.015)	Loss 0.0593 (0.0885)	Prec@1 98.828 (97.022)	Prec@5 100.000 (99.981)
2022-06-17 18:38:25 - INFO - TRAINING - Epoch: [120][150/196]	Time 0.112 (0.126)	Data 0.000 (0.014)	Loss 0.0905 (0.0890)	Prec@1 96.875 (97.010)	Prec@5 100.000 (99.982)
2022-06-17 18:38:26 - INFO - TRAINING - Epoch: [120][160/196]	Time 0.117 (0.126)	Data 0.000 (0.013)	Loss 0.0786 (0.0887)	Prec@1 96.094 (96.991)	Prec@5 100.000 (99.983)
2022-06-17 18:38:28 - INFO - TRAINING - Epoch: [120][170/196]	Time 0.122 (0.125)	Data 0.000 (0.012)	Loss 0.1057 (0.0889)	Prec@1 96.484 (96.996)	Prec@5 100.000 (99.984)
2022-06-17 18:38:29 - INFO - TRAINING - Epoch: [120][180/196]	Time 0.104 (0.125)	Data 0.000 (0.012)	Loss 0.0993 (0.0890)	Prec@1 97.266 (96.987)	Prec@5 100.000 (99.985)
2022-06-17 18:38:30 - INFO - TRAINING - Epoch: [120][190/196]	Time 0.104 (0.124)	Data 0.000 (0.011)	Loss 0.0543 (0.0883)	Prec@1 99.219 (97.008)	Prec@5 100.000 (99.986)
2022-06-17 18:38:32 - INFO - EVALUATING - Epoch: [120][0/40]	Time 1.249 (1.249)	Data 1.204 (1.204)	Loss 0.2613 (0.2613)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:38:33 - INFO - EVALUATING - Epoch: [120][10/40]	Time 0.043 (0.231)	Data 0.000 (0.185)	Loss 0.4737 (0.4151)	Prec@1 88.281 (88.601)	Prec@5 98.828 (99.467)
2022-06-17 18:38:34 - INFO - EVALUATING - Epoch: [120][20/40]	Time 0.095 (0.171)	Data 0.052 (0.124)	Loss 0.3399 (0.4171)	Prec@1 87.500 (88.095)	Prec@5 99.609 (99.442)
2022-06-17 18:38:35 - INFO - EVALUATING - Epoch: [120][30/40]	Time 0.092 (0.151)	Data 0.049 (0.105)	Loss 0.5112 (0.4102)	Prec@1 87.109 (88.256)	Prec@5 100.000 (99.483)
2022-06-17 18:38:37 - INFO - 
 Epoch: 121	Training Loss 0.0883 	Training Prec@1 97.006 	Training Prec@5 99.986 	Validation Loss 0.4050 	Validation Prec@1 88.300 	Validation Prec@5 99.550 

2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:38:37 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:38:39 - INFO - TRAINING - Epoch: [121][0/196]	Time 1.779 (1.779)	Data 1.725 (1.725)	Loss 0.0856 (0.0856)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:38:40 - INFO - TRAINING - Epoch: [121][10/196]	Time 0.111 (0.271)	Data 0.000 (0.157)	Loss 0.0910 (0.0924)	Prec@1 97.656 (96.662)	Prec@5 100.000 (99.964)
2022-06-17 18:38:41 - INFO - TRAINING - Epoch: [121][20/196]	Time 0.128 (0.201)	Data 0.000 (0.082)	Loss 0.1134 (0.0861)	Prec@1 95.703 (96.968)	Prec@5 100.000 (99.981)
2022-06-17 18:38:43 - INFO - TRAINING - Epoch: [121][30/196]	Time 0.108 (0.172)	Data 0.000 (0.056)	Loss 0.1004 (0.0879)	Prec@1 96.875 (96.963)	Prec@5 100.000 (99.975)
2022-06-17 18:38:44 - INFO - TRAINING - Epoch: [121][40/196]	Time 0.103 (0.157)	Data 0.000 (0.042)	Loss 0.0796 (0.0891)	Prec@1 96.875 (96.894)	Prec@5 100.000 (99.981)
2022-06-17 18:38:45 - INFO - TRAINING - Epoch: [121][50/196]	Time 0.112 (0.148)	Data 0.000 (0.034)	Loss 0.0779 (0.0884)	Prec@1 98.047 (96.998)	Prec@5 100.000 (99.985)
2022-06-17 18:38:46 - INFO - TRAINING - Epoch: [121][60/196]	Time 0.105 (0.141)	Data 0.000 (0.029)	Loss 0.0421 (0.0873)	Prec@1 99.219 (97.022)	Prec@5 100.000 (99.987)
2022-06-17 18:38:47 - INFO - TRAINING - Epoch: [121][70/196]	Time 0.111 (0.137)	Data 0.000 (0.025)	Loss 0.1063 (0.0883)	Prec@1 95.703 (96.985)	Prec@5 100.000 (99.978)
2022-06-17 18:38:48 - INFO - TRAINING - Epoch: [121][80/196]	Time 0.102 (0.134)	Data 0.000 (0.022)	Loss 0.0790 (0.0881)	Prec@1 97.656 (97.000)	Prec@5 100.000 (99.981)
2022-06-17 18:38:49 - INFO - TRAINING - Epoch: [121][90/196]	Time 0.101 (0.131)	Data 0.000 (0.019)	Loss 0.0616 (0.0870)	Prec@1 98.438 (97.021)	Prec@5 100.000 (99.983)
2022-06-17 18:38:50 - INFO - TRAINING - Epoch: [121][100/196]	Time 0.111 (0.129)	Data 0.000 (0.017)	Loss 0.0825 (0.0872)	Prec@1 96.875 (97.014)	Prec@5 100.000 (99.985)
2022-06-17 18:38:51 - INFO - TRAINING - Epoch: [121][110/196]	Time 0.109 (0.128)	Data 0.000 (0.016)	Loss 0.0865 (0.0876)	Prec@1 96.875 (97.002)	Prec@5 100.000 (99.986)
2022-06-17 18:38:52 - INFO - TRAINING - Epoch: [121][120/196]	Time 0.103 (0.126)	Data 0.000 (0.015)	Loss 0.1556 (0.0883)	Prec@1 94.922 (96.975)	Prec@5 100.000 (99.987)
2022-06-17 18:38:54 - INFO - TRAINING - Epoch: [121][130/196]	Time 0.111 (0.125)	Data 0.000 (0.013)	Loss 0.0675 (0.0875)	Prec@1 97.656 (97.021)	Prec@5 100.000 (99.988)
2022-06-17 18:38:55 - INFO - TRAINING - Epoch: [121][140/196]	Time 0.107 (0.124)	Data 0.000 (0.013)	Loss 0.1064 (0.0874)	Prec@1 96.875 (97.030)	Prec@5 100.000 (99.989)
2022-06-17 18:38:56 - INFO - TRAINING - Epoch: [121][150/196]	Time 0.109 (0.123)	Data 0.000 (0.012)	Loss 0.0868 (0.0874)	Prec@1 97.266 (97.017)	Prec@5 100.000 (99.987)
2022-06-17 18:38:57 - INFO - TRAINING - Epoch: [121][160/196]	Time 0.109 (0.122)	Data 0.000 (0.011)	Loss 0.0988 (0.0880)	Prec@1 96.875 (97.013)	Prec@5 100.000 (99.988)
2022-06-17 18:38:58 - INFO - TRAINING - Epoch: [121][170/196]	Time 0.130 (0.121)	Data 0.000 (0.010)	Loss 0.1017 (0.0877)	Prec@1 96.484 (97.021)	Prec@5 100.000 (99.989)
2022-06-17 18:38:59 - INFO - TRAINING - Epoch: [121][180/196]	Time 0.106 (0.121)	Data 0.000 (0.010)	Loss 0.0814 (0.0878)	Prec@1 97.266 (97.017)	Prec@5 100.000 (99.987)
2022-06-17 18:39:00 - INFO - TRAINING - Epoch: [121][190/196]	Time 0.105 (0.121)	Data 0.000 (0.009)	Loss 0.0565 (0.0875)	Prec@1 98.438 (97.028)	Prec@5 100.000 (99.988)
2022-06-17 18:39:03 - INFO - EVALUATING - Epoch: [121][0/40]	Time 1.841 (1.841)	Data 1.794 (1.794)	Loss 0.2637 (0.2637)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:39:04 - INFO - EVALUATING - Epoch: [121][10/40]	Time 0.044 (0.264)	Data 0.000 (0.214)	Loss 0.4689 (0.4155)	Prec@1 87.500 (88.565)	Prec@5 99.219 (99.396)
2022-06-17 18:39:04 - INFO - EVALUATING - Epoch: [121][20/40]	Time 0.094 (0.166)	Data 0.051 (0.115)	Loss 0.3404 (0.4184)	Prec@1 87.891 (88.132)	Prec@5 99.609 (99.368)
2022-06-17 18:39:06 - INFO - EVALUATING - Epoch: [121][30/40]	Time 0.105 (0.153)	Data 0.063 (0.104)	Loss 0.5097 (0.4112)	Prec@1 86.328 (88.193)	Prec@5 100.000 (99.446)
2022-06-17 18:39:08 - INFO - 
 Epoch: 122	Training Loss 0.0874 	Training Prec@1 97.028 	Training Prec@5 99.988 	Validation Loss 0.4060 	Validation Prec@1 88.300 	Validation Prec@5 99.530 

2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:39:08 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:39:09 - INFO - TRAINING - Epoch: [122][0/196]	Time 1.600 (1.600)	Data 1.547 (1.547)	Loss 0.0969 (0.0969)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:39:11 - INFO - TRAINING - Epoch: [122][10/196]	Time 0.103 (0.271)	Data 0.000 (0.180)	Loss 0.0703 (0.0766)	Prec@1 98.047 (97.337)	Prec@5 100.000 (100.000)
2022-06-17 18:39:12 - INFO - TRAINING - Epoch: [122][20/196]	Time 0.121 (0.198)	Data 0.000 (0.094)	Loss 0.1321 (0.0785)	Prec@1 94.141 (97.061)	Prec@5 100.000 (100.000)
2022-06-17 18:39:13 - INFO - TRAINING - Epoch: [122][30/196]	Time 0.108 (0.172)	Data 0.000 (0.064)	Loss 0.0531 (0.0779)	Prec@1 99.219 (97.190)	Prec@5 100.000 (100.000)
2022-06-17 18:39:14 - INFO - TRAINING - Epoch: [122][40/196]	Time 0.108 (0.157)	Data 0.000 (0.049)	Loss 0.0490 (0.0794)	Prec@1 98.438 (97.142)	Prec@5 100.000 (99.990)
2022-06-17 18:39:15 - INFO - TRAINING - Epoch: [122][50/196]	Time 0.101 (0.148)	Data 0.000 (0.039)	Loss 0.0825 (0.0805)	Prec@1 97.266 (97.105)	Prec@5 100.000 (99.992)
2022-06-17 18:39:16 - INFO - TRAINING - Epoch: [122][60/196]	Time 0.117 (0.142)	Data 0.001 (0.033)	Loss 0.1025 (0.0811)	Prec@1 98.047 (97.125)	Prec@5 100.000 (99.994)
2022-06-17 18:39:17 - INFO - TRAINING - Epoch: [122][70/196]	Time 0.127 (0.138)	Data 0.000 (0.028)	Loss 0.0722 (0.0815)	Prec@1 98.438 (97.222)	Prec@5 100.000 (99.994)
2022-06-17 18:39:19 - INFO - TRAINING - Epoch: [122][80/196]	Time 0.117 (0.136)	Data 0.000 (0.025)	Loss 0.0846 (0.0810)	Prec@1 97.266 (97.203)	Prec@5 100.000 (99.995)
2022-06-17 18:39:20 - INFO - TRAINING - Epoch: [122][90/196]	Time 0.102 (0.133)	Data 0.000 (0.022)	Loss 0.0963 (0.0829)	Prec@1 96.875 (97.150)	Prec@5 100.000 (99.991)
2022-06-17 18:39:21 - INFO - TRAINING - Epoch: [122][100/196]	Time 0.126 (0.132)	Data 0.000 (0.020)	Loss 0.1380 (0.0835)	Prec@1 94.922 (97.134)	Prec@5 100.000 (99.992)
2022-06-17 18:39:22 - INFO - TRAINING - Epoch: [122][110/196]	Time 0.121 (0.130)	Data 0.000 (0.018)	Loss 0.1117 (0.0845)	Prec@1 95.703 (97.079)	Prec@5 100.000 (99.986)
2022-06-17 18:39:23 - INFO - TRAINING - Epoch: [122][120/196]	Time 0.128 (0.129)	Data 0.000 (0.017)	Loss 0.1456 (0.0851)	Prec@1 96.094 (97.049)	Prec@5 100.000 (99.984)
2022-06-17 18:39:24 - INFO - TRAINING - Epoch: [122][130/196]	Time 0.108 (0.128)	Data 0.000 (0.015)	Loss 0.1212 (0.0867)	Prec@1 96.484 (96.976)	Prec@5 100.000 (99.982)
2022-06-17 18:39:26 - INFO - TRAINING - Epoch: [122][140/196]	Time 0.136 (0.128)	Data 0.000 (0.014)	Loss 0.1172 (0.0869)	Prec@1 95.312 (96.983)	Prec@5 100.000 (99.983)
2022-06-17 18:39:27 - INFO - TRAINING - Epoch: [122][150/196]	Time 0.121 (0.127)	Data 0.000 (0.013)	Loss 0.1042 (0.0870)	Prec@1 96.094 (96.989)	Prec@5 100.000 (99.979)
2022-06-17 18:39:28 - INFO - TRAINING - Epoch: [122][160/196]	Time 0.109 (0.126)	Data 0.000 (0.013)	Loss 0.0785 (0.0861)	Prec@1 98.047 (97.040)	Prec@5 100.000 (99.981)
2022-06-17 18:39:29 - INFO - TRAINING - Epoch: [122][170/196]	Time 0.103 (0.125)	Data 0.000 (0.012)	Loss 0.0526 (0.0858)	Prec@1 98.047 (97.053)	Prec@5 100.000 (99.979)
2022-06-17 18:39:30 - INFO - TRAINING - Epoch: [122][180/196]	Time 0.123 (0.124)	Data 0.000 (0.011)	Loss 0.1118 (0.0863)	Prec@1 94.922 (97.022)	Prec@5 100.000 (99.981)
2022-06-17 18:39:31 - INFO - TRAINING - Epoch: [122][190/196]	Time 0.102 (0.124)	Data 0.000 (0.011)	Loss 0.1085 (0.0864)	Prec@1 96.875 (97.030)	Prec@5 100.000 (99.980)
2022-06-17 18:39:34 - INFO - EVALUATING - Epoch: [122][0/40]	Time 1.899 (1.899)	Data 1.854 (1.854)	Loss 0.2653 (0.2653)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:39:34 - INFO - EVALUATING - Epoch: [122][10/40]	Time 0.044 (0.242)	Data 0.000 (0.194)	Loss 0.4693 (0.4173)	Prec@1 87.500 (88.246)	Prec@5 99.219 (99.467)
2022-06-17 18:39:35 - INFO - EVALUATING - Epoch: [122][20/40]	Time 0.220 (0.176)	Data 0.176 (0.129)	Loss 0.3414 (0.4216)	Prec@1 87.891 (87.760)	Prec@5 100.000 (99.423)
2022-06-17 18:39:37 - INFO - EVALUATING - Epoch: [122][30/40]	Time 0.045 (0.153)	Data 0.000 (0.106)	Loss 0.5108 (0.4124)	Prec@1 85.938 (88.054)	Prec@5 100.000 (99.471)
2022-06-17 18:39:38 - INFO - 
 Epoch: 123	Training Loss 0.0862 	Training Prec@1 97.042 	Training Prec@5 99.980 	Validation Loss 0.4077 	Validation Prec@1 88.080 	Validation Prec@5 99.550 

2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:39:38 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:39:40 - INFO - TRAINING - Epoch: [123][0/196]	Time 1.441 (1.441)	Data 1.387 (1.387)	Loss 0.0909 (0.0909)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:39:41 - INFO - TRAINING - Epoch: [123][10/196]	Time 0.104 (0.272)	Data 0.000 (0.181)	Loss 0.0725 (0.0815)	Prec@1 97.656 (97.337)	Prec@5 100.000 (100.000)
2022-06-17 18:39:42 - INFO - TRAINING - Epoch: [123][20/196]	Time 0.102 (0.195)	Data 0.000 (0.095)	Loss 0.1034 (0.0822)	Prec@1 96.094 (97.321)	Prec@5 100.000 (100.000)
2022-06-17 18:39:43 - INFO - TRAINING - Epoch: [123][30/196]	Time 0.103 (0.167)	Data 0.000 (0.064)	Loss 0.1069 (0.0824)	Prec@1 96.094 (97.165)	Prec@5 100.000 (100.000)
2022-06-17 18:39:45 - INFO - TRAINING - Epoch: [123][40/196]	Time 0.111 (0.153)	Data 0.000 (0.049)	Loss 0.0764 (0.0867)	Prec@1 97.266 (96.932)	Prec@5 100.000 (100.000)
2022-06-17 18:39:46 - INFO - TRAINING - Epoch: [123][50/196]	Time 0.108 (0.145)	Data 0.000 (0.039)	Loss 0.1067 (0.0881)	Prec@1 96.484 (96.936)	Prec@5 100.000 (99.992)
2022-06-17 18:39:47 - INFO - TRAINING - Epoch: [123][60/196]	Time 0.118 (0.140)	Data 0.000 (0.033)	Loss 0.0831 (0.0887)	Prec@1 96.484 (96.920)	Prec@5 100.000 (99.987)
2022-06-17 18:39:48 - INFO - TRAINING - Epoch: [123][70/196]	Time 0.110 (0.136)	Data 0.000 (0.028)	Loss 0.1181 (0.0888)	Prec@1 95.703 (96.914)	Prec@5 100.000 (99.989)
2022-06-17 18:39:49 - INFO - TRAINING - Epoch: [123][80/196]	Time 0.109 (0.132)	Data 0.000 (0.025)	Loss 0.0892 (0.0881)	Prec@1 96.875 (96.967)	Prec@5 99.609 (99.986)
2022-06-17 18:39:50 - INFO - TRAINING - Epoch: [123][90/196]	Time 0.118 (0.130)	Data 0.000 (0.022)	Loss 0.1209 (0.0874)	Prec@1 95.703 (96.999)	Prec@5 100.000 (99.987)
2022-06-17 18:39:51 - INFO - TRAINING - Epoch: [123][100/196]	Time 0.134 (0.129)	Data 0.000 (0.020)	Loss 0.0878 (0.0879)	Prec@1 96.875 (96.995)	Prec@5 100.000 (99.981)
2022-06-17 18:39:53 - INFO - TRAINING - Epoch: [123][110/196]	Time 0.137 (0.128)	Data 0.000 (0.018)	Loss 0.0866 (0.0884)	Prec@1 96.094 (96.952)	Prec@5 100.000 (99.982)
2022-06-17 18:39:54 - INFO - TRAINING - Epoch: [123][120/196]	Time 0.124 (0.127)	Data 0.000 (0.017)	Loss 0.0572 (0.0877)	Prec@1 98.828 (96.994)	Prec@5 100.000 (99.981)
2022-06-17 18:39:55 - INFO - TRAINING - Epoch: [123][130/196]	Time 0.125 (0.126)	Data 0.000 (0.015)	Loss 0.1001 (0.0870)	Prec@1 96.484 (97.024)	Prec@5 100.000 (99.979)
2022-06-17 18:39:56 - INFO - TRAINING - Epoch: [123][140/196]	Time 0.123 (0.126)	Data 0.000 (0.014)	Loss 0.0614 (0.0864)	Prec@1 98.828 (97.077)	Prec@5 100.000 (99.981)
2022-06-17 18:39:57 - INFO - TRAINING - Epoch: [123][150/196]	Time 0.110 (0.125)	Data 0.000 (0.013)	Loss 0.1037 (0.0863)	Prec@1 96.875 (97.092)	Prec@5 100.000 (99.977)
2022-06-17 18:39:58 - INFO - TRAINING - Epoch: [123][160/196]	Time 0.103 (0.124)	Data 0.000 (0.013)	Loss 0.0788 (0.0862)	Prec@1 97.266 (97.127)	Prec@5 100.000 (99.978)
2022-06-17 18:39:59 - INFO - TRAINING - Epoch: [123][170/196]	Time 0.110 (0.123)	Data 0.000 (0.012)	Loss 0.0884 (0.0865)	Prec@1 97.266 (97.097)	Prec@5 100.000 (99.979)
2022-06-17 18:40:01 - INFO - TRAINING - Epoch: [123][180/196]	Time 0.121 (0.123)	Data 0.000 (0.011)	Loss 0.0647 (0.0860)	Prec@1 98.047 (97.106)	Prec@5 100.000 (99.981)
2022-06-17 18:40:02 - INFO - TRAINING - Epoch: [123][190/196]	Time 0.103 (0.122)	Data 0.000 (0.011)	Loss 0.0957 (0.0866)	Prec@1 96.484 (97.075)	Prec@5 100.000 (99.978)
2022-06-17 18:40:04 - INFO - EVALUATING - Epoch: [123][0/40]	Time 1.692 (1.692)	Data 1.645 (1.645)	Loss 0.2675 (0.2675)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:40:05 - INFO - EVALUATING - Epoch: [123][10/40]	Time 0.073 (0.263)	Data 0.029 (0.217)	Loss 0.4774 (0.4208)	Prec@1 88.281 (88.494)	Prec@5 99.219 (99.467)
2022-06-17 18:40:06 - INFO - EVALUATING - Epoch: [123][20/40]	Time 0.110 (0.171)	Data 0.070 (0.126)	Loss 0.3313 (0.4212)	Prec@1 87.109 (87.984)	Prec@5 99.609 (99.386)
2022-06-17 18:40:07 - INFO - EVALUATING - Epoch: [123][30/40]	Time 0.086 (0.151)	Data 0.043 (0.107)	Loss 0.5233 (0.4142)	Prec@1 85.938 (88.155)	Prec@5 100.000 (99.458)
2022-06-17 18:40:09 - INFO - 
 Epoch: 124	Training Loss 0.0866 	Training Prec@1 97.082 	Training Prec@5 99.978 	Validation Loss 0.4088 	Validation Prec@1 88.180 	Validation Prec@5 99.530 

2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:40:09 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:40:11 - INFO - TRAINING - Epoch: [124][0/196]	Time 2.049 (2.049)	Data 1.995 (1.995)	Loss 0.1031 (0.1031)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:40:12 - INFO - TRAINING - Epoch: [124][10/196]	Time 0.103 (0.286)	Data 0.000 (0.182)	Loss 0.0984 (0.0967)	Prec@1 96.094 (96.555)	Prec@5 100.000 (99.929)
2022-06-17 18:40:13 - INFO - TRAINING - Epoch: [124][20/196]	Time 0.103 (0.202)	Data 0.000 (0.095)	Loss 0.1014 (0.0894)	Prec@1 95.703 (96.726)	Prec@5 100.000 (99.963)
2022-06-17 18:40:14 - INFO - TRAINING - Epoch: [124][30/196]	Time 0.107 (0.172)	Data 0.000 (0.065)	Loss 0.0620 (0.0871)	Prec@1 98.438 (97.001)	Prec@5 100.000 (99.962)
2022-06-17 18:40:15 - INFO - TRAINING - Epoch: [124][40/196]	Time 0.110 (0.156)	Data 0.000 (0.049)	Loss 0.0891 (0.0863)	Prec@1 96.094 (97.027)	Prec@5 100.000 (99.971)
2022-06-17 18:40:17 - INFO - TRAINING - Epoch: [124][50/196]	Time 0.127 (0.148)	Data 0.000 (0.039)	Loss 0.0696 (0.0827)	Prec@1 98.047 (97.227)	Prec@5 100.000 (99.977)
2022-06-17 18:40:18 - INFO - TRAINING - Epoch: [124][60/196]	Time 0.107 (0.142)	Data 0.000 (0.033)	Loss 0.0553 (0.0836)	Prec@1 97.266 (97.195)	Prec@5 100.000 (99.981)
2022-06-17 18:40:19 - INFO - TRAINING - Epoch: [124][70/196]	Time 0.105 (0.137)	Data 0.000 (0.028)	Loss 0.0508 (0.0840)	Prec@1 98.438 (97.123)	Prec@5 100.000 (99.983)
2022-06-17 18:40:20 - INFO - TRAINING - Epoch: [124][80/196]	Time 0.109 (0.134)	Data 0.000 (0.025)	Loss 0.1186 (0.0837)	Prec@1 96.875 (97.116)	Prec@5 100.000 (99.986)
2022-06-17 18:40:21 - INFO - TRAINING - Epoch: [124][90/196]	Time 0.103 (0.131)	Data 0.000 (0.022)	Loss 0.0524 (0.0843)	Prec@1 98.438 (97.060)	Prec@5 100.000 (99.987)
2022-06-17 18:40:22 - INFO - TRAINING - Epoch: [124][100/196]	Time 0.106 (0.129)	Data 0.000 (0.020)	Loss 0.0540 (0.0840)	Prec@1 98.438 (97.088)	Prec@5 100.000 (99.988)
2022-06-17 18:40:23 - INFO - TRAINING - Epoch: [124][110/196]	Time 0.103 (0.127)	Data 0.000 (0.018)	Loss 0.0719 (0.0831)	Prec@1 97.656 (97.135)	Prec@5 100.000 (99.989)
2022-06-17 18:40:24 - INFO - TRAINING - Epoch: [124][120/196]	Time 0.128 (0.126)	Data 0.000 (0.017)	Loss 0.0934 (0.0838)	Prec@1 98.047 (97.091)	Prec@5 100.000 (99.990)
2022-06-17 18:40:25 - INFO - TRAINING - Epoch: [124][130/196]	Time 0.110 (0.125)	Data 0.000 (0.016)	Loss 0.0672 (0.0837)	Prec@1 98.047 (97.108)	Prec@5 100.000 (99.991)
2022-06-17 18:40:26 - INFO - TRAINING - Epoch: [124][140/196]	Time 0.106 (0.124)	Data 0.000 (0.014)	Loss 0.1256 (0.0851)	Prec@1 96.484 (97.074)	Prec@5 100.000 (99.989)
2022-06-17 18:40:28 - INFO - TRAINING - Epoch: [124][150/196]	Time 0.121 (0.123)	Data 0.000 (0.014)	Loss 0.0867 (0.0854)	Prec@1 97.656 (97.061)	Prec@5 99.609 (99.987)
2022-06-17 18:40:29 - INFO - TRAINING - Epoch: [124][160/196]	Time 0.108 (0.122)	Data 0.001 (0.013)	Loss 0.0691 (0.0851)	Prec@1 98.047 (97.093)	Prec@5 100.000 (99.988)
2022-06-17 18:40:30 - INFO - TRAINING - Epoch: [124][170/196]	Time 0.109 (0.122)	Data 0.000 (0.012)	Loss 0.0722 (0.0847)	Prec@1 97.656 (97.115)	Prec@5 100.000 (99.989)
2022-06-17 18:40:31 - INFO - TRAINING - Epoch: [124][180/196]	Time 0.101 (0.121)	Data 0.000 (0.011)	Loss 0.0548 (0.0850)	Prec@1 97.656 (97.084)	Prec@5 100.000 (99.985)
2022-06-17 18:40:32 - INFO - TRAINING - Epoch: [124][190/196]	Time 0.103 (0.120)	Data 0.000 (0.011)	Loss 0.1059 (0.0851)	Prec@1 96.484 (97.088)	Prec@5 100.000 (99.986)
2022-06-17 18:40:34 - INFO - EVALUATING - Epoch: [124][0/40]	Time 1.709 (1.709)	Data 1.662 (1.662)	Loss 0.2614 (0.2614)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
2022-06-17 18:40:35 - INFO - EVALUATING - Epoch: [124][10/40]	Time 0.044 (0.243)	Data 0.000 (0.191)	Loss 0.4676 (0.4189)	Prec@1 88.281 (88.494)	Prec@5 99.219 (99.467)
2022-06-17 18:40:36 - INFO - EVALUATING - Epoch: [124][20/40]	Time 0.044 (0.171)	Data 0.000 (0.120)	Loss 0.3415 (0.4202)	Prec@1 87.109 (88.132)	Prec@5 99.609 (99.405)
2022-06-17 18:40:37 - INFO - EVALUATING - Epoch: [124][30/40]	Time 0.265 (0.154)	Data 0.223 (0.104)	Loss 0.5177 (0.4132)	Prec@1 86.719 (88.269)	Prec@5 100.000 (99.471)
2022-06-17 18:40:39 - INFO - 
 Epoch: 125	Training Loss 0.0855 	Training Prec@1 97.068 	Training Prec@5 99.986 	Validation Loss 0.4081 	Validation Prec@1 88.290 	Validation Prec@5 99.530 

2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:40:39 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:40:40 - INFO - TRAINING - Epoch: [125][0/196]	Time 1.413 (1.413)	Data 1.358 (1.358)	Loss 0.0735 (0.0735)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:40:42 - INFO - TRAINING - Epoch: [125][10/196]	Time 0.306 (0.274)	Data 0.256 (0.204)	Loss 0.0678 (0.0750)	Prec@1 97.656 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:40:43 - INFO - TRAINING - Epoch: [125][20/196]	Time 0.107 (0.198)	Data 0.000 (0.107)	Loss 0.1297 (0.0774)	Prec@1 95.703 (97.340)	Prec@5 100.000 (99.981)
2022-06-17 18:40:44 - INFO - TRAINING - Epoch: [125][30/196]	Time 0.108 (0.171)	Data 0.000 (0.073)	Loss 0.1096 (0.0793)	Prec@1 96.094 (97.253)	Prec@5 99.609 (99.962)
2022-06-17 18:40:45 - INFO - TRAINING - Epoch: [125][40/196]	Time 0.106 (0.156)	Data 0.000 (0.055)	Loss 0.0794 (0.0795)	Prec@1 96.875 (97.199)	Prec@5 100.000 (99.962)
2022-06-17 18:40:47 - INFO - TRAINING - Epoch: [125][50/196]	Time 0.102 (0.148)	Data 0.000 (0.044)	Loss 0.0915 (0.0812)	Prec@1 95.703 (97.158)	Prec@5 100.000 (99.969)
2022-06-17 18:40:48 - INFO - TRAINING - Epoch: [125][60/196]	Time 0.110 (0.142)	Data 0.000 (0.037)	Loss 0.0716 (0.0817)	Prec@1 96.875 (97.131)	Prec@5 100.000 (99.974)
2022-06-17 18:40:49 - INFO - TRAINING - Epoch: [125][70/196]	Time 0.110 (0.138)	Data 0.000 (0.032)	Loss 0.0674 (0.0825)	Prec@1 97.266 (97.062)	Prec@5 100.000 (99.978)
2022-06-17 18:40:50 - INFO - TRAINING - Epoch: [125][80/196]	Time 0.111 (0.135)	Data 0.000 (0.028)	Loss 0.1052 (0.0824)	Prec@1 95.312 (97.087)	Prec@5 100.000 (99.981)
2022-06-17 18:40:51 - INFO - TRAINING - Epoch: [125][90/196]	Time 0.119 (0.133)	Data 0.000 (0.025)	Loss 0.0988 (0.0832)	Prec@1 97.266 (97.111)	Prec@5 99.609 (99.979)
2022-06-17 18:40:52 - INFO - TRAINING - Epoch: [125][100/196]	Time 0.125 (0.131)	Data 0.000 (0.023)	Loss 0.0730 (0.0844)	Prec@1 98.047 (97.111)	Prec@5 100.000 (99.977)
2022-06-17 18:40:53 - INFO - TRAINING - Epoch: [125][110/196]	Time 0.103 (0.130)	Data 0.000 (0.021)	Loss 0.0651 (0.0838)	Prec@1 98.047 (97.128)	Prec@5 100.000 (99.979)
2022-06-17 18:40:55 - INFO - TRAINING - Epoch: [125][120/196]	Time 0.122 (0.129)	Data 0.000 (0.019)	Loss 0.0955 (0.0826)	Prec@1 96.875 (97.175)	Prec@5 100.000 (99.977)
2022-06-17 18:40:56 - INFO - TRAINING - Epoch: [125][130/196]	Time 0.117 (0.128)	Data 0.000 (0.017)	Loss 0.0760 (0.0828)	Prec@1 97.656 (97.164)	Prec@5 100.000 (99.973)
2022-06-17 18:40:57 - INFO - TRAINING - Epoch: [125][140/196]	Time 0.135 (0.127)	Data 0.000 (0.016)	Loss 0.0934 (0.0824)	Prec@1 96.875 (97.174)	Prec@5 100.000 (99.975)
2022-06-17 18:40:58 - INFO - TRAINING - Epoch: [125][150/196]	Time 0.102 (0.125)	Data 0.000 (0.015)	Loss 0.0856 (0.0824)	Prec@1 97.656 (97.185)	Prec@5 100.000 (99.977)
2022-06-17 18:40:59 - INFO - TRAINING - Epoch: [125][160/196]	Time 0.128 (0.125)	Data 0.000 (0.014)	Loss 0.0544 (0.0826)	Prec@1 98.828 (97.186)	Prec@5 100.000 (99.978)
2022-06-17 18:41:00 - INFO - TRAINING - Epoch: [125][170/196]	Time 0.106 (0.124)	Data 0.000 (0.013)	Loss 0.0904 (0.0825)	Prec@1 96.875 (97.177)	Prec@5 100.000 (99.979)
2022-06-17 18:41:01 - INFO - TRAINING - Epoch: [125][180/196]	Time 0.104 (0.124)	Data 0.000 (0.013)	Loss 0.0723 (0.0826)	Prec@1 98.047 (97.192)	Prec@5 100.000 (99.981)
2022-06-17 18:41:02 - INFO - TRAINING - Epoch: [125][190/196]	Time 0.104 (0.123)	Data 0.000 (0.012)	Loss 0.1001 (0.0829)	Prec@1 96.875 (97.165)	Prec@5 100.000 (99.982)
2022-06-17 18:41:05 - INFO - EVALUATING - Epoch: [125][0/40]	Time 1.929 (1.929)	Data 1.884 (1.884)	Loss 0.2673 (0.2673)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:41:06 - INFO - EVALUATING - Epoch: [125][10/40]	Time 0.045 (0.262)	Data 0.000 (0.214)	Loss 0.4701 (0.4196)	Prec@1 87.891 (88.423)	Prec@5 99.219 (99.467)
2022-06-17 18:41:07 - INFO - EVALUATING - Epoch: [125][20/40]	Time 0.149 (0.174)	Data 0.105 (0.125)	Loss 0.3329 (0.4206)	Prec@1 87.109 (88.114)	Prec@5 99.609 (99.405)
2022-06-17 18:41:08 - INFO - EVALUATING - Epoch: [125][30/40]	Time 0.057 (0.162)	Data 0.000 (0.114)	Loss 0.5149 (0.4137)	Prec@1 87.109 (88.218)	Prec@5 100.000 (99.471)
2022-06-17 18:41:10 - INFO - 
 Epoch: 126	Training Loss 0.0829 	Training Prec@1 97.166 	Training Prec@5 99.982 	Validation Loss 0.4085 	Validation Prec@1 88.240 	Validation Prec@5 99.540 

2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:41:10 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:41:11 - INFO - TRAINING - Epoch: [126][0/196]	Time 1.714 (1.714)	Data 1.661 (1.661)	Loss 0.0687 (0.0687)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:41:13 - INFO - TRAINING - Epoch: [126][10/196]	Time 0.108 (0.262)	Data 0.000 (0.159)	Loss 0.0557 (0.0785)	Prec@1 98.047 (97.053)	Prec@5 100.000 (99.964)
2022-06-17 18:41:14 - INFO - TRAINING - Epoch: [126][20/196]	Time 0.122 (0.192)	Data 0.000 (0.084)	Loss 0.0788 (0.0849)	Prec@1 96.875 (96.894)	Prec@5 100.000 (99.981)
2022-06-17 18:41:15 - INFO - TRAINING - Epoch: [126][30/196]	Time 0.101 (0.167)	Data 0.000 (0.057)	Loss 0.1125 (0.0853)	Prec@1 96.484 (96.976)	Prec@5 100.000 (99.987)
2022-06-17 18:41:16 - INFO - TRAINING - Epoch: [126][40/196]	Time 0.118 (0.154)	Data 0.000 (0.043)	Loss 0.1107 (0.0852)	Prec@1 96.094 (97.027)	Prec@5 100.000 (99.990)
2022-06-17 18:41:17 - INFO - TRAINING - Epoch: [126][50/196]	Time 0.117 (0.147)	Data 0.000 (0.035)	Loss 0.0833 (0.0851)	Prec@1 97.656 (96.990)	Prec@5 100.000 (99.992)
2022-06-17 18:41:18 - INFO - TRAINING - Epoch: [126][60/196]	Time 0.137 (0.142)	Data 0.000 (0.029)	Loss 0.1121 (0.0840)	Prec@1 97.266 (97.067)	Prec@5 100.000 (99.994)
2022-06-17 18:41:20 - INFO - TRAINING - Epoch: [126][70/196]	Time 0.103 (0.138)	Data 0.000 (0.025)	Loss 0.0539 (0.0836)	Prec@1 98.047 (97.112)	Prec@5 100.000 (99.994)
2022-06-17 18:41:21 - INFO - TRAINING - Epoch: [126][80/196]	Time 0.111 (0.136)	Data 0.000 (0.022)	Loss 0.0948 (0.0849)	Prec@1 97.266 (97.073)	Prec@5 100.000 (99.990)
2022-06-17 18:41:22 - INFO - TRAINING - Epoch: [126][90/196]	Time 0.128 (0.134)	Data 0.000 (0.020)	Loss 0.0984 (0.0838)	Prec@1 96.484 (97.124)	Prec@5 100.000 (99.991)
2022-06-17 18:41:23 - INFO - TRAINING - Epoch: [126][100/196]	Time 0.120 (0.133)	Data 0.000 (0.018)	Loss 0.1061 (0.0848)	Prec@1 96.094 (97.088)	Prec@5 100.000 (99.992)
2022-06-17 18:41:24 - INFO - TRAINING - Epoch: [126][110/196]	Time 0.103 (0.132)	Data 0.000 (0.016)	Loss 0.0774 (0.0842)	Prec@1 97.266 (97.107)	Prec@5 100.000 (99.989)
2022-06-17 18:41:25 - INFO - TRAINING - Epoch: [126][120/196]	Time 0.125 (0.130)	Data 0.000 (0.015)	Loss 0.0835 (0.0839)	Prec@1 97.266 (97.127)	Prec@5 100.000 (99.987)
2022-06-17 18:41:27 - INFO - TRAINING - Epoch: [126][130/196]	Time 0.116 (0.129)	Data 0.000 (0.014)	Loss 0.0841 (0.0843)	Prec@1 96.484 (97.117)	Prec@5 100.000 (99.985)
2022-06-17 18:41:28 - INFO - TRAINING - Epoch: [126][140/196]	Time 0.130 (0.128)	Data 0.000 (0.013)	Loss 0.0732 (0.0835)	Prec@1 97.656 (97.122)	Prec@5 100.000 (99.986)
2022-06-17 18:41:29 - INFO - TRAINING - Epoch: [126][150/196]	Time 0.139 (0.128)	Data 0.000 (0.012)	Loss 0.0699 (0.0832)	Prec@1 97.656 (97.139)	Prec@5 100.000 (99.987)
2022-06-17 18:41:30 - INFO - TRAINING - Epoch: [126][160/196]	Time 0.119 (0.127)	Data 0.000 (0.011)	Loss 0.0781 (0.0835)	Prec@1 97.266 (97.139)	Prec@5 100.000 (99.985)
2022-06-17 18:41:31 - INFO - TRAINING - Epoch: [126][170/196]	Time 0.110 (0.127)	Data 0.000 (0.011)	Loss 0.1192 (0.0835)	Prec@1 95.703 (97.140)	Prec@5 100.000 (99.986)
2022-06-17 18:41:33 - INFO - TRAINING - Epoch: [126][180/196]	Time 0.107 (0.126)	Data 0.000 (0.010)	Loss 0.0507 (0.0836)	Prec@1 99.219 (97.143)	Prec@5 100.000 (99.987)
2022-06-17 18:41:34 - INFO - TRAINING - Epoch: [126][190/196]	Time 0.107 (0.125)	Data 0.000 (0.010)	Loss 0.0976 (0.0839)	Prec@1 96.094 (97.133)	Prec@5 100.000 (99.988)
2022-06-17 18:41:36 - INFO - EVALUATING - Epoch: [126][0/40]	Time 1.665 (1.665)	Data 1.619 (1.619)	Loss 0.2616 (0.2616)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:41:37 - INFO - EVALUATING - Epoch: [126][10/40]	Time 0.478 (0.251)	Data 0.436 (0.201)	Loss 0.4737 (0.4159)	Prec@1 87.891 (88.317)	Prec@5 99.609 (99.467)
2022-06-17 18:41:38 - INFO - EVALUATING - Epoch: [126][20/40]	Time 0.101 (0.161)	Data 0.059 (0.111)	Loss 0.3463 (0.4193)	Prec@1 87.500 (87.909)	Prec@5 100.000 (99.461)
2022-06-17 18:41:39 - INFO - EVALUATING - Epoch: [126][30/40]	Time 0.093 (0.145)	Data 0.051 (0.097)	Loss 0.5228 (0.4126)	Prec@1 85.938 (88.092)	Prec@5 100.000 (99.509)
2022-06-17 18:41:41 - INFO - 
 Epoch: 127	Training Loss 0.0839 	Training Prec@1 97.132 	Training Prec@5 99.988 	Validation Loss 0.4073 	Validation Prec@1 88.120 	Validation Prec@5 99.570 

2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:41:41 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:41:42 - INFO - TRAINING - Epoch: [127][0/196]	Time 1.427 (1.427)	Data 1.373 (1.373)	Loss 0.0742 (0.0742)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:41:44 - INFO - TRAINING - Epoch: [127][10/196]	Time 0.102 (0.264)	Data 0.000 (0.165)	Loss 0.0896 (0.0845)	Prec@1 96.484 (97.195)	Prec@5 100.000 (100.000)
2022-06-17 18:41:45 - INFO - TRAINING - Epoch: [127][20/196]	Time 0.109 (0.188)	Data 0.000 (0.086)	Loss 0.0968 (0.0818)	Prec@1 96.094 (97.303)	Prec@5 100.000 (100.000)
2022-06-17 18:41:46 - INFO - TRAINING - Epoch: [127][30/196]	Time 0.109 (0.164)	Data 0.000 (0.059)	Loss 0.1296 (0.0850)	Prec@1 95.312 (97.190)	Prec@5 100.000 (99.987)
2022-06-17 18:41:47 - INFO - TRAINING - Epoch: [127][40/196]	Time 0.102 (0.151)	Data 0.000 (0.044)	Loss 0.1076 (0.0844)	Prec@1 96.484 (97.247)	Prec@5 100.000 (99.990)
2022-06-17 18:41:48 - INFO - TRAINING - Epoch: [127][50/196]	Time 0.105 (0.143)	Data 0.000 (0.036)	Loss 0.0984 (0.0831)	Prec@1 97.266 (97.266)	Prec@5 100.000 (99.985)
2022-06-17 18:41:49 - INFO - TRAINING - Epoch: [127][60/196]	Time 0.115 (0.138)	Data 0.000 (0.030)	Loss 0.1047 (0.0825)	Prec@1 96.875 (97.285)	Prec@5 100.000 (99.987)
2022-06-17 18:41:50 - INFO - TRAINING - Epoch: [127][70/196]	Time 0.113 (0.134)	Data 0.000 (0.026)	Loss 0.0819 (0.0835)	Prec@1 97.656 (97.216)	Prec@5 100.000 (99.983)
2022-06-17 18:41:51 - INFO - TRAINING - Epoch: [127][80/196]	Time 0.120 (0.132)	Data 0.000 (0.023)	Loss 0.1115 (0.0847)	Prec@1 94.922 (97.145)	Prec@5 100.000 (99.981)
2022-06-17 18:41:53 - INFO - TRAINING - Epoch: [127][90/196]	Time 0.117 (0.130)	Data 0.000 (0.020)	Loss 0.0709 (0.0842)	Prec@1 97.266 (97.163)	Prec@5 100.000 (99.983)
2022-06-17 18:41:54 - INFO - TRAINING - Epoch: [127][100/196]	Time 0.116 (0.128)	Data 0.000 (0.018)	Loss 0.0847 (0.0836)	Prec@1 96.875 (97.177)	Prec@5 100.000 (99.985)
2022-06-17 18:41:55 - INFO - TRAINING - Epoch: [127][110/196]	Time 0.108 (0.126)	Data 0.000 (0.017)	Loss 0.0982 (0.0829)	Prec@1 96.875 (97.209)	Prec@5 100.000 (99.986)
2022-06-17 18:41:56 - INFO - TRAINING - Epoch: [127][120/196]	Time 0.103 (0.125)	Data 0.000 (0.015)	Loss 0.1077 (0.0844)	Prec@1 96.094 (97.175)	Prec@5 100.000 (99.987)
2022-06-17 18:41:57 - INFO - TRAINING - Epoch: [127][130/196]	Time 0.123 (0.124)	Data 0.000 (0.014)	Loss 0.0940 (0.0846)	Prec@1 96.484 (97.146)	Prec@5 100.000 (99.988)
2022-06-17 18:41:58 - INFO - TRAINING - Epoch: [127][140/196]	Time 0.117 (0.123)	Data 0.000 (0.013)	Loss 0.1200 (0.0850)	Prec@1 96.484 (97.141)	Prec@5 100.000 (99.989)
2022-06-17 18:41:59 - INFO - TRAINING - Epoch: [127][150/196]	Time 0.106 (0.122)	Data 0.000 (0.012)	Loss 0.0975 (0.0850)	Prec@1 96.484 (97.136)	Prec@5 100.000 (99.987)
2022-06-17 18:42:00 - INFO - TRAINING - Epoch: [127][160/196]	Time 0.103 (0.122)	Data 0.000 (0.012)	Loss 0.0662 (0.0847)	Prec@1 98.438 (97.144)	Prec@5 100.000 (99.988)
2022-06-17 18:42:01 - INFO - TRAINING - Epoch: [127][170/196]	Time 0.113 (0.121)	Data 0.000 (0.011)	Loss 0.0907 (0.0844)	Prec@1 97.266 (97.149)	Prec@5 100.000 (99.989)
2022-06-17 18:42:03 - INFO - TRAINING - Epoch: [127][180/196]	Time 0.119 (0.121)	Data 0.000 (0.010)	Loss 0.0834 (0.0843)	Prec@1 96.094 (97.166)	Prec@5 99.609 (99.987)
2022-06-17 18:42:04 - INFO - TRAINING - Epoch: [127][190/196]	Time 0.102 (0.120)	Data 0.000 (0.010)	Loss 0.0888 (0.0842)	Prec@1 98.438 (97.170)	Prec@5 100.000 (99.988)
2022-06-17 18:42:06 - INFO - EVALUATING - Epoch: [127][0/40]	Time 1.895 (1.895)	Data 1.849 (1.849)	Loss 0.2621 (0.2621)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:42:07 - INFO - EVALUATING - Epoch: [127][10/40]	Time 0.045 (0.264)	Data 0.000 (0.217)	Loss 0.4820 (0.4161)	Prec@1 87.891 (88.778)	Prec@5 98.828 (99.467)
2022-06-17 18:42:08 - INFO - EVALUATING - Epoch: [127][20/40]	Time 0.109 (0.172)	Data 0.065 (0.123)	Loss 0.3415 (0.4199)	Prec@1 87.500 (88.188)	Prec@5 100.000 (99.405)
2022-06-17 18:42:09 - INFO - EVALUATING - Epoch: [127][30/40]	Time 0.051 (0.154)	Data 0.000 (0.106)	Loss 0.5124 (0.4120)	Prec@1 85.156 (88.231)	Prec@5 100.000 (99.471)
2022-06-17 18:42:11 - INFO - 
 Epoch: 128	Training Loss 0.0843 	Training Prec@1 97.158 	Training Prec@5 99.988 	Validation Loss 0.4075 	Validation Prec@1 88.230 	Validation Prec@5 99.550 

2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:42:11 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:42:13 - INFO - TRAINING - Epoch: [128][0/196]	Time 1.945 (1.945)	Data 1.890 (1.890)	Loss 0.0527 (0.0527)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 18:42:14 - INFO - TRAINING - Epoch: [128][10/196]	Time 0.105 (0.276)	Data 0.000 (0.172)	Loss 0.0965 (0.0859)	Prec@1 97.266 (97.372)	Prec@5 100.000 (100.000)
2022-06-17 18:42:15 - INFO - TRAINING - Epoch: [128][20/196]	Time 0.112 (0.198)	Data 0.000 (0.090)	Loss 0.0803 (0.0880)	Prec@1 97.656 (97.098)	Prec@5 100.000 (100.000)
2022-06-17 18:42:16 - INFO - TRAINING - Epoch: [128][30/196]	Time 0.104 (0.171)	Data 0.000 (0.061)	Loss 0.0638 (0.0870)	Prec@1 98.047 (97.140)	Prec@5 100.000 (99.987)
2022-06-17 18:42:17 - INFO - TRAINING - Epoch: [128][40/196]	Time 0.105 (0.157)	Data 0.000 (0.046)	Loss 0.0819 (0.0891)	Prec@1 98.047 (97.018)	Prec@5 100.000 (99.990)
2022-06-17 18:42:19 - INFO - TRAINING - Epoch: [128][50/196]	Time 0.109 (0.149)	Data 0.000 (0.037)	Loss 0.0830 (0.0878)	Prec@1 97.266 (97.028)	Prec@5 99.609 (99.985)
2022-06-17 18:42:20 - INFO - TRAINING - Epoch: [128][60/196]	Time 0.131 (0.143)	Data 0.000 (0.031)	Loss 0.0845 (0.0860)	Prec@1 97.656 (97.106)	Prec@5 100.000 (99.987)
2022-06-17 18:42:21 - INFO - TRAINING - Epoch: [128][70/196]	Time 0.109 (0.139)	Data 0.000 (0.027)	Loss 0.0536 (0.0862)	Prec@1 98.438 (97.073)	Prec@5 100.000 (99.989)
2022-06-17 18:42:22 - INFO - TRAINING - Epoch: [128][80/196]	Time 0.108 (0.136)	Data 0.000 (0.024)	Loss 0.0566 (0.0856)	Prec@1 98.438 (97.073)	Prec@5 100.000 (99.990)
2022-06-17 18:42:23 - INFO - TRAINING - Epoch: [128][90/196]	Time 0.106 (0.134)	Data 0.000 (0.021)	Loss 0.0818 (0.0851)	Prec@1 97.266 (97.094)	Prec@5 100.000 (99.991)
2022-06-17 18:42:24 - INFO - TRAINING - Epoch: [128][100/196]	Time 0.130 (0.132)	Data 0.000 (0.019)	Loss 0.1006 (0.0854)	Prec@1 96.484 (97.080)	Prec@5 100.000 (99.988)
2022-06-17 18:42:25 - INFO - TRAINING - Epoch: [128][110/196]	Time 0.105 (0.131)	Data 0.000 (0.017)	Loss 0.0559 (0.0849)	Prec@1 98.438 (97.083)	Prec@5 100.000 (99.989)
2022-06-17 18:42:27 - INFO - TRAINING - Epoch: [128][120/196]	Time 0.123 (0.130)	Data 0.000 (0.016)	Loss 0.0758 (0.0846)	Prec@1 97.656 (97.098)	Prec@5 100.000 (99.990)
2022-06-17 18:42:28 - INFO - TRAINING - Epoch: [128][130/196]	Time 0.131 (0.128)	Data 0.000 (0.015)	Loss 0.0685 (0.0834)	Prec@1 98.438 (97.128)	Prec@5 100.000 (99.991)
2022-06-17 18:42:29 - INFO - TRAINING - Epoch: [128][140/196]	Time 0.123 (0.128)	Data 0.000 (0.014)	Loss 0.1139 (0.0836)	Prec@1 96.094 (97.122)	Prec@5 100.000 (99.992)
2022-06-17 18:42:30 - INFO - TRAINING - Epoch: [128][150/196]	Time 0.103 (0.127)	Data 0.000 (0.013)	Loss 0.0767 (0.0836)	Prec@1 96.875 (97.129)	Prec@5 100.000 (99.990)
2022-06-17 18:42:31 - INFO - TRAINING - Epoch: [128][160/196]	Time 0.127 (0.126)	Data 0.000 (0.012)	Loss 0.1054 (0.0837)	Prec@1 96.094 (97.135)	Prec@5 100.000 (99.990)
2022-06-17 18:42:32 - INFO - TRAINING - Epoch: [128][170/196]	Time 0.119 (0.126)	Data 0.000 (0.011)	Loss 0.1288 (0.0838)	Prec@1 94.922 (97.117)	Prec@5 100.000 (99.991)
2022-06-17 18:42:34 - INFO - TRAINING - Epoch: [128][180/196]	Time 0.111 (0.125)	Data 0.000 (0.011)	Loss 0.1095 (0.0836)	Prec@1 96.484 (97.130)	Prec@5 100.000 (99.991)
2022-06-17 18:42:35 - INFO - TRAINING - Epoch: [128][190/196]	Time 0.102 (0.124)	Data 0.000 (0.010)	Loss 0.0610 (0.0833)	Prec@1 98.047 (97.131)	Prec@5 100.000 (99.992)
2022-06-17 18:42:37 - INFO - EVALUATING - Epoch: [128][0/40]	Time 2.129 (2.129)	Data 2.084 (2.084)	Loss 0.2589 (0.2589)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:42:38 - INFO - EVALUATING - Epoch: [128][10/40]	Time 0.044 (0.246)	Data 0.000 (0.198)	Loss 0.4700 (0.4152)	Prec@1 87.891 (88.388)	Prec@5 99.219 (99.503)
2022-06-17 18:42:39 - INFO - EVALUATING - Epoch: [128][20/40]	Time 0.140 (0.168)	Data 0.099 (0.119)	Loss 0.3454 (0.4193)	Prec@1 87.891 (87.984)	Prec@5 100.000 (99.442)
2022-06-17 18:42:40 - INFO - EVALUATING - Epoch: [128][30/40]	Time 0.067 (0.152)	Data 0.000 (0.104)	Loss 0.5066 (0.4112)	Prec@1 86.719 (88.168)	Prec@5 100.000 (99.496)
2022-06-17 18:42:42 - INFO - 
 Epoch: 129	Training Loss 0.0836 	Training Prec@1 97.114 	Training Prec@5 99.992 	Validation Loss 0.4063 	Validation Prec@1 88.240 	Validation Prec@5 99.560 

2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:42:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:42:43 - INFO - TRAINING - Epoch: [129][0/196]	Time 1.363 (1.363)	Data 1.308 (1.308)	Loss 0.0666 (0.0666)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:42:45 - INFO - TRAINING - Epoch: [129][10/196]	Time 0.110 (0.234)	Data 0.000 (0.156)	Loss 0.0658 (0.0821)	Prec@1 97.656 (97.443)	Prec@5 100.000 (100.000)
2022-06-17 18:42:46 - INFO - TRAINING - Epoch: [129][20/196]	Time 0.110 (0.175)	Data 0.000 (0.086)	Loss 0.0794 (0.0833)	Prec@1 97.656 (97.284)	Prec@5 100.000 (100.000)
2022-06-17 18:42:47 - INFO - TRAINING - Epoch: [129][30/196]	Time 0.145 (0.157)	Data 0.000 (0.061)	Loss 0.0827 (0.0829)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:42:48 - INFO - TRAINING - Epoch: [129][40/196]	Time 0.104 (0.147)	Data 0.000 (0.047)	Loss 0.1162 (0.0829)	Prec@1 95.312 (97.285)	Prec@5 100.000 (100.000)
2022-06-17 18:42:49 - INFO - TRAINING - Epoch: [129][50/196]	Time 0.113 (0.141)	Data 0.000 (0.037)	Loss 0.0762 (0.0804)	Prec@1 97.656 (97.381)	Prec@5 100.000 (100.000)
2022-06-17 18:42:50 - INFO - TRAINING - Epoch: [129][60/196]	Time 0.120 (0.137)	Data 0.000 (0.031)	Loss 0.0858 (0.0819)	Prec@1 96.484 (97.291)	Prec@5 100.000 (100.000)
2022-06-17 18:42:51 - INFO - TRAINING - Epoch: [129][70/196]	Time 0.103 (0.135)	Data 0.000 (0.027)	Loss 0.0671 (0.0830)	Prec@1 98.047 (97.211)	Prec@5 100.000 (100.000)
2022-06-17 18:42:53 - INFO - TRAINING - Epoch: [129][80/196]	Time 0.101 (0.132)	Data 0.000 (0.024)	Loss 0.0914 (0.0836)	Prec@1 96.484 (97.155)	Prec@5 100.000 (100.000)
2022-06-17 18:42:54 - INFO - TRAINING - Epoch: [129][90/196]	Time 0.116 (0.130)	Data 0.000 (0.021)	Loss 0.0692 (0.0831)	Prec@1 98.047 (97.184)	Prec@5 100.000 (100.000)
2022-06-17 18:42:55 - INFO - TRAINING - Epoch: [129][100/196]	Time 0.122 (0.128)	Data 0.000 (0.019)	Loss 0.1014 (0.0836)	Prec@1 95.703 (97.157)	Prec@5 100.000 (100.000)
2022-06-17 18:42:56 - INFO - TRAINING - Epoch: [129][110/196]	Time 0.111 (0.127)	Data 0.000 (0.017)	Loss 0.0862 (0.0832)	Prec@1 96.875 (97.160)	Prec@5 100.000 (100.000)
2022-06-17 18:42:57 - INFO - TRAINING - Epoch: [129][120/196]	Time 0.106 (0.126)	Data 0.000 (0.016)	Loss 0.0547 (0.0820)	Prec@1 98.828 (97.198)	Prec@5 100.000 (100.000)
2022-06-17 18:42:58 - INFO - TRAINING - Epoch: [129][130/196]	Time 0.133 (0.125)	Data 0.000 (0.015)	Loss 0.0719 (0.0821)	Prec@1 97.656 (97.203)	Prec@5 100.000 (100.000)
2022-06-17 18:43:00 - INFO - TRAINING - Epoch: [129][140/196]	Time 0.131 (0.125)	Data 0.000 (0.014)	Loss 0.0587 (0.0822)	Prec@1 98.438 (97.210)	Prec@5 100.000 (100.000)
2022-06-17 18:43:01 - INFO - TRAINING - Epoch: [129][150/196]	Time 0.110 (0.124)	Data 0.000 (0.013)	Loss 0.1417 (0.0834)	Prec@1 96.094 (97.172)	Prec@5 100.000 (100.000)
2022-06-17 18:43:02 - INFO - TRAINING - Epoch: [129][160/196]	Time 0.106 (0.123)	Data 0.000 (0.012)	Loss 0.0966 (0.0835)	Prec@1 96.484 (97.176)	Prec@5 100.000 (100.000)
2022-06-17 18:43:03 - INFO - TRAINING - Epoch: [129][170/196]	Time 0.129 (0.122)	Data 0.000 (0.011)	Loss 0.0878 (0.0835)	Prec@1 96.094 (97.170)	Prec@5 100.000 (100.000)
2022-06-17 18:43:04 - INFO - TRAINING - Epoch: [129][180/196]	Time 0.132 (0.122)	Data 0.000 (0.011)	Loss 0.0783 (0.0840)	Prec@1 97.656 (97.166)	Prec@5 100.000 (100.000)
2022-06-17 18:43:05 - INFO - TRAINING - Epoch: [129][190/196]	Time 0.101 (0.121)	Data 0.000 (0.010)	Loss 0.1221 (0.0840)	Prec@1 95.703 (97.167)	Prec@5 100.000 (100.000)
2022-06-17 18:43:07 - INFO - EVALUATING - Epoch: [129][0/40]	Time 1.794 (1.794)	Data 1.748 (1.748)	Loss 0.2634 (0.2634)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:43:08 - INFO - EVALUATING - Epoch: [129][10/40]	Time 0.044 (0.256)	Data 0.000 (0.209)	Loss 0.4784 (0.4204)	Prec@1 87.891 (88.281)	Prec@5 99.609 (99.467)
2022-06-17 18:43:10 - INFO - EVALUATING - Epoch: [129][20/40]	Time 0.397 (0.185)	Data 0.356 (0.137)	Loss 0.3399 (0.4226)	Prec@1 88.281 (88.002)	Prec@5 100.000 (99.423)
2022-06-17 18:43:11 - INFO - EVALUATING - Epoch: [129][30/40]	Time 0.170 (0.161)	Data 0.127 (0.114)	Loss 0.5085 (0.4144)	Prec@1 87.109 (88.218)	Prec@5 100.000 (99.483)
2022-06-17 18:43:12 - INFO - 
 Epoch: 130	Training Loss 0.0840 	Training Prec@1 97.170 	Training Prec@5 99.998 	Validation Loss 0.4094 	Validation Prec@1 88.220 	Validation Prec@5 99.540 

2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:43:12 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:43:14 - INFO - TRAINING - Epoch: [130][0/196]	Time 1.259 (1.259)	Data 1.207 (1.207)	Loss 0.0725 (0.0725)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:43:15 - INFO - TRAINING - Epoch: [130][10/196]	Time 0.111 (0.230)	Data 0.039 (0.142)	Loss 0.0943 (0.0712)	Prec@1 95.703 (97.692)	Prec@5 100.000 (100.000)
2022-06-17 18:43:16 - INFO - TRAINING - Epoch: [130][20/196]	Time 0.105 (0.182)	Data 0.000 (0.085)	Loss 0.0524 (0.0750)	Prec@1 98.047 (97.507)	Prec@5 100.000 (99.981)
2022-06-17 18:43:17 - INFO - TRAINING - Epoch: [130][30/196]	Time 0.129 (0.161)	Data 0.026 (0.058)	Loss 0.1064 (0.0770)	Prec@1 96.094 (97.429)	Prec@5 100.000 (99.975)
2022-06-17 18:43:19 - INFO - TRAINING - Epoch: [130][40/196]	Time 0.107 (0.148)	Data 0.000 (0.044)	Loss 0.0589 (0.0780)	Prec@1 99.609 (97.409)	Prec@5 100.000 (99.981)
2022-06-17 18:43:20 - INFO - TRAINING - Epoch: [130][50/196]	Time 0.103 (0.140)	Data 0.000 (0.035)	Loss 0.1165 (0.0802)	Prec@1 96.094 (97.281)	Prec@5 99.609 (99.977)
2022-06-17 18:43:21 - INFO - TRAINING - Epoch: [130][60/196]	Time 0.130 (0.135)	Data 0.000 (0.030)	Loss 0.0960 (0.0798)	Prec@1 97.266 (97.317)	Prec@5 100.000 (99.981)
2022-06-17 18:43:22 - INFO - TRAINING - Epoch: [130][70/196]	Time 0.111 (0.132)	Data 0.000 (0.026)	Loss 0.0769 (0.0791)	Prec@1 97.656 (97.381)	Prec@5 100.000 (99.983)
2022-06-17 18:43:23 - INFO - TRAINING - Epoch: [130][80/196]	Time 0.110 (0.130)	Data 0.000 (0.022)	Loss 0.1008 (0.0786)	Prec@1 96.875 (97.434)	Prec@5 100.000 (99.986)
2022-06-17 18:43:24 - INFO - TRAINING - Epoch: [130][90/196]	Time 0.137 (0.128)	Data 0.000 (0.020)	Loss 0.1032 (0.0783)	Prec@1 96.875 (97.472)	Prec@5 100.000 (99.987)
2022-06-17 18:43:25 - INFO - TRAINING - Epoch: [130][100/196]	Time 0.105 (0.127)	Data 0.000 (0.018)	Loss 0.0903 (0.0798)	Prec@1 97.266 (97.397)	Prec@5 100.000 (99.985)
2022-06-17 18:43:26 - INFO - TRAINING - Epoch: [130][110/196]	Time 0.103 (0.125)	Data 0.000 (0.016)	Loss 0.0889 (0.0806)	Prec@1 96.094 (97.336)	Prec@5 100.000 (99.986)
2022-06-17 18:43:27 - INFO - TRAINING - Epoch: [130][120/196]	Time 0.111 (0.123)	Data 0.000 (0.015)	Loss 0.0732 (0.0823)	Prec@1 97.266 (97.259)	Prec@5 100.000 (99.984)
2022-06-17 18:43:28 - INFO - TRAINING - Epoch: [130][130/196]	Time 0.104 (0.122)	Data 0.000 (0.014)	Loss 0.0618 (0.0822)	Prec@1 97.656 (97.251)	Prec@5 100.000 (99.985)
2022-06-17 18:43:30 - INFO - TRAINING - Epoch: [130][140/196]	Time 0.127 (0.122)	Data 0.000 (0.013)	Loss 0.0741 (0.0830)	Prec@1 96.875 (97.194)	Prec@5 100.000 (99.986)
2022-06-17 18:43:31 - INFO - TRAINING - Epoch: [130][150/196]	Time 0.103 (0.121)	Data 0.000 (0.012)	Loss 0.0722 (0.0818)	Prec@1 98.438 (97.229)	Prec@5 100.000 (99.987)
2022-06-17 18:43:32 - INFO - TRAINING - Epoch: [130][160/196]	Time 0.112 (0.120)	Data 0.000 (0.011)	Loss 0.0928 (0.0819)	Prec@1 97.266 (97.222)	Prec@5 100.000 (99.988)
2022-06-17 18:43:33 - INFO - TRAINING - Epoch: [130][170/196]	Time 0.102 (0.119)	Data 0.000 (0.011)	Loss 0.0796 (0.0823)	Prec@1 97.656 (97.209)	Prec@5 100.000 (99.984)
2022-06-17 18:43:34 - INFO - TRAINING - Epoch: [130][180/196]	Time 0.103 (0.118)	Data 0.000 (0.010)	Loss 0.0520 (0.0821)	Prec@1 98.828 (97.199)	Prec@5 100.000 (99.985)
2022-06-17 18:43:35 - INFO - TRAINING - Epoch: [130][190/196]	Time 0.101 (0.117)	Data 0.000 (0.010)	Loss 0.0872 (0.0823)	Prec@1 96.875 (97.188)	Prec@5 100.000 (99.986)
2022-06-17 18:43:37 - INFO - EVALUATING - Epoch: [130][0/40]	Time 1.390 (1.390)	Data 1.344 (1.344)	Loss 0.2674 (0.2674)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:43:38 - INFO - EVALUATING - Epoch: [130][10/40]	Time 0.069 (0.264)	Data 0.000 (0.213)	Loss 0.4796 (0.4222)	Prec@1 87.891 (88.459)	Prec@5 99.219 (99.432)
2022-06-17 18:43:39 - INFO - EVALUATING - Epoch: [130][20/40]	Time 0.069 (0.164)	Data 0.000 (0.112)	Loss 0.3417 (0.4245)	Prec@1 87.109 (88.077)	Prec@5 100.000 (99.423)
2022-06-17 18:43:40 - INFO - EVALUATING - Epoch: [130][30/40]	Time 0.051 (0.145)	Data 0.000 (0.094)	Loss 0.5157 (0.4160)	Prec@1 86.719 (88.206)	Prec@5 100.000 (99.483)
2022-06-17 18:43:42 - INFO - 
 Epoch: 131	Training Loss 0.0822 	Training Prec@1 97.182 	Training Prec@5 99.986 	Validation Loss 0.4106 	Validation Prec@1 88.250 	Validation Prec@5 99.550 

2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:43:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:43:43 - INFO - TRAINING - Epoch: [131][0/196]	Time 1.478 (1.478)	Data 1.425 (1.425)	Loss 0.1107 (0.1107)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 18:43:45 - INFO - TRAINING - Epoch: [131][10/196]	Time 0.110 (0.267)	Data 0.000 (0.167)	Loss 0.0603 (0.0791)	Prec@1 97.656 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:43:46 - INFO - TRAINING - Epoch: [131][20/196]	Time 0.106 (0.191)	Data 0.000 (0.087)	Loss 0.0435 (0.0788)	Prec@1 98.047 (97.210)	Prec@5 100.000 (100.000)
2022-06-17 18:43:47 - INFO - TRAINING - Epoch: [131][30/196]	Time 0.102 (0.163)	Data 0.000 (0.059)	Loss 0.0749 (0.0818)	Prec@1 98.828 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:43:48 - INFO - TRAINING - Epoch: [131][40/196]	Time 0.103 (0.150)	Data 0.000 (0.045)	Loss 0.0964 (0.0825)	Prec@1 95.703 (97.180)	Prec@5 100.000 (99.990)
2022-06-17 18:43:49 - INFO - TRAINING - Epoch: [131][50/196]	Time 0.103 (0.143)	Data 0.000 (0.036)	Loss 0.0829 (0.0823)	Prec@1 96.484 (97.189)	Prec@5 100.000 (99.992)
2022-06-17 18:43:50 - INFO - TRAINING - Epoch: [131][60/196]	Time 0.111 (0.137)	Data 0.000 (0.030)	Loss 0.0942 (0.0816)	Prec@1 96.484 (97.227)	Prec@5 100.000 (99.994)
2022-06-17 18:43:51 - INFO - TRAINING - Epoch: [131][70/196]	Time 0.129 (0.133)	Data 0.000 (0.026)	Loss 0.0443 (0.0808)	Prec@1 98.828 (97.244)	Prec@5 100.000 (99.989)
2022-06-17 18:43:52 - INFO - TRAINING - Epoch: [131][80/196]	Time 0.103 (0.131)	Data 0.000 (0.023)	Loss 0.1035 (0.0818)	Prec@1 95.703 (97.203)	Prec@5 100.000 (99.990)
2022-06-17 18:43:54 - INFO - TRAINING - Epoch: [131][90/196]	Time 0.119 (0.129)	Data 0.000 (0.020)	Loss 0.0586 (0.0813)	Prec@1 99.219 (97.227)	Prec@5 100.000 (99.991)
2022-06-17 18:43:55 - INFO - TRAINING - Epoch: [131][100/196]	Time 0.127 (0.127)	Data 0.000 (0.018)	Loss 0.0733 (0.0805)	Prec@1 96.484 (97.227)	Prec@5 100.000 (99.992)
2022-06-17 18:43:56 - INFO - TRAINING - Epoch: [131][110/196]	Time 0.112 (0.125)	Data 0.000 (0.017)	Loss 0.1052 (0.0809)	Prec@1 96.484 (97.216)	Prec@5 100.000 (99.993)
2022-06-17 18:43:57 - INFO - TRAINING - Epoch: [131][120/196]	Time 0.133 (0.125)	Data 0.000 (0.015)	Loss 0.0711 (0.0804)	Prec@1 97.656 (97.237)	Prec@5 99.609 (99.990)
2022-06-17 18:43:58 - INFO - TRAINING - Epoch: [131][130/196]	Time 0.131 (0.124)	Data 0.000 (0.014)	Loss 0.0762 (0.0807)	Prec@1 96.094 (97.227)	Prec@5 100.000 (99.991)
2022-06-17 18:43:59 - INFO - TRAINING - Epoch: [131][140/196]	Time 0.107 (0.123)	Data 0.000 (0.013)	Loss 0.0556 (0.0800)	Prec@1 98.438 (97.260)	Prec@5 100.000 (99.992)
2022-06-17 18:44:00 - INFO - TRAINING - Epoch: [131][150/196]	Time 0.118 (0.123)	Data 0.000 (0.012)	Loss 0.0726 (0.0796)	Prec@1 98.438 (97.286)	Prec@5 100.000 (99.992)
2022-06-17 18:44:02 - INFO - TRAINING - Epoch: [131][160/196]	Time 0.120 (0.122)	Data 0.000 (0.012)	Loss 0.0822 (0.0803)	Prec@1 98.047 (97.273)	Prec@5 100.000 (99.993)
2022-06-17 18:44:03 - INFO - TRAINING - Epoch: [131][170/196]	Time 0.104 (0.122)	Data 0.000 (0.011)	Loss 0.1143 (0.0809)	Prec@1 95.703 (97.231)	Prec@5 100.000 (99.991)
2022-06-17 18:44:04 - INFO - TRAINING - Epoch: [131][180/196]	Time 0.108 (0.121)	Data 0.000 (0.010)	Loss 0.0953 (0.0810)	Prec@1 96.484 (97.235)	Prec@5 100.000 (99.991)
2022-06-17 18:44:05 - INFO - TRAINING - Epoch: [131][190/196]	Time 0.102 (0.121)	Data 0.000 (0.010)	Loss 0.0517 (0.0805)	Prec@1 99.219 (97.241)	Prec@5 100.000 (99.992)
2022-06-17 18:44:08 - INFO - EVALUATING - Epoch: [131][0/40]	Time 2.108 (2.108)	Data 2.063 (2.063)	Loss 0.2580 (0.2580)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 18:44:08 - INFO - EVALUATING - Epoch: [131][10/40]	Time 0.063 (0.271)	Data 0.000 (0.223)	Loss 0.4693 (0.4187)	Prec@1 88.672 (88.601)	Prec@5 99.219 (99.467)
2022-06-17 18:44:09 - INFO - EVALUATING - Epoch: [131][20/40]	Time 0.106 (0.169)	Data 0.065 (0.120)	Loss 0.3365 (0.4206)	Prec@1 87.109 (88.188)	Prec@5 99.609 (99.423)
2022-06-17 18:44:10 - INFO - EVALUATING - Epoch: [131][30/40]	Time 0.042 (0.154)	Data 0.000 (0.106)	Loss 0.5151 (0.4126)	Prec@1 86.719 (88.344)	Prec@5 100.000 (99.483)
2022-06-17 18:44:13 - INFO - 
 Epoch: 132	Training Loss 0.0805 	Training Prec@1 97.238 	Training Prec@5 99.992 	Validation Loss 0.4079 	Validation Prec@1 88.380 	Validation Prec@5 99.560 

2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:44:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:44:14 - INFO - TRAINING - Epoch: [132][0/196]	Time 1.506 (1.506)	Data 1.452 (1.452)	Loss 0.0586 (0.0586)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:44:16 - INFO - TRAINING - Epoch: [132][10/196]	Time 0.125 (0.282)	Data 0.000 (0.190)	Loss 0.0855 (0.0803)	Prec@1 96.094 (97.159)	Prec@5 100.000 (99.929)
2022-06-17 18:44:17 - INFO - TRAINING - Epoch: [132][20/196]	Time 0.111 (0.205)	Data 0.000 (0.100)	Loss 0.0788 (0.0826)	Prec@1 97.656 (97.173)	Prec@5 100.000 (99.963)
2022-06-17 18:44:18 - INFO - TRAINING - Epoch: [132][30/196]	Time 0.138 (0.178)	Data 0.000 (0.068)	Loss 0.0907 (0.0829)	Prec@1 97.266 (97.127)	Prec@5 100.000 (99.975)
2022-06-17 18:44:19 - INFO - TRAINING - Epoch: [132][40/196]	Time 0.131 (0.163)	Data 0.000 (0.051)	Loss 0.1181 (0.0857)	Prec@1 96.094 (97.037)	Prec@5 100.000 (99.981)
2022-06-17 18:44:21 - INFO - TRAINING - Epoch: [132][50/196]	Time 0.105 (0.153)	Data 0.000 (0.041)	Loss 0.0548 (0.0858)	Prec@1 98.047 (96.990)	Prec@5 100.000 (99.985)
2022-06-17 18:44:22 - INFO - TRAINING - Epoch: [132][60/196]	Time 0.109 (0.147)	Data 0.000 (0.034)	Loss 0.0793 (0.0836)	Prec@1 96.484 (97.093)	Prec@5 100.000 (99.987)
2022-06-17 18:44:23 - INFO - TRAINING - Epoch: [132][70/196]	Time 0.115 (0.143)	Data 0.000 (0.030)	Loss 0.0676 (0.0834)	Prec@1 98.047 (97.073)	Prec@5 100.000 (99.989)
2022-06-17 18:44:24 - INFO - TRAINING - Epoch: [132][80/196]	Time 0.125 (0.140)	Data 0.000 (0.026)	Loss 0.1124 (0.0834)	Prec@1 95.312 (97.078)	Prec@5 100.000 (99.990)
2022-06-17 18:44:25 - INFO - TRAINING - Epoch: [132][90/196]	Time 0.104 (0.137)	Data 0.000 (0.023)	Loss 0.0878 (0.0833)	Prec@1 96.484 (97.068)	Prec@5 100.000 (99.991)
2022-06-17 18:44:26 - INFO - TRAINING - Epoch: [132][100/196]	Time 0.105 (0.135)	Data 0.000 (0.021)	Loss 0.0851 (0.0839)	Prec@1 96.875 (97.072)	Prec@5 100.000 (99.992)
2022-06-17 18:44:28 - INFO - TRAINING - Epoch: [132][110/196]	Time 0.135 (0.134)	Data 0.000 (0.019)	Loss 0.0859 (0.0840)	Prec@1 96.875 (97.100)	Prec@5 100.000 (99.993)
2022-06-17 18:44:29 - INFO - TRAINING - Epoch: [132][120/196]	Time 0.103 (0.133)	Data 0.000 (0.018)	Loss 0.0710 (0.0836)	Prec@1 97.266 (97.101)	Prec@5 100.000 (99.994)
2022-06-17 18:44:30 - INFO - TRAINING - Epoch: [132][130/196]	Time 0.129 (0.132)	Data 0.000 (0.016)	Loss 0.0572 (0.0828)	Prec@1 98.438 (97.120)	Prec@5 100.000 (99.994)
2022-06-17 18:44:31 - INFO - TRAINING - Epoch: [132][140/196]	Time 0.104 (0.131)	Data 0.000 (0.015)	Loss 0.1151 (0.0835)	Prec@1 94.922 (97.105)	Prec@5 100.000 (99.994)
2022-06-17 18:44:32 - INFO - TRAINING - Epoch: [132][150/196]	Time 0.105 (0.130)	Data 0.000 (0.014)	Loss 0.0568 (0.0830)	Prec@1 98.828 (97.141)	Prec@5 100.000 (99.995)
2022-06-17 18:44:34 - INFO - TRAINING - Epoch: [132][160/196]	Time 0.116 (0.129)	Data 0.000 (0.013)	Loss 0.0789 (0.0826)	Prec@1 97.656 (97.137)	Prec@5 100.000 (99.993)
2022-06-17 18:44:35 - INFO - TRAINING - Epoch: [132][170/196]	Time 0.108 (0.129)	Data 0.000 (0.012)	Loss 0.0640 (0.0821)	Prec@1 96.875 (97.161)	Prec@5 100.000 (99.991)
2022-06-17 18:44:36 - INFO - TRAINING - Epoch: [132][180/196]	Time 0.107 (0.128)	Data 0.000 (0.012)	Loss 0.1077 (0.0823)	Prec@1 96.094 (97.140)	Prec@5 100.000 (99.991)
2022-06-17 18:44:37 - INFO - TRAINING - Epoch: [132][190/196]	Time 0.108 (0.127)	Data 0.000 (0.011)	Loss 0.1085 (0.0830)	Prec@1 96.875 (97.125)	Prec@5 100.000 (99.992)
2022-06-17 18:44:39 - INFO - EVALUATING - Epoch: [132][0/40]	Time 1.398 (1.398)	Data 1.352 (1.352)	Loss 0.2686 (0.2686)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:44:41 - INFO - EVALUATING - Epoch: [132][10/40]	Time 0.042 (0.269)	Data 0.000 (0.220)	Loss 0.4741 (0.4195)	Prec@1 87.891 (88.210)	Prec@5 99.219 (99.467)
2022-06-17 18:44:41 - INFO - EVALUATING - Epoch: [132][20/40]	Time 0.112 (0.171)	Data 0.070 (0.122)	Loss 0.3393 (0.4221)	Prec@1 87.500 (87.928)	Prec@5 100.000 (99.461)
2022-06-17 18:44:42 - INFO - EVALUATING - Epoch: [132][30/40]	Time 0.265 (0.156)	Data 0.221 (0.108)	Loss 0.5147 (0.4140)	Prec@1 86.719 (88.130)	Prec@5 100.000 (99.534)
2022-06-17 18:44:44 - INFO - 
 Epoch: 133	Training Loss 0.0828 	Training Prec@1 97.136 	Training Prec@5 99.992 	Validation Loss 0.4088 	Validation Prec@1 88.250 	Validation Prec@5 99.600 

2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:44:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:44:46 - INFO - TRAINING - Epoch: [133][0/196]	Time 1.524 (1.524)	Data 1.471 (1.471)	Loss 0.0772 (0.0772)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
2022-06-17 18:44:47 - INFO - TRAINING - Epoch: [133][10/196]	Time 0.107 (0.278)	Data 0.000 (0.183)	Loss 0.0912 (0.0812)	Prec@1 96.094 (97.230)	Prec@5 100.000 (100.000)
2022-06-17 18:44:48 - INFO - TRAINING - Epoch: [133][20/196]	Time 0.114 (0.197)	Data 0.000 (0.096)	Loss 0.0773 (0.0791)	Prec@1 97.266 (97.321)	Prec@5 100.000 (100.000)
2022-06-17 18:44:50 - INFO - TRAINING - Epoch: [133][30/196]	Time 0.103 (0.171)	Data 0.000 (0.065)	Loss 0.0606 (0.0759)	Prec@1 98.047 (97.354)	Prec@5 100.000 (100.000)
2022-06-17 18:44:51 - INFO - TRAINING - Epoch: [133][40/196]	Time 0.106 (0.158)	Data 0.000 (0.049)	Loss 0.0585 (0.0786)	Prec@1 98.828 (97.275)	Prec@5 100.000 (99.990)
2022-06-17 18:44:52 - INFO - TRAINING - Epoch: [133][50/196]	Time 0.106 (0.150)	Data 0.000 (0.040)	Loss 0.0959 (0.0775)	Prec@1 95.703 (97.319)	Prec@5 100.000 (99.992)
2022-06-17 18:44:53 - INFO - TRAINING - Epoch: [133][60/196]	Time 0.123 (0.144)	Data 0.000 (0.033)	Loss 0.0508 (0.0784)	Prec@1 99.219 (97.272)	Prec@5 100.000 (99.994)
2022-06-17 18:44:54 - INFO - TRAINING - Epoch: [133][70/196]	Time 0.108 (0.140)	Data 0.000 (0.029)	Loss 0.1153 (0.0797)	Prec@1 97.266 (97.238)	Prec@5 100.000 (99.994)
2022-06-17 18:44:55 - INFO - TRAINING - Epoch: [133][80/196]	Time 0.124 (0.137)	Data 0.000 (0.025)	Loss 0.0581 (0.0801)	Prec@1 97.266 (97.227)	Prec@5 100.000 (99.995)
2022-06-17 18:44:56 - INFO - TRAINING - Epoch: [133][90/196]	Time 0.104 (0.135)	Data 0.000 (0.022)	Loss 0.0946 (0.0799)	Prec@1 96.484 (97.227)	Prec@5 100.000 (99.996)
2022-06-17 18:44:58 - INFO - TRAINING - Epoch: [133][100/196]	Time 0.119 (0.133)	Data 0.000 (0.020)	Loss 0.0726 (0.0798)	Prec@1 97.656 (97.258)	Prec@5 100.000 (99.996)
2022-06-17 18:44:59 - INFO - TRAINING - Epoch: [133][110/196]	Time 0.106 (0.131)	Data 0.000 (0.018)	Loss 0.0829 (0.0811)	Prec@1 97.266 (97.206)	Prec@5 100.000 (99.996)
2022-06-17 18:45:00 - INFO - TRAINING - Epoch: [133][120/196]	Time 0.123 (0.130)	Data 0.000 (0.017)	Loss 0.0781 (0.0816)	Prec@1 96.484 (97.201)	Prec@5 100.000 (99.994)
2022-06-17 18:45:01 - INFO - TRAINING - Epoch: [133][130/196]	Time 0.103 (0.129)	Data 0.000 (0.016)	Loss 0.0817 (0.0818)	Prec@1 97.656 (97.215)	Prec@5 100.000 (99.994)
2022-06-17 18:45:02 - INFO - TRAINING - Epoch: [133][140/196]	Time 0.110 (0.128)	Data 0.000 (0.015)	Loss 0.0955 (0.0819)	Prec@1 96.484 (97.196)	Prec@5 100.000 (99.994)
2022-06-17 18:45:03 - INFO - TRAINING - Epoch: [133][150/196]	Time 0.108 (0.127)	Data 0.000 (0.014)	Loss 0.1456 (0.0828)	Prec@1 96.094 (97.191)	Prec@5 100.000 (99.995)
2022-06-17 18:45:05 - INFO - TRAINING - Epoch: [133][160/196]	Time 0.129 (0.127)	Data 0.000 (0.013)	Loss 0.0882 (0.0832)	Prec@1 98.047 (97.152)	Prec@5 100.000 (99.995)
2022-06-17 18:45:06 - INFO - TRAINING - Epoch: [133][170/196]	Time 0.110 (0.126)	Data 0.000 (0.012)	Loss 0.0685 (0.0833)	Prec@1 98.047 (97.147)	Prec@5 100.000 (99.993)
2022-06-17 18:45:07 - INFO - TRAINING - Epoch: [133][180/196]	Time 0.125 (0.126)	Data 0.000 (0.011)	Loss 0.0933 (0.0831)	Prec@1 96.875 (97.153)	Prec@5 100.000 (99.994)
2022-06-17 18:45:08 - INFO - TRAINING - Epoch: [133][190/196]	Time 0.102 (0.125)	Data 0.000 (0.011)	Loss 0.0665 (0.0830)	Prec@1 98.047 (97.163)	Prec@5 100.000 (99.992)
2022-06-17 18:45:10 - INFO - EVALUATING - Epoch: [133][0/40]	Time 1.239 (1.239)	Data 1.193 (1.193)	Loss 0.2655 (0.2655)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:45:12 - INFO - EVALUATING - Epoch: [133][10/40]	Time 0.057 (0.257)	Data 0.000 (0.210)	Loss 0.4797 (0.4191)	Prec@1 88.281 (88.317)	Prec@5 99.219 (99.503)
2022-06-17 18:45:12 - INFO - EVALUATING - Epoch: [133][20/40]	Time 0.072 (0.163)	Data 0.000 (0.114)	Loss 0.3340 (0.4202)	Prec@1 87.500 (87.984)	Prec@5 100.000 (99.479)
2022-06-17 18:45:13 - INFO - EVALUATING - Epoch: [133][30/40]	Time 0.057 (0.144)	Data 0.000 (0.097)	Loss 0.5134 (0.4122)	Prec@1 86.719 (88.168)	Prec@5 100.000 (99.509)
2022-06-17 18:45:15 - INFO - 
 Epoch: 134	Training Loss 0.0829 	Training Prec@1 97.166 	Training Prec@5 99.992 	Validation Loss 0.4073 	Validation Prec@1 88.240 	Validation Prec@5 99.570 

2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:45:15 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:45:17 - INFO - TRAINING - Epoch: [134][0/196]	Time 1.423 (1.423)	Data 1.369 (1.369)	Loss 0.0739 (0.0739)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:45:18 - INFO - TRAINING - Epoch: [134][10/196]	Time 0.115 (0.265)	Data 0.000 (0.174)	Loss 0.0570 (0.0778)	Prec@1 98.828 (97.834)	Prec@5 100.000 (100.000)
2022-06-17 18:45:19 - INFO - TRAINING - Epoch: [134][20/196]	Time 0.120 (0.194)	Data 0.000 (0.091)	Loss 0.0987 (0.0784)	Prec@1 97.266 (97.526)	Prec@5 100.000 (100.000)
2022-06-17 18:45:20 - INFO - TRAINING - Epoch: [134][30/196]	Time 0.121 (0.170)	Data 0.000 (0.062)	Loss 0.0995 (0.0824)	Prec@1 97.656 (97.392)	Prec@5 100.000 (99.987)
2022-06-17 18:45:22 - INFO - TRAINING - Epoch: [134][40/196]	Time 0.130 (0.159)	Data 0.000 (0.047)	Loss 0.0879 (0.0840)	Prec@1 97.656 (97.275)	Prec@5 100.000 (99.990)
2022-06-17 18:45:23 - INFO - TRAINING - Epoch: [134][50/196]	Time 0.107 (0.150)	Data 0.000 (0.038)	Loss 0.0722 (0.0829)	Prec@1 97.266 (97.281)	Prec@5 100.000 (99.992)
2022-06-17 18:45:24 - INFO - TRAINING - Epoch: [134][60/196]	Time 0.106 (0.145)	Data 0.000 (0.032)	Loss 0.0994 (0.0836)	Prec@1 96.094 (97.240)	Prec@5 100.000 (99.994)
2022-06-17 18:45:25 - INFO - TRAINING - Epoch: [134][70/196]	Time 0.107 (0.141)	Data 0.000 (0.027)	Loss 0.0828 (0.0835)	Prec@1 97.266 (97.233)	Prec@5 100.000 (99.994)
2022-06-17 18:45:26 - INFO - TRAINING - Epoch: [134][80/196]	Time 0.126 (0.138)	Data 0.000 (0.024)	Loss 0.0899 (0.0822)	Prec@1 96.484 (97.290)	Prec@5 100.000 (99.995)
2022-06-17 18:45:27 - INFO - TRAINING - Epoch: [134][90/196]	Time 0.125 (0.136)	Data 0.000 (0.021)	Loss 0.1264 (0.0827)	Prec@1 96.094 (97.236)	Prec@5 100.000 (99.991)
2022-06-17 18:45:29 - INFO - TRAINING - Epoch: [134][100/196]	Time 0.115 (0.134)	Data 0.000 (0.019)	Loss 0.0957 (0.0825)	Prec@1 96.094 (97.215)	Prec@5 100.000 (99.992)
2022-06-17 18:45:30 - INFO - TRAINING - Epoch: [134][110/196]	Time 0.116 (0.133)	Data 0.000 (0.017)	Loss 0.0815 (0.0824)	Prec@1 98.047 (97.252)	Prec@5 100.000 (99.993)
2022-06-17 18:45:31 - INFO - TRAINING - Epoch: [134][120/196]	Time 0.124 (0.131)	Data 0.000 (0.016)	Loss 0.0862 (0.0825)	Prec@1 97.656 (97.246)	Prec@5 100.000 (99.990)
2022-06-17 18:45:32 - INFO - TRAINING - Epoch: [134][130/196]	Time 0.121 (0.131)	Data 0.000 (0.015)	Loss 0.0689 (0.0833)	Prec@1 97.266 (97.215)	Prec@5 100.000 (99.991)
2022-06-17 18:45:33 - INFO - TRAINING - Epoch: [134][140/196]	Time 0.128 (0.130)	Data 0.000 (0.014)	Loss 0.0830 (0.0836)	Prec@1 97.266 (97.194)	Prec@5 100.000 (99.989)
2022-06-17 18:45:35 - INFO - TRAINING - Epoch: [134][150/196]	Time 0.119 (0.129)	Data 0.000 (0.013)	Loss 0.0638 (0.0830)	Prec@1 97.656 (97.204)	Prec@5 100.000 (99.990)
2022-06-17 18:45:36 - INFO - TRAINING - Epoch: [134][160/196]	Time 0.136 (0.128)	Data 0.000 (0.012)	Loss 0.1068 (0.0835)	Prec@1 96.875 (97.188)	Prec@5 100.000 (99.988)
2022-06-17 18:45:37 - INFO - TRAINING - Epoch: [134][170/196]	Time 0.125 (0.128)	Data 0.000 (0.011)	Loss 0.0669 (0.0834)	Prec@1 98.047 (97.193)	Prec@5 100.000 (99.989)
2022-06-17 18:45:38 - INFO - TRAINING - Epoch: [134][180/196]	Time 0.118 (0.128)	Data 0.000 (0.011)	Loss 0.0966 (0.0836)	Prec@1 96.484 (97.179)	Prec@5 100.000 (99.987)
2022-06-17 18:45:39 - INFO - TRAINING - Epoch: [134][190/196]	Time 0.101 (0.127)	Data 0.000 (0.010)	Loss 0.0923 (0.0836)	Prec@1 98.047 (97.196)	Prec@5 100.000 (99.988)
2022-06-17 18:45:42 - INFO - EVALUATING - Epoch: [134][0/40]	Time 1.751 (1.751)	Data 1.705 (1.705)	Loss 0.2632 (0.2632)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:45:43 - INFO - EVALUATING - Epoch: [134][10/40]	Time 0.535 (0.259)	Data 0.494 (0.211)	Loss 0.4825 (0.4213)	Prec@1 87.109 (88.139)	Prec@5 99.219 (99.503)
2022-06-17 18:45:44 - INFO - EVALUATING - Epoch: [134][20/40]	Time 0.439 (0.183)	Data 0.398 (0.136)	Loss 0.3359 (0.4236)	Prec@1 86.719 (87.946)	Prec@5 99.609 (99.442)
2022-06-17 18:45:45 - INFO - EVALUATING - Epoch: [134][30/40]	Time 0.298 (0.155)	Data 0.257 (0.108)	Loss 0.5166 (0.4155)	Prec@1 86.719 (88.168)	Prec@5 100.000 (99.496)
2022-06-17 18:45:47 - INFO - 
 Epoch: 135	Training Loss 0.0835 	Training Prec@1 97.204 	Training Prec@5 99.988 	Validation Loss 0.4100 	Validation Prec@1 88.210 	Validation Prec@5 99.560 

2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:45:47 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:45:48 - INFO - TRAINING - Epoch: [135][0/196]	Time 1.773 (1.773)	Data 1.720 (1.720)	Loss 0.0738 (0.0738)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:45:50 - INFO - TRAINING - Epoch: [135][10/196]	Time 0.106 (0.276)	Data 0.000 (0.171)	Loss 0.0883 (0.0690)	Prec@1 98.047 (97.905)	Prec@5 100.000 (99.964)
2022-06-17 18:45:51 - INFO - TRAINING - Epoch: [135][20/196]	Time 0.114 (0.201)	Data 0.000 (0.090)	Loss 0.0684 (0.0683)	Prec@1 96.875 (97.805)	Prec@5 100.000 (99.981)
2022-06-17 18:45:52 - INFO - TRAINING - Epoch: [135][30/196]	Time 0.129 (0.173)	Data 0.000 (0.061)	Loss 0.1007 (0.0695)	Prec@1 96.484 (97.807)	Prec@5 100.000 (99.987)
2022-06-17 18:45:53 - INFO - TRAINING - Epoch: [135][40/196]	Time 0.137 (0.159)	Data 0.000 (0.046)	Loss 0.0658 (0.0712)	Prec@1 98.047 (97.723)	Prec@5 100.000 (99.990)
2022-06-17 18:45:54 - INFO - TRAINING - Epoch: [135][50/196]	Time 0.110 (0.150)	Data 0.000 (0.037)	Loss 0.0724 (0.0725)	Prec@1 99.219 (97.649)	Prec@5 100.000 (99.992)
2022-06-17 18:45:55 - INFO - TRAINING - Epoch: [135][60/196]	Time 0.116 (0.144)	Data 0.000 (0.031)	Loss 0.1280 (0.0752)	Prec@1 95.703 (97.528)	Prec@5 99.609 (99.987)
2022-06-17 18:45:56 - INFO - TRAINING - Epoch: [135][70/196]	Time 0.115 (0.140)	Data 0.000 (0.027)	Loss 0.0693 (0.0759)	Prec@1 97.656 (97.541)	Prec@5 100.000 (99.989)
2022-06-17 18:45:58 - INFO - TRAINING - Epoch: [135][80/196]	Time 0.113 (0.137)	Data 0.000 (0.024)	Loss 0.0894 (0.0768)	Prec@1 97.656 (97.526)	Prec@5 100.000 (99.990)
2022-06-17 18:45:59 - INFO - TRAINING - Epoch: [135][90/196]	Time 0.120 (0.134)	Data 0.000 (0.021)	Loss 0.1140 (0.0765)	Prec@1 96.484 (97.540)	Prec@5 100.000 (99.991)
2022-06-17 18:46:00 - INFO - TRAINING - Epoch: [135][100/196]	Time 0.109 (0.131)	Data 0.000 (0.019)	Loss 0.0794 (0.0771)	Prec@1 97.656 (97.490)	Prec@5 100.000 (99.992)
2022-06-17 18:46:01 - INFO - TRAINING - Epoch: [135][110/196]	Time 0.109 (0.129)	Data 0.000 (0.017)	Loss 0.1168 (0.0772)	Prec@1 94.922 (97.480)	Prec@5 100.000 (99.993)
2022-06-17 18:46:02 - INFO - TRAINING - Epoch: [135][120/196]	Time 0.116 (0.128)	Data 0.000 (0.016)	Loss 0.0768 (0.0769)	Prec@1 97.656 (97.475)	Prec@5 100.000 (99.994)
2022-06-17 18:46:03 - INFO - TRAINING - Epoch: [135][130/196]	Time 0.120 (0.127)	Data 0.000 (0.015)	Loss 0.1188 (0.0777)	Prec@1 96.094 (97.430)	Prec@5 100.000 (99.994)
2022-06-17 18:46:04 - INFO - TRAINING - Epoch: [135][140/196]	Time 0.110 (0.125)	Data 0.000 (0.014)	Loss 0.0728 (0.0779)	Prec@1 97.266 (97.426)	Prec@5 100.000 (99.994)
2022-06-17 18:46:05 - INFO - TRAINING - Epoch: [135][150/196]	Time 0.114 (0.124)	Data 0.000 (0.013)	Loss 0.1057 (0.0781)	Prec@1 96.484 (97.423)	Prec@5 100.000 (99.995)
2022-06-17 18:46:06 - INFO - TRAINING - Epoch: [135][160/196]	Time 0.104 (0.123)	Data 0.000 (0.012)	Loss 0.0634 (0.0787)	Prec@1 97.656 (97.418)	Prec@5 100.000 (99.993)
2022-06-17 18:46:07 - INFO - TRAINING - Epoch: [135][170/196]	Time 0.117 (0.123)	Data 0.000 (0.011)	Loss 0.0545 (0.0789)	Prec@1 98.438 (97.426)	Prec@5 100.000 (99.993)
2022-06-17 18:46:09 - INFO - TRAINING - Epoch: [135][180/196]	Time 0.104 (0.122)	Data 0.000 (0.011)	Loss 0.0758 (0.0797)	Prec@1 97.266 (97.382)	Prec@5 100.000 (99.994)
2022-06-17 18:46:10 - INFO - TRAINING - Epoch: [135][190/196]	Time 0.111 (0.121)	Data 0.000 (0.010)	Loss 0.1143 (0.0800)	Prec@1 96.484 (97.370)	Prec@5 100.000 (99.994)
2022-06-17 18:46:12 - INFO - EVALUATING - Epoch: [135][0/40]	Time 2.055 (2.055)	Data 2.009 (2.009)	Loss 0.2712 (0.2712)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:46:13 - INFO - EVALUATING - Epoch: [135][10/40]	Time 0.044 (0.274)	Data 0.000 (0.227)	Loss 0.4815 (0.4225)	Prec@1 87.891 (88.033)	Prec@5 99.219 (99.467)
2022-06-17 18:46:14 - INFO - EVALUATING - Epoch: [135][20/40]	Time 0.042 (0.169)	Data 0.001 (0.119)	Loss 0.3381 (0.4253)	Prec@1 87.500 (87.779)	Prec@5 99.609 (99.405)
2022-06-17 18:46:15 - INFO - EVALUATING - Epoch: [135][30/40]	Time 0.047 (0.152)	Data 0.000 (0.104)	Loss 0.5175 (0.4162)	Prec@1 85.938 (87.954)	Prec@5 100.000 (99.446)
2022-06-17 18:46:17 - INFO - 
 Epoch: 136	Training Loss 0.0802 	Training Prec@1 97.358 	Training Prec@5 99.994 	Validation Loss 0.4111 	Validation Prec@1 87.960 	Validation Prec@5 99.520 

2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:46:17 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:46:19 - INFO - TRAINING - Epoch: [136][0/196]	Time 1.651 (1.651)	Data 1.597 (1.597)	Loss 0.1001 (0.1001)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
2022-06-17 18:46:20 - INFO - TRAINING - Epoch: [136][10/196]	Time 0.105 (0.278)	Data 0.000 (0.184)	Loss 0.0828 (0.0802)	Prec@1 96.875 (97.159)	Prec@5 100.000 (100.000)
2022-06-17 18:46:21 - INFO - TRAINING - Epoch: [136][20/196]	Time 0.120 (0.200)	Data 0.000 (0.097)	Loss 0.1016 (0.0790)	Prec@1 96.094 (97.284)	Prec@5 100.000 (100.000)
2022-06-17 18:46:22 - INFO - TRAINING - Epoch: [136][30/196]	Time 0.119 (0.171)	Data 0.000 (0.066)	Loss 0.0921 (0.0782)	Prec@1 97.266 (97.429)	Prec@5 100.000 (100.000)
2022-06-17 18:46:23 - INFO - TRAINING - Epoch: [136][40/196]	Time 0.104 (0.156)	Data 0.000 (0.050)	Loss 0.0700 (0.0762)	Prec@1 97.656 (97.637)	Prec@5 100.000 (99.981)
2022-06-17 18:46:24 - INFO - TRAINING - Epoch: [136][50/196]	Time 0.123 (0.148)	Data 0.000 (0.040)	Loss 0.0957 (0.0775)	Prec@1 96.094 (97.526)	Prec@5 100.000 (99.985)
2022-06-17 18:46:26 - INFO - TRAINING - Epoch: [136][60/196]	Time 0.122 (0.141)	Data 0.000 (0.034)	Loss 0.1013 (0.0785)	Prec@1 95.703 (97.490)	Prec@5 100.000 (99.987)
2022-06-17 18:46:27 - INFO - TRAINING - Epoch: [136][70/196]	Time 0.113 (0.137)	Data 0.000 (0.029)	Loss 0.1440 (0.0795)	Prec@1 93.750 (97.420)	Prec@5 100.000 (99.983)
2022-06-17 18:46:28 - INFO - TRAINING - Epoch: [136][80/196]	Time 0.107 (0.133)	Data 0.000 (0.025)	Loss 0.0499 (0.0808)	Prec@1 99.219 (97.367)	Prec@5 100.000 (99.976)
2022-06-17 18:46:29 - INFO - TRAINING - Epoch: [136][90/196]	Time 0.109 (0.131)	Data 0.000 (0.023)	Loss 0.0788 (0.0804)	Prec@1 97.266 (97.403)	Prec@5 100.000 (99.979)
2022-06-17 18:46:30 - INFO - TRAINING - Epoch: [136][100/196]	Time 0.115 (0.129)	Data 0.000 (0.020)	Loss 0.0763 (0.0811)	Prec@1 97.266 (97.374)	Prec@5 100.000 (99.981)
2022-06-17 18:46:31 - INFO - TRAINING - Epoch: [136][110/196]	Time 0.109 (0.127)	Data 0.000 (0.019)	Loss 0.0916 (0.0811)	Prec@1 96.484 (97.350)	Prec@5 100.000 (99.982)
2022-06-17 18:46:32 - INFO - TRAINING - Epoch: [136][120/196]	Time 0.105 (0.126)	Data 0.000 (0.017)	Loss 0.0959 (0.0823)	Prec@1 97.266 (97.298)	Prec@5 100.000 (99.984)
2022-06-17 18:46:33 - INFO - TRAINING - Epoch: [136][130/196]	Time 0.104 (0.124)	Data 0.000 (0.016)	Loss 0.0464 (0.0823)	Prec@1 98.828 (97.278)	Prec@5 100.000 (99.985)
2022-06-17 18:46:34 - INFO - TRAINING - Epoch: [136][140/196]	Time 0.126 (0.124)	Data 0.000 (0.015)	Loss 0.0755 (0.0828)	Prec@1 97.656 (97.255)	Prec@5 100.000 (99.986)
2022-06-17 18:46:35 - INFO - TRAINING - Epoch: [136][150/196]	Time 0.108 (0.123)	Data 0.000 (0.014)	Loss 0.0986 (0.0828)	Prec@1 97.266 (97.248)	Prec@5 100.000 (99.987)
2022-06-17 18:46:37 - INFO - TRAINING - Epoch: [136][160/196]	Time 0.113 (0.122)	Data 0.001 (0.013)	Loss 0.0346 (0.0829)	Prec@1 99.609 (97.273)	Prec@5 100.000 (99.988)
2022-06-17 18:46:38 - INFO - TRAINING - Epoch: [136][170/196]	Time 0.120 (0.121)	Data 0.000 (0.012)	Loss 0.1121 (0.0827)	Prec@1 96.875 (97.275)	Prec@5 100.000 (99.989)
2022-06-17 18:46:39 - INFO - TRAINING - Epoch: [136][180/196]	Time 0.119 (0.121)	Data 0.000 (0.012)	Loss 0.0566 (0.0824)	Prec@1 98.828 (97.261)	Prec@5 100.000 (99.989)
2022-06-17 18:46:40 - INFO - TRAINING - Epoch: [136][190/196]	Time 0.101 (0.120)	Data 0.000 (0.011)	Loss 0.1387 (0.0825)	Prec@1 95.703 (97.255)	Prec@5 100.000 (99.988)
2022-06-17 18:46:42 - INFO - EVALUATING - Epoch: [136][0/40]	Time 1.496 (1.496)	Data 1.450 (1.450)	Loss 0.2675 (0.2675)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:46:43 - INFO - EVALUATING - Epoch: [136][10/40]	Time 0.084 (0.221)	Data 0.043 (0.173)	Loss 0.4783 (0.4251)	Prec@1 87.500 (88.104)	Prec@5 99.609 (99.396)
2022-06-17 18:46:44 - INFO - EVALUATING - Epoch: [136][20/40]	Time 0.126 (0.170)	Data 0.085 (0.120)	Loss 0.3389 (0.4257)	Prec@1 87.109 (87.853)	Prec@5 99.609 (99.349)
2022-06-17 18:46:45 - INFO - EVALUATING - Epoch: [136][30/40]	Time 0.044 (0.152)	Data 0.000 (0.103)	Loss 0.5119 (0.4160)	Prec@1 87.109 (88.155)	Prec@5 100.000 (99.446)
2022-06-17 18:46:47 - INFO - 
 Epoch: 137	Training Loss 0.0823 	Training Prec@1 97.260 	Training Prec@5 99.988 	Validation Loss 0.4104 	Validation Prec@1 88.210 	Validation Prec@5 99.520 

2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:46:47 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:46:49 - INFO - TRAINING - Epoch: [137][0/196]	Time 1.538 (1.538)	Data 1.484 (1.484)	Loss 0.0587 (0.0587)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:46:50 - INFO - TRAINING - Epoch: [137][10/196]	Time 0.124 (0.243)	Data 0.000 (0.135)	Loss 0.0781 (0.0757)	Prec@1 96.875 (97.408)	Prec@5 100.000 (100.000)
2022-06-17 18:46:51 - INFO - TRAINING - Epoch: [137][20/196]	Time 0.122 (0.183)	Data 0.000 (0.074)	Loss 0.0839 (0.0791)	Prec@1 97.266 (97.210)	Prec@5 100.000 (100.000)
2022-06-17 18:46:52 - INFO - TRAINING - Epoch: [137][30/196]	Time 0.111 (0.160)	Data 0.000 (0.050)	Loss 0.1016 (0.0822)	Prec@1 94.531 (97.114)	Prec@5 100.000 (99.987)
2022-06-17 18:46:53 - INFO - TRAINING - Epoch: [137][40/196]	Time 0.119 (0.149)	Data 0.000 (0.038)	Loss 0.0714 (0.0807)	Prec@1 97.656 (97.151)	Prec@5 100.000 (99.990)
2022-06-17 18:46:55 - INFO - TRAINING - Epoch: [137][50/196]	Time 0.119 (0.144)	Data 0.000 (0.030)	Loss 0.0621 (0.0792)	Prec@1 97.656 (97.243)	Prec@5 100.000 (99.992)
2022-06-17 18:46:56 - INFO - TRAINING - Epoch: [137][60/196]	Time 0.121 (0.140)	Data 0.000 (0.026)	Loss 0.0993 (0.0797)	Prec@1 97.656 (97.202)	Prec@5 100.000 (99.994)
2022-06-17 18:46:57 - INFO - TRAINING - Epoch: [137][70/196]	Time 0.111 (0.137)	Data 0.000 (0.022)	Loss 0.0598 (0.0796)	Prec@1 97.656 (97.233)	Prec@5 100.000 (99.994)
2022-06-17 18:46:58 - INFO - TRAINING - Epoch: [137][80/196]	Time 0.103 (0.134)	Data 0.000 (0.019)	Loss 0.0753 (0.0794)	Prec@1 96.875 (97.217)	Prec@5 100.000 (99.990)
2022-06-17 18:46:59 - INFO - TRAINING - Epoch: [137][90/196]	Time 0.129 (0.133)	Data 0.000 (0.018)	Loss 0.0895 (0.0806)	Prec@1 95.703 (97.133)	Prec@5 100.000 (99.991)
2022-06-17 18:47:01 - INFO - TRAINING - Epoch: [137][100/196]	Time 0.112 (0.132)	Data 0.000 (0.016)	Loss 0.1395 (0.0814)	Prec@1 94.531 (97.123)	Prec@5 100.000 (99.992)
2022-06-17 18:47:02 - INFO - TRAINING - Epoch: [137][110/196]	Time 0.116 (0.130)	Data 0.000 (0.015)	Loss 0.0572 (0.0811)	Prec@1 98.438 (97.111)	Prec@5 100.000 (99.993)
2022-06-17 18:47:03 - INFO - TRAINING - Epoch: [137][120/196]	Time 0.116 (0.129)	Data 0.000 (0.014)	Loss 0.0834 (0.0806)	Prec@1 96.875 (97.159)	Prec@5 100.000 (99.990)
2022-06-17 18:47:04 - INFO - TRAINING - Epoch: [137][130/196]	Time 0.138 (0.129)	Data 0.000 (0.013)	Loss 0.0683 (0.0811)	Prec@1 98.047 (97.164)	Prec@5 100.000 (99.985)
2022-06-17 18:47:05 - INFO - TRAINING - Epoch: [137][140/196]	Time 0.122 (0.128)	Data 0.000 (0.012)	Loss 0.0621 (0.0805)	Prec@1 96.875 (97.205)	Prec@5 100.000 (99.986)
2022-06-17 18:47:07 - INFO - TRAINING - Epoch: [137][150/196]	Time 0.113 (0.128)	Data 0.000 (0.011)	Loss 0.0721 (0.0816)	Prec@1 98.047 (97.172)	Prec@5 100.000 (99.984)
2022-06-17 18:47:08 - INFO - TRAINING - Epoch: [137][160/196]	Time 0.104 (0.127)	Data 0.000 (0.010)	Loss 0.0745 (0.0814)	Prec@1 98.047 (97.183)	Prec@5 100.000 (99.983)
2022-06-17 18:47:09 - INFO - TRAINING - Epoch: [137][170/196]	Time 0.135 (0.127)	Data 0.000 (0.010)	Loss 0.0934 (0.0815)	Prec@1 96.484 (97.181)	Prec@5 100.000 (99.984)
2022-06-17 18:47:10 - INFO - TRAINING - Epoch: [137][180/196]	Time 0.120 (0.127)	Data 0.000 (0.009)	Loss 0.0672 (0.0812)	Prec@1 97.656 (97.190)	Prec@5 100.000 (99.985)
2022-06-17 18:47:11 - INFO - TRAINING - Epoch: [137][190/196]	Time 0.111 (0.126)	Data 0.058 (0.009)	Loss 0.1062 (0.0813)	Prec@1 96.484 (97.180)	Prec@5 100.000 (99.986)
2022-06-17 18:47:13 - INFO - EVALUATING - Epoch: [137][0/40]	Time 1.466 (1.466)	Data 1.420 (1.420)	Loss 0.2629 (0.2629)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:47:15 - INFO - EVALUATING - Epoch: [137][10/40]	Time 0.059 (0.250)	Data 0.000 (0.200)	Loss 0.4814 (0.4199)	Prec@1 87.500 (88.459)	Prec@5 99.219 (99.503)
2022-06-17 18:47:15 - INFO - EVALUATING - Epoch: [137][20/40]	Time 0.107 (0.170)	Data 0.066 (0.120)	Loss 0.3424 (0.4219)	Prec@1 87.109 (88.021)	Prec@5 99.609 (99.461)
2022-06-17 18:47:17 - INFO - EVALUATING - Epoch: [137][30/40]	Time 0.108 (0.153)	Data 0.064 (0.104)	Loss 0.5126 (0.4129)	Prec@1 86.328 (88.193)	Prec@5 100.000 (99.521)
2022-06-17 18:47:19 - INFO - 
 Epoch: 138	Training Loss 0.0813 	Training Prec@1 97.174 	Training Prec@5 99.986 	Validation Loss 0.4085 	Validation Prec@1 88.160 	Validation Prec@5 99.580 

2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:47:19 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:47:20 - INFO - TRAINING - Epoch: [138][0/196]	Time 1.249 (1.249)	Data 1.196 (1.196)	Loss 0.0606 (0.0606)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:47:22 - INFO - TRAINING - Epoch: [138][10/196]	Time 0.110 (0.277)	Data 0.000 (0.189)	Loss 0.0739 (0.0855)	Prec@1 96.484 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:47:23 - INFO - TRAINING - Epoch: [138][20/196]	Time 0.114 (0.199)	Data 0.000 (0.099)	Loss 0.0822 (0.0803)	Prec@1 97.656 (97.321)	Prec@5 100.000 (100.000)
2022-06-17 18:47:24 - INFO - TRAINING - Epoch: [138][30/196]	Time 0.105 (0.172)	Data 0.000 (0.067)	Loss 0.0716 (0.0798)	Prec@1 97.656 (97.329)	Prec@5 100.000 (100.000)
2022-06-17 18:47:25 - INFO - TRAINING - Epoch: [138][40/196]	Time 0.106 (0.159)	Data 0.000 (0.051)	Loss 0.0375 (0.0783)	Prec@1 99.609 (97.447)	Prec@5 100.000 (100.000)
2022-06-17 18:47:26 - INFO - TRAINING - Epoch: [138][50/196]	Time 0.129 (0.150)	Data 0.000 (0.041)	Loss 0.0777 (0.0766)	Prec@1 97.266 (97.511)	Prec@5 100.000 (100.000)
2022-06-17 18:47:27 - INFO - TRAINING - Epoch: [138][60/196]	Time 0.130 (0.145)	Data 0.000 (0.034)	Loss 0.0836 (0.0760)	Prec@1 97.656 (97.535)	Prec@5 100.000 (100.000)
2022-06-17 18:47:29 - INFO - TRAINING - Epoch: [138][70/196]	Time 0.113 (0.141)	Data 0.000 (0.030)	Loss 0.0525 (0.0769)	Prec@1 97.656 (97.502)	Prec@5 100.000 (99.994)
2022-06-17 18:47:30 - INFO - TRAINING - Epoch: [138][80/196]	Time 0.103 (0.138)	Data 0.000 (0.026)	Loss 0.0802 (0.0782)	Prec@1 98.047 (97.430)	Prec@5 100.000 (99.990)
2022-06-17 18:47:31 - INFO - TRAINING - Epoch: [138][90/196]	Time 0.121 (0.136)	Data 0.000 (0.023)	Loss 0.0521 (0.0784)	Prec@1 98.828 (97.472)	Prec@5 100.000 (99.991)
2022-06-17 18:47:32 - INFO - TRAINING - Epoch: [138][100/196]	Time 0.139 (0.134)	Data 0.000 (0.021)	Loss 0.0766 (0.0791)	Prec@1 96.484 (97.409)	Prec@5 100.000 (99.988)
2022-06-17 18:47:33 - INFO - TRAINING - Epoch: [138][110/196]	Time 0.125 (0.133)	Data 0.000 (0.019)	Loss 0.0774 (0.0785)	Prec@1 97.266 (97.406)	Prec@5 100.000 (99.989)
2022-06-17 18:47:35 - INFO - TRAINING - Epoch: [138][120/196]	Time 0.107 (0.132)	Data 0.000 (0.017)	Loss 0.0871 (0.0786)	Prec@1 96.875 (97.395)	Prec@5 100.000 (99.987)
2022-06-17 18:47:36 - INFO - TRAINING - Epoch: [138][130/196]	Time 0.125 (0.131)	Data 0.000 (0.016)	Loss 0.0505 (0.0789)	Prec@1 98.828 (97.367)	Prec@5 100.000 (99.988)
2022-06-17 18:47:37 - INFO - TRAINING - Epoch: [138][140/196]	Time 0.126 (0.130)	Data 0.000 (0.015)	Loss 0.0608 (0.0781)	Prec@1 98.438 (97.401)	Prec@5 100.000 (99.989)
2022-06-17 18:47:38 - INFO - TRAINING - Epoch: [138][150/196]	Time 0.108 (0.130)	Data 0.000 (0.014)	Loss 0.0729 (0.0790)	Prec@1 97.656 (97.369)	Prec@5 100.000 (99.990)
2022-06-17 18:47:39 - INFO - TRAINING - Epoch: [138][160/196]	Time 0.106 (0.129)	Data 0.000 (0.013)	Loss 0.0428 (0.0789)	Prec@1 98.828 (97.389)	Prec@5 100.000 (99.988)
2022-06-17 18:47:40 - INFO - TRAINING - Epoch: [138][170/196]	Time 0.122 (0.128)	Data 0.000 (0.012)	Loss 0.1031 (0.0793)	Prec@1 95.703 (97.368)	Prec@5 100.000 (99.989)
2022-06-17 18:47:42 - INFO - TRAINING - Epoch: [138][180/196]	Time 0.133 (0.128)	Data 0.000 (0.012)	Loss 0.0766 (0.0791)	Prec@1 97.266 (97.367)	Prec@5 100.000 (99.989)
2022-06-17 18:47:43 - INFO - TRAINING - Epoch: [138][190/196]	Time 0.104 (0.127)	Data 0.000 (0.011)	Loss 0.1075 (0.0796)	Prec@1 95.703 (97.323)	Prec@5 100.000 (99.990)
2022-06-17 18:47:45 - INFO - EVALUATING - Epoch: [138][0/40]	Time 1.620 (1.620)	Data 1.574 (1.574)	Loss 0.2653 (0.2653)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:47:46 - INFO - EVALUATING - Epoch: [138][10/40]	Time 0.055 (0.272)	Data 0.000 (0.225)	Loss 0.4785 (0.4271)	Prec@1 87.109 (87.962)	Prec@5 98.828 (99.432)
2022-06-17 18:47:47 - INFO - EVALUATING - Epoch: [138][20/40]	Time 0.045 (0.170)	Data 0.000 (0.121)	Loss 0.3461 (0.4298)	Prec@1 87.109 (87.760)	Prec@5 99.609 (99.405)
2022-06-17 18:47:48 - INFO - EVALUATING - Epoch: [138][30/40]	Time 0.044 (0.150)	Data 0.000 (0.103)	Loss 0.5171 (0.4205)	Prec@1 85.938 (88.017)	Prec@5 100.000 (99.471)
2022-06-17 18:47:50 - INFO - 
 Epoch: 139	Training Loss 0.0798 	Training Prec@1 97.312 	Training Prec@5 99.988 	Validation Loss 0.4156 	Validation Prec@1 88.050 	Validation Prec@5 99.540 

2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:47:50 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:47:52 - INFO - TRAINING - Epoch: [139][0/196]	Time 1.682 (1.682)	Data 1.628 (1.628)	Loss 0.0749 (0.0749)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:47:53 - INFO - TRAINING - Epoch: [139][10/196]	Time 0.125 (0.268)	Data 0.000 (0.162)	Loss 0.0550 (0.0754)	Prec@1 98.047 (97.443)	Prec@5 100.000 (100.000)
2022-06-17 18:47:54 - INFO - TRAINING - Epoch: [139][20/196]	Time 0.111 (0.194)	Data 0.000 (0.085)	Loss 0.0749 (0.0746)	Prec@1 98.438 (97.396)	Prec@5 100.000 (100.000)
2022-06-17 18:47:55 - INFO - TRAINING - Epoch: [139][30/196]	Time 0.126 (0.169)	Data 0.000 (0.058)	Loss 0.0758 (0.0774)	Prec@1 96.484 (97.291)	Prec@5 100.000 (99.987)
2022-06-17 18:47:56 - INFO - TRAINING - Epoch: [139][40/196]	Time 0.120 (0.156)	Data 0.000 (0.044)	Loss 0.0656 (0.0778)	Prec@1 98.047 (97.361)	Prec@5 100.000 (99.990)
2022-06-17 18:47:58 - INFO - TRAINING - Epoch: [139][50/196]	Time 0.119 (0.148)	Data 0.000 (0.035)	Loss 0.0709 (0.0762)	Prec@1 97.656 (97.434)	Prec@5 100.000 (99.992)
2022-06-17 18:47:59 - INFO - TRAINING - Epoch: [139][60/196]	Time 0.105 (0.143)	Data 0.000 (0.030)	Loss 0.0753 (0.0776)	Prec@1 97.656 (97.400)	Prec@5 100.000 (99.994)
2022-06-17 18:48:00 - INFO - TRAINING - Epoch: [139][70/196]	Time 0.107 (0.139)	Data 0.000 (0.025)	Loss 0.0709 (0.0787)	Prec@1 97.656 (97.365)	Prec@5 100.000 (99.994)
2022-06-17 18:48:01 - INFO - TRAINING - Epoch: [139][80/196]	Time 0.114 (0.136)	Data 0.000 (0.022)	Loss 0.0956 (0.0780)	Prec@1 96.094 (97.377)	Prec@5 100.000 (99.995)
2022-06-17 18:48:02 - INFO - TRAINING - Epoch: [139][90/196]	Time 0.106 (0.134)	Data 0.000 (0.020)	Loss 0.1090 (0.0783)	Prec@1 96.875 (97.373)	Prec@5 100.000 (99.996)
2022-06-17 18:48:03 - INFO - TRAINING - Epoch: [139][100/196]	Time 0.135 (0.132)	Data 0.000 (0.018)	Loss 0.0720 (0.0786)	Prec@1 98.438 (97.366)	Prec@5 100.000 (99.996)
2022-06-17 18:48:04 - INFO - TRAINING - Epoch: [139][110/196]	Time 0.103 (0.131)	Data 0.000 (0.016)	Loss 0.0702 (0.0780)	Prec@1 97.656 (97.382)	Prec@5 100.000 (99.996)
2022-06-17 18:48:06 - INFO - TRAINING - Epoch: [139][120/196]	Time 0.120 (0.130)	Data 0.000 (0.015)	Loss 0.0799 (0.0789)	Prec@1 97.266 (97.343)	Prec@5 100.000 (99.990)
2022-06-17 18:48:07 - INFO - TRAINING - Epoch: [139][130/196]	Time 0.118 (0.129)	Data 0.000 (0.014)	Loss 0.1126 (0.0789)	Prec@1 96.484 (97.349)	Prec@5 100.000 (99.991)
2022-06-17 18:48:08 - INFO - TRAINING - Epoch: [139][140/196]	Time 0.108 (0.128)	Data 0.000 (0.013)	Loss 0.0807 (0.0792)	Prec@1 97.266 (97.318)	Prec@5 100.000 (99.989)
2022-06-17 18:48:09 - INFO - TRAINING - Epoch: [139][150/196]	Time 0.105 (0.127)	Data 0.000 (0.012)	Loss 0.0787 (0.0798)	Prec@1 98.047 (97.276)	Prec@5 100.000 (99.990)
2022-06-17 18:48:10 - INFO - TRAINING - Epoch: [139][160/196]	Time 0.121 (0.126)	Data 0.000 (0.011)	Loss 0.0745 (0.0792)	Prec@1 97.656 (97.297)	Prec@5 100.000 (99.990)
2022-06-17 18:48:11 - INFO - TRAINING - Epoch: [139][170/196]	Time 0.115 (0.126)	Data 0.000 (0.011)	Loss 0.0871 (0.0795)	Prec@1 97.266 (97.300)	Prec@5 100.000 (99.991)
2022-06-17 18:48:13 - INFO - TRAINING - Epoch: [139][180/196]	Time 0.104 (0.125)	Data 0.000 (0.010)	Loss 0.0819 (0.0798)	Prec@1 96.484 (97.281)	Prec@5 100.000 (99.991)
2022-06-17 18:48:14 - INFO - TRAINING - Epoch: [139][190/196]	Time 0.101 (0.124)	Data 0.000 (0.010)	Loss 0.0510 (0.0796)	Prec@1 98.828 (97.280)	Prec@5 100.000 (99.990)
2022-06-17 18:48:16 - INFO - EVALUATING - Epoch: [139][0/40]	Time 1.902 (1.902)	Data 1.857 (1.857)	Loss 0.2627 (0.2627)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:48:17 - INFO - EVALUATING - Epoch: [139][10/40]	Time 0.061 (0.234)	Data 0.000 (0.185)	Loss 0.4773 (0.4162)	Prec@1 88.281 (88.388)	Prec@5 99.219 (99.503)
2022-06-17 18:48:18 - INFO - EVALUATING - Epoch: [139][20/40]	Time 0.044 (0.167)	Data 0.000 (0.117)	Loss 0.3539 (0.4203)	Prec@1 87.500 (88.095)	Prec@5 99.609 (99.423)
2022-06-17 18:48:19 - INFO - EVALUATING - Epoch: [139][30/40]	Time 0.043 (0.146)	Data 0.000 (0.098)	Loss 0.5078 (0.4115)	Prec@1 86.719 (88.294)	Prec@5 100.000 (99.496)
2022-06-17 18:48:21 - INFO - 
 Epoch: 140	Training Loss 0.0798 	Training Prec@1 97.288 	Training Prec@5 99.990 	Validation Loss 0.4079 	Validation Prec@1 88.270 	Validation Prec@5 99.570 

2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:48:21 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:48:23 - INFO - TRAINING - Epoch: [140][0/196]	Time 1.760 (1.760)	Data 1.707 (1.707)	Loss 0.0974 (0.0974)	Prec@1 96.484 (96.484)	Prec@5 99.609 (99.609)
2022-06-17 18:48:24 - INFO - TRAINING - Epoch: [140][10/196]	Time 0.110 (0.268)	Data 0.000 (0.172)	Loss 0.1073 (0.0785)	Prec@1 96.484 (97.408)	Prec@5 100.000 (99.964)
2022-06-17 18:48:25 - INFO - TRAINING - Epoch: [140][20/196]	Time 0.103 (0.190)	Data 0.000 (0.090)	Loss 0.0571 (0.0770)	Prec@1 98.047 (97.340)	Prec@5 100.000 (99.963)
2022-06-17 18:48:26 - INFO - TRAINING - Epoch: [140][30/196]	Time 0.105 (0.164)	Data 0.000 (0.061)	Loss 0.0878 (0.0800)	Prec@1 97.656 (97.303)	Prec@5 100.000 (99.975)
2022-06-17 18:48:27 - INFO - TRAINING - Epoch: [140][40/196]	Time 0.112 (0.152)	Data 0.000 (0.046)	Loss 0.0774 (0.0800)	Prec@1 97.656 (97.237)	Prec@5 100.000 (99.981)
2022-06-17 18:48:28 - INFO - TRAINING - Epoch: [140][50/196]	Time 0.108 (0.144)	Data 0.000 (0.037)	Loss 0.0894 (0.0811)	Prec@1 96.875 (97.197)	Prec@5 100.000 (99.985)
2022-06-17 18:48:29 - INFO - TRAINING - Epoch: [140][60/196]	Time 0.112 (0.139)	Data 0.001 (0.031)	Loss 0.0787 (0.0814)	Prec@1 96.875 (97.106)	Prec@5 100.000 (99.987)
2022-06-17 18:48:31 - INFO - TRAINING - Epoch: [140][70/196]	Time 0.102 (0.134)	Data 0.000 (0.027)	Loss 0.0763 (0.0808)	Prec@1 96.875 (97.134)	Prec@5 100.000 (99.989)
2022-06-17 18:48:32 - INFO - TRAINING - Epoch: [140][80/196]	Time 0.103 (0.131)	Data 0.000 (0.024)	Loss 0.0519 (0.0820)	Prec@1 98.828 (97.097)	Prec@5 100.000 (99.990)
2022-06-17 18:48:33 - INFO - TRAINING - Epoch: [140][90/196]	Time 0.106 (0.129)	Data 0.000 (0.021)	Loss 0.0914 (0.0829)	Prec@1 96.875 (97.081)	Prec@5 100.000 (99.991)
2022-06-17 18:48:34 - INFO - TRAINING - Epoch: [140][100/196]	Time 0.110 (0.127)	Data 0.000 (0.019)	Loss 0.0590 (0.0814)	Prec@1 97.656 (97.107)	Prec@5 100.000 (99.988)
2022-06-17 18:48:35 - INFO - TRAINING - Epoch: [140][110/196]	Time 0.109 (0.125)	Data 0.000 (0.017)	Loss 0.0701 (0.0808)	Prec@1 96.484 (97.121)	Prec@5 100.000 (99.989)
2022-06-17 18:48:36 - INFO - TRAINING - Epoch: [140][120/196]	Time 0.147 (0.125)	Data 0.000 (0.016)	Loss 0.0611 (0.0795)	Prec@1 97.656 (97.172)	Prec@5 100.000 (99.990)
2022-06-17 18:48:37 - INFO - TRAINING - Epoch: [140][130/196]	Time 0.111 (0.123)	Data 0.000 (0.015)	Loss 0.0694 (0.0795)	Prec@1 97.266 (97.182)	Prec@5 100.000 (99.991)
2022-06-17 18:48:38 - INFO - TRAINING - Epoch: [140][140/196]	Time 0.106 (0.123)	Data 0.000 (0.014)	Loss 0.0547 (0.0792)	Prec@1 98.828 (97.213)	Prec@5 100.000 (99.992)
2022-06-17 18:48:39 - INFO - TRAINING - Epoch: [140][150/196]	Time 0.105 (0.122)	Data 0.000 (0.013)	Loss 0.0830 (0.0784)	Prec@1 96.484 (97.248)	Prec@5 100.000 (99.992)
2022-06-17 18:48:40 - INFO - TRAINING - Epoch: [140][160/196]	Time 0.108 (0.121)	Data 0.000 (0.012)	Loss 0.0672 (0.0778)	Prec@1 97.266 (97.275)	Prec@5 100.000 (99.993)
2022-06-17 18:48:42 - INFO - TRAINING - Epoch: [140][170/196]	Time 0.112 (0.121)	Data 0.000 (0.011)	Loss 0.1154 (0.0783)	Prec@1 96.484 (97.256)	Prec@5 99.219 (99.989)
2022-06-17 18:48:43 - INFO - TRAINING - Epoch: [140][180/196]	Time 0.107 (0.120)	Data 0.000 (0.011)	Loss 0.0695 (0.0786)	Prec@1 98.047 (97.244)	Prec@5 100.000 (99.989)
2022-06-17 18:48:44 - INFO - TRAINING - Epoch: [140][190/196]	Time 0.111 (0.120)	Data 0.000 (0.010)	Loss 0.0487 (0.0789)	Prec@1 98.438 (97.229)	Prec@5 100.000 (99.988)
2022-06-17 18:48:46 - INFO - EVALUATING - Epoch: [140][0/40]	Time 1.434 (1.434)	Data 1.388 (1.388)	Loss 0.2650 (0.2650)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:48:47 - INFO - EVALUATING - Epoch: [140][10/40]	Time 0.063 (0.229)	Data 0.000 (0.178)	Loss 0.4706 (0.4202)	Prec@1 87.500 (88.388)	Prec@5 99.219 (99.361)
2022-06-17 18:48:48 - INFO - EVALUATING - Epoch: [140][20/40]	Time 0.041 (0.171)	Data 0.000 (0.122)	Loss 0.3569 (0.4244)	Prec@1 87.500 (87.965)	Prec@5 100.000 (99.368)
2022-06-17 18:48:49 - INFO - EVALUATING - Epoch: [140][30/40]	Time 0.043 (0.151)	Data 0.000 (0.104)	Loss 0.5179 (0.4154)	Prec@1 85.156 (88.193)	Prec@5 100.000 (99.446)
2022-06-17 18:48:51 - INFO - 
 Epoch: 141	Training Loss 0.0784 	Training Prec@1 97.260 	Training Prec@5 99.988 	Validation Loss 0.4104 	Validation Prec@1 88.220 	Validation Prec@5 99.530 

2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:48:51 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:48:52 - INFO - TRAINING - Epoch: [141][0/196]	Time 1.473 (1.473)	Data 1.420 (1.420)	Loss 0.0390 (0.0390)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
2022-06-17 18:48:54 - INFO - TRAINING - Epoch: [141][10/196]	Time 0.104 (0.284)	Data 0.000 (0.191)	Loss 0.0586 (0.0679)	Prec@1 97.656 (97.692)	Prec@5 100.000 (100.000)
2022-06-17 18:48:55 - INFO - TRAINING - Epoch: [141][20/196]	Time 0.126 (0.202)	Data 0.000 (0.100)	Loss 0.0862 (0.0778)	Prec@1 96.484 (97.210)	Prec@5 100.000 (100.000)
2022-06-17 18:48:56 - INFO - TRAINING - Epoch: [141][30/196]	Time 0.121 (0.174)	Data 0.000 (0.068)	Loss 0.0959 (0.0783)	Prec@1 97.266 (97.253)	Prec@5 100.000 (100.000)
2022-06-17 18:48:58 - INFO - TRAINING - Epoch: [141][40/196]	Time 0.115 (0.161)	Data 0.000 (0.052)	Loss 0.0474 (0.0777)	Prec@1 98.438 (97.275)	Prec@5 100.000 (100.000)
2022-06-17 18:48:59 - INFO - TRAINING - Epoch: [141][50/196]	Time 0.106 (0.152)	Data 0.000 (0.041)	Loss 0.0559 (0.0777)	Prec@1 97.266 (97.289)	Prec@5 100.000 (100.000)
2022-06-17 18:49:00 - INFO - TRAINING - Epoch: [141][60/196]	Time 0.133 (0.147)	Data 0.000 (0.035)	Loss 0.0674 (0.0748)	Prec@1 98.047 (97.439)	Prec@5 100.000 (100.000)
2022-06-17 18:49:01 - INFO - TRAINING - Epoch: [141][70/196]	Time 0.108 (0.143)	Data 0.000 (0.030)	Loss 0.1027 (0.0761)	Prec@1 97.266 (97.425)	Prec@5 100.000 (100.000)
2022-06-17 18:49:02 - INFO - TRAINING - Epoch: [141][80/196]	Time 0.122 (0.140)	Data 0.000 (0.026)	Loss 0.0677 (0.0765)	Prec@1 97.266 (97.386)	Prec@5 100.000 (100.000)
2022-06-17 18:49:03 - INFO - TRAINING - Epoch: [141][90/196]	Time 0.103 (0.137)	Data 0.000 (0.023)	Loss 0.0618 (0.0778)	Prec@1 98.047 (97.339)	Prec@5 100.000 (100.000)
2022-06-17 18:49:05 - INFO - TRAINING - Epoch: [141][100/196]	Time 0.131 (0.135)	Data 0.000 (0.021)	Loss 0.0692 (0.0772)	Prec@1 97.656 (97.370)	Prec@5 100.000 (100.000)
2022-06-17 18:49:06 - INFO - TRAINING - Epoch: [141][110/196]	Time 0.130 (0.134)	Data 0.000 (0.019)	Loss 0.0875 (0.0777)	Prec@1 96.094 (97.354)	Prec@5 100.000 (100.000)
2022-06-17 18:49:07 - INFO - TRAINING - Epoch: [141][120/196]	Time 0.130 (0.133)	Data 0.000 (0.018)	Loss 0.0759 (0.0776)	Prec@1 96.875 (97.353)	Prec@5 100.000 (100.000)
2022-06-17 18:49:08 - INFO - TRAINING - Epoch: [141][130/196]	Time 0.103 (0.132)	Data 0.000 (0.016)	Loss 0.0686 (0.0775)	Prec@1 97.266 (97.370)	Prec@5 100.000 (99.997)
2022-06-17 18:49:09 - INFO - TRAINING - Epoch: [141][140/196]	Time 0.127 (0.131)	Data 0.000 (0.015)	Loss 0.1108 (0.0775)	Prec@1 94.922 (97.354)	Prec@5 100.000 (99.997)
2022-06-17 18:49:11 - INFO - TRAINING - Epoch: [141][150/196]	Time 0.109 (0.130)	Data 0.000 (0.014)	Loss 0.0580 (0.0775)	Prec@1 98.047 (97.367)	Prec@5 100.000 (99.997)
2022-06-17 18:49:12 - INFO - TRAINING - Epoch: [141][160/196]	Time 0.122 (0.129)	Data 0.000 (0.013)	Loss 0.0678 (0.0781)	Prec@1 96.875 (97.351)	Prec@5 100.000 (99.993)
2022-06-17 18:49:13 - INFO - TRAINING - Epoch: [141][170/196]	Time 0.108 (0.129)	Data 0.000 (0.013)	Loss 0.1028 (0.0784)	Prec@1 96.484 (97.348)	Prec@5 100.000 (99.993)
2022-06-17 18:49:14 - INFO - TRAINING - Epoch: [141][180/196]	Time 0.118 (0.128)	Data 0.000 (0.012)	Loss 0.0994 (0.0785)	Prec@1 95.703 (97.328)	Prec@5 100.000 (99.994)
2022-06-17 18:49:15 - INFO - TRAINING - Epoch: [141][190/196]	Time 0.102 (0.127)	Data 0.000 (0.011)	Loss 0.0782 (0.0786)	Prec@1 96.875 (97.296)	Prec@5 100.000 (99.994)
2022-06-17 18:49:17 - INFO - EVALUATING - Epoch: [141][0/40]	Time 1.503 (1.503)	Data 1.458 (1.458)	Loss 0.2610 (0.2610)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:49:18 - INFO - EVALUATING - Epoch: [141][10/40]	Time 0.262 (0.243)	Data 0.218 (0.198)	Loss 0.4890 (0.4226)	Prec@1 88.281 (88.423)	Prec@5 99.219 (99.467)
2022-06-17 18:49:19 - INFO - EVALUATING - Epoch: [141][20/40]	Time 0.041 (0.169)	Data 0.001 (0.125)	Loss 0.3541 (0.4233)	Prec@1 87.109 (88.188)	Prec@5 99.609 (99.405)
2022-06-17 18:49:20 - INFO - EVALUATING - Epoch: [141][30/40]	Time 0.087 (0.148)	Data 0.044 (0.105)	Loss 0.5217 (0.4150)	Prec@1 86.328 (88.344)	Prec@5 100.000 (99.471)
2022-06-17 18:49:22 - INFO - 
 Epoch: 142	Training Loss 0.0787 	Training Prec@1 97.304 	Training Prec@5 99.992 	Validation Loss 0.4106 	Validation Prec@1 88.340 	Validation Prec@5 99.530 

2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:49:22 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:49:24 - INFO - TRAINING - Epoch: [142][0/196]	Time 1.332 (1.332)	Data 1.279 (1.279)	Loss 0.1312 (0.1312)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2022-06-17 18:49:25 - INFO - TRAINING - Epoch: [142][10/196]	Time 0.111 (0.235)	Data 0.061 (0.153)	Loss 0.0528 (0.0743)	Prec@1 98.438 (97.372)	Prec@5 100.000 (100.000)
2022-06-17 18:49:26 - INFO - TRAINING - Epoch: [142][20/196]	Time 0.113 (0.175)	Data 0.000 (0.082)	Loss 0.0962 (0.0709)	Prec@1 97.266 (97.545)	Prec@5 100.000 (100.000)
2022-06-17 18:49:27 - INFO - TRAINING - Epoch: [142][30/196]	Time 0.102 (0.154)	Data 0.000 (0.056)	Loss 0.0543 (0.0721)	Prec@1 98.828 (97.555)	Prec@5 100.000 (99.987)
2022-06-17 18:49:28 - INFO - TRAINING - Epoch: [142][40/196]	Time 0.138 (0.145)	Data 0.000 (0.042)	Loss 0.0874 (0.0720)	Prec@1 96.875 (97.609)	Prec@5 100.000 (99.990)
2022-06-17 18:49:29 - INFO - TRAINING - Epoch: [142][50/196]	Time 0.109 (0.139)	Data 0.000 (0.034)	Loss 0.0812 (0.0733)	Prec@1 98.047 (97.595)	Prec@5 100.000 (99.992)
2022-06-17 18:49:30 - INFO - TRAINING - Epoch: [142][60/196]	Time 0.115 (0.134)	Data 0.000 (0.029)	Loss 0.0588 (0.0743)	Prec@1 98.828 (97.560)	Prec@5 100.000 (99.994)
2022-06-17 18:49:32 - INFO - TRAINING - Epoch: [142][70/196]	Time 0.106 (0.131)	Data 0.000 (0.025)	Loss 0.0907 (0.0754)	Prec@1 96.094 (97.502)	Prec@5 100.000 (99.994)
2022-06-17 18:49:33 - INFO - TRAINING - Epoch: [142][80/196]	Time 0.134 (0.129)	Data 0.000 (0.022)	Loss 0.1159 (0.0765)	Prec@1 95.703 (97.454)	Prec@5 100.000 (99.995)
2022-06-17 18:49:34 - INFO - TRAINING - Epoch: [142][90/196]	Time 0.108 (0.127)	Data 0.000 (0.019)	Loss 0.0668 (0.0760)	Prec@1 96.875 (97.454)	Prec@5 100.000 (99.996)
2022-06-17 18:49:35 - INFO - TRAINING - Epoch: [142][100/196]	Time 0.102 (0.126)	Data 0.000 (0.017)	Loss 0.0611 (0.0750)	Prec@1 96.875 (97.474)	Prec@5 100.000 (99.996)
2022-06-17 18:49:36 - INFO - TRAINING - Epoch: [142][110/196]	Time 0.101 (0.124)	Data 0.000 (0.016)	Loss 0.0708 (0.0755)	Prec@1 97.266 (97.466)	Prec@5 100.000 (99.993)
2022-06-17 18:49:37 - INFO - TRAINING - Epoch: [142][120/196]	Time 0.119 (0.123)	Data 0.000 (0.015)	Loss 0.0635 (0.0760)	Prec@1 97.266 (97.453)	Prec@5 100.000 (99.994)
2022-06-17 18:49:38 - INFO - TRAINING - Epoch: [142][130/196]	Time 0.102 (0.123)	Data 0.000 (0.013)	Loss 0.0647 (0.0765)	Prec@1 97.656 (97.436)	Prec@5 100.000 (99.991)
2022-06-17 18:49:39 - INFO - TRAINING - Epoch: [142][140/196]	Time 0.100 (0.122)	Data 0.000 (0.013)	Loss 0.0637 (0.0770)	Prec@1 97.266 (97.401)	Prec@5 100.000 (99.992)
2022-06-17 18:49:41 - INFO - TRAINING - Epoch: [142][150/196]	Time 0.102 (0.121)	Data 0.000 (0.012)	Loss 0.0910 (0.0780)	Prec@1 96.875 (97.361)	Prec@5 100.000 (99.992)
2022-06-17 18:49:42 - INFO - TRAINING - Epoch: [142][160/196]	Time 0.109 (0.121)	Data 0.000 (0.011)	Loss 0.0544 (0.0782)	Prec@1 98.828 (97.370)	Prec@5 100.000 (99.988)
2022-06-17 18:49:43 - INFO - TRAINING - Epoch: [142][170/196]	Time 0.127 (0.121)	Data 0.000 (0.010)	Loss 0.0814 (0.0779)	Prec@1 96.875 (97.382)	Prec@5 100.000 (99.989)
2022-06-17 18:49:44 - INFO - TRAINING - Epoch: [142][180/196]	Time 0.101 (0.120)	Data 0.000 (0.010)	Loss 0.0755 (0.0785)	Prec@1 98.047 (97.345)	Prec@5 99.609 (99.987)
2022-06-17 18:49:45 - INFO - TRAINING - Epoch: [142][190/196]	Time 0.102 (0.120)	Data 0.000 (0.009)	Loss 0.0532 (0.0787)	Prec@1 98.828 (97.337)	Prec@5 100.000 (99.988)
2022-06-17 18:49:48 - INFO - EVALUATING - Epoch: [142][0/40]	Time 1.832 (1.832)	Data 1.786 (1.786)	Loss 0.2596 (0.2596)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:49:49 - INFO - EVALUATING - Epoch: [142][10/40]	Time 0.062 (0.266)	Data 0.000 (0.216)	Loss 0.4886 (0.4231)	Prec@1 89.062 (88.281)	Prec@5 99.219 (99.467)
2022-06-17 18:49:49 - INFO - EVALUATING - Epoch: [142][20/40]	Time 0.067 (0.174)	Data 0.000 (0.122)	Loss 0.3499 (0.4255)	Prec@1 87.891 (88.077)	Prec@5 100.000 (99.423)
2022-06-17 18:49:51 - INFO - EVALUATING - Epoch: [142][30/40]	Time 0.061 (0.156)	Data 0.000 (0.106)	Loss 0.5291 (0.4172)	Prec@1 84.766 (88.155)	Prec@5 100.000 (99.496)
2022-06-17 18:49:52 - INFO - 
 Epoch: 143	Training Loss 0.0786 	Training Prec@1 97.330 	Training Prec@5 99.988 	Validation Loss 0.4118 	Validation Prec@1 88.210 	Validation Prec@5 99.560 

2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:49:52 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:49:54 - INFO - TRAINING - Epoch: [143][0/196]	Time 1.207 (1.207)	Data 1.153 (1.153)	Loss 0.0849 (0.0849)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:49:55 - INFO - TRAINING - Epoch: [143][10/196]	Time 0.212 (0.249)	Data 0.164 (0.158)	Loss 0.0846 (0.0812)	Prec@1 97.266 (97.230)	Prec@5 100.000 (100.000)
2022-06-17 18:49:56 - INFO - TRAINING - Epoch: [143][20/196]	Time 0.106 (0.180)	Data 0.000 (0.083)	Loss 0.0525 (0.0766)	Prec@1 98.047 (97.321)	Prec@5 100.000 (100.000)
2022-06-17 18:49:57 - INFO - TRAINING - Epoch: [143][30/196]	Time 0.110 (0.158)	Data 0.000 (0.056)	Loss 0.0673 (0.0809)	Prec@1 96.484 (97.203)	Prec@5 100.000 (100.000)
2022-06-17 18:49:59 - INFO - TRAINING - Epoch: [143][40/196]	Time 0.108 (0.148)	Data 0.000 (0.043)	Loss 0.0617 (0.0827)	Prec@1 98.047 (97.123)	Prec@5 100.000 (99.990)
2022-06-17 18:50:00 - INFO - TRAINING - Epoch: [143][50/196]	Time 0.109 (0.141)	Data 0.000 (0.034)	Loss 0.0680 (0.0815)	Prec@1 97.656 (97.174)	Prec@5 100.000 (99.992)
2022-06-17 18:50:01 - INFO - TRAINING - Epoch: [143][60/196]	Time 0.106 (0.136)	Data 0.000 (0.029)	Loss 0.0546 (0.0799)	Prec@1 98.438 (97.253)	Prec@5 100.000 (99.994)
2022-06-17 18:50:02 - INFO - TRAINING - Epoch: [143][70/196]	Time 0.117 (0.132)	Data 0.000 (0.025)	Loss 0.0561 (0.0809)	Prec@1 98.047 (97.178)	Prec@5 100.000 (99.994)
2022-06-17 18:50:03 - INFO - TRAINING - Epoch: [143][80/196]	Time 0.107 (0.130)	Data 0.000 (0.022)	Loss 0.1069 (0.0810)	Prec@1 96.484 (97.208)	Prec@5 100.000 (99.995)
2022-06-17 18:50:04 - INFO - TRAINING - Epoch: [143][90/196]	Time 0.116 (0.128)	Data 0.000 (0.019)	Loss 0.0532 (0.0813)	Prec@1 97.266 (97.171)	Prec@5 100.000 (99.996)
2022-06-17 18:50:05 - INFO - TRAINING - Epoch: [143][100/196]	Time 0.104 (0.127)	Data 0.000 (0.018)	Loss 0.0859 (0.0813)	Prec@1 97.656 (97.181)	Prec@5 100.000 (99.996)
2022-06-17 18:50:06 - INFO - TRAINING - Epoch: [143][110/196]	Time 0.117 (0.125)	Data 0.000 (0.016)	Loss 0.0863 (0.0822)	Prec@1 96.484 (97.142)	Prec@5 100.000 (99.989)
2022-06-17 18:50:07 - INFO - TRAINING - Epoch: [143][120/196]	Time 0.116 (0.124)	Data 0.000 (0.015)	Loss 0.0923 (0.0816)	Prec@1 96.484 (97.172)	Prec@5 100.000 (99.984)
2022-06-17 18:50:09 - INFO - TRAINING - Epoch: [143][130/196]	Time 0.103 (0.123)	Data 0.000 (0.014)	Loss 0.0932 (0.0817)	Prec@1 96.094 (97.173)	Prec@5 100.000 (99.982)
2022-06-17 18:50:10 - INFO - TRAINING - Epoch: [143][140/196]	Time 0.112 (0.122)	Data 0.000 (0.013)	Loss 0.1233 (0.0822)	Prec@1 95.703 (97.141)	Prec@5 100.000 (99.983)
2022-06-17 18:50:11 - INFO - TRAINING - Epoch: [143][150/196]	Time 0.119 (0.121)	Data 0.000 (0.012)	Loss 0.0891 (0.0811)	Prec@1 97.266 (97.180)	Prec@5 100.000 (99.984)
2022-06-17 18:50:12 - INFO - TRAINING - Epoch: [143][160/196]	Time 0.106 (0.121)	Data 0.000 (0.011)	Loss 0.0471 (0.0801)	Prec@1 98.047 (97.222)	Prec@5 100.000 (99.985)
2022-06-17 18:50:13 - INFO - TRAINING - Epoch: [143][170/196]	Time 0.127 (0.121)	Data 0.000 (0.010)	Loss 0.0519 (0.0798)	Prec@1 98.438 (97.234)	Prec@5 100.000 (99.986)
2022-06-17 18:50:14 - INFO - TRAINING - Epoch: [143][180/196]	Time 0.125 (0.121)	Data 0.000 (0.010)	Loss 0.0675 (0.0801)	Prec@1 97.656 (97.235)	Prec@5 100.000 (99.987)
2022-06-17 18:50:15 - INFO - TRAINING - Epoch: [143][190/196]	Time 0.107 (0.120)	Data 0.000 (0.009)	Loss 0.0662 (0.0799)	Prec@1 98.047 (97.247)	Prec@5 100.000 (99.988)
2022-06-17 18:50:18 - INFO - EVALUATING - Epoch: [143][0/40]	Time 1.565 (1.565)	Data 1.519 (1.519)	Loss 0.2691 (0.2691)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:50:19 - INFO - EVALUATING - Epoch: [143][10/40]	Time 0.065 (0.257)	Data 0.000 (0.206)	Loss 0.4800 (0.4244)	Prec@1 88.281 (88.317)	Prec@5 99.219 (99.432)
2022-06-17 18:50:20 - INFO - EVALUATING - Epoch: [143][20/40]	Time 0.109 (0.174)	Data 0.064 (0.124)	Loss 0.3519 (0.4256)	Prec@1 87.109 (87.965)	Prec@5 100.000 (99.442)
2022-06-17 18:50:21 - INFO - EVALUATING - Epoch: [143][30/40]	Time 0.183 (0.154)	Data 0.139 (0.105)	Loss 0.5293 (0.4172)	Prec@1 86.328 (88.168)	Prec@5 100.000 (99.509)
2022-06-17 18:50:23 - INFO - 
 Epoch: 144	Training Loss 0.0800 	Training Prec@1 97.242 	Training Prec@5 99.988 	Validation Loss 0.4115 	Validation Prec@1 88.250 	Validation Prec@5 99.580 

2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:50:23 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:50:25 - INFO - TRAINING - Epoch: [144][0/196]	Time 1.788 (1.788)	Data 1.734 (1.734)	Loss 0.0549 (0.0549)	Prec@1 98.828 (98.828)	Prec@5 100.000 (100.000)
2022-06-17 18:50:26 - INFO - TRAINING - Epoch: [144][10/196]	Time 0.106 (0.266)	Data 0.000 (0.158)	Loss 0.0553 (0.0698)	Prec@1 98.828 (97.798)	Prec@5 100.000 (100.000)
2022-06-17 18:50:27 - INFO - TRAINING - Epoch: [144][20/196]	Time 0.106 (0.193)	Data 0.000 (0.083)	Loss 0.0395 (0.0666)	Prec@1 99.609 (98.028)	Prec@5 100.000 (100.000)
2022-06-17 18:50:28 - INFO - TRAINING - Epoch: [144][30/196]	Time 0.113 (0.169)	Data 0.000 (0.056)	Loss 0.0754 (0.0707)	Prec@1 97.656 (97.744)	Prec@5 100.000 (100.000)
2022-06-17 18:50:29 - INFO - TRAINING - Epoch: [144][40/196]	Time 0.107 (0.156)	Data 0.000 (0.043)	Loss 0.0699 (0.0742)	Prec@1 97.266 (97.561)	Prec@5 100.000 (99.990)
2022-06-17 18:50:30 - INFO - TRAINING - Epoch: [144][50/196]	Time 0.108 (0.147)	Data 0.000 (0.034)	Loss 0.1112 (0.0742)	Prec@1 95.703 (97.495)	Prec@5 100.000 (99.992)
2022-06-17 18:50:32 - INFO - TRAINING - Epoch: [144][60/196]	Time 0.107 (0.143)	Data 0.000 (0.029)	Loss 0.0849 (0.0754)	Prec@1 97.266 (97.503)	Prec@5 100.000 (99.987)
2022-06-17 18:50:33 - INFO - TRAINING - Epoch: [144][70/196]	Time 0.105 (0.139)	Data 0.000 (0.025)	Loss 0.1085 (0.0763)	Prec@1 96.094 (97.453)	Prec@5 100.000 (99.989)
2022-06-17 18:50:34 - INFO - TRAINING - Epoch: [144][80/196]	Time 0.118 (0.136)	Data 0.000 (0.022)	Loss 0.1070 (0.0760)	Prec@1 97.266 (97.468)	Prec@5 100.000 (99.990)
2022-06-17 18:50:35 - INFO - TRAINING - Epoch: [144][90/196]	Time 0.122 (0.134)	Data 0.000 (0.019)	Loss 0.0661 (0.0775)	Prec@1 98.047 (97.399)	Prec@5 100.000 (99.991)
2022-06-17 18:50:36 - INFO - TRAINING - Epoch: [144][100/196]	Time 0.113 (0.132)	Data 0.000 (0.017)	Loss 0.0812 (0.0773)	Prec@1 96.484 (97.436)	Prec@5 100.000 (99.992)
2022-06-17 18:50:37 - INFO - TRAINING - Epoch: [144][110/196]	Time 0.103 (0.131)	Data 0.000 (0.016)	Loss 0.0846 (0.0768)	Prec@1 96.875 (97.445)	Prec@5 100.000 (99.993)
2022-06-17 18:50:38 - INFO - TRAINING - Epoch: [144][120/196]	Time 0.126 (0.130)	Data 0.000 (0.015)	Loss 0.0449 (0.0765)	Prec@1 99.219 (97.450)	Prec@5 100.000 (99.990)
2022-06-17 18:50:40 - INFO - TRAINING - Epoch: [144][130/196]	Time 0.122 (0.128)	Data 0.000 (0.014)	Loss 0.0913 (0.0763)	Prec@1 97.266 (97.451)	Prec@5 100.000 (99.991)
2022-06-17 18:50:41 - INFO - TRAINING - Epoch: [144][140/196]	Time 0.123 (0.128)	Data 0.000 (0.013)	Loss 0.0657 (0.0761)	Prec@1 97.656 (97.448)	Prec@5 100.000 (99.992)
2022-06-17 18:50:42 - INFO - TRAINING - Epoch: [144][150/196]	Time 0.126 (0.127)	Data 0.000 (0.012)	Loss 0.0727 (0.0760)	Prec@1 97.656 (97.447)	Prec@5 100.000 (99.992)
2022-06-17 18:50:43 - INFO - TRAINING - Epoch: [144][160/196]	Time 0.120 (0.127)	Data 0.000 (0.011)	Loss 0.0576 (0.0758)	Prec@1 98.828 (97.467)	Prec@5 100.000 (99.993)
2022-06-17 18:50:44 - INFO - TRAINING - Epoch: [144][170/196]	Time 0.124 (0.126)	Data 0.000 (0.010)	Loss 0.0537 (0.0766)	Prec@1 98.438 (97.435)	Prec@5 100.000 (99.993)
2022-06-17 18:50:46 - INFO - TRAINING - Epoch: [144][180/196]	Time 0.114 (0.126)	Data 0.000 (0.010)	Loss 0.0777 (0.0764)	Prec@1 98.047 (97.460)	Prec@5 100.000 (99.994)
2022-06-17 18:50:47 - INFO - TRAINING - Epoch: [144][190/196]	Time 0.104 (0.125)	Data 0.000 (0.009)	Loss 0.0635 (0.0762)	Prec@1 98.828 (97.476)	Prec@5 100.000 (99.994)
2022-06-17 18:50:49 - INFO - EVALUATING - Epoch: [144][0/40]	Time 1.565 (1.565)	Data 1.519 (1.519)	Loss 0.2688 (0.2688)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:50:50 - INFO - EVALUATING - Epoch: [144][10/40]	Time 0.045 (0.235)	Data 0.000 (0.185)	Loss 0.4872 (0.4222)	Prec@1 88.281 (88.530)	Prec@5 99.219 (99.432)
2022-06-17 18:50:51 - INFO - EVALUATING - Epoch: [144][20/40]	Time 0.147 (0.176)	Data 0.105 (0.126)	Loss 0.3506 (0.4223)	Prec@1 88.281 (88.356)	Prec@5 99.609 (99.368)
2022-06-17 18:50:52 - INFO - EVALUATING - Epoch: [144][30/40]	Time 0.044 (0.150)	Data 0.000 (0.100)	Loss 0.5227 (0.4152)	Prec@1 86.328 (88.508)	Prec@5 100.000 (99.446)
2022-06-17 18:50:54 - INFO - 
 Epoch: 145	Training Loss 0.0762 	Training Prec@1 97.478 	Training Prec@5 99.994 	Validation Loss 0.4101 	Validation Prec@1 88.410 	Validation Prec@5 99.520 

2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:50:54 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:50:56 - INFO - TRAINING - Epoch: [145][0/196]	Time 1.530 (1.530)	Data 1.476 (1.476)	Loss 0.0778 (0.0778)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:50:57 - INFO - TRAINING - Epoch: [145][10/196]	Time 0.102 (0.251)	Data 0.000 (0.167)	Loss 0.0327 (0.0664)	Prec@1 99.609 (97.514)	Prec@5 100.000 (100.000)
2022-06-17 18:50:58 - INFO - TRAINING - Epoch: [145][20/196]	Time 0.102 (0.181)	Data 0.000 (0.088)	Loss 0.0428 (0.0699)	Prec@1 98.828 (97.470)	Prec@5 100.000 (100.000)
2022-06-17 18:50:59 - INFO - TRAINING - Epoch: [145][30/196]	Time 0.111 (0.157)	Data 0.000 (0.060)	Loss 0.1061 (0.0735)	Prec@1 96.875 (97.455)	Prec@5 100.000 (100.000)
2022-06-17 18:51:00 - INFO - TRAINING - Epoch: [145][40/196]	Time 0.106 (0.144)	Data 0.000 (0.045)	Loss 0.0722 (0.0746)	Prec@1 96.875 (97.456)	Prec@5 100.000 (100.000)
2022-06-17 18:51:01 - INFO - TRAINING - Epoch: [145][50/196]	Time 0.108 (0.137)	Data 0.000 (0.036)	Loss 0.1030 (0.0745)	Prec@1 96.875 (97.457)	Prec@5 100.000 (99.992)
2022-06-17 18:51:03 - INFO - TRAINING - Epoch: [145][60/196]	Time 0.120 (0.134)	Data 0.000 (0.030)	Loss 0.1147 (0.0761)	Prec@1 96.875 (97.381)	Prec@5 100.000 (99.994)
2022-06-17 18:51:04 - INFO - TRAINING - Epoch: [145][70/196]	Time 0.110 (0.131)	Data 0.000 (0.026)	Loss 0.0750 (0.0767)	Prec@1 97.266 (97.337)	Prec@5 100.000 (99.989)
2022-06-17 18:51:05 - INFO - TRAINING - Epoch: [145][80/196]	Time 0.122 (0.128)	Data 0.000 (0.023)	Loss 0.0724 (0.0770)	Prec@1 97.656 (97.357)	Prec@5 100.000 (99.990)
2022-06-17 18:51:06 - INFO - TRAINING - Epoch: [145][90/196]	Time 0.109 (0.126)	Data 0.000 (0.021)	Loss 0.0846 (0.0764)	Prec@1 96.875 (97.390)	Prec@5 100.000 (99.991)
2022-06-17 18:51:07 - INFO - TRAINING - Epoch: [145][100/196]	Time 0.105 (0.124)	Data 0.000 (0.019)	Loss 0.0753 (0.0760)	Prec@1 97.656 (97.389)	Prec@5 100.000 (99.992)
2022-06-17 18:51:08 - INFO - TRAINING - Epoch: [145][110/196]	Time 0.106 (0.123)	Data 0.000 (0.017)	Loss 0.0840 (0.0768)	Prec@1 96.875 (97.354)	Prec@5 100.000 (99.993)
2022-06-17 18:51:09 - INFO - TRAINING - Epoch: [145][120/196]	Time 0.123 (0.122)	Data 0.000 (0.016)	Loss 0.0709 (0.0761)	Prec@1 98.047 (97.375)	Prec@5 100.000 (99.994)
2022-06-17 18:51:10 - INFO - TRAINING - Epoch: [145][130/196]	Time 0.113 (0.121)	Data 0.000 (0.014)	Loss 0.0696 (0.0762)	Prec@1 98.047 (97.385)	Prec@5 100.000 (99.994)
2022-06-17 18:51:11 - INFO - TRAINING - Epoch: [145][140/196]	Time 0.106 (0.120)	Data 0.000 (0.013)	Loss 0.0709 (0.0761)	Prec@1 97.656 (97.385)	Prec@5 100.000 (99.994)
2022-06-17 18:51:12 - INFO - TRAINING - Epoch: [145][150/196]	Time 0.115 (0.120)	Data 0.000 (0.013)	Loss 0.0727 (0.0757)	Prec@1 97.656 (97.405)	Prec@5 100.000 (99.995)
2022-06-17 18:51:14 - INFO - TRAINING - Epoch: [145][160/196]	Time 0.123 (0.119)	Data 0.000 (0.012)	Loss 0.1965 (0.0768)	Prec@1 94.531 (97.377)	Prec@5 99.219 (99.990)
2022-06-17 18:51:15 - INFO - TRAINING - Epoch: [145][170/196]	Time 0.114 (0.119)	Data 0.000 (0.011)	Loss 0.1084 (0.0771)	Prec@1 96.875 (97.382)	Prec@5 99.219 (99.986)
2022-06-17 18:51:16 - INFO - TRAINING - Epoch: [145][180/196]	Time 0.107 (0.118)	Data 0.000 (0.011)	Loss 0.0639 (0.0769)	Prec@1 98.047 (97.397)	Prec@5 100.000 (99.987)
2022-06-17 18:51:17 - INFO - TRAINING - Epoch: [145][190/196]	Time 0.103 (0.118)	Data 0.000 (0.010)	Loss 0.0667 (0.0766)	Prec@1 97.266 (97.413)	Prec@5 100.000 (99.986)
2022-06-17 18:51:19 - INFO - EVALUATING - Epoch: [145][0/40]	Time 1.582 (1.582)	Data 1.536 (1.536)	Loss 0.2716 (0.2716)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:51:20 - INFO - EVALUATING - Epoch: [145][10/40]	Time 0.051 (0.262)	Data 0.000 (0.215)	Loss 0.4834 (0.4239)	Prec@1 87.891 (88.281)	Prec@5 99.219 (99.432)
2022-06-17 18:51:21 - INFO - EVALUATING - Epoch: [145][20/40]	Time 0.055 (0.171)	Data 0.001 (0.122)	Loss 0.3546 (0.4270)	Prec@1 87.500 (88.039)	Prec@5 100.000 (99.442)
2022-06-17 18:51:22 - INFO - EVALUATING - Epoch: [145][30/40]	Time 0.098 (0.147)	Data 0.054 (0.100)	Loss 0.5289 (0.4189)	Prec@1 85.938 (88.105)	Prec@5 100.000 (99.496)
2022-06-17 18:51:24 - INFO - 
 Epoch: 146	Training Loss 0.0764 	Training Prec@1 97.426 	Training Prec@5 99.986 	Validation Loss 0.4134 	Validation Prec@1 88.180 	Validation Prec@5 99.570 

2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:51:24 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:51:25 - INFO - TRAINING - Epoch: [146][0/196]	Time 1.252 (1.252)	Data 1.198 (1.198)	Loss 0.1053 (0.1053)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:51:27 - INFO - TRAINING - Epoch: [146][10/196]	Time 0.105 (0.264)	Data 0.050 (0.176)	Loss 0.0922 (0.0795)	Prec@1 97.266 (97.550)	Prec@5 100.000 (100.000)
2022-06-17 18:51:28 - INFO - TRAINING - Epoch: [146][20/196]	Time 0.101 (0.193)	Data 0.000 (0.092)	Loss 0.0878 (0.0815)	Prec@1 96.094 (97.452)	Prec@5 100.000 (100.000)
2022-06-17 18:51:29 - INFO - TRAINING - Epoch: [146][30/196]	Time 0.113 (0.166)	Data 0.000 (0.062)	Loss 0.0420 (0.0813)	Prec@1 98.828 (97.404)	Prec@5 100.000 (100.000)
2022-06-17 18:51:30 - INFO - TRAINING - Epoch: [146][40/196]	Time 0.109 (0.153)	Data 0.000 (0.047)	Loss 0.0752 (0.0817)	Prec@1 97.266 (97.351)	Prec@5 100.000 (99.981)
2022-06-17 18:51:32 - INFO - TRAINING - Epoch: [146][50/196]	Time 0.114 (0.145)	Data 0.000 (0.038)	Loss 0.0986 (0.0822)	Prec@1 95.703 (97.227)	Prec@5 100.000 (99.977)
2022-06-17 18:51:33 - INFO - TRAINING - Epoch: [146][60/196]	Time 0.117 (0.139)	Data 0.000 (0.032)	Loss 0.0695 (0.0814)	Prec@1 97.656 (97.221)	Prec@5 100.000 (99.981)
2022-06-17 18:51:34 - INFO - TRAINING - Epoch: [146][70/196]	Time 0.120 (0.135)	Data 0.000 (0.027)	Loss 0.0927 (0.0809)	Prec@1 96.094 (97.238)	Prec@5 100.000 (99.983)
2022-06-17 18:51:35 - INFO - TRAINING - Epoch: [146][80/196]	Time 0.123 (0.133)	Data 0.000 (0.024)	Loss 0.0610 (0.0810)	Prec@1 96.875 (97.208)	Prec@5 100.000 (99.986)
2022-06-17 18:51:36 - INFO - TRAINING - Epoch: [146][90/196]	Time 0.121 (0.131)	Data 0.000 (0.021)	Loss 0.1086 (0.0801)	Prec@1 96.484 (97.248)	Prec@5 100.000 (99.983)
2022-06-17 18:51:37 - INFO - TRAINING - Epoch: [146][100/196]	Time 0.116 (0.129)	Data 0.000 (0.019)	Loss 0.1015 (0.0796)	Prec@1 97.266 (97.266)	Prec@5 100.000 (99.985)
2022-06-17 18:51:38 - INFO - TRAINING - Epoch: [146][110/196]	Time 0.108 (0.127)	Data 0.000 (0.018)	Loss 0.0867 (0.0799)	Prec@1 97.266 (97.273)	Prec@5 100.000 (99.986)
2022-06-17 18:51:39 - INFO - TRAINING - Epoch: [146][120/196]	Time 0.125 (0.126)	Data 0.000 (0.016)	Loss 0.0588 (0.0796)	Prec@1 98.047 (97.269)	Prec@5 100.000 (99.987)
2022-06-17 18:51:40 - INFO - TRAINING - Epoch: [146][130/196]	Time 0.110 (0.125)	Data 0.000 (0.015)	Loss 0.0693 (0.0786)	Prec@1 97.266 (97.319)	Prec@5 100.000 (99.988)
2022-06-17 18:51:42 - INFO - TRAINING - Epoch: [146][140/196]	Time 0.104 (0.124)	Data 0.000 (0.014)	Loss 0.0903 (0.0793)	Prec@1 94.531 (97.274)	Prec@5 100.000 (99.989)
2022-06-17 18:51:43 - INFO - TRAINING - Epoch: [146][150/196]	Time 0.104 (0.123)	Data 0.000 (0.013)	Loss 0.1007 (0.0796)	Prec@1 96.484 (97.263)	Prec@5 100.000 (99.990)
2022-06-17 18:51:44 - INFO - TRAINING - Epoch: [146][160/196]	Time 0.130 (0.123)	Data 0.000 (0.012)	Loss 0.0913 (0.0793)	Prec@1 96.094 (97.270)	Prec@5 100.000 (99.988)
2022-06-17 18:51:45 - INFO - TRAINING - Epoch: [146][170/196]	Time 0.127 (0.122)	Data 0.000 (0.012)	Loss 0.0990 (0.0789)	Prec@1 96.094 (97.288)	Prec@5 100.000 (99.989)
2022-06-17 18:51:46 - INFO - TRAINING - Epoch: [146][180/196]	Time 0.108 (0.122)	Data 0.000 (0.011)	Loss 0.0874 (0.0788)	Prec@1 96.875 (97.281)	Prec@5 100.000 (99.989)
2022-06-17 18:51:47 - INFO - TRAINING - Epoch: [146][190/196]	Time 0.101 (0.121)	Data 0.000 (0.010)	Loss 0.0760 (0.0788)	Prec@1 98.047 (97.284)	Prec@5 100.000 (99.990)
2022-06-17 18:51:50 - INFO - EVALUATING - Epoch: [146][0/40]	Time 1.785 (1.785)	Data 1.739 (1.739)	Loss 0.2738 (0.2738)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:51:50 - INFO - EVALUATING - Epoch: [146][10/40]	Time 0.045 (0.237)	Data 0.001 (0.187)	Loss 0.4770 (0.4239)	Prec@1 89.062 (88.459)	Prec@5 99.219 (99.503)
2022-06-17 18:51:51 - INFO - EVALUATING - Epoch: [146][20/40]	Time 0.102 (0.153)	Data 0.059 (0.104)	Loss 0.3447 (0.4245)	Prec@1 87.109 (88.114)	Prec@5 99.609 (99.405)
2022-06-17 18:51:52 - INFO - EVALUATING - Epoch: [146][30/40]	Time 0.048 (0.144)	Data 0.000 (0.097)	Loss 0.5279 (0.4171)	Prec@1 86.328 (88.256)	Prec@5 100.000 (99.483)
2022-06-17 18:51:54 - INFO - 
 Epoch: 147	Training Loss 0.0787 	Training Prec@1 97.282 	Training Prec@5 99.990 	Validation Loss 0.4120 	Validation Prec@1 88.260 	Validation Prec@5 99.540 

2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:51:54 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:51:56 - INFO - TRAINING - Epoch: [147][0/196]	Time 1.579 (1.579)	Data 1.525 (1.525)	Loss 0.1104 (0.1104)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2022-06-17 18:51:57 - INFO - TRAINING - Epoch: [147][10/196]	Time 0.102 (0.256)	Data 0.000 (0.162)	Loss 0.0582 (0.0777)	Prec@1 97.266 (97.053)	Prec@5 100.000 (99.964)
2022-06-17 18:51:58 - INFO - TRAINING - Epoch: [147][20/196]	Time 0.114 (0.185)	Data 0.000 (0.085)	Loss 0.0737 (0.0775)	Prec@1 96.875 (97.117)	Prec@5 100.000 (99.981)
2022-06-17 18:51:59 - INFO - TRAINING - Epoch: [147][30/196]	Time 0.105 (0.161)	Data 0.000 (0.058)	Loss 0.1685 (0.0801)	Prec@1 95.312 (97.127)	Prec@5 99.609 (99.975)
2022-06-17 18:52:00 - INFO - TRAINING - Epoch: [147][40/196]	Time 0.104 (0.150)	Data 0.000 (0.044)	Loss 0.0386 (0.0819)	Prec@1 98.438 (97.123)	Prec@5 100.000 (99.971)
2022-06-17 18:52:01 - INFO - TRAINING - Epoch: [147][50/196]	Time 0.108 (0.142)	Data 0.000 (0.035)	Loss 0.0691 (0.0802)	Prec@1 98.047 (97.258)	Prec@5 100.000 (99.977)
2022-06-17 18:52:02 - INFO - TRAINING - Epoch: [147][60/196]	Time 0.108 (0.137)	Data 0.000 (0.029)	Loss 0.0745 (0.0798)	Prec@1 98.047 (97.310)	Prec@5 100.000 (99.981)
2022-06-17 18:52:04 - INFO - TRAINING - Epoch: [147][70/196]	Time 0.108 (0.133)	Data 0.000 (0.025)	Loss 0.0845 (0.0785)	Prec@1 96.875 (97.332)	Prec@5 100.000 (99.983)
2022-06-17 18:52:05 - INFO - TRAINING - Epoch: [147][80/196]	Time 0.128 (0.131)	Data 0.000 (0.022)	Loss 0.0928 (0.0799)	Prec@1 98.047 (97.280)	Prec@5 100.000 (99.986)
2022-06-17 18:52:06 - INFO - TRAINING - Epoch: [147][90/196]	Time 0.120 (0.129)	Data 0.000 (0.020)	Loss 0.0798 (0.0792)	Prec@1 98.047 (97.343)	Prec@5 100.000 (99.983)
2022-06-17 18:52:07 - INFO - TRAINING - Epoch: [147][100/196]	Time 0.142 (0.127)	Data 0.000 (0.018)	Loss 0.0721 (0.0797)	Prec@1 97.656 (97.304)	Prec@5 100.000 (99.985)
2022-06-17 18:52:08 - INFO - TRAINING - Epoch: [147][110/196]	Time 0.120 (0.126)	Data 0.000 (0.016)	Loss 0.0674 (0.0782)	Prec@1 97.656 (97.382)	Prec@5 100.000 (99.986)
2022-06-17 18:52:09 - INFO - TRAINING - Epoch: [147][120/196]	Time 0.107 (0.124)	Data 0.000 (0.015)	Loss 0.0719 (0.0781)	Prec@1 97.266 (97.346)	Prec@5 100.000 (99.987)
2022-06-17 18:52:10 - INFO - TRAINING - Epoch: [147][130/196]	Time 0.112 (0.123)	Data 0.000 (0.014)	Loss 0.1034 (0.0793)	Prec@1 95.703 (97.281)	Prec@5 100.000 (99.988)
2022-06-17 18:52:11 - INFO - TRAINING - Epoch: [147][140/196]	Time 0.111 (0.122)	Data 0.000 (0.013)	Loss 0.0669 (0.0797)	Prec@1 97.266 (97.249)	Prec@5 100.000 (99.989)
2022-06-17 18:52:13 - INFO - TRAINING - Epoch: [147][150/196]	Time 0.109 (0.122)	Data 0.000 (0.012)	Loss 0.0784 (0.0788)	Prec@1 97.266 (97.302)	Prec@5 100.000 (99.990)
2022-06-17 18:52:14 - INFO - TRAINING - Epoch: [147][160/196]	Time 0.110 (0.122)	Data 0.000 (0.011)	Loss 0.0816 (0.0790)	Prec@1 96.484 (97.278)	Prec@5 100.000 (99.988)
2022-06-17 18:52:15 - INFO - TRAINING - Epoch: [147][170/196]	Time 0.109 (0.121)	Data 0.000 (0.011)	Loss 0.0776 (0.0790)	Prec@1 97.656 (97.282)	Prec@5 100.000 (99.989)
2022-06-17 18:52:16 - INFO - TRAINING - Epoch: [147][180/196]	Time 0.109 (0.120)	Data 0.000 (0.010)	Loss 0.0560 (0.0791)	Prec@1 98.047 (97.283)	Prec@5 100.000 (99.987)
2022-06-17 18:52:17 - INFO - TRAINING - Epoch: [147][190/196]	Time 0.102 (0.120)	Data 0.000 (0.010)	Loss 0.0671 (0.0790)	Prec@1 97.266 (97.284)	Prec@5 100.000 (99.988)
2022-06-17 18:52:19 - INFO - EVALUATING - Epoch: [147][0/40]	Time 1.824 (1.824)	Data 1.779 (1.779)	Loss 0.2746 (0.2746)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
2022-06-17 18:52:20 - INFO - EVALUATING - Epoch: [147][10/40]	Time 0.073 (0.263)	Data 0.000 (0.209)	Loss 0.4798 (0.4223)	Prec@1 87.891 (88.175)	Prec@5 99.219 (99.432)
2022-06-17 18:52:21 - INFO - EVALUATING - Epoch: [147][20/40]	Time 0.041 (0.169)	Data 0.000 (0.118)	Loss 0.3470 (0.4239)	Prec@1 87.891 (88.021)	Prec@5 100.000 (99.386)
2022-06-17 18:52:22 - INFO - EVALUATING - Epoch: [147][30/40]	Time 0.051 (0.152)	Data 0.000 (0.103)	Loss 0.5242 (0.4163)	Prec@1 85.547 (88.180)	Prec@5 100.000 (99.471)
2022-06-17 18:52:24 - INFO - 
 Epoch: 148	Training Loss 0.0790 	Training Prec@1 97.288 	Training Prec@5 99.988 	Validation Loss 0.4107 	Validation Prec@1 88.250 	Validation Prec@5 99.540 

2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:52:24 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:52:25 - INFO - TRAINING - Epoch: [148][0/196]	Time 1.337 (1.337)	Data 1.281 (1.281)	Loss 0.0837 (0.0837)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:52:27 - INFO - TRAINING - Epoch: [148][10/196]	Time 0.137 (0.262)	Data 0.000 (0.166)	Loss 0.0537 (0.0831)	Prec@1 98.047 (97.550)	Prec@5 100.000 (100.000)
2022-06-17 18:52:28 - INFO - TRAINING - Epoch: [148][20/196]	Time 0.108 (0.189)	Data 0.000 (0.087)	Loss 0.0654 (0.0766)	Prec@1 97.266 (97.600)	Prec@5 100.000 (100.000)
2022-06-17 18:52:29 - INFO - TRAINING - Epoch: [148][30/196]	Time 0.106 (0.163)	Data 0.000 (0.059)	Loss 0.0648 (0.0748)	Prec@1 98.047 (97.568)	Prec@5 100.000 (100.000)
2022-06-17 18:52:30 - INFO - TRAINING - Epoch: [148][40/196]	Time 0.106 (0.150)	Data 0.000 (0.045)	Loss 0.1084 (0.0762)	Prec@1 95.703 (97.513)	Prec@5 100.000 (100.000)
2022-06-17 18:52:31 - INFO - TRAINING - Epoch: [148][50/196]	Time 0.106 (0.142)	Data 0.000 (0.036)	Loss 0.0733 (0.0778)	Prec@1 97.266 (97.396)	Prec@5 100.000 (100.000)
2022-06-17 18:52:32 - INFO - TRAINING - Epoch: [148][60/196]	Time 0.113 (0.137)	Data 0.000 (0.030)	Loss 0.0947 (0.0774)	Prec@1 96.094 (97.407)	Prec@5 100.000 (99.994)
2022-06-17 18:52:34 - INFO - TRAINING - Epoch: [148][70/196]	Time 0.112 (0.133)	Data 0.000 (0.026)	Loss 0.0618 (0.0766)	Prec@1 98.047 (97.425)	Prec@5 100.000 (99.994)
2022-06-17 18:52:35 - INFO - TRAINING - Epoch: [148][80/196]	Time 0.128 (0.131)	Data 0.000 (0.023)	Loss 0.0734 (0.0771)	Prec@1 97.266 (97.415)	Prec@5 100.000 (99.995)
2022-06-17 18:52:36 - INFO - TRAINING - Epoch: [148][90/196]	Time 0.117 (0.129)	Data 0.000 (0.020)	Loss 0.0667 (0.0762)	Prec@1 98.438 (97.467)	Prec@5 100.000 (99.996)
2022-06-17 18:52:37 - INFO - TRAINING - Epoch: [148][100/196]	Time 0.120 (0.127)	Data 0.000 (0.018)	Loss 0.0556 (0.0756)	Prec@1 98.047 (97.463)	Prec@5 100.000 (99.996)
2022-06-17 18:52:38 - INFO - TRAINING - Epoch: [148][110/196]	Time 0.111 (0.126)	Data 0.000 (0.017)	Loss 0.0626 (0.0757)	Prec@1 97.656 (97.456)	Prec@5 100.000 (99.996)
2022-06-17 18:52:39 - INFO - TRAINING - Epoch: [148][120/196]	Time 0.101 (0.125)	Data 0.000 (0.015)	Loss 0.1026 (0.0763)	Prec@1 96.484 (97.417)	Prec@5 100.000 (99.997)
2022-06-17 18:52:40 - INFO - TRAINING - Epoch: [148][130/196]	Time 0.118 (0.124)	Data 0.000 (0.014)	Loss 0.0514 (0.0761)	Prec@1 98.828 (97.427)	Prec@5 100.000 (99.997)
2022-06-17 18:52:41 - INFO - TRAINING - Epoch: [148][140/196]	Time 0.118 (0.123)	Data 0.000 (0.013)	Loss 0.0739 (0.0769)	Prec@1 97.266 (97.374)	Prec@5 100.000 (99.992)
2022-06-17 18:52:42 - INFO - TRAINING - Epoch: [148][150/196]	Time 0.103 (0.122)	Data 0.000 (0.012)	Loss 0.1418 (0.0778)	Prec@1 95.312 (97.372)	Prec@5 100.000 (99.992)
2022-06-17 18:52:44 - INFO - TRAINING - Epoch: [148][160/196]	Time 0.102 (0.121)	Data 0.000 (0.012)	Loss 0.1010 (0.0778)	Prec@1 96.484 (97.382)	Prec@5 100.000 (99.990)
2022-06-17 18:52:45 - INFO - TRAINING - Epoch: [148][170/196]	Time 0.102 (0.120)	Data 0.000 (0.011)	Loss 0.0736 (0.0783)	Prec@1 98.438 (97.366)	Prec@5 100.000 (99.991)
2022-06-17 18:52:46 - INFO - TRAINING - Epoch: [148][180/196]	Time 0.125 (0.120)	Data 0.000 (0.010)	Loss 0.0937 (0.0784)	Prec@1 96.094 (97.363)	Prec@5 100.000 (99.991)
2022-06-17 18:52:47 - INFO - TRAINING - Epoch: [148][190/196]	Time 0.101 (0.119)	Data 0.000 (0.010)	Loss 0.0673 (0.0784)	Prec@1 97.266 (97.372)	Prec@5 100.000 (99.990)
2022-06-17 18:52:49 - INFO - EVALUATING - Epoch: [148][0/40]	Time 2.031 (2.031)	Data 1.985 (1.985)	Loss 0.2802 (0.2802)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:52:50 - INFO - EVALUATING - Epoch: [148][10/40]	Time 0.045 (0.243)	Data 0.000 (0.190)	Loss 0.4790 (0.4283)	Prec@1 88.281 (87.926)	Prec@5 99.219 (99.467)
2022-06-17 18:52:51 - INFO - EVALUATING - Epoch: [148][20/40]	Time 0.122 (0.164)	Data 0.081 (0.114)	Loss 0.3491 (0.4287)	Prec@1 87.500 (87.853)	Prec@5 99.609 (99.405)
2022-06-17 18:52:52 - INFO - EVALUATING - Epoch: [148][30/40]	Time 0.356 (0.153)	Data 0.316 (0.105)	Loss 0.5264 (0.4203)	Prec@1 85.547 (88.017)	Prec@5 100.000 (99.471)
2022-06-17 18:52:54 - INFO - 
 Epoch: 149	Training Loss 0.0784 	Training Prec@1 97.372 	Training Prec@5 99.990 	Validation Loss 0.4141 	Validation Prec@1 88.070 	Validation Prec@5 99.540 

2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:52:54 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:52:56 - INFO - TRAINING - Epoch: [149][0/196]	Time 1.837 (1.837)	Data 1.784 (1.784)	Loss 0.0939 (0.0939)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:52:57 - INFO - TRAINING - Epoch: [149][10/196]	Time 0.102 (0.268)	Data 0.000 (0.167)	Loss 0.0423 (0.0888)	Prec@1 99.609 (96.946)	Prec@5 100.000 (100.000)
2022-06-17 18:52:58 - INFO - TRAINING - Epoch: [149][20/196]	Time 0.119 (0.192)	Data 0.000 (0.088)	Loss 0.0969 (0.0842)	Prec@1 96.875 (97.135)	Prec@5 100.000 (100.000)
2022-06-17 18:52:59 - INFO - TRAINING - Epoch: [149][30/196]	Time 0.102 (0.165)	Data 0.000 (0.059)	Loss 0.1172 (0.0834)	Prec@1 95.312 (97.114)	Prec@5 100.000 (99.987)
2022-06-17 18:53:00 - INFO - TRAINING - Epoch: [149][40/196]	Time 0.108 (0.152)	Data 0.000 (0.045)	Loss 0.1276 (0.0829)	Prec@1 96.484 (97.189)	Prec@5 100.000 (99.990)
2022-06-17 18:53:01 - INFO - TRAINING - Epoch: [149][50/196]	Time 0.122 (0.144)	Data 0.000 (0.036)	Loss 0.0938 (0.0847)	Prec@1 97.266 (97.066)	Prec@5 100.000 (99.985)
2022-06-17 18:53:02 - INFO - TRAINING - Epoch: [149][60/196]	Time 0.115 (0.139)	Data 0.000 (0.030)	Loss 0.0246 (0.0840)	Prec@1 99.609 (97.106)	Prec@5 100.000 (99.987)
2022-06-17 18:53:03 - INFO - TRAINING - Epoch: [149][70/196]	Time 0.105 (0.135)	Data 0.000 (0.026)	Loss 0.0925 (0.0829)	Prec@1 96.875 (97.101)	Prec@5 100.000 (99.989)
2022-06-17 18:53:05 - INFO - TRAINING - Epoch: [149][80/196]	Time 0.107 (0.132)	Data 0.000 (0.023)	Loss 0.0654 (0.0819)	Prec@1 98.047 (97.160)	Prec@5 100.000 (99.990)
2022-06-17 18:53:06 - INFO - TRAINING - Epoch: [149][90/196]	Time 0.110 (0.130)	Data 0.000 (0.020)	Loss 0.0768 (0.0817)	Prec@1 96.875 (97.154)	Prec@5 100.000 (99.991)
2022-06-17 18:53:07 - INFO - TRAINING - Epoch: [149][100/196]	Time 0.137 (0.129)	Data 0.000 (0.018)	Loss 0.1075 (0.0814)	Prec@1 95.312 (97.161)	Prec@5 100.000 (99.988)
2022-06-17 18:53:08 - INFO - TRAINING - Epoch: [149][110/196]	Time 0.127 (0.127)	Data 0.000 (0.017)	Loss 0.1035 (0.0805)	Prec@1 96.484 (97.209)	Prec@5 99.609 (99.986)
2022-06-17 18:53:09 - INFO - TRAINING - Epoch: [149][120/196]	Time 0.110 (0.127)	Data 0.000 (0.015)	Loss 0.0768 (0.0799)	Prec@1 98.047 (97.246)	Prec@5 100.000 (99.987)
2022-06-17 18:53:10 - INFO - TRAINING - Epoch: [149][130/196]	Time 0.123 (0.126)	Data 0.000 (0.014)	Loss 0.0738 (0.0797)	Prec@1 96.875 (97.272)	Prec@5 100.000 (99.988)
2022-06-17 18:53:11 - INFO - TRAINING - Epoch: [149][140/196]	Time 0.115 (0.125)	Data 0.000 (0.013)	Loss 0.0533 (0.0787)	Prec@1 99.219 (97.313)	Prec@5 100.000 (99.989)
2022-06-17 18:53:13 - INFO - TRAINING - Epoch: [149][150/196]	Time 0.109 (0.124)	Data 0.000 (0.012)	Loss 0.0700 (0.0784)	Prec@1 97.266 (97.348)	Prec@5 100.000 (99.987)
2022-06-17 18:53:14 - INFO - TRAINING - Epoch: [149][160/196]	Time 0.125 (0.123)	Data 0.000 (0.012)	Loss 0.0419 (0.0780)	Prec@1 99.609 (97.358)	Prec@5 100.000 (99.988)
2022-06-17 18:53:15 - INFO - TRAINING - Epoch: [149][170/196]	Time 0.106 (0.122)	Data 0.000 (0.011)	Loss 0.0481 (0.0779)	Prec@1 99.219 (97.389)	Prec@5 100.000 (99.986)
2022-06-17 18:53:16 - INFO - TRAINING - Epoch: [149][180/196]	Time 0.109 (0.121)	Data 0.000 (0.010)	Loss 0.0961 (0.0778)	Prec@1 97.656 (97.408)	Prec@5 100.000 (99.987)
2022-06-17 18:53:17 - INFO - TRAINING - Epoch: [149][190/196]	Time 0.111 (0.121)	Data 0.000 (0.010)	Loss 0.1035 (0.0773)	Prec@1 97.656 (97.435)	Prec@5 100.000 (99.988)
2022-06-17 18:53:19 - INFO - EVALUATING - Epoch: [149][0/40]	Time 1.583 (1.583)	Data 1.537 (1.537)	Loss 0.2788 (0.2788)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:53:20 - INFO - EVALUATING - Epoch: [149][10/40]	Time 0.249 (0.253)	Data 0.208 (0.202)	Loss 0.4736 (0.4290)	Prec@1 87.109 (87.820)	Prec@5 99.219 (99.432)
2022-06-17 18:53:21 - INFO - EVALUATING - Epoch: [149][20/40]	Time 0.126 (0.162)	Data 0.084 (0.112)	Loss 0.3478 (0.4300)	Prec@1 87.891 (87.779)	Prec@5 100.000 (99.405)
2022-06-17 18:53:22 - INFO - EVALUATING - Epoch: [149][30/40]	Time 0.135 (0.149)	Data 0.091 (0.101)	Loss 0.5193 (0.4203)	Prec@1 86.328 (87.979)	Prec@5 100.000 (99.471)
2022-06-17 18:53:24 - INFO - 
 Epoch: 150	Training Loss 0.0770 	Training Prec@1 97.450 	Training Prec@5 99.988 	Validation Loss 0.4143 	Validation Prec@1 88.050 	Validation Prec@5 99.550 

2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:53:24 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:53:26 - INFO - TRAINING - Epoch: [150][0/196]	Time 1.430 (1.430)	Data 1.376 (1.376)	Loss 0.0550 (0.0550)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 18:53:27 - INFO - TRAINING - Epoch: [150][10/196]	Time 0.205 (0.262)	Data 0.156 (0.171)	Loss 0.0518 (0.0844)	Prec@1 98.828 (96.911)	Prec@5 100.000 (100.000)
2022-06-17 18:53:28 - INFO - TRAINING - Epoch: [150][20/196]	Time 0.101 (0.189)	Data 0.000 (0.090)	Loss 0.0649 (0.0745)	Prec@1 98.047 (97.452)	Prec@5 100.000 (100.000)
2022-06-17 18:53:29 - INFO - TRAINING - Epoch: [150][30/196]	Time 0.116 (0.166)	Data 0.000 (0.061)	Loss 0.0975 (0.0736)	Prec@1 96.484 (97.455)	Prec@5 100.000 (100.000)
2022-06-17 18:53:31 - INFO - TRAINING - Epoch: [150][40/196]	Time 0.118 (0.154)	Data 0.000 (0.046)	Loss 0.0593 (0.0758)	Prec@1 97.266 (97.370)	Prec@5 100.000 (100.000)
2022-06-17 18:53:32 - INFO - TRAINING - Epoch: [150][50/196]	Time 0.130 (0.147)	Data 0.000 (0.037)	Loss 0.1015 (0.0767)	Prec@1 97.266 (97.350)	Prec@5 100.000 (100.000)
2022-06-17 18:53:33 - INFO - TRAINING - Epoch: [150][60/196]	Time 0.106 (0.142)	Data 0.000 (0.031)	Loss 0.0893 (0.0755)	Prec@1 96.484 (97.419)	Prec@5 100.000 (100.000)
2022-06-17 18:53:34 - INFO - TRAINING - Epoch: [150][70/196]	Time 0.115 (0.139)	Data 0.000 (0.027)	Loss 0.0861 (0.0766)	Prec@1 96.875 (97.376)	Prec@5 100.000 (100.000)
2022-06-17 18:53:35 - INFO - TRAINING - Epoch: [150][80/196]	Time 0.115 (0.137)	Data 0.000 (0.023)	Loss 0.0557 (0.0752)	Prec@1 98.828 (97.410)	Prec@5 100.000 (100.000)
2022-06-17 18:53:37 - INFO - TRAINING - Epoch: [150][90/196]	Time 0.111 (0.135)	Data 0.000 (0.021)	Loss 0.0925 (0.0749)	Prec@1 96.094 (97.429)	Prec@5 100.000 (100.000)
2022-06-17 18:53:38 - INFO - TRAINING - Epoch: [150][100/196]	Time 0.115 (0.134)	Data 0.000 (0.019)	Loss 0.0734 (0.0740)	Prec@1 97.266 (97.471)	Prec@5 100.000 (99.996)
2022-06-17 18:53:39 - INFO - TRAINING - Epoch: [150][110/196]	Time 0.131 (0.132)	Data 0.000 (0.017)	Loss 0.0844 (0.0743)	Prec@1 97.266 (97.435)	Prec@5 100.000 (99.996)
2022-06-17 18:53:40 - INFO - TRAINING - Epoch: [150][120/196]	Time 0.126 (0.131)	Data 0.000 (0.016)	Loss 0.0583 (0.0746)	Prec@1 98.828 (97.404)	Prec@5 100.000 (99.997)
2022-06-17 18:53:41 - INFO - TRAINING - Epoch: [150][130/196]	Time 0.112 (0.130)	Data 0.000 (0.015)	Loss 0.1068 (0.0745)	Prec@1 96.875 (97.436)	Prec@5 100.000 (99.997)
2022-06-17 18:53:43 - INFO - TRAINING - Epoch: [150][140/196]	Time 0.109 (0.130)	Data 0.000 (0.014)	Loss 0.0543 (0.0741)	Prec@1 98.438 (97.437)	Prec@5 100.000 (99.997)
2022-06-17 18:53:44 - INFO - TRAINING - Epoch: [150][150/196]	Time 0.132 (0.129)	Data 0.000 (0.013)	Loss 0.0700 (0.0745)	Prec@1 97.656 (97.421)	Prec@5 100.000 (99.997)
2022-06-17 18:53:45 - INFO - TRAINING - Epoch: [150][160/196]	Time 0.127 (0.129)	Data 0.000 (0.012)	Loss 0.0858 (0.0750)	Prec@1 96.484 (97.423)	Prec@5 100.000 (99.995)
2022-06-17 18:53:46 - INFO - TRAINING - Epoch: [150][170/196]	Time 0.116 (0.128)	Data 0.000 (0.011)	Loss 0.1043 (0.0749)	Prec@1 96.094 (97.437)	Prec@5 100.000 (99.995)
2022-06-17 18:53:47 - INFO - TRAINING - Epoch: [150][180/196]	Time 0.133 (0.128)	Data 0.000 (0.011)	Loss 0.1037 (0.0748)	Prec@1 96.484 (97.432)	Prec@5 100.000 (99.996)
2022-06-17 18:53:49 - INFO - TRAINING - Epoch: [150][190/196]	Time 0.102 (0.127)	Data 0.000 (0.010)	Loss 0.1249 (0.0749)	Prec@1 95.312 (97.427)	Prec@5 100.000 (99.996)
2022-06-17 18:53:51 - INFO - EVALUATING - Epoch: [150][0/40]	Time 1.978 (1.978)	Data 1.933 (1.933)	Loss 0.2707 (0.2707)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:53:52 - INFO - EVALUATING - Epoch: [150][10/40]	Time 0.055 (0.272)	Data 0.000 (0.223)	Loss 0.4774 (0.4217)	Prec@1 87.891 (88.459)	Prec@5 99.219 (99.396)
2022-06-17 18:53:53 - INFO - EVALUATING - Epoch: [150][20/40]	Time 0.076 (0.172)	Data 0.036 (0.125)	Loss 0.3483 (0.4248)	Prec@1 87.891 (88.170)	Prec@5 99.609 (99.368)
2022-06-17 18:53:54 - INFO - EVALUATING - Epoch: [150][30/40]	Time 0.185 (0.154)	Data 0.144 (0.108)	Loss 0.5133 (0.4179)	Prec@1 86.328 (88.294)	Prec@5 100.000 (99.433)
2022-06-17 18:53:56 - INFO - 
 Epoch: 151	Training Loss 0.0751 	Training Prec@1 97.418 	Training Prec@5 99.996 	Validation Loss 0.4127 	Validation Prec@1 88.260 	Validation Prec@5 99.510 

2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:53:56 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:53:58 - INFO - TRAINING - Epoch: [151][0/196]	Time 2.063 (2.063)	Data 2.011 (2.011)	Loss 0.0868 (0.0868)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
2022-06-17 18:53:59 - INFO - TRAINING - Epoch: [151][10/196]	Time 0.106 (0.291)	Data 0.000 (0.183)	Loss 0.0895 (0.0753)	Prec@1 97.266 (97.585)	Prec@5 100.000 (100.000)
2022-06-17 18:54:00 - INFO - TRAINING - Epoch: [151][20/196]	Time 0.124 (0.207)	Data 0.000 (0.096)	Loss 0.0709 (0.0726)	Prec@1 98.047 (97.619)	Prec@5 100.000 (100.000)
2022-06-17 18:54:01 - INFO - TRAINING - Epoch: [151][30/196]	Time 0.121 (0.177)	Data 0.000 (0.065)	Loss 0.0669 (0.0694)	Prec@1 97.266 (97.732)	Prec@5 100.000 (100.000)
2022-06-17 18:54:02 - INFO - TRAINING - Epoch: [151][40/196]	Time 0.108 (0.161)	Data 0.000 (0.049)	Loss 0.1026 (0.0735)	Prec@1 97.266 (97.675)	Prec@5 100.000 (99.981)
2022-06-17 18:54:03 - INFO - TRAINING - Epoch: [151][50/196]	Time 0.119 (0.152)	Data 0.000 (0.040)	Loss 0.0837 (0.0739)	Prec@1 96.875 (97.610)	Prec@5 100.000 (99.977)
2022-06-17 18:54:05 - INFO - TRAINING - Epoch: [151][60/196]	Time 0.135 (0.145)	Data 0.000 (0.033)	Loss 0.0799 (0.0729)	Prec@1 97.266 (97.631)	Prec@5 100.000 (99.981)
2022-06-17 18:54:06 - INFO - TRAINING - Epoch: [151][70/196]	Time 0.107 (0.141)	Data 0.000 (0.029)	Loss 0.0845 (0.0730)	Prec@1 97.656 (97.623)	Prec@5 100.000 (99.983)
2022-06-17 18:54:07 - INFO - TRAINING - Epoch: [151][80/196]	Time 0.111 (0.137)	Data 0.000 (0.025)	Loss 0.0729 (0.0742)	Prec@1 98.047 (97.526)	Prec@5 100.000 (99.981)
2022-06-17 18:54:08 - INFO - TRAINING - Epoch: [151][90/196]	Time 0.132 (0.135)	Data 0.000 (0.022)	Loss 0.0917 (0.0741)	Prec@1 97.266 (97.519)	Prec@5 100.000 (99.983)
2022-06-17 18:54:09 - INFO - TRAINING - Epoch: [151][100/196]	Time 0.108 (0.132)	Data 0.000 (0.020)	Loss 0.0478 (0.0731)	Prec@1 98.828 (97.571)	Prec@5 100.000 (99.985)
2022-06-17 18:54:10 - INFO - TRAINING - Epoch: [151][110/196]	Time 0.107 (0.130)	Data 0.000 (0.018)	Loss 0.0935 (0.0738)	Prec@1 96.484 (97.551)	Prec@5 100.000 (99.986)
2022-06-17 18:54:11 - INFO - TRAINING - Epoch: [151][120/196]	Time 0.102 (0.128)	Data 0.000 (0.017)	Loss 0.0805 (0.0747)	Prec@1 96.484 (97.511)	Prec@5 100.000 (99.984)
2022-06-17 18:54:12 - INFO - TRAINING - Epoch: [151][130/196]	Time 0.104 (0.127)	Data 0.000 (0.016)	Loss 0.0372 (0.0742)	Prec@1 98.828 (97.546)	Prec@5 100.000 (99.985)
2022-06-17 18:54:13 - INFO - TRAINING - Epoch: [151][140/196]	Time 0.122 (0.126)	Data 0.000 (0.015)	Loss 0.0858 (0.0740)	Prec@1 96.875 (97.568)	Prec@5 100.000 (99.986)
2022-06-17 18:54:14 - INFO - TRAINING - Epoch: [151][150/196]	Time 0.113 (0.124)	Data 0.000 (0.014)	Loss 0.1018 (0.0744)	Prec@1 96.094 (97.548)	Prec@5 100.000 (99.987)
2022-06-17 18:54:16 - INFO - TRAINING - Epoch: [151][160/196]	Time 0.103 (0.123)	Data 0.000 (0.013)	Loss 0.0374 (0.0746)	Prec@1 99.609 (97.533)	Prec@5 100.000 (99.988)
2022-06-17 18:54:17 - INFO - TRAINING - Epoch: [151][170/196]	Time 0.109 (0.123)	Data 0.000 (0.012)	Loss 0.1158 (0.0753)	Prec@1 95.312 (97.494)	Prec@5 100.000 (99.989)
2022-06-17 18:54:18 - INFO - TRAINING - Epoch: [151][180/196]	Time 0.102 (0.122)	Data 0.000 (0.011)	Loss 0.0719 (0.0756)	Prec@1 97.266 (97.475)	Prec@5 100.000 (99.989)
2022-06-17 18:54:19 - INFO - TRAINING - Epoch: [151][190/196]	Time 0.105 (0.121)	Data 0.000 (0.011)	Loss 0.0617 (0.0756)	Prec@1 98.047 (97.478)	Prec@5 100.000 (99.990)
2022-06-17 18:54:22 - INFO - EVALUATING - Epoch: [151][0/40]	Time 2.085 (2.085)	Data 2.039 (2.039)	Loss 0.2732 (0.2732)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:54:22 - INFO - EVALUATING - Epoch: [151][10/40]	Time 0.043 (0.257)	Data 0.000 (0.205)	Loss 0.4850 (0.4332)	Prec@1 88.281 (87.820)	Prec@5 99.219 (99.432)
2022-06-17 18:54:23 - INFO - EVALUATING - Epoch: [151][20/40]	Time 0.129 (0.169)	Data 0.089 (0.119)	Loss 0.3505 (0.4346)	Prec@1 86.719 (87.742)	Prec@5 99.609 (99.386)
2022-06-17 18:54:24 - INFO - EVALUATING - Epoch: [151][30/40]	Time 0.047 (0.152)	Data 0.000 (0.102)	Loss 0.5454 (0.4272)	Prec@1 86.328 (87.979)	Prec@5 100.000 (99.458)
2022-06-17 18:54:26 - INFO - 
 Epoch: 152	Training Loss 0.0754 	Training Prec@1 97.480 	Training Prec@5 99.990 	Validation Loss 0.4217 	Validation Prec@1 88.050 	Validation Prec@5 99.520 

2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:54:26 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:54:28 - INFO - TRAINING - Epoch: [152][0/196]	Time 2.012 (2.012)	Data 1.960 (1.960)	Loss 0.0626 (0.0626)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:54:29 - INFO - TRAINING - Epoch: [152][10/196]	Time 0.128 (0.286)	Data 0.000 (0.185)	Loss 0.0438 (0.0803)	Prec@1 98.438 (97.230)	Prec@5 100.000 (99.964)
2022-06-17 18:54:30 - INFO - TRAINING - Epoch: [152][20/196]	Time 0.111 (0.200)	Data 0.000 (0.097)	Loss 0.0915 (0.0767)	Prec@1 96.484 (97.191)	Prec@5 100.000 (99.981)
2022-06-17 18:54:31 - INFO - TRAINING - Epoch: [152][30/196]	Time 0.111 (0.172)	Data 0.000 (0.066)	Loss 0.1011 (0.0786)	Prec@1 97.266 (97.303)	Prec@5 100.000 (99.987)
2022-06-17 18:54:32 - INFO - TRAINING - Epoch: [152][40/196]	Time 0.104 (0.159)	Data 0.001 (0.050)	Loss 0.0699 (0.0785)	Prec@1 97.266 (97.285)	Prec@5 100.000 (99.990)
2022-06-17 18:54:34 - INFO - TRAINING - Epoch: [152][50/196]	Time 0.112 (0.150)	Data 0.000 (0.040)	Loss 0.0644 (0.0783)	Prec@1 98.047 (97.312)	Prec@5 100.000 (99.992)
2022-06-17 18:54:35 - INFO - TRAINING - Epoch: [152][60/196]	Time 0.131 (0.144)	Data 0.000 (0.034)	Loss 0.0834 (0.0761)	Prec@1 96.875 (97.394)	Prec@5 100.000 (99.994)
2022-06-17 18:54:36 - INFO - TRAINING - Epoch: [152][70/196]	Time 0.107 (0.140)	Data 0.000 (0.029)	Loss 0.0942 (0.0772)	Prec@1 97.266 (97.343)	Prec@5 100.000 (99.994)
2022-06-17 18:54:37 - INFO - TRAINING - Epoch: [152][80/196]	Time 0.108 (0.137)	Data 0.000 (0.025)	Loss 0.0604 (0.0757)	Prec@1 97.656 (97.405)	Prec@5 100.000 (99.995)
2022-06-17 18:54:38 - INFO - TRAINING - Epoch: [152][90/196]	Time 0.121 (0.135)	Data 0.001 (0.023)	Loss 0.0646 (0.0749)	Prec@1 98.438 (97.442)	Prec@5 100.000 (99.996)
2022-06-17 18:54:39 - INFO - TRAINING - Epoch: [152][100/196]	Time 0.115 (0.133)	Data 0.000 (0.020)	Loss 0.0446 (0.0746)	Prec@1 98.438 (97.455)	Prec@5 100.000 (99.996)
2022-06-17 18:54:40 - INFO - TRAINING - Epoch: [152][110/196]	Time 0.114 (0.131)	Data 0.000 (0.019)	Loss 0.0514 (0.0748)	Prec@1 98.438 (97.452)	Prec@5 100.000 (99.996)
2022-06-17 18:54:42 - INFO - TRAINING - Epoch: [152][120/196]	Time 0.115 (0.129)	Data 0.000 (0.017)	Loss 0.1309 (0.0758)	Prec@1 94.922 (97.414)	Prec@5 100.000 (99.997)
2022-06-17 18:54:43 - INFO - TRAINING - Epoch: [152][130/196]	Time 0.108 (0.128)	Data 0.000 (0.016)	Loss 0.0540 (0.0755)	Prec@1 98.047 (97.427)	Prec@5 100.000 (99.997)
2022-06-17 18:54:44 - INFO - TRAINING - Epoch: [152][140/196]	Time 0.109 (0.127)	Data 0.000 (0.015)	Loss 0.0752 (0.0764)	Prec@1 96.484 (97.382)	Prec@5 100.000 (99.997)
2022-06-17 18:54:45 - INFO - TRAINING - Epoch: [152][150/196]	Time 0.107 (0.126)	Data 0.000 (0.014)	Loss 0.0727 (0.0770)	Prec@1 97.656 (97.356)	Prec@5 100.000 (99.997)
2022-06-17 18:54:46 - INFO - TRAINING - Epoch: [152][160/196]	Time 0.117 (0.126)	Data 0.000 (0.013)	Loss 0.0802 (0.0770)	Prec@1 96.484 (97.336)	Prec@5 100.000 (99.998)
2022-06-17 18:54:47 - INFO - TRAINING - Epoch: [152][170/196]	Time 0.112 (0.125)	Data 0.000 (0.012)	Loss 0.0657 (0.0771)	Prec@1 97.266 (97.325)	Prec@5 100.000 (99.998)
2022-06-17 18:54:48 - INFO - TRAINING - Epoch: [152][180/196]	Time 0.108 (0.124)	Data 0.000 (0.012)	Loss 0.0866 (0.0774)	Prec@1 96.484 (97.317)	Prec@5 100.000 (99.998)
2022-06-17 18:54:49 - INFO - TRAINING - Epoch: [152][190/196]	Time 0.104 (0.123)	Data 0.000 (0.011)	Loss 0.0628 (0.0773)	Prec@1 98.047 (97.327)	Prec@5 100.000 (99.998)
2022-06-17 18:54:52 - INFO - EVALUATING - Epoch: [152][0/40]	Time 2.087 (2.087)	Data 2.040 (2.040)	Loss 0.2697 (0.2697)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:54:53 - INFO - EVALUATING - Epoch: [152][10/40]	Time 0.044 (0.263)	Data 0.001 (0.209)	Loss 0.4822 (0.4232)	Prec@1 88.281 (88.707)	Prec@5 99.219 (99.467)
2022-06-17 18:54:54 - INFO - EVALUATING - Epoch: [152][20/40]	Time 0.112 (0.170)	Data 0.070 (0.116)	Loss 0.3603 (0.4270)	Prec@1 87.109 (88.170)	Prec@5 99.609 (99.386)
2022-06-17 18:54:55 - INFO - EVALUATING - Epoch: [152][30/40]	Time 0.104 (0.151)	Data 0.060 (0.101)	Loss 0.5187 (0.4177)	Prec@1 86.719 (88.382)	Prec@5 100.000 (99.458)
2022-06-17 18:54:57 - INFO - 
 Epoch: 153	Training Loss 0.0771 	Training Prec@1 97.328 	Training Prec@5 99.998 	Validation Loss 0.4134 	Validation Prec@1 88.300 	Validation Prec@5 99.540 

2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:54:57 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:54:59 - INFO - TRAINING - Epoch: [153][0/196]	Time 1.955 (1.955)	Data 1.901 (1.901)	Loss 0.0642 (0.0642)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:55:00 - INFO - TRAINING - Epoch: [153][10/196]	Time 0.102 (0.279)	Data 0.000 (0.173)	Loss 0.0797 (0.0735)	Prec@1 98.047 (97.656)	Prec@5 100.000 (99.929)
2022-06-17 18:55:01 - INFO - TRAINING - Epoch: [153][20/196]	Time 0.113 (0.195)	Data 0.000 (0.091)	Loss 0.0518 (0.0720)	Prec@1 98.438 (97.861)	Prec@5 100.000 (99.963)
2022-06-17 18:55:02 - INFO - TRAINING - Epoch: [153][30/196]	Time 0.119 (0.170)	Data 0.000 (0.062)	Loss 0.0727 (0.0732)	Prec@1 97.266 (97.606)	Prec@5 100.000 (99.975)
2022-06-17 18:55:03 - INFO - TRAINING - Epoch: [153][40/196]	Time 0.121 (0.156)	Data 0.000 (0.047)	Loss 0.0906 (0.0749)	Prec@1 98.047 (97.475)	Prec@5 100.000 (99.981)
2022-06-17 18:55:04 - INFO - TRAINING - Epoch: [153][50/196]	Time 0.108 (0.147)	Data 0.000 (0.038)	Loss 0.0466 (0.0733)	Prec@1 98.438 (97.472)	Prec@5 100.000 (99.985)
2022-06-17 18:55:05 - INFO - TRAINING - Epoch: [153][60/196]	Time 0.106 (0.141)	Data 0.000 (0.032)	Loss 0.0533 (0.0734)	Prec@1 98.828 (97.509)	Prec@5 100.000 (99.987)
2022-06-17 18:55:07 - INFO - TRAINING - Epoch: [153][70/196]	Time 0.114 (0.138)	Data 0.001 (0.027)	Loss 0.0869 (0.0723)	Prec@1 97.266 (97.563)	Prec@5 100.000 (99.989)
2022-06-17 18:55:08 - INFO - TRAINING - Epoch: [153][80/196]	Time 0.104 (0.134)	Data 0.000 (0.024)	Loss 0.0657 (0.0723)	Prec@1 97.266 (97.594)	Prec@5 100.000 (99.990)
2022-06-17 18:55:09 - INFO - TRAINING - Epoch: [153][90/196]	Time 0.108 (0.132)	Data 0.000 (0.021)	Loss 0.0506 (0.0729)	Prec@1 98.438 (97.532)	Prec@5 100.000 (99.991)
2022-06-17 18:55:10 - INFO - TRAINING - Epoch: [153][100/196]	Time 0.123 (0.130)	Data 0.000 (0.019)	Loss 0.0459 (0.0729)	Prec@1 99.219 (97.540)	Prec@5 100.000 (99.992)
2022-06-17 18:55:11 - INFO - TRAINING - Epoch: [153][110/196]	Time 0.107 (0.129)	Data 0.000 (0.017)	Loss 0.0660 (0.0724)	Prec@1 98.047 (97.572)	Prec@5 100.000 (99.993)
2022-06-17 18:55:12 - INFO - TRAINING - Epoch: [153][120/196]	Time 0.115 (0.127)	Data 0.000 (0.016)	Loss 0.0846 (0.0731)	Prec@1 96.484 (97.527)	Prec@5 100.000 (99.994)
2022-06-17 18:55:13 - INFO - TRAINING - Epoch: [153][130/196]	Time 0.108 (0.126)	Data 0.000 (0.015)	Loss 0.1023 (0.0732)	Prec@1 96.875 (97.543)	Prec@5 100.000 (99.991)
2022-06-17 18:55:15 - INFO - TRAINING - Epoch: [153][140/196]	Time 0.101 (0.125)	Data 0.000 (0.014)	Loss 0.0877 (0.0740)	Prec@1 96.484 (97.501)	Prec@5 100.000 (99.992)
2022-06-17 18:55:16 - INFO - TRAINING - Epoch: [153][150/196]	Time 0.113 (0.124)	Data 0.000 (0.013)	Loss 0.0611 (0.0745)	Prec@1 97.266 (97.480)	Prec@5 100.000 (99.992)
2022-06-17 18:55:17 - INFO - TRAINING - Epoch: [153][160/196]	Time 0.115 (0.123)	Data 0.000 (0.012)	Loss 0.0731 (0.0741)	Prec@1 97.266 (97.494)	Prec@5 100.000 (99.993)
2022-06-17 18:55:18 - INFO - TRAINING - Epoch: [153][170/196]	Time 0.111 (0.123)	Data 0.000 (0.011)	Loss 0.0509 (0.0748)	Prec@1 98.047 (97.476)	Prec@5 100.000 (99.993)
2022-06-17 18:55:19 - INFO - TRAINING - Epoch: [153][180/196]	Time 0.101 (0.122)	Data 0.000 (0.011)	Loss 0.0711 (0.0746)	Prec@1 97.266 (97.475)	Prec@5 100.000 (99.994)
2022-06-17 18:55:20 - INFO - TRAINING - Epoch: [153][190/196]	Time 0.101 (0.121)	Data 0.000 (0.010)	Loss 0.0868 (0.0753)	Prec@1 97.656 (97.464)	Prec@5 100.000 (99.994)
2022-06-17 18:55:22 - INFO - EVALUATING - Epoch: [153][0/40]	Time 1.823 (1.823)	Data 1.777 (1.777)	Loss 0.2715 (0.2715)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:55:24 - INFO - EVALUATING - Epoch: [153][10/40]	Time 0.044 (0.275)	Data 0.000 (0.226)	Loss 0.4903 (0.4258)	Prec@1 87.891 (88.246)	Prec@5 99.219 (99.432)
2022-06-17 18:55:24 - INFO - EVALUATING - Epoch: [153][20/40]	Time 0.178 (0.175)	Data 0.136 (0.125)	Loss 0.3530 (0.4288)	Prec@1 87.500 (87.909)	Prec@5 100.000 (99.405)
2022-06-17 18:55:25 - INFO - EVALUATING - Epoch: [153][30/40]	Time 0.054 (0.156)	Data 0.000 (0.106)	Loss 0.5190 (0.4215)	Prec@1 86.719 (88.168)	Prec@5 100.000 (99.471)
2022-06-17 18:55:27 - INFO - 
 Epoch: 154	Training Loss 0.0751 	Training Prec@1 97.470 	Training Prec@5 99.994 	Validation Loss 0.4165 	Validation Prec@1 88.230 	Validation Prec@5 99.540 

2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:55:27 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:55:29 - INFO - TRAINING - Epoch: [154][0/196]	Time 1.723 (1.723)	Data 1.667 (1.667)	Loss 0.1245 (0.1245)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 18:55:30 - INFO - TRAINING - Epoch: [154][10/196]	Time 0.104 (0.263)	Data 0.000 (0.169)	Loss 0.0785 (0.0735)	Prec@1 98.438 (97.834)	Prec@5 100.000 (100.000)
2022-06-17 18:55:31 - INFO - TRAINING - Epoch: [154][20/196]	Time 0.103 (0.193)	Data 0.000 (0.089)	Loss 0.0432 (0.0737)	Prec@1 98.438 (97.786)	Prec@5 100.000 (100.000)
2022-06-17 18:55:33 - INFO - TRAINING - Epoch: [154][30/196]	Time 0.114 (0.169)	Data 0.000 (0.060)	Loss 0.0835 (0.0762)	Prec@1 97.266 (97.719)	Prec@5 100.000 (100.000)
2022-06-17 18:55:34 - INFO - TRAINING - Epoch: [154][40/196]	Time 0.123 (0.156)	Data 0.000 (0.046)	Loss 0.0987 (0.0789)	Prec@1 97.266 (97.532)	Prec@5 99.609 (99.990)
2022-06-17 18:55:35 - INFO - TRAINING - Epoch: [154][50/196]	Time 0.115 (0.148)	Data 0.000 (0.037)	Loss 0.1116 (0.0782)	Prec@1 96.484 (97.457)	Prec@5 100.000 (99.992)
2022-06-17 18:55:36 - INFO - TRAINING - Epoch: [154][60/196]	Time 0.133 (0.142)	Data 0.000 (0.031)	Loss 0.0644 (0.0756)	Prec@1 98.047 (97.541)	Prec@5 100.000 (99.994)
2022-06-17 18:55:37 - INFO - TRAINING - Epoch: [154][70/196]	Time 0.118 (0.139)	Data 0.000 (0.026)	Loss 0.1063 (0.0762)	Prec@1 96.484 (97.524)	Prec@5 100.000 (99.994)
2022-06-17 18:55:38 - INFO - TRAINING - Epoch: [154][80/196]	Time 0.116 (0.136)	Data 0.000 (0.023)	Loss 0.0833 (0.0756)	Prec@1 96.094 (97.521)	Prec@5 100.000 (99.995)
2022-06-17 18:55:40 - INFO - TRAINING - Epoch: [154][90/196]	Time 0.108 (0.134)	Data 0.000 (0.021)	Loss 0.0873 (0.0750)	Prec@1 97.266 (97.545)	Prec@5 100.000 (99.996)
2022-06-17 18:55:41 - INFO - TRAINING - Epoch: [154][100/196]	Time 0.108 (0.133)	Data 0.000 (0.019)	Loss 0.0976 (0.0755)	Prec@1 95.703 (97.509)	Prec@5 100.000 (99.996)
2022-06-17 18:55:42 - INFO - TRAINING - Epoch: [154][110/196]	Time 0.118 (0.131)	Data 0.000 (0.017)	Loss 0.0716 (0.0750)	Prec@1 97.656 (97.540)	Prec@5 100.000 (99.993)
2022-06-17 18:55:43 - INFO - TRAINING - Epoch: [154][120/196]	Time 0.102 (0.130)	Data 0.000 (0.016)	Loss 0.0350 (0.0752)	Prec@1 100.000 (97.550)	Prec@5 100.000 (99.994)
2022-06-17 18:55:44 - INFO - TRAINING - Epoch: [154][130/196]	Time 0.125 (0.129)	Data 0.000 (0.014)	Loss 0.0580 (0.0748)	Prec@1 98.828 (97.576)	Prec@5 100.000 (99.994)
2022-06-17 18:55:45 - INFO - TRAINING - Epoch: [154][140/196]	Time 0.111 (0.128)	Data 0.000 (0.013)	Loss 0.0588 (0.0747)	Prec@1 97.656 (97.548)	Prec@5 100.000 (99.994)
2022-06-17 18:55:47 - INFO - TRAINING - Epoch: [154][150/196]	Time 0.118 (0.128)	Data 0.000 (0.013)	Loss 0.1191 (0.0750)	Prec@1 96.094 (97.545)	Prec@5 100.000 (99.995)
2022-06-17 18:55:48 - INFO - TRAINING - Epoch: [154][160/196]	Time 0.133 (0.127)	Data 0.000 (0.012)	Loss 0.0734 (0.0748)	Prec@1 96.875 (97.537)	Prec@5 100.000 (99.995)
2022-06-17 18:55:49 - INFO - TRAINING - Epoch: [154][170/196]	Time 0.110 (0.127)	Data 0.000 (0.011)	Loss 0.0822 (0.0748)	Prec@1 97.656 (97.521)	Prec@5 100.000 (99.993)
2022-06-17 18:55:50 - INFO - TRAINING - Epoch: [154][180/196]	Time 0.128 (0.126)	Data 0.000 (0.011)	Loss 0.0855 (0.0747)	Prec@1 96.875 (97.531)	Prec@5 99.609 (99.991)
2022-06-17 18:55:51 - INFO - TRAINING - Epoch: [154][190/196]	Time 0.121 (0.125)	Data 0.000 (0.010)	Loss 0.0847 (0.0747)	Prec@1 97.656 (97.556)	Prec@5 100.000 (99.990)
2022-06-17 18:55:54 - INFO - EVALUATING - Epoch: [154][0/40]	Time 2.072 (2.072)	Data 2.027 (2.027)	Loss 0.2696 (0.2696)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:55:55 - INFO - EVALUATING - Epoch: [154][10/40]	Time 0.044 (0.281)	Data 0.000 (0.231)	Loss 0.4860 (0.4228)	Prec@1 87.891 (88.778)	Prec@5 99.219 (99.396)
2022-06-17 18:55:55 - INFO - EVALUATING - Epoch: [154][20/40]	Time 0.042 (0.173)	Data 0.000 (0.123)	Loss 0.3564 (0.4270)	Prec@1 87.500 (88.188)	Prec@5 99.609 (99.349)
2022-06-17 18:55:57 - INFO - EVALUATING - Epoch: [154][30/40]	Time 0.057 (0.153)	Data 0.000 (0.103)	Loss 0.5153 (0.4190)	Prec@1 87.109 (88.382)	Prec@5 100.000 (99.433)
2022-06-17 18:55:58 - INFO - 
 Epoch: 155	Training Loss 0.0747 	Training Prec@1 97.550 	Training Prec@5 99.990 	Validation Loss 0.4149 	Validation Prec@1 88.380 	Validation Prec@5 99.510 

2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:55:59 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:56:00 - INFO - TRAINING - Epoch: [155][0/196]	Time 1.613 (1.613)	Data 1.562 (1.562)	Loss 0.0645 (0.0645)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:56:01 - INFO - TRAINING - Epoch: [155][10/196]	Time 0.124 (0.247)	Data 0.000 (0.142)	Loss 0.0656 (0.0625)	Prec@1 97.266 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:56:02 - INFO - TRAINING - Epoch: [155][20/196]	Time 0.119 (0.182)	Data 0.000 (0.075)	Loss 0.0526 (0.0647)	Prec@1 98.438 (98.010)	Prec@5 100.000 (100.000)
2022-06-17 18:56:03 - INFO - TRAINING - Epoch: [155][30/196]	Time 0.112 (0.161)	Data 0.000 (0.051)	Loss 0.0508 (0.0709)	Prec@1 98.438 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 18:56:05 - INFO - TRAINING - Epoch: [155][40/196]	Time 0.118 (0.150)	Data 0.000 (0.038)	Loss 0.0833 (0.0731)	Prec@1 98.047 (97.637)	Prec@5 100.000 (99.990)
2022-06-17 18:56:06 - INFO - TRAINING - Epoch: [155][50/196]	Time 0.126 (0.144)	Data 0.000 (0.031)	Loss 0.0926 (0.0742)	Prec@1 96.484 (97.580)	Prec@5 100.000 (99.985)
2022-06-17 18:56:07 - INFO - TRAINING - Epoch: [155][60/196]	Time 0.129 (0.140)	Data 0.000 (0.026)	Loss 0.0837 (0.0774)	Prec@1 97.266 (97.432)	Prec@5 100.000 (99.987)
2022-06-17 18:56:08 - INFO - TRAINING - Epoch: [155][70/196]	Time 0.132 (0.138)	Data 0.000 (0.022)	Loss 0.0775 (0.0770)	Prec@1 96.484 (97.420)	Prec@5 100.000 (99.989)
2022-06-17 18:56:09 - INFO - TRAINING - Epoch: [155][80/196]	Time 0.119 (0.136)	Data 0.000 (0.020)	Loss 0.0746 (0.0750)	Prec@1 98.047 (97.497)	Prec@5 100.000 (99.990)
2022-06-17 18:56:11 - INFO - TRAINING - Epoch: [155][90/196]	Time 0.126 (0.134)	Data 0.000 (0.017)	Loss 0.0540 (0.0751)	Prec@1 99.219 (97.476)	Prec@5 100.000 (99.991)
2022-06-17 18:56:12 - INFO - TRAINING - Epoch: [155][100/196]	Time 0.133 (0.133)	Data 0.000 (0.016)	Loss 0.0991 (0.0744)	Prec@1 96.484 (97.502)	Prec@5 100.000 (99.988)
2022-06-17 18:56:13 - INFO - TRAINING - Epoch: [155][110/196]	Time 0.128 (0.132)	Data 0.000 (0.014)	Loss 0.0701 (0.0754)	Prec@1 97.656 (97.470)	Prec@5 100.000 (99.989)
2022-06-17 18:56:14 - INFO - TRAINING - Epoch: [155][120/196]	Time 0.123 (0.131)	Data 0.000 (0.013)	Loss 0.0713 (0.0754)	Prec@1 98.438 (97.475)	Prec@5 100.000 (99.984)
2022-06-17 18:56:16 - INFO - TRAINING - Epoch: [155][130/196]	Time 0.123 (0.130)	Data 0.000 (0.012)	Loss 0.0778 (0.0761)	Prec@1 95.703 (97.439)	Prec@5 100.000 (99.985)
2022-06-17 18:56:17 - INFO - TRAINING - Epoch: [155][140/196]	Time 0.110 (0.129)	Data 0.000 (0.011)	Loss 0.0754 (0.0754)	Prec@1 97.656 (97.457)	Prec@5 100.000 (99.986)
2022-06-17 18:56:18 - INFO - TRAINING - Epoch: [155][150/196]	Time 0.129 (0.129)	Data 0.000 (0.011)	Loss 0.0566 (0.0748)	Prec@1 97.656 (97.488)	Prec@5 100.000 (99.987)
2022-06-17 18:56:19 - INFO - TRAINING - Epoch: [155][160/196]	Time 0.126 (0.128)	Data 0.000 (0.010)	Loss 0.0601 (0.0746)	Prec@1 98.047 (97.486)	Prec@5 100.000 (99.988)
2022-06-17 18:56:20 - INFO - TRAINING - Epoch: [155][170/196]	Time 0.126 (0.127)	Data 0.000 (0.009)	Loss 0.0580 (0.0746)	Prec@1 98.438 (97.480)	Prec@5 100.000 (99.989)
2022-06-17 18:56:21 - INFO - TRAINING - Epoch: [155][180/196]	Time 0.105 (0.127)	Data 0.000 (0.009)	Loss 0.0866 (0.0752)	Prec@1 97.266 (97.456)	Prec@5 100.000 (99.987)
2022-06-17 18:56:23 - INFO - TRAINING - Epoch: [155][190/196]	Time 0.107 (0.126)	Data 0.000 (0.008)	Loss 0.0666 (0.0752)	Prec@1 98.047 (97.444)	Prec@5 100.000 (99.988)
2022-06-17 18:56:25 - INFO - EVALUATING - Epoch: [155][0/40]	Time 1.610 (1.610)	Data 1.564 (1.564)	Loss 0.2677 (0.2677)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 18:56:26 - INFO - EVALUATING - Epoch: [155][10/40]	Time 0.405 (0.269)	Data 0.360 (0.222)	Loss 0.4840 (0.4239)	Prec@1 89.062 (88.494)	Prec@5 99.219 (99.467)
2022-06-17 18:56:27 - INFO - EVALUATING - Epoch: [155][20/40]	Time 0.072 (0.173)	Data 0.029 (0.123)	Loss 0.3487 (0.4279)	Prec@1 87.500 (88.132)	Prec@5 99.609 (99.405)
2022-06-17 18:56:28 - INFO - EVALUATING - Epoch: [155][30/40]	Time 0.064 (0.154)	Data 0.000 (0.106)	Loss 0.5292 (0.4198)	Prec@1 86.719 (88.395)	Prec@5 100.000 (99.471)
2022-06-17 18:56:30 - INFO - 
 Epoch: 156	Training Loss 0.0755 	Training Prec@1 97.434 	Training Prec@5 99.988 	Validation Loss 0.4158 	Validation Prec@1 88.370 	Validation Prec@5 99.540 

2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:56:30 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:56:32 - INFO - TRAINING - Epoch: [156][0/196]	Time 1.767 (1.767)	Data 1.716 (1.716)	Loss 0.0794 (0.0794)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:56:33 - INFO - TRAINING - Epoch: [156][10/196]	Time 0.100 (0.264)	Data 0.000 (0.156)	Loss 0.0802 (0.0702)	Prec@1 97.266 (97.621)	Prec@5 100.000 (100.000)
2022-06-17 18:56:34 - INFO - TRAINING - Epoch: [156][20/196]	Time 0.117 (0.190)	Data 0.000 (0.082)	Loss 0.0760 (0.0702)	Prec@1 98.047 (97.470)	Prec@5 100.000 (100.000)
2022-06-17 18:56:35 - INFO - TRAINING - Epoch: [156][30/196]	Time 0.107 (0.165)	Data 0.000 (0.056)	Loss 0.0716 (0.0710)	Prec@1 96.875 (97.442)	Prec@5 100.000 (99.987)
2022-06-17 18:56:36 - INFO - TRAINING - Epoch: [156][40/196]	Time 0.112 (0.152)	Data 0.000 (0.042)	Loss 0.0619 (0.0702)	Prec@1 98.047 (97.580)	Prec@5 100.000 (99.990)
2022-06-17 18:56:37 - INFO - TRAINING - Epoch: [156][50/196]	Time 0.133 (0.144)	Data 0.000 (0.034)	Loss 0.0603 (0.0700)	Prec@1 98.438 (97.595)	Prec@5 100.000 (99.985)
2022-06-17 18:56:38 - INFO - TRAINING - Epoch: [156][60/196]	Time 0.132 (0.140)	Data 0.000 (0.028)	Loss 0.0563 (0.0717)	Prec@1 98.438 (97.579)	Prec@5 100.000 (99.987)
2022-06-17 18:56:40 - INFO - TRAINING - Epoch: [156][70/196]	Time 0.107 (0.136)	Data 0.000 (0.024)	Loss 0.0849 (0.0724)	Prec@1 97.656 (97.552)	Prec@5 100.000 (99.989)
2022-06-17 18:56:41 - INFO - TRAINING - Epoch: [156][80/196]	Time 0.104 (0.132)	Data 0.000 (0.021)	Loss 0.0677 (0.0715)	Prec@1 97.656 (97.608)	Prec@5 100.000 (99.990)
2022-06-17 18:56:42 - INFO - TRAINING - Epoch: [156][90/196]	Time 0.119 (0.130)	Data 0.000 (0.019)	Loss 0.0566 (0.0716)	Prec@1 98.828 (97.648)	Prec@5 100.000 (99.991)
2022-06-17 18:56:43 - INFO - TRAINING - Epoch: [156][100/196]	Time 0.130 (0.129)	Data 0.000 (0.017)	Loss 0.0740 (0.0712)	Prec@1 97.656 (97.645)	Prec@5 100.000 (99.988)
2022-06-17 18:56:44 - INFO - TRAINING - Epoch: [156][110/196]	Time 0.106 (0.127)	Data 0.001 (0.016)	Loss 0.0494 (0.0716)	Prec@1 98.828 (97.642)	Prec@5 100.000 (99.989)
2022-06-17 18:56:45 - INFO - TRAINING - Epoch: [156][120/196]	Time 0.103 (0.126)	Data 0.000 (0.014)	Loss 0.0579 (0.0717)	Prec@1 98.438 (97.653)	Prec@5 100.000 (99.990)
2022-06-17 18:56:46 - INFO - TRAINING - Epoch: [156][130/196]	Time 0.122 (0.125)	Data 0.000 (0.013)	Loss 0.0731 (0.0718)	Prec@1 97.266 (97.632)	Prec@5 100.000 (99.991)
2022-06-17 18:56:47 - INFO - TRAINING - Epoch: [156][140/196]	Time 0.111 (0.124)	Data 0.000 (0.012)	Loss 0.0688 (0.0715)	Prec@1 97.266 (97.648)	Prec@5 100.000 (99.992)
2022-06-17 18:56:49 - INFO - TRAINING - Epoch: [156][150/196]	Time 0.122 (0.123)	Data 0.000 (0.012)	Loss 0.0744 (0.0719)	Prec@1 97.266 (97.630)	Prec@5 100.000 (99.992)
2022-06-17 18:56:50 - INFO - TRAINING - Epoch: [156][160/196]	Time 0.105 (0.122)	Data 0.000 (0.011)	Loss 0.0675 (0.0721)	Prec@1 98.047 (97.608)	Prec@5 100.000 (99.990)
2022-06-17 18:56:51 - INFO - TRAINING - Epoch: [156][170/196]	Time 0.109 (0.122)	Data 0.000 (0.010)	Loss 0.0372 (0.0718)	Prec@1 99.219 (97.624)	Prec@5 100.000 (99.991)
2022-06-17 18:56:52 - INFO - TRAINING - Epoch: [156][180/196]	Time 0.125 (0.121)	Data 0.000 (0.010)	Loss 0.0895 (0.0717)	Prec@1 95.703 (97.635)	Prec@5 100.000 (99.991)
2022-06-17 18:56:53 - INFO - TRAINING - Epoch: [156][190/196]	Time 0.106 (0.121)	Data 0.000 (0.009)	Loss 0.0744 (0.0717)	Prec@1 96.875 (97.621)	Prec@5 100.000 (99.992)
2022-06-17 18:56:56 - INFO - EVALUATING - Epoch: [156][0/40]	Time 1.923 (1.923)	Data 1.877 (1.877)	Loss 0.2704 (0.2704)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
2022-06-17 18:56:56 - INFO - EVALUATING - Epoch: [156][10/40]	Time 0.044 (0.249)	Data 0.000 (0.200)	Loss 0.4810 (0.4280)	Prec@1 89.062 (88.068)	Prec@5 99.219 (99.396)
2022-06-17 18:56:57 - INFO - EVALUATING - Epoch: [156][20/40]	Time 0.044 (0.175)	Data 0.000 (0.126)	Loss 0.3481 (0.4300)	Prec@1 87.500 (87.816)	Prec@5 99.609 (99.368)
2022-06-17 18:56:58 - INFO - EVALUATING - Epoch: [156][30/40]	Time 0.125 (0.148)	Data 0.085 (0.100)	Loss 0.5305 (0.4210)	Prec@1 86.719 (88.092)	Prec@5 100.000 (99.446)
2022-06-17 18:57:00 - INFO - 
 Epoch: 157	Training Loss 0.0719 	Training Prec@1 97.606 	Training Prec@5 99.992 	Validation Loss 0.4162 	Validation Prec@1 88.140 	Validation Prec@5 99.520 

2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:57:00 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:57:02 - INFO - TRAINING - Epoch: [157][0/196]	Time 1.690 (1.690)	Data 1.634 (1.634)	Loss 0.0466 (0.0466)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:57:03 - INFO - TRAINING - Epoch: [157][10/196]	Time 0.116 (0.265)	Data 0.065 (0.171)	Loss 0.0683 (0.0774)	Prec@1 96.484 (97.017)	Prec@5 100.000 (100.000)
2022-06-17 18:57:04 - INFO - TRAINING - Epoch: [157][20/196]	Time 0.108 (0.192)	Data 0.000 (0.092)	Loss 0.1031 (0.0801)	Prec@1 96.484 (97.173)	Prec@5 100.000 (99.981)
2022-06-17 18:57:05 - INFO - TRAINING - Epoch: [157][30/196]	Time 0.124 (0.166)	Data 0.000 (0.062)	Loss 0.0566 (0.0795)	Prec@1 98.438 (97.278)	Prec@5 100.000 (99.987)
2022-06-17 18:57:06 - INFO - TRAINING - Epoch: [157][40/196]	Time 0.114 (0.154)	Data 0.000 (0.047)	Loss 0.0859 (0.0788)	Prec@1 97.266 (97.304)	Prec@5 100.000 (99.990)
2022-06-17 18:57:07 - INFO - TRAINING - Epoch: [157][50/196]	Time 0.139 (0.147)	Data 0.000 (0.038)	Loss 0.0694 (0.0783)	Prec@1 97.656 (97.350)	Prec@5 100.000 (99.985)
2022-06-17 18:57:09 - INFO - TRAINING - Epoch: [157][60/196]	Time 0.123 (0.141)	Data 0.000 (0.032)	Loss 0.0985 (0.0780)	Prec@1 96.484 (97.400)	Prec@5 100.000 (99.987)
2022-06-17 18:57:10 - INFO - TRAINING - Epoch: [157][70/196]	Time 0.121 (0.137)	Data 0.000 (0.027)	Loss 0.0649 (0.0771)	Prec@1 97.656 (97.453)	Prec@5 100.000 (99.989)
2022-06-17 18:57:11 - INFO - TRAINING - Epoch: [157][80/196]	Time 0.121 (0.134)	Data 0.000 (0.024)	Loss 0.0679 (0.0775)	Prec@1 98.047 (97.405)	Prec@5 100.000 (99.990)
2022-06-17 18:57:12 - INFO - TRAINING - Epoch: [157][90/196]	Time 0.134 (0.132)	Data 0.000 (0.021)	Loss 0.0753 (0.0776)	Prec@1 96.094 (97.399)	Prec@5 100.000 (99.991)
2022-06-17 18:57:13 - INFO - TRAINING - Epoch: [157][100/196]	Time 0.128 (0.130)	Data 0.000 (0.019)	Loss 0.0653 (0.0785)	Prec@1 98.047 (97.355)	Prec@5 100.000 (99.992)
2022-06-17 18:57:14 - INFO - TRAINING - Epoch: [157][110/196]	Time 0.109 (0.129)	Data 0.000 (0.018)	Loss 0.0820 (0.0782)	Prec@1 98.438 (97.332)	Prec@5 100.000 (99.993)
2022-06-17 18:57:15 - INFO - TRAINING - Epoch: [157][120/196]	Time 0.110 (0.127)	Data 0.000 (0.016)	Loss 0.0618 (0.0779)	Prec@1 98.438 (97.340)	Prec@5 100.000 (99.990)
2022-06-17 18:57:17 - INFO - TRAINING - Epoch: [157][130/196]	Time 0.115 (0.126)	Data 0.000 (0.015)	Loss 0.1063 (0.0776)	Prec@1 97.656 (97.352)	Prec@5 100.000 (99.991)
2022-06-17 18:57:18 - INFO - TRAINING - Epoch: [157][140/196]	Time 0.104 (0.125)	Data 0.000 (0.014)	Loss 0.0714 (0.0775)	Prec@1 97.266 (97.349)	Prec@5 100.000 (99.992)
2022-06-17 18:57:19 - INFO - TRAINING - Epoch: [157][150/196]	Time 0.132 (0.124)	Data 0.000 (0.013)	Loss 0.0727 (0.0766)	Prec@1 98.047 (97.400)	Prec@5 100.000 (99.992)
2022-06-17 18:57:20 - INFO - TRAINING - Epoch: [157][160/196]	Time 0.123 (0.124)	Data 0.000 (0.012)	Loss 0.0853 (0.0762)	Prec@1 97.656 (97.428)	Prec@5 99.609 (99.990)
2022-06-17 18:57:21 - INFO - TRAINING - Epoch: [157][170/196]	Time 0.132 (0.123)	Data 0.000 (0.012)	Loss 0.0747 (0.0757)	Prec@1 97.656 (97.442)	Prec@5 100.000 (99.991)
2022-06-17 18:57:22 - INFO - TRAINING - Epoch: [157][180/196]	Time 0.110 (0.123)	Data 0.000 (0.011)	Loss 0.0931 (0.0757)	Prec@1 95.703 (97.434)	Prec@5 100.000 (99.991)
2022-06-17 18:57:23 - INFO - TRAINING - Epoch: [157][190/196]	Time 0.102 (0.122)	Data 0.000 (0.010)	Loss 0.0356 (0.0754)	Prec@1 99.609 (97.437)	Prec@5 100.000 (99.990)
2022-06-17 18:57:25 - INFO - EVALUATING - Epoch: [157][0/40]	Time 1.363 (1.363)	Data 1.317 (1.317)	Loss 0.2761 (0.2761)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:57:26 - INFO - EVALUATING - Epoch: [157][10/40]	Time 0.067 (0.213)	Data 0.000 (0.163)	Loss 0.4932 (0.4289)	Prec@1 87.891 (88.423)	Prec@5 99.219 (99.396)
2022-06-17 18:57:27 - INFO - EVALUATING - Epoch: [157][20/40]	Time 0.042 (0.161)	Data 0.000 (0.113)	Loss 0.3528 (0.4309)	Prec@1 87.891 (87.946)	Prec@5 99.609 (99.349)
2022-06-17 18:57:28 - INFO - EVALUATING - Epoch: [157][30/40]	Time 0.045 (0.144)	Data 0.000 (0.097)	Loss 0.5270 (0.4213)	Prec@1 87.109 (88.206)	Prec@5 100.000 (99.433)
2022-06-17 18:57:30 - INFO - 
 Epoch: 158	Training Loss 0.0757 	Training Prec@1 97.420 	Training Prec@5 99.990 	Validation Loss 0.4169 	Validation Prec@1 88.220 	Validation Prec@5 99.520 

2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:57:30 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:57:32 - INFO - TRAINING - Epoch: [158][0/196]	Time 1.568 (1.568)	Data 1.515 (1.515)	Loss 0.0466 (0.0466)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 18:57:33 - INFO - TRAINING - Epoch: [158][10/196]	Time 0.112 (0.261)	Data 0.000 (0.164)	Loss 0.0549 (0.0687)	Prec@1 97.656 (97.585)	Prec@5 100.000 (100.000)
2022-06-17 18:57:34 - INFO - TRAINING - Epoch: [158][20/196]	Time 0.111 (0.189)	Data 0.000 (0.086)	Loss 0.0663 (0.0756)	Prec@1 97.656 (97.321)	Prec@5 100.000 (100.000)
2022-06-17 18:57:35 - INFO - TRAINING - Epoch: [158][30/196]	Time 0.103 (0.165)	Data 0.000 (0.058)	Loss 0.0866 (0.0786)	Prec@1 96.094 (97.228)	Prec@5 100.000 (99.987)
2022-06-17 18:57:36 - INFO - TRAINING - Epoch: [158][40/196]	Time 0.109 (0.151)	Data 0.000 (0.044)	Loss 0.0629 (0.0764)	Prec@1 97.656 (97.323)	Prec@5 100.000 (99.990)
2022-06-17 18:57:37 - INFO - TRAINING - Epoch: [158][50/196]	Time 0.121 (0.143)	Data 0.000 (0.036)	Loss 0.0555 (0.0745)	Prec@1 98.438 (97.419)	Prec@5 100.000 (99.992)
2022-06-17 18:57:39 - INFO - TRAINING - Epoch: [158][60/196]	Time 0.107 (0.138)	Data 0.000 (0.030)	Loss 0.0514 (0.0725)	Prec@1 98.047 (97.458)	Prec@5 100.000 (99.994)
2022-06-17 18:57:40 - INFO - TRAINING - Epoch: [158][70/196]	Time 0.109 (0.134)	Data 0.000 (0.026)	Loss 0.0310 (0.0725)	Prec@1 99.219 (97.458)	Prec@5 100.000 (99.994)
2022-06-17 18:57:41 - INFO - TRAINING - Epoch: [158][80/196]	Time 0.104 (0.131)	Data 0.000 (0.023)	Loss 0.0757 (0.0734)	Prec@1 96.875 (97.425)	Prec@5 100.000 (99.995)
2022-06-17 18:57:42 - INFO - TRAINING - Epoch: [158][90/196]	Time 0.114 (0.129)	Data 0.000 (0.020)	Loss 0.0982 (0.0741)	Prec@1 96.484 (97.399)	Prec@5 100.000 (99.996)
2022-06-17 18:57:43 - INFO - TRAINING - Epoch: [158][100/196]	Time 0.103 (0.127)	Data 0.000 (0.018)	Loss 0.0694 (0.0740)	Prec@1 97.656 (97.389)	Prec@5 100.000 (99.996)
2022-06-17 18:57:44 - INFO - TRAINING - Epoch: [158][110/196]	Time 0.106 (0.125)	Data 0.000 (0.017)	Loss 0.0659 (0.0736)	Prec@1 97.656 (97.389)	Prec@5 100.000 (99.996)
2022-06-17 18:57:45 - INFO - TRAINING - Epoch: [158][120/196]	Time 0.110 (0.124)	Data 0.000 (0.015)	Loss 0.0457 (0.0729)	Prec@1 99.219 (97.424)	Prec@5 100.000 (99.997)
2022-06-17 18:57:46 - INFO - TRAINING - Epoch: [158][130/196]	Time 0.104 (0.123)	Data 0.000 (0.014)	Loss 0.0717 (0.0723)	Prec@1 97.266 (97.465)	Prec@5 100.000 (99.997)
2022-06-17 18:57:47 - INFO - TRAINING - Epoch: [158][140/196]	Time 0.102 (0.122)	Data 0.000 (0.013)	Loss 0.0413 (0.0724)	Prec@1 98.438 (97.476)	Prec@5 100.000 (99.997)
2022-06-17 18:57:48 - INFO - TRAINING - Epoch: [158][150/196]	Time 0.115 (0.121)	Data 0.000 (0.012)	Loss 0.1012 (0.0728)	Prec@1 97.656 (97.473)	Prec@5 99.609 (99.995)
2022-06-17 18:57:50 - INFO - TRAINING - Epoch: [158][160/196]	Time 0.125 (0.121)	Data 0.000 (0.012)	Loss 0.0814 (0.0733)	Prec@1 97.266 (97.457)	Prec@5 100.000 (99.995)
2022-06-17 18:57:51 - INFO - TRAINING - Epoch: [158][170/196]	Time 0.108 (0.120)	Data 0.000 (0.011)	Loss 0.0758 (0.0731)	Prec@1 97.266 (97.476)	Prec@5 100.000 (99.995)
2022-06-17 18:57:52 - INFO - TRAINING - Epoch: [158][180/196]	Time 0.124 (0.120)	Data 0.000 (0.010)	Loss 0.0836 (0.0730)	Prec@1 96.875 (97.475)	Prec@5 100.000 (99.996)
2022-06-17 18:57:53 - INFO - TRAINING - Epoch: [158][190/196]	Time 0.107 (0.119)	Data 0.000 (0.010)	Loss 0.0743 (0.0739)	Prec@1 97.656 (97.448)	Prec@5 100.000 (99.996)
2022-06-17 18:57:55 - INFO - EVALUATING - Epoch: [158][0/40]	Time 1.509 (1.509)	Data 1.463 (1.463)	Loss 0.2747 (0.2747)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 18:57:56 - INFO - EVALUATING - Epoch: [158][10/40]	Time 0.081 (0.256)	Data 0.001 (0.204)	Loss 0.4802 (0.4261)	Prec@1 87.500 (88.246)	Prec@5 99.219 (99.538)
2022-06-17 18:57:57 - INFO - EVALUATING - Epoch: [158][20/40]	Time 0.110 (0.161)	Data 0.067 (0.110)	Loss 0.3540 (0.4290)	Prec@1 87.891 (87.853)	Prec@5 99.609 (99.423)
2022-06-17 18:57:58 - INFO - EVALUATING - Epoch: [158][30/40]	Time 0.092 (0.151)	Data 0.048 (0.101)	Loss 0.5287 (0.4200)	Prec@1 86.719 (88.143)	Prec@5 100.000 (99.471)
2022-06-17 18:58:00 - INFO - 
 Epoch: 159	Training Loss 0.0738 	Training Prec@1 97.458 	Training Prec@5 99.996 	Validation Loss 0.4156 	Validation Prec@1 88.210 	Validation Prec@5 99.550 

2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:58:00 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:58:01 - INFO - TRAINING - Epoch: [159][0/196]	Time 1.381 (1.381)	Data 1.323 (1.323)	Loss 0.0719 (0.0719)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 18:58:03 - INFO - TRAINING - Epoch: [159][10/196]	Time 0.111 (0.265)	Data 0.000 (0.167)	Loss 0.0803 (0.0745)	Prec@1 96.484 (97.372)	Prec@5 100.000 (100.000)
2022-06-17 18:58:04 - INFO - TRAINING - Epoch: [159][20/196]	Time 0.109 (0.190)	Data 0.000 (0.087)	Loss 0.0522 (0.0754)	Prec@1 97.656 (97.526)	Prec@5 100.000 (100.000)
2022-06-17 18:58:05 - INFO - TRAINING - Epoch: [159][30/196]	Time 0.111 (0.165)	Data 0.000 (0.059)	Loss 0.0542 (0.0729)	Prec@1 98.438 (97.606)	Prec@5 100.000 (99.987)
2022-06-17 18:58:06 - INFO - TRAINING - Epoch: [159][40/196]	Time 0.112 (0.152)	Data 0.000 (0.045)	Loss 0.0808 (0.0710)	Prec@1 97.656 (97.618)	Prec@5 100.000 (99.990)
2022-06-17 18:58:07 - INFO - TRAINING - Epoch: [159][50/196]	Time 0.110 (0.144)	Data 0.000 (0.036)	Loss 0.0415 (0.0697)	Prec@1 99.609 (97.626)	Prec@5 100.000 (99.992)
2022-06-17 18:58:09 - INFO - TRAINING - Epoch: [159][60/196]	Time 0.111 (0.138)	Data 0.000 (0.030)	Loss 0.0990 (0.0713)	Prec@1 95.703 (97.579)	Prec@5 100.000 (99.987)
2022-06-17 18:58:10 - INFO - TRAINING - Epoch: [159][70/196]	Time 0.128 (0.134)	Data 0.000 (0.026)	Loss 0.0642 (0.0704)	Prec@1 98.047 (97.601)	Prec@5 100.000 (99.989)
2022-06-17 18:58:11 - INFO - TRAINING - Epoch: [159][80/196]	Time 0.104 (0.131)	Data 0.000 (0.023)	Loss 0.0733 (0.0720)	Prec@1 98.047 (97.512)	Prec@5 100.000 (99.990)
2022-06-17 18:58:12 - INFO - TRAINING - Epoch: [159][90/196]	Time 0.106 (0.129)	Data 0.000 (0.020)	Loss 0.0812 (0.0730)	Prec@1 96.875 (97.446)	Prec@5 100.000 (99.991)
2022-06-17 18:58:13 - INFO - TRAINING - Epoch: [159][100/196]	Time 0.122 (0.127)	Data 0.000 (0.018)	Loss 0.0703 (0.0737)	Prec@1 96.875 (97.382)	Prec@5 100.000 (99.992)
2022-06-17 18:58:14 - INFO - TRAINING - Epoch: [159][110/196]	Time 0.113 (0.126)	Data 0.000 (0.017)	Loss 0.0835 (0.0735)	Prec@1 98.047 (97.385)	Prec@5 100.000 (99.993)
2022-06-17 18:58:15 - INFO - TRAINING - Epoch: [159][120/196]	Time 0.107 (0.125)	Data 0.000 (0.015)	Loss 0.0539 (0.0732)	Prec@1 98.047 (97.401)	Prec@5 100.000 (99.994)
2022-06-17 18:58:16 - INFO - TRAINING - Epoch: [159][130/196]	Time 0.103 (0.123)	Data 0.000 (0.014)	Loss 0.0548 (0.0736)	Prec@1 97.656 (97.430)	Prec@5 100.000 (99.988)
2022-06-17 18:58:17 - INFO - TRAINING - Epoch: [159][140/196]	Time 0.107 (0.123)	Data 0.000 (0.013)	Loss 0.0730 (0.0730)	Prec@1 98.047 (97.482)	Prec@5 100.000 (99.989)
2022-06-17 18:58:18 - INFO - TRAINING - Epoch: [159][150/196]	Time 0.111 (0.122)	Data 0.000 (0.012)	Loss 0.0581 (0.0731)	Prec@1 98.828 (97.491)	Prec@5 100.000 (99.990)
2022-06-17 18:58:20 - INFO - TRAINING - Epoch: [159][160/196]	Time 0.112 (0.121)	Data 0.000 (0.012)	Loss 0.0548 (0.0731)	Prec@1 97.656 (97.496)	Prec@5 100.000 (99.988)
2022-06-17 18:58:21 - INFO - TRAINING - Epoch: [159][170/196]	Time 0.104 (0.120)	Data 0.000 (0.011)	Loss 0.0785 (0.0735)	Prec@1 96.875 (97.489)	Prec@5 100.000 (99.989)
2022-06-17 18:58:22 - INFO - TRAINING - Epoch: [159][180/196]	Time 0.113 (0.120)	Data 0.000 (0.010)	Loss 0.0445 (0.0727)	Prec@1 98.828 (97.531)	Prec@5 100.000 (99.989)
2022-06-17 18:58:23 - INFO - TRAINING - Epoch: [159][190/196]	Time 0.111 (0.119)	Data 0.000 (0.010)	Loss 0.0685 (0.0734)	Prec@1 97.656 (97.505)	Prec@5 100.000 (99.986)
2022-06-17 18:58:25 - INFO - EVALUATING - Epoch: [159][0/40]	Time 1.803 (1.803)	Data 1.758 (1.758)	Loss 0.2782 (0.2782)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:58:26 - INFO - EVALUATING - Epoch: [159][10/40]	Time 0.045 (0.240)	Data 0.000 (0.190)	Loss 0.4949 (0.4311)	Prec@1 87.891 (88.459)	Prec@5 99.219 (99.432)
2022-06-17 18:58:27 - INFO - EVALUATING - Epoch: [159][20/40]	Time 0.041 (0.167)	Data 0.000 (0.117)	Loss 0.3553 (0.4321)	Prec@1 87.500 (88.077)	Prec@5 100.000 (99.405)
2022-06-17 18:58:28 - INFO - EVALUATING - Epoch: [159][30/40]	Time 0.089 (0.142)	Data 0.045 (0.092)	Loss 0.5291 (0.4242)	Prec@1 87.109 (88.306)	Prec@5 100.000 (99.471)
2022-06-17 18:58:30 - INFO - 
 Epoch: 160	Training Loss 0.0736 	Training Prec@1 97.500 	Training Prec@5 99.984 	Validation Loss 0.4187 	Validation Prec@1 88.340 	Validation Prec@5 99.550 

2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:58:30 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:58:31 - INFO - TRAINING - Epoch: [160][0/196]	Time 1.504 (1.504)	Data 1.450 (1.450)	Loss 0.0844 (0.0844)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 18:58:33 - INFO - TRAINING - Epoch: [160][10/196]	Time 0.115 (0.274)	Data 0.000 (0.174)	Loss 0.0583 (0.0701)	Prec@1 98.438 (97.869)	Prec@5 100.000 (100.000)
2022-06-17 18:58:34 - INFO - TRAINING - Epoch: [160][20/196]	Time 0.117 (0.197)	Data 0.000 (0.091)	Loss 0.0549 (0.0679)	Prec@1 98.438 (97.991)	Prec@5 100.000 (100.000)
2022-06-17 18:58:35 - INFO - TRAINING - Epoch: [160][30/196]	Time 0.115 (0.168)	Data 0.000 (0.062)	Loss 0.0651 (0.0666)	Prec@1 98.047 (97.959)	Prec@5 100.000 (100.000)
2022-06-17 18:58:36 - INFO - TRAINING - Epoch: [160][40/196]	Time 0.106 (0.154)	Data 0.000 (0.047)	Loss 0.0749 (0.0671)	Prec@1 98.047 (97.828)	Prec@5 100.000 (100.000)
2022-06-17 18:58:37 - INFO - TRAINING - Epoch: [160][50/196]	Time 0.114 (0.145)	Data 0.000 (0.038)	Loss 0.0948 (0.0680)	Prec@1 96.484 (97.825)	Prec@5 100.000 (100.000)
2022-06-17 18:58:38 - INFO - TRAINING - Epoch: [160][60/196]	Time 0.129 (0.140)	Data 0.000 (0.032)	Loss 0.0572 (0.0666)	Prec@1 98.438 (97.848)	Prec@5 100.000 (100.000)
2022-06-17 18:58:40 - INFO - TRAINING - Epoch: [160][70/196]	Time 0.113 (0.137)	Data 0.000 (0.027)	Loss 0.0997 (0.0674)	Prec@1 96.094 (97.816)	Prec@5 100.000 (100.000)
2022-06-17 18:58:41 - INFO - TRAINING - Epoch: [160][80/196]	Time 0.109 (0.134)	Data 0.000 (0.024)	Loss 0.0889 (0.0676)	Prec@1 96.484 (97.806)	Prec@5 100.000 (100.000)
2022-06-17 18:58:42 - INFO - TRAINING - Epoch: [160][90/196]	Time 0.109 (0.133)	Data 0.000 (0.021)	Loss 0.0639 (0.0675)	Prec@1 98.047 (97.764)	Prec@5 100.000 (100.000)
2022-06-17 18:58:43 - INFO - TRAINING - Epoch: [160][100/196]	Time 0.107 (0.131)	Data 0.000 (0.019)	Loss 0.0785 (0.0682)	Prec@1 97.266 (97.730)	Prec@5 100.000 (99.996)
2022-06-17 18:58:44 - INFO - TRAINING - Epoch: [160][110/196]	Time 0.113 (0.130)	Data 0.000 (0.017)	Loss 0.0600 (0.0684)	Prec@1 98.047 (97.720)	Prec@5 100.000 (99.993)
2022-06-17 18:58:45 - INFO - TRAINING - Epoch: [160][120/196]	Time 0.103 (0.128)	Data 0.000 (0.016)	Loss 0.0685 (0.0689)	Prec@1 98.047 (97.705)	Prec@5 100.000 (99.994)
2022-06-17 18:58:46 - INFO - TRAINING - Epoch: [160][130/196]	Time 0.117 (0.127)	Data 0.000 (0.015)	Loss 0.0576 (0.0695)	Prec@1 98.438 (97.686)	Prec@5 100.000 (99.994)
2022-06-17 18:58:47 - INFO - TRAINING - Epoch: [160][140/196]	Time 0.104 (0.125)	Data 0.000 (0.014)	Loss 0.0711 (0.0703)	Prec@1 97.266 (97.656)	Prec@5 100.000 (99.989)
2022-06-17 18:58:49 - INFO - TRAINING - Epoch: [160][150/196]	Time 0.126 (0.124)	Data 0.000 (0.013)	Loss 0.0504 (0.0707)	Prec@1 98.438 (97.661)	Prec@5 100.000 (99.987)
2022-06-17 18:58:50 - INFO - TRAINING - Epoch: [160][160/196]	Time 0.102 (0.123)	Data 0.000 (0.012)	Loss 0.0716 (0.0705)	Prec@1 96.484 (97.671)	Prec@5 100.000 (99.988)
2022-06-17 18:58:51 - INFO - TRAINING - Epoch: [160][170/196]	Time 0.109 (0.123)	Data 0.000 (0.011)	Loss 0.0743 (0.0702)	Prec@1 97.656 (97.672)	Prec@5 100.000 (99.989)
2022-06-17 18:58:52 - INFO - TRAINING - Epoch: [160][180/196]	Time 0.118 (0.122)	Data 0.000 (0.011)	Loss 0.0538 (0.0697)	Prec@1 97.656 (97.686)	Prec@5 100.000 (99.989)
2022-06-17 18:58:53 - INFO - TRAINING - Epoch: [160][190/196]	Time 0.102 (0.121)	Data 0.000 (0.010)	Loss 0.0866 (0.0702)	Prec@1 97.656 (97.669)	Prec@5 100.000 (99.990)
2022-06-17 18:58:55 - INFO - EVALUATING - Epoch: [160][0/40]	Time 1.647 (1.647)	Data 1.602 (1.602)	Loss 0.2788 (0.2788)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 18:58:56 - INFO - EVALUATING - Epoch: [160][10/40]	Time 0.068 (0.251)	Data 0.000 (0.199)	Loss 0.4857 (0.4273)	Prec@1 87.891 (88.246)	Prec@5 99.219 (99.467)
2022-06-17 18:58:57 - INFO - EVALUATING - Epoch: [160][20/40]	Time 0.124 (0.168)	Data 0.081 (0.119)	Loss 0.3626 (0.4298)	Prec@1 87.109 (87.965)	Prec@5 100.000 (99.405)
2022-06-17 18:58:58 - INFO - EVALUATING - Epoch: [160][30/40]	Time 0.044 (0.156)	Data 0.000 (0.106)	Loss 0.5232 (0.4224)	Prec@1 87.109 (88.193)	Prec@5 100.000 (99.471)
2022-06-17 18:59:00 - INFO - 
 Epoch: 161	Training Loss 0.0701 	Training Prec@1 97.672 	Training Prec@5 99.990 	Validation Loss 0.4167 	Validation Prec@1 88.300 	Validation Prec@5 99.550 

2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:59:00 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:59:02 - INFO - TRAINING - Epoch: [161][0/196]	Time 2.018 (2.018)	Data 1.965 (1.965)	Loss 0.0501 (0.0501)	Prec@1 98.828 (98.828)	Prec@5 100.000 (100.000)
2022-06-17 18:59:03 - INFO - TRAINING - Epoch: [161][10/196]	Time 0.112 (0.287)	Data 0.000 (0.179)	Loss 0.0526 (0.0690)	Prec@1 98.828 (97.727)	Prec@5 100.000 (99.964)
2022-06-17 18:59:04 - INFO - TRAINING - Epoch: [161][20/196]	Time 0.130 (0.207)	Data 0.000 (0.094)	Loss 0.0517 (0.0711)	Prec@1 97.656 (97.600)	Prec@5 100.000 (99.981)
2022-06-17 18:59:06 - INFO - TRAINING - Epoch: [161][30/196]	Time 0.113 (0.178)	Data 0.000 (0.064)	Loss 0.0431 (0.0723)	Prec@1 98.438 (97.492)	Prec@5 100.000 (99.975)
2022-06-17 18:59:07 - INFO - TRAINING - Epoch: [161][40/196]	Time 0.108 (0.163)	Data 0.000 (0.048)	Loss 0.0499 (0.0719)	Prec@1 98.438 (97.551)	Prec@5 100.000 (99.981)
2022-06-17 18:59:08 - INFO - TRAINING - Epoch: [161][50/196]	Time 0.112 (0.153)	Data 0.000 (0.039)	Loss 0.0904 (0.0713)	Prec@1 95.312 (97.541)	Prec@5 100.000 (99.985)
2022-06-17 18:59:09 - INFO - TRAINING - Epoch: [161][60/196]	Time 0.120 (0.145)	Data 0.000 (0.033)	Loss 0.0394 (0.0714)	Prec@1 99.609 (97.579)	Prec@5 100.000 (99.987)
2022-06-17 18:59:10 - INFO - TRAINING - Epoch: [161][70/196]	Time 0.113 (0.141)	Data 0.000 (0.028)	Loss 0.0831 (0.0713)	Prec@1 96.875 (97.568)	Prec@5 100.000 (99.989)
2022-06-17 18:59:11 - INFO - TRAINING - Epoch: [161][80/196]	Time 0.102 (0.137)	Data 0.000 (0.025)	Loss 0.0640 (0.0712)	Prec@1 97.656 (97.569)	Prec@5 100.000 (99.990)
2022-06-17 18:59:12 - INFO - TRAINING - Epoch: [161][90/196]	Time 0.103 (0.134)	Data 0.000 (0.022)	Loss 0.0910 (0.0710)	Prec@1 96.094 (97.553)	Prec@5 100.000 (99.991)
2022-06-17 18:59:14 - INFO - TRAINING - Epoch: [161][100/196]	Time 0.103 (0.132)	Data 0.000 (0.020)	Loss 0.0589 (0.0711)	Prec@1 97.266 (97.556)	Prec@5 100.000 (99.988)
2022-06-17 18:59:15 - INFO - TRAINING - Epoch: [161][110/196]	Time 0.117 (0.130)	Data 0.000 (0.018)	Loss 0.0837 (0.0717)	Prec@1 97.266 (97.561)	Prec@5 100.000 (99.989)
2022-06-17 18:59:16 - INFO - TRAINING - Epoch: [161][120/196]	Time 0.104 (0.128)	Data 0.000 (0.017)	Loss 0.0785 (0.0728)	Prec@1 96.875 (97.521)	Prec@5 100.000 (99.990)
2022-06-17 18:59:17 - INFO - TRAINING - Epoch: [161][130/196]	Time 0.111 (0.127)	Data 0.000 (0.015)	Loss 0.0794 (0.0721)	Prec@1 97.266 (97.537)	Prec@5 100.000 (99.991)
2022-06-17 18:59:18 - INFO - TRAINING - Epoch: [161][140/196]	Time 0.113 (0.126)	Data 0.000 (0.014)	Loss 0.0429 (0.0723)	Prec@1 99.219 (97.562)	Prec@5 100.000 (99.989)
2022-06-17 18:59:19 - INFO - TRAINING - Epoch: [161][150/196]	Time 0.106 (0.125)	Data 0.000 (0.013)	Loss 0.0711 (0.0720)	Prec@1 97.656 (97.568)	Prec@5 100.000 (99.987)
2022-06-17 18:59:20 - INFO - TRAINING - Epoch: [161][160/196]	Time 0.105 (0.125)	Data 0.000 (0.013)	Loss 0.1059 (0.0724)	Prec@1 96.094 (97.562)	Prec@5 100.000 (99.985)
2022-06-17 18:59:21 - INFO - TRAINING - Epoch: [161][170/196]	Time 0.131 (0.124)	Data 0.000 (0.012)	Loss 0.0791 (0.0717)	Prec@1 97.266 (97.601)	Prec@5 100.000 (99.986)
2022-06-17 18:59:23 - INFO - TRAINING - Epoch: [161][180/196]	Time 0.121 (0.124)	Data 0.000 (0.011)	Loss 0.0895 (0.0720)	Prec@1 97.266 (97.602)	Prec@5 100.000 (99.987)
2022-06-17 18:59:24 - INFO - TRAINING - Epoch: [161][190/196]	Time 0.101 (0.123)	Data 0.000 (0.011)	Loss 0.0953 (0.0727)	Prec@1 96.484 (97.556)	Prec@5 100.000 (99.986)
2022-06-17 18:59:26 - INFO - EVALUATING - Epoch: [161][0/40]	Time 1.848 (1.848)	Data 1.803 (1.803)	Loss 0.2778 (0.2778)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 18:59:27 - INFO - EVALUATING - Epoch: [161][10/40]	Time 0.122 (0.220)	Data 0.080 (0.171)	Loss 0.4765 (0.4285)	Prec@1 87.891 (88.388)	Prec@5 99.219 (99.467)
2022-06-17 18:59:28 - INFO - EVALUATING - Epoch: [161][20/40]	Time 0.065 (0.181)	Data 0.000 (0.133)	Loss 0.3591 (0.4327)	Prec@1 87.500 (88.039)	Prec@5 99.609 (99.405)
2022-06-17 18:59:29 - INFO - EVALUATING - Epoch: [161][30/40]	Time 0.044 (0.151)	Data 0.000 (0.102)	Loss 0.5240 (0.4246)	Prec@1 87.109 (88.319)	Prec@5 100.000 (99.483)
2022-06-17 18:59:31 - INFO - 
 Epoch: 162	Training Loss 0.0725 	Training Prec@1 97.564 	Training Prec@5 99.986 	Validation Loss 0.4190 	Validation Prec@1 88.380 	Validation Prec@5 99.560 

2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 18:59:31 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 18:59:32 - INFO - TRAINING - Epoch: [162][0/196]	Time 1.669 (1.669)	Data 1.613 (1.613)	Loss 0.0712 (0.0712)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 18:59:34 - INFO - TRAINING - Epoch: [162][10/196]	Time 0.107 (0.277)	Data 0.000 (0.184)	Loss 0.0812 (0.0801)	Prec@1 96.484 (97.124)	Prec@5 100.000 (100.000)
2022-06-17 18:59:35 - INFO - TRAINING - Epoch: [162][20/196]	Time 0.110 (0.198)	Data 0.000 (0.096)	Loss 0.0502 (0.0758)	Prec@1 98.828 (97.396)	Prec@5 100.000 (100.000)
2022-06-17 18:59:36 - INFO - TRAINING - Epoch: [162][30/196]	Time 0.119 (0.169)	Data 0.000 (0.065)	Loss 0.0655 (0.0737)	Prec@1 97.656 (97.455)	Prec@5 100.000 (100.000)
2022-06-17 18:59:37 - INFO - TRAINING - Epoch: [162][40/196]	Time 0.108 (0.155)	Data 0.000 (0.050)	Loss 0.1293 (0.0753)	Prec@1 95.703 (97.466)	Prec@5 99.609 (99.990)
2022-06-17 18:59:38 - INFO - TRAINING - Epoch: [162][50/196]	Time 0.118 (0.147)	Data 0.000 (0.040)	Loss 0.0700 (0.0744)	Prec@1 97.656 (97.442)	Prec@5 100.000 (99.985)
2022-06-17 18:59:39 - INFO - TRAINING - Epoch: [162][60/196]	Time 0.111 (0.140)	Data 0.000 (0.033)	Loss 0.0728 (0.0738)	Prec@1 97.266 (97.464)	Prec@5 100.000 (99.987)
2022-06-17 18:59:41 - INFO - TRAINING - Epoch: [162][70/196]	Time 0.109 (0.137)	Data 0.000 (0.029)	Loss 0.0651 (0.0742)	Prec@1 97.656 (97.480)	Prec@5 100.000 (99.983)
2022-06-17 18:59:42 - INFO - TRAINING - Epoch: [162][80/196]	Time 0.108 (0.133)	Data 0.000 (0.025)	Loss 0.1002 (0.0730)	Prec@1 96.094 (97.531)	Prec@5 100.000 (99.986)
2022-06-17 18:59:43 - INFO - TRAINING - Epoch: [162][90/196]	Time 0.112 (0.131)	Data 0.000 (0.022)	Loss 0.0416 (0.0723)	Prec@1 98.438 (97.553)	Prec@5 100.000 (99.987)
2022-06-17 18:59:44 - INFO - TRAINING - Epoch: [162][100/196]	Time 0.108 (0.128)	Data 0.000 (0.020)	Loss 0.0532 (0.0706)	Prec@1 97.656 (97.618)	Prec@5 100.000 (99.988)
2022-06-17 18:59:45 - INFO - TRAINING - Epoch: [162][110/196]	Time 0.103 (0.126)	Data 0.000 (0.018)	Loss 0.0649 (0.0711)	Prec@1 97.266 (97.593)	Prec@5 100.000 (99.989)
2022-06-17 18:59:46 - INFO - TRAINING - Epoch: [162][120/196]	Time 0.105 (0.125)	Data 0.000 (0.017)	Loss 0.0707 (0.0710)	Prec@1 97.656 (97.585)	Prec@5 100.000 (99.990)
2022-06-17 18:59:47 - INFO - TRAINING - Epoch: [162][130/196]	Time 0.113 (0.124)	Data 0.000 (0.016)	Loss 0.0886 (0.0709)	Prec@1 97.266 (97.585)	Prec@5 100.000 (99.991)
2022-06-17 18:59:48 - INFO - TRAINING - Epoch: [162][140/196]	Time 0.110 (0.123)	Data 0.000 (0.015)	Loss 0.0969 (0.0706)	Prec@1 96.875 (97.615)	Prec@5 100.000 (99.992)
2022-06-17 18:59:49 - INFO - TRAINING - Epoch: [162][150/196]	Time 0.103 (0.122)	Data 0.000 (0.014)	Loss 0.0509 (0.0702)	Prec@1 98.438 (97.623)	Prec@5 100.000 (99.992)
2022-06-17 18:59:50 - INFO - TRAINING - Epoch: [162][160/196]	Time 0.106 (0.121)	Data 0.000 (0.013)	Loss 0.0755 (0.0709)	Prec@1 97.656 (97.576)	Prec@5 100.000 (99.993)
2022-06-17 18:59:51 - INFO - TRAINING - Epoch: [162][170/196]	Time 0.120 (0.121)	Data 0.000 (0.012)	Loss 0.0685 (0.0712)	Prec@1 97.656 (97.581)	Prec@5 100.000 (99.991)
2022-06-17 18:59:53 - INFO - TRAINING - Epoch: [162][180/196]	Time 0.120 (0.120)	Data 0.000 (0.011)	Loss 0.0953 (0.0715)	Prec@1 95.703 (97.572)	Prec@5 100.000 (99.991)
2022-06-17 18:59:54 - INFO - TRAINING - Epoch: [162][190/196]	Time 0.101 (0.119)	Data 0.000 (0.011)	Loss 0.0723 (0.0716)	Prec@1 98.047 (97.572)	Prec@5 100.000 (99.992)
2022-06-17 18:59:56 - INFO - EVALUATING - Epoch: [162][0/40]	Time 1.664 (1.664)	Data 1.618 (1.618)	Loss 0.2807 (0.2807)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 18:59:57 - INFO - EVALUATING - Epoch: [162][10/40]	Time 0.045 (0.267)	Data 0.001 (0.218)	Loss 0.4802 (0.4315)	Prec@1 87.500 (88.139)	Prec@5 99.219 (99.538)
2022-06-17 18:59:58 - INFO - EVALUATING - Epoch: [162][20/40]	Time 0.060 (0.165)	Data 0.000 (0.114)	Loss 0.3633 (0.4337)	Prec@1 87.109 (87.909)	Prec@5 99.609 (99.423)
2022-06-17 18:59:59 - INFO - EVALUATING - Epoch: [162][30/40]	Time 0.071 (0.146)	Data 0.028 (0.097)	Loss 0.5231 (0.4254)	Prec@1 86.719 (88.155)	Prec@5 100.000 (99.483)
2022-06-17 19:00:01 - INFO - 
 Epoch: 163	Training Loss 0.0718 	Training Prec@1 97.572 	Training Prec@5 99.992 	Validation Loss 0.4192 	Validation Prec@1 88.170 	Validation Prec@5 99.560 

2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:00:01 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:00:02 - INFO - TRAINING - Epoch: [163][0/196]	Time 1.243 (1.243)	Data 1.189 (1.189)	Loss 0.0845 (0.0845)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 19:00:03 - INFO - TRAINING - Epoch: [163][10/196]	Time 0.099 (0.236)	Data 0.000 (0.144)	Loss 0.0637 (0.0755)	Prec@1 98.828 (97.621)	Prec@5 100.000 (100.000)
2022-06-17 19:00:04 - INFO - TRAINING - Epoch: [163][20/196]	Time 0.104 (0.177)	Data 0.000 (0.076)	Loss 0.0610 (0.0702)	Prec@1 96.875 (97.731)	Prec@5 100.000 (100.000)
2022-06-17 19:00:05 - INFO - TRAINING - Epoch: [163][30/196]	Time 0.111 (0.154)	Data 0.000 (0.051)	Loss 0.0719 (0.0702)	Prec@1 98.047 (97.744)	Prec@5 100.000 (99.987)
2022-06-17 19:00:07 - INFO - TRAINING - Epoch: [163][40/196]	Time 0.107 (0.142)	Data 0.000 (0.039)	Loss 0.0813 (0.0680)	Prec@1 96.875 (97.771)	Prec@5 100.000 (99.990)
2022-06-17 19:00:08 - INFO - TRAINING - Epoch: [163][50/196]	Time 0.105 (0.135)	Data 0.000 (0.031)	Loss 0.0405 (0.0678)	Prec@1 98.828 (97.802)	Prec@5 100.000 (99.992)
2022-06-17 19:00:09 - INFO - TRAINING - Epoch: [163][60/196]	Time 0.115 (0.130)	Data 0.000 (0.026)	Loss 0.0780 (0.0674)	Prec@1 96.875 (97.791)	Prec@5 100.000 (99.994)
2022-06-17 19:00:10 - INFO - TRAINING - Epoch: [163][70/196]	Time 0.113 (0.128)	Data 0.000 (0.023)	Loss 0.0754 (0.0676)	Prec@1 96.875 (97.761)	Prec@5 100.000 (99.994)
2022-06-17 19:00:11 - INFO - TRAINING - Epoch: [163][80/196]	Time 0.124 (0.126)	Data 0.000 (0.020)	Loss 0.0818 (0.0684)	Prec@1 95.312 (97.685)	Prec@5 100.000 (99.995)
2022-06-17 19:00:12 - INFO - TRAINING - Epoch: [163][90/196]	Time 0.107 (0.125)	Data 0.000 (0.018)	Loss 0.1024 (0.0686)	Prec@1 95.703 (97.665)	Prec@5 100.000 (99.996)
2022-06-17 19:00:13 - INFO - TRAINING - Epoch: [163][100/196]	Time 0.115 (0.124)	Data 0.000 (0.016)	Loss 0.0609 (0.0686)	Prec@1 97.656 (97.660)	Prec@5 100.000 (99.992)
2022-06-17 19:00:14 - INFO - TRAINING - Epoch: [163][110/196]	Time 0.121 (0.124)	Data 0.000 (0.015)	Loss 0.0730 (0.0683)	Prec@1 97.266 (97.691)	Prec@5 100.000 (99.993)
2022-06-17 19:00:16 - INFO - TRAINING - Epoch: [163][120/196]	Time 0.129 (0.123)	Data 0.000 (0.013)	Loss 0.0779 (0.0680)	Prec@1 96.484 (97.711)	Prec@5 100.000 (99.994)
2022-06-17 19:00:17 - INFO - TRAINING - Epoch: [163][130/196]	Time 0.107 (0.122)	Data 0.000 (0.012)	Loss 0.0847 (0.0681)	Prec@1 96.875 (97.722)	Prec@5 100.000 (99.994)
2022-06-17 19:00:18 - INFO - TRAINING - Epoch: [163][140/196]	Time 0.119 (0.122)	Data 0.000 (0.011)	Loss 0.0860 (0.0684)	Prec@1 97.656 (97.712)	Prec@5 100.000 (99.994)
2022-06-17 19:00:19 - INFO - TRAINING - Epoch: [163][150/196]	Time 0.113 (0.121)	Data 0.000 (0.011)	Loss 0.1015 (0.0689)	Prec@1 96.484 (97.685)	Prec@5 100.000 (99.995)
2022-06-17 19:00:20 - INFO - TRAINING - Epoch: [163][160/196]	Time 0.110 (0.121)	Data 0.000 (0.010)	Loss 0.0861 (0.0700)	Prec@1 96.484 (97.644)	Prec@5 100.000 (99.993)
2022-06-17 19:00:21 - INFO - TRAINING - Epoch: [163][170/196]	Time 0.120 (0.121)	Data 0.000 (0.010)	Loss 0.0888 (0.0703)	Prec@1 97.656 (97.647)	Prec@5 100.000 (99.993)
2022-06-17 19:00:22 - INFO - TRAINING - Epoch: [163][180/196]	Time 0.112 (0.120)	Data 0.000 (0.009)	Loss 0.1074 (0.0706)	Prec@1 95.703 (97.637)	Prec@5 100.000 (99.994)
2022-06-17 19:00:24 - INFO - TRAINING - Epoch: [163][190/196]	Time 0.109 (0.120)	Data 0.000 (0.009)	Loss 0.0556 (0.0706)	Prec@1 98.047 (97.632)	Prec@5 100.000 (99.992)
2022-06-17 19:00:26 - INFO - EVALUATING - Epoch: [163][0/40]	Time 1.394 (1.394)	Data 1.348 (1.348)	Loss 0.2751 (0.2751)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 19:00:27 - INFO - EVALUATING - Epoch: [163][10/40]	Time 0.302 (0.249)	Data 0.257 (0.200)	Loss 0.4729 (0.4298)	Prec@1 88.281 (88.317)	Prec@5 99.219 (99.432)
2022-06-17 19:00:28 - INFO - EVALUATING - Epoch: [163][20/40]	Time 0.042 (0.157)	Data 0.000 (0.105)	Loss 0.3616 (0.4326)	Prec@1 87.109 (88.058)	Prec@5 99.609 (99.386)
2022-06-17 19:00:29 - INFO - EVALUATING - Epoch: [163][30/40]	Time 0.085 (0.144)	Data 0.041 (0.094)	Loss 0.5253 (0.4242)	Prec@1 87.109 (88.231)	Prec@5 100.000 (99.446)
2022-06-17 19:00:30 - INFO - 
 Epoch: 164	Training Loss 0.0704 	Training Prec@1 97.636 	Training Prec@5 99.992 	Validation Loss 0.4183 	Validation Prec@1 88.270 	Validation Prec@5 99.530 

2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:00:30 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:00:32 - INFO - TRAINING - Epoch: [164][0/196]	Time 1.643 (1.643)	Data 1.589 (1.589)	Loss 0.0411 (0.0411)	Prec@1 98.828 (98.828)	Prec@5 100.000 (100.000)
2022-06-17 19:00:34 - INFO - TRAINING - Epoch: [164][10/196]	Time 0.107 (0.292)	Data 0.000 (0.193)	Loss 0.0422 (0.0651)	Prec@1 99.219 (97.869)	Prec@5 100.000 (99.964)
2022-06-17 19:00:35 - INFO - TRAINING - Epoch: [164][20/196]	Time 0.120 (0.209)	Data 0.000 (0.101)	Loss 0.0557 (0.0663)	Prec@1 98.438 (97.935)	Prec@5 100.000 (99.981)
2022-06-17 19:00:36 - INFO - TRAINING - Epoch: [164][30/196]	Time 0.106 (0.178)	Data 0.000 (0.069)	Loss 0.0714 (0.0708)	Prec@1 98.047 (97.694)	Prec@5 100.000 (99.987)
2022-06-17 19:00:37 - INFO - TRAINING - Epoch: [164][40/196]	Time 0.111 (0.162)	Data 0.000 (0.052)	Loss 0.0445 (0.0681)	Prec@1 98.047 (97.790)	Prec@5 100.000 (99.990)
2022-06-17 19:00:38 - INFO - TRAINING - Epoch: [164][50/196]	Time 0.111 (0.152)	Data 0.000 (0.042)	Loss 0.0623 (0.0674)	Prec@1 97.656 (97.817)	Prec@5 100.000 (99.992)
2022-06-17 19:00:39 - INFO - TRAINING - Epoch: [164][60/196]	Time 0.129 (0.147)	Data 0.000 (0.035)	Loss 0.1062 (0.0685)	Prec@1 96.094 (97.784)	Prec@5 100.000 (99.994)
2022-06-17 19:00:41 - INFO - TRAINING - Epoch: [164][70/196]	Time 0.106 (0.143)	Data 0.000 (0.030)	Loss 0.0591 (0.0685)	Prec@1 98.047 (97.788)	Prec@5 100.000 (99.994)
2022-06-17 19:00:42 - INFO - TRAINING - Epoch: [164][80/196]	Time 0.118 (0.139)	Data 0.000 (0.026)	Loss 0.0633 (0.0689)	Prec@1 96.875 (97.748)	Prec@5 100.000 (99.990)
2022-06-17 19:00:43 - INFO - TRAINING - Epoch: [164][90/196]	Time 0.128 (0.136)	Data 0.000 (0.024)	Loss 0.0545 (0.0696)	Prec@1 98.438 (97.703)	Prec@5 100.000 (99.987)
2022-06-17 19:00:44 - INFO - TRAINING - Epoch: [164][100/196]	Time 0.127 (0.135)	Data 0.000 (0.021)	Loss 0.0782 (0.0698)	Prec@1 97.656 (97.652)	Prec@5 99.609 (99.985)
2022-06-17 19:00:45 - INFO - TRAINING - Epoch: [164][110/196]	Time 0.107 (0.133)	Data 0.000 (0.019)	Loss 0.0863 (0.0691)	Prec@1 96.875 (97.670)	Prec@5 100.000 (99.986)
2022-06-17 19:00:46 - INFO - TRAINING - Epoch: [164][120/196]	Time 0.108 (0.131)	Data 0.000 (0.018)	Loss 0.0555 (0.0699)	Prec@1 98.438 (97.630)	Prec@5 100.000 (99.984)
2022-06-17 19:00:48 - INFO - TRAINING - Epoch: [164][130/196]	Time 0.119 (0.130)	Data 0.000 (0.016)	Loss 0.0817 (0.0698)	Prec@1 96.094 (97.644)	Prec@5 100.000 (99.985)
2022-06-17 19:00:49 - INFO - TRAINING - Epoch: [164][140/196]	Time 0.123 (0.129)	Data 0.000 (0.015)	Loss 0.0386 (0.0698)	Prec@1 99.219 (97.651)	Prec@5 100.000 (99.986)
2022-06-17 19:00:50 - INFO - TRAINING - Epoch: [164][150/196]	Time 0.105 (0.128)	Data 0.000 (0.014)	Loss 0.0685 (0.0700)	Prec@1 97.656 (97.636)	Prec@5 100.000 (99.987)
2022-06-17 19:00:51 - INFO - TRAINING - Epoch: [164][160/196]	Time 0.105 (0.128)	Data 0.000 (0.013)	Loss 0.0725 (0.0706)	Prec@1 97.266 (97.605)	Prec@5 100.000 (99.988)
2022-06-17 19:00:52 - INFO - TRAINING - Epoch: [164][170/196]	Time 0.130 (0.127)	Data 0.000 (0.013)	Loss 0.0504 (0.0707)	Prec@1 97.656 (97.601)	Prec@5 100.000 (99.989)
2022-06-17 19:00:53 - INFO - TRAINING - Epoch: [164][180/196]	Time 0.105 (0.127)	Data 0.000 (0.012)	Loss 0.0507 (0.0708)	Prec@1 99.219 (97.604)	Prec@5 100.000 (99.989)
2022-06-17 19:00:54 - INFO - TRAINING - Epoch: [164][190/196]	Time 0.101 (0.126)	Data 0.000 (0.011)	Loss 0.0628 (0.0708)	Prec@1 98.828 (97.603)	Prec@5 100.000 (99.988)
2022-06-17 19:00:57 - INFO - EVALUATING - Epoch: [164][0/40]	Time 1.567 (1.567)	Data 1.521 (1.521)	Loss 0.2681 (0.2681)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:00:58 - INFO - EVALUATING - Epoch: [164][10/40]	Time 0.114 (0.253)	Data 0.069 (0.205)	Loss 0.4753 (0.4291)	Prec@1 88.672 (88.104)	Prec@5 99.219 (99.361)
2022-06-17 19:00:59 - INFO - EVALUATING - Epoch: [164][20/40]	Time 0.191 (0.171)	Data 0.150 (0.123)	Loss 0.3603 (0.4313)	Prec@1 87.500 (87.965)	Prec@5 99.609 (99.368)
2022-06-17 19:01:00 - INFO - EVALUATING - Epoch: [164][30/40]	Time 0.246 (0.158)	Data 0.205 (0.111)	Loss 0.5314 (0.4237)	Prec@1 85.547 (88.067)	Prec@5 100.000 (99.458)
2022-06-17 19:01:02 - INFO - 
 Epoch: 165	Training Loss 0.0708 	Training Prec@1 97.608 	Training Prec@5 99.988 	Validation Loss 0.4180 	Validation Prec@1 88.170 	Validation Prec@5 99.530 

2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:01:02 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:01:03 - INFO - TRAINING - Epoch: [165][0/196]	Time 1.373 (1.373)	Data 1.321 (1.321)	Loss 0.0629 (0.0629)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 19:01:05 - INFO - TRAINING - Epoch: [165][10/196]	Time 0.102 (0.273)	Data 0.000 (0.181)	Loss 0.0910 (0.0727)	Prec@1 97.266 (97.692)	Prec@5 100.000 (100.000)
2022-06-17 19:01:06 - INFO - TRAINING - Epoch: [165][20/196]	Time 0.116 (0.199)	Data 0.000 (0.095)	Loss 0.0503 (0.0770)	Prec@1 98.438 (97.507)	Prec@5 100.000 (100.000)
2022-06-17 19:01:07 - INFO - TRAINING - Epoch: [165][30/196]	Time 0.108 (0.172)	Data 0.000 (0.064)	Loss 0.0667 (0.0740)	Prec@1 98.047 (97.681)	Prec@5 100.000 (100.000)
2022-06-17 19:01:08 - INFO - TRAINING - Epoch: [165][40/196]	Time 0.113 (0.157)	Data 0.000 (0.049)	Loss 0.0548 (0.0732)	Prec@1 97.656 (97.609)	Prec@5 100.000 (99.990)
2022-06-17 19:01:09 - INFO - TRAINING - Epoch: [165][50/196]	Time 0.116 (0.149)	Data 0.000 (0.039)	Loss 0.0934 (0.0748)	Prec@1 96.875 (97.580)	Prec@5 100.000 (99.992)
2022-06-17 19:01:11 - INFO - TRAINING - Epoch: [165][60/196]	Time 0.125 (0.144)	Data 0.000 (0.033)	Loss 0.0503 (0.0741)	Prec@1 98.438 (97.573)	Prec@5 100.000 (99.994)
2022-06-17 19:01:12 - INFO - TRAINING - Epoch: [165][70/196]	Time 0.113 (0.140)	Data 0.000 (0.028)	Loss 0.0825 (0.0736)	Prec@1 96.875 (97.618)	Prec@5 100.000 (99.994)
2022-06-17 19:01:13 - INFO - TRAINING - Epoch: [165][80/196]	Time 0.133 (0.137)	Data 0.000 (0.025)	Loss 0.0685 (0.0746)	Prec@1 97.656 (97.579)	Prec@5 100.000 (99.990)
2022-06-17 19:01:14 - INFO - TRAINING - Epoch: [165][90/196]	Time 0.119 (0.135)	Data 0.000 (0.022)	Loss 0.0660 (0.0732)	Prec@1 98.438 (97.669)	Prec@5 100.000 (99.991)
2022-06-17 19:01:15 - INFO - TRAINING - Epoch: [165][100/196]	Time 0.127 (0.133)	Data 0.000 (0.020)	Loss 0.0758 (0.0736)	Prec@1 98.047 (97.672)	Prec@5 100.000 (99.992)
2022-06-17 19:01:16 - INFO - TRAINING - Epoch: [165][110/196]	Time 0.111 (0.131)	Data 0.000 (0.018)	Loss 0.0536 (0.0731)	Prec@1 98.828 (97.688)	Prec@5 100.000 (99.989)
2022-06-17 19:01:17 - INFO - TRAINING - Epoch: [165][120/196]	Time 0.105 (0.130)	Data 0.000 (0.017)	Loss 0.0664 (0.0724)	Prec@1 98.438 (97.705)	Prec@5 100.000 (99.987)
2022-06-17 19:01:19 - INFO - TRAINING - Epoch: [165][130/196]	Time 0.120 (0.129)	Data 0.000 (0.015)	Loss 0.0709 (0.0723)	Prec@1 98.047 (97.692)	Prec@5 99.609 (99.985)
2022-06-17 19:01:20 - INFO - TRAINING - Epoch: [165][140/196]	Time 0.103 (0.128)	Data 0.000 (0.014)	Loss 0.0785 (0.0723)	Prec@1 96.484 (97.692)	Prec@5 100.000 (99.986)
2022-06-17 19:01:21 - INFO - TRAINING - Epoch: [165][150/196]	Time 0.130 (0.127)	Data 0.000 (0.013)	Loss 0.0883 (0.0722)	Prec@1 95.703 (97.690)	Prec@5 100.000 (99.987)
2022-06-17 19:01:22 - INFO - TRAINING - Epoch: [165][160/196]	Time 0.108 (0.126)	Data 0.000 (0.013)	Loss 0.0561 (0.0717)	Prec@1 97.656 (97.705)	Prec@5 100.000 (99.988)
2022-06-17 19:01:23 - INFO - TRAINING - Epoch: [165][170/196]	Time 0.124 (0.126)	Data 0.000 (0.012)	Loss 0.0440 (0.0722)	Prec@1 98.438 (97.672)	Prec@5 100.000 (99.989)
2022-06-17 19:01:24 - INFO - TRAINING - Epoch: [165][180/196]	Time 0.120 (0.125)	Data 0.000 (0.011)	Loss 0.0784 (0.0723)	Prec@1 96.484 (97.650)	Prec@5 100.000 (99.989)
2022-06-17 19:01:26 - INFO - TRAINING - Epoch: [165][190/196]	Time 0.104 (0.125)	Data 0.000 (0.011)	Loss 0.0862 (0.0719)	Prec@1 96.094 (97.660)	Prec@5 100.000 (99.990)
2022-06-17 19:01:28 - INFO - EVALUATING - Epoch: [165][0/40]	Time 1.942 (1.942)	Data 1.896 (1.896)	Loss 0.2688 (0.2688)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 19:01:29 - INFO - EVALUATING - Epoch: [165][10/40]	Time 0.065 (0.261)	Data 0.000 (0.214)	Loss 0.4864 (0.4296)	Prec@1 87.500 (88.175)	Prec@5 99.219 (99.467)
2022-06-17 19:01:30 - INFO - EVALUATING - Epoch: [165][20/40]	Time 0.117 (0.169)	Data 0.075 (0.121)	Loss 0.3610 (0.4318)	Prec@1 87.500 (88.021)	Prec@5 99.609 (99.423)
2022-06-17 19:01:31 - INFO - EVALUATING - Epoch: [165][30/40]	Time 0.060 (0.152)	Data 0.000 (0.105)	Loss 0.5434 (0.4238)	Prec@1 87.109 (88.243)	Prec@5 100.000 (99.471)
2022-06-17 19:01:33 - INFO - 
 Epoch: 166	Training Loss 0.0717 	Training Prec@1 97.666 	Training Prec@5 99.990 	Validation Loss 0.4187 	Validation Prec@1 88.210 	Validation Prec@5 99.540 

2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:01:33 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:01:35 - INFO - TRAINING - Epoch: [166][0/196]	Time 1.837 (1.837)	Data 1.784 (1.784)	Loss 0.0717 (0.0717)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:01:36 - INFO - TRAINING - Epoch: [166][10/196]	Time 0.109 (0.274)	Data 0.000 (0.174)	Loss 0.0654 (0.0654)	Prec@1 98.438 (97.976)	Prec@5 100.000 (100.000)
2022-06-17 19:01:37 - INFO - TRAINING - Epoch: [166][20/196]	Time 0.106 (0.195)	Data 0.000 (0.091)	Loss 0.1057 (0.0667)	Prec@1 97.656 (97.786)	Prec@5 100.000 (100.000)
2022-06-17 19:01:38 - INFO - TRAINING - Epoch: [166][30/196]	Time 0.106 (0.166)	Data 0.000 (0.062)	Loss 0.0442 (0.0683)	Prec@1 98.438 (97.669)	Prec@5 100.000 (100.000)
2022-06-17 19:01:39 - INFO - TRAINING - Epoch: [166][40/196]	Time 0.112 (0.151)	Data 0.000 (0.047)	Loss 0.0847 (0.0677)	Prec@1 97.656 (97.742)	Prec@5 100.000 (100.000)
2022-06-17 19:01:40 - INFO - TRAINING - Epoch: [166][50/196]	Time 0.112 (0.143)	Data 0.000 (0.038)	Loss 0.0622 (0.0679)	Prec@1 98.828 (97.718)	Prec@5 100.000 (99.992)
2022-06-17 19:01:41 - INFO - TRAINING - Epoch: [166][60/196]	Time 0.108 (0.137)	Data 0.000 (0.032)	Loss 0.0891 (0.0685)	Prec@1 96.484 (97.643)	Prec@5 100.000 (99.987)
2022-06-17 19:01:42 - INFO - TRAINING - Epoch: [166][70/196]	Time 0.106 (0.132)	Data 0.000 (0.027)	Loss 0.0696 (0.0678)	Prec@1 97.266 (97.662)	Prec@5 100.000 (99.989)
2022-06-17 19:01:43 - INFO - TRAINING - Epoch: [166][80/196]	Time 0.102 (0.129)	Data 0.000 (0.024)	Loss 0.0949 (0.0686)	Prec@1 97.266 (97.632)	Prec@5 100.000 (99.990)
2022-06-17 19:01:44 - INFO - TRAINING - Epoch: [166][90/196]	Time 0.111 (0.126)	Data 0.000 (0.021)	Loss 0.0774 (0.0688)	Prec@1 97.656 (97.639)	Prec@5 100.000 (99.991)
2022-06-17 19:01:45 - INFO - TRAINING - Epoch: [166][100/196]	Time 0.101 (0.124)	Data 0.000 (0.019)	Loss 0.0840 (0.0689)	Prec@1 96.875 (97.645)	Prec@5 100.000 (99.992)
2022-06-17 19:01:46 - INFO - TRAINING - Epoch: [166][110/196]	Time 0.109 (0.123)	Data 0.000 (0.018)	Loss 0.0737 (0.0692)	Prec@1 97.656 (97.646)	Prec@5 100.000 (99.989)
2022-06-17 19:01:47 - INFO - TRAINING - Epoch: [166][120/196]	Time 0.103 (0.121)	Data 0.000 (0.016)	Loss 0.0766 (0.0697)	Prec@1 96.094 (97.627)	Prec@5 100.000 (99.984)
2022-06-17 19:01:48 - INFO - TRAINING - Epoch: [166][130/196]	Time 0.135 (0.120)	Data 0.001 (0.015)	Loss 0.0376 (0.0696)	Prec@1 98.828 (97.623)	Prec@5 100.000 (99.985)
2022-06-17 19:01:50 - INFO - TRAINING - Epoch: [166][140/196]	Time 0.111 (0.120)	Data 0.000 (0.014)	Loss 0.0527 (0.0694)	Prec@1 98.438 (97.642)	Prec@5 100.000 (99.983)
2022-06-17 19:01:51 - INFO - TRAINING - Epoch: [166][150/196]	Time 0.103 (0.119)	Data 0.000 (0.013)	Loss 0.0535 (0.0697)	Prec@1 98.047 (97.625)	Prec@5 100.000 (99.984)
2022-06-17 19:01:52 - INFO - TRAINING - Epoch: [166][160/196]	Time 0.113 (0.118)	Data 0.000 (0.012)	Loss 0.0691 (0.0695)	Prec@1 97.656 (97.625)	Prec@5 100.000 (99.985)
2022-06-17 19:01:53 - INFO - TRAINING - Epoch: [166][170/196]	Time 0.124 (0.118)	Data 0.000 (0.012)	Loss 0.0839 (0.0694)	Prec@1 96.875 (97.629)	Prec@5 100.000 (99.986)
2022-06-17 19:01:54 - INFO - TRAINING - Epoch: [166][180/196]	Time 0.102 (0.117)	Data 0.000 (0.011)	Loss 0.0936 (0.0695)	Prec@1 96.484 (97.637)	Prec@5 100.000 (99.987)
2022-06-17 19:01:55 - INFO - TRAINING - Epoch: [166][190/196]	Time 0.101 (0.117)	Data 0.000 (0.010)	Loss 0.0617 (0.0697)	Prec@1 97.656 (97.632)	Prec@5 100.000 (99.986)
2022-06-17 19:01:57 - INFO - EVALUATING - Epoch: [166][0/40]	Time 1.424 (1.424)	Data 1.378 (1.378)	Loss 0.2685 (0.2685)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:01:58 - INFO - EVALUATING - Epoch: [166][10/40]	Time 0.106 (0.262)	Data 0.061 (0.215)	Loss 0.4876 (0.4287)	Prec@1 87.891 (88.388)	Prec@5 99.219 (99.467)
2022-06-17 19:01:59 - INFO - EVALUATING - Epoch: [166][20/40]	Time 0.045 (0.174)	Data 0.001 (0.126)	Loss 0.3583 (0.4322)	Prec@1 87.500 (88.002)	Prec@5 100.000 (99.405)
2022-06-17 19:02:00 - INFO - EVALUATING - Epoch: [166][30/40]	Time 0.089 (0.152)	Data 0.048 (0.105)	Loss 0.5404 (0.4243)	Prec@1 87.500 (88.231)	Prec@5 100.000 (99.471)
2022-06-17 19:02:02 - INFO - 
 Epoch: 167	Training Loss 0.0697 	Training Prec@1 97.632 	Training Prec@5 99.986 	Validation Loss 0.4184 	Validation Prec@1 88.320 	Validation Prec@5 99.530 

2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:02:02 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:02:04 - INFO - TRAINING - Epoch: [167][0/196]	Time 1.766 (1.766)	Data 1.715 (1.715)	Loss 0.0445 (0.0445)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 19:02:05 - INFO - TRAINING - Epoch: [167][10/196]	Time 0.112 (0.268)	Data 0.055 (0.179)	Loss 0.0781 (0.0682)	Prec@1 97.266 (97.763)	Prec@5 100.000 (100.000)
2022-06-17 19:02:06 - INFO - TRAINING - Epoch: [167][20/196]	Time 0.108 (0.195)	Data 0.000 (0.094)	Loss 0.0672 (0.0645)	Prec@1 97.266 (97.898)	Prec@5 100.000 (100.000)
2022-06-17 19:02:07 - INFO - TRAINING - Epoch: [167][30/196]	Time 0.106 (0.169)	Data 0.000 (0.064)	Loss 0.0714 (0.0660)	Prec@1 96.875 (97.795)	Prec@5 100.000 (99.987)
2022-06-17 19:02:09 - INFO - TRAINING - Epoch: [167][40/196]	Time 0.108 (0.157)	Data 0.000 (0.048)	Loss 0.0490 (0.0644)	Prec@1 99.219 (97.894)	Prec@5 100.000 (99.990)
2022-06-17 19:02:10 - INFO - TRAINING - Epoch: [167][50/196]	Time 0.123 (0.149)	Data 0.000 (0.039)	Loss 0.0850 (0.0653)	Prec@1 97.266 (97.917)	Prec@5 100.000 (99.992)
2022-06-17 19:02:11 - INFO - TRAINING - Epoch: [167][60/196]	Time 0.105 (0.142)	Data 0.000 (0.033)	Loss 0.0537 (0.0657)	Prec@1 98.828 (97.938)	Prec@5 100.000 (99.994)
2022-06-17 19:02:12 - INFO - TRAINING - Epoch: [167][70/196]	Time 0.130 (0.139)	Data 0.000 (0.028)	Loss 0.0698 (0.0653)	Prec@1 97.266 (97.876)	Prec@5 100.000 (99.994)
2022-06-17 19:02:13 - INFO - TRAINING - Epoch: [167][80/196]	Time 0.119 (0.136)	Data 0.000 (0.025)	Loss 0.0503 (0.0658)	Prec@1 98.047 (97.815)	Prec@5 100.000 (99.995)
2022-06-17 19:02:14 - INFO - TRAINING - Epoch: [167][90/196]	Time 0.126 (0.134)	Data 0.000 (0.022)	Loss 0.0642 (0.0659)	Prec@1 97.656 (97.802)	Prec@5 100.000 (99.996)
2022-06-17 19:02:15 - INFO - TRAINING - Epoch: [167][100/196]	Time 0.106 (0.132)	Data 0.000 (0.020)	Loss 0.0435 (0.0661)	Prec@1 98.828 (97.815)	Prec@5 100.000 (99.996)
2022-06-17 19:02:17 - INFO - TRAINING - Epoch: [167][110/196]	Time 0.107 (0.130)	Data 0.000 (0.018)	Loss 0.0422 (0.0662)	Prec@1 98.438 (97.801)	Prec@5 100.000 (99.996)
2022-06-17 19:02:18 - INFO - TRAINING - Epoch: [167][120/196]	Time 0.102 (0.129)	Data 0.000 (0.017)	Loss 0.0821 (0.0668)	Prec@1 98.047 (97.782)	Prec@5 100.000 (99.997)
2022-06-17 19:02:19 - INFO - TRAINING - Epoch: [167][130/196]	Time 0.107 (0.128)	Data 0.000 (0.015)	Loss 0.0604 (0.0662)	Prec@1 98.047 (97.808)	Prec@5 100.000 (99.997)
2022-06-17 19:02:20 - INFO - TRAINING - Epoch: [167][140/196]	Time 0.121 (0.127)	Data 0.000 (0.014)	Loss 0.1154 (0.0661)	Prec@1 94.922 (97.803)	Prec@5 100.000 (99.994)
2022-06-17 19:02:21 - INFO - TRAINING - Epoch: [167][150/196]	Time 0.110 (0.126)	Data 0.000 (0.013)	Loss 0.0682 (0.0666)	Prec@1 98.047 (97.767)	Prec@5 100.000 (99.995)
2022-06-17 19:02:22 - INFO - TRAINING - Epoch: [167][160/196]	Time 0.102 (0.125)	Data 0.000 (0.013)	Loss 0.0789 (0.0666)	Prec@1 97.266 (97.773)	Prec@5 100.000 (99.995)
2022-06-17 19:02:23 - INFO - TRAINING - Epoch: [167][170/196]	Time 0.108 (0.125)	Data 0.000 (0.012)	Loss 0.0380 (0.0670)	Prec@1 98.828 (97.745)	Prec@5 100.000 (99.993)
2022-06-17 19:02:25 - INFO - TRAINING - Epoch: [167][180/196]	Time 0.127 (0.125)	Data 0.000 (0.011)	Loss 0.0734 (0.0679)	Prec@1 97.656 (97.732)	Prec@5 100.000 (99.991)
2022-06-17 19:02:26 - INFO - TRAINING - Epoch: [167][190/196]	Time 0.118 (0.124)	Data 0.000 (0.011)	Loss 0.0633 (0.0686)	Prec@1 97.266 (97.687)	Prec@5 100.000 (99.990)
2022-06-17 19:02:28 - INFO - EVALUATING - Epoch: [167][0/40]	Time 1.422 (1.422)	Data 1.376 (1.376)	Loss 0.2684 (0.2684)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:02:29 - INFO - EVALUATING - Epoch: [167][10/40]	Time 0.093 (0.246)	Data 0.049 (0.199)	Loss 0.4844 (0.4320)	Prec@1 87.109 (88.175)	Prec@5 99.219 (99.503)
2022-06-17 19:02:30 - INFO - EVALUATING - Epoch: [167][20/40]	Time 0.074 (0.166)	Data 0.030 (0.118)	Loss 0.3552 (0.4341)	Prec@1 87.500 (87.965)	Prec@5 100.000 (99.423)
2022-06-17 19:02:31 - INFO - EVALUATING - Epoch: [167][30/40]	Time 0.053 (0.156)	Data 0.000 (0.110)	Loss 0.5379 (0.4262)	Prec@1 87.109 (88.206)	Prec@5 100.000 (99.483)
2022-06-17 19:02:33 - INFO - 
 Epoch: 168	Training Loss 0.0689 	Training Prec@1 97.668 	Training Prec@5 99.990 	Validation Loss 0.4211 	Validation Prec@1 88.230 	Validation Prec@5 99.540 

2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:02:33 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:02:35 - INFO - TRAINING - Epoch: [168][0/196]	Time 2.003 (2.003)	Data 1.952 (1.952)	Loss 0.0826 (0.0826)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:02:36 - INFO - TRAINING - Epoch: [168][10/196]	Time 0.106 (0.291)	Data 0.000 (0.178)	Loss 0.0662 (0.0671)	Prec@1 98.438 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:02:37 - INFO - TRAINING - Epoch: [168][20/196]	Time 0.108 (0.208)	Data 0.000 (0.093)	Loss 0.0596 (0.0693)	Prec@1 97.266 (97.824)	Prec@5 100.000 (100.000)
2022-06-17 19:02:38 - INFO - TRAINING - Epoch: [168][30/196]	Time 0.118 (0.178)	Data 0.000 (0.063)	Loss 0.0814 (0.0696)	Prec@1 96.484 (97.757)	Prec@5 100.000 (100.000)
2022-06-17 19:02:40 - INFO - TRAINING - Epoch: [168][40/196]	Time 0.105 (0.162)	Data 0.000 (0.048)	Loss 0.0468 (0.0689)	Prec@1 98.438 (97.742)	Prec@5 100.000 (100.000)
2022-06-17 19:02:41 - INFO - TRAINING - Epoch: [168][50/196]	Time 0.112 (0.153)	Data 0.000 (0.039)	Loss 0.0526 (0.0690)	Prec@1 98.438 (97.702)	Prec@5 100.000 (100.000)
2022-06-17 19:02:42 - INFO - TRAINING - Epoch: [168][60/196]	Time 0.116 (0.145)	Data 0.000 (0.032)	Loss 0.1219 (0.0689)	Prec@1 96.094 (97.746)	Prec@5 100.000 (100.000)
2022-06-17 19:02:43 - INFO - TRAINING - Epoch: [168][70/196]	Time 0.113 (0.141)	Data 0.000 (0.028)	Loss 0.0569 (0.0691)	Prec@1 98.438 (97.766)	Prec@5 100.000 (100.000)
2022-06-17 19:02:44 - INFO - TRAINING - Epoch: [168][80/196]	Time 0.123 (0.137)	Data 0.000 (0.024)	Loss 0.0465 (0.0692)	Prec@1 98.438 (97.767)	Prec@5 100.000 (100.000)
2022-06-17 19:02:45 - INFO - TRAINING - Epoch: [168][90/196]	Time 0.128 (0.135)	Data 0.000 (0.022)	Loss 0.0530 (0.0686)	Prec@1 98.438 (97.798)	Prec@5 100.000 (100.000)
2022-06-17 19:02:46 - INFO - TRAINING - Epoch: [168][100/196]	Time 0.102 (0.132)	Data 0.000 (0.020)	Loss 0.0738 (0.0688)	Prec@1 97.656 (97.772)	Prec@5 99.609 (99.992)
2022-06-17 19:02:47 - INFO - TRAINING - Epoch: [168][110/196]	Time 0.133 (0.131)	Data 0.000 (0.018)	Loss 0.0434 (0.0695)	Prec@1 99.219 (97.734)	Prec@5 100.000 (99.993)
2022-06-17 19:02:49 - INFO - TRAINING - Epoch: [168][120/196]	Time 0.122 (0.129)	Data 0.000 (0.016)	Loss 0.0781 (0.0705)	Prec@1 97.266 (97.701)	Prec@5 100.000 (99.990)
2022-06-17 19:02:50 - INFO - TRAINING - Epoch: [168][130/196]	Time 0.137 (0.128)	Data 0.000 (0.015)	Loss 0.0878 (0.0708)	Prec@1 96.484 (97.695)	Prec@5 100.000 (99.991)
2022-06-17 19:02:51 - INFO - TRAINING - Epoch: [168][140/196]	Time 0.111 (0.127)	Data 0.000 (0.014)	Loss 0.0589 (0.0709)	Prec@1 98.828 (97.698)	Prec@5 100.000 (99.992)
2022-06-17 19:02:52 - INFO - TRAINING - Epoch: [168][150/196]	Time 0.108 (0.126)	Data 0.000 (0.013)	Loss 0.0541 (0.0705)	Prec@1 98.828 (97.724)	Prec@5 100.000 (99.992)
2022-06-17 19:02:53 - INFO - TRAINING - Epoch: [168][160/196]	Time 0.116 (0.125)	Data 0.000 (0.012)	Loss 0.0446 (0.0701)	Prec@1 98.828 (97.746)	Prec@5 100.000 (99.993)
2022-06-17 19:02:54 - INFO - TRAINING - Epoch: [168][170/196]	Time 0.117 (0.125)	Data 0.000 (0.012)	Loss 0.0957 (0.0701)	Prec@1 95.703 (97.738)	Prec@5 100.000 (99.993)
2022-06-17 19:02:55 - INFO - TRAINING - Epoch: [168][180/196]	Time 0.113 (0.124)	Data 0.000 (0.011)	Loss 0.0659 (0.0697)	Prec@1 98.828 (97.751)	Prec@5 100.000 (99.994)
2022-06-17 19:02:56 - INFO - TRAINING - Epoch: [168][190/196]	Time 0.103 (0.123)	Data 0.000 (0.010)	Loss 0.0986 (0.0701)	Prec@1 96.484 (97.746)	Prec@5 100.000 (99.990)
2022-06-17 19:02:59 - INFO - EVALUATING - Epoch: [168][0/40]	Time 1.644 (1.644)	Data 1.599 (1.599)	Loss 0.2702 (0.2702)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
2022-06-17 19:03:00 - INFO - EVALUATING - Epoch: [168][10/40]	Time 0.044 (0.267)	Data 0.000 (0.219)	Loss 0.4799 (0.4297)	Prec@1 87.500 (88.210)	Prec@5 99.219 (99.432)
2022-06-17 19:03:01 - INFO - EVALUATING - Epoch: [168][20/40]	Time 0.049 (0.176)	Data 0.000 (0.126)	Loss 0.3572 (0.4320)	Prec@1 87.891 (88.095)	Prec@5 99.609 (99.386)
2022-06-17 19:03:02 - INFO - EVALUATING - Epoch: [168][30/40]	Time 0.050 (0.158)	Data 0.000 (0.109)	Loss 0.5382 (0.4239)	Prec@1 86.719 (88.231)	Prec@5 100.000 (99.446)
2022-06-17 19:03:04 - INFO - 
 Epoch: 169	Training Loss 0.0701 	Training Prec@1 97.742 	Training Prec@5 99.990 	Validation Loss 0.4194 	Validation Prec@1 88.270 	Validation Prec@5 99.520 

2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:03:04 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:03:05 - INFO - TRAINING - Epoch: [169][0/196]	Time 1.587 (1.587)	Data 1.535 (1.535)	Loss 0.0644 (0.0644)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 19:03:07 - INFO - TRAINING - Epoch: [169][10/196]	Time 0.109 (0.274)	Data 0.000 (0.185)	Loss 0.0824 (0.0698)	Prec@1 97.656 (97.834)	Prec@5 100.000 (100.000)
2022-06-17 19:03:08 - INFO - TRAINING - Epoch: [169][20/196]	Time 0.110 (0.197)	Data 0.000 (0.097)	Loss 0.1198 (0.0729)	Prec@1 96.094 (97.731)	Prec@5 100.000 (100.000)
2022-06-17 19:03:09 - INFO - TRAINING - Epoch: [169][30/196]	Time 0.112 (0.169)	Data 0.000 (0.066)	Loss 0.0558 (0.0722)	Prec@1 98.828 (97.694)	Prec@5 100.000 (99.987)
2022-06-17 19:03:10 - INFO - TRAINING - Epoch: [169][40/196]	Time 0.110 (0.156)	Data 0.000 (0.050)	Loss 0.0552 (0.0710)	Prec@1 98.438 (97.742)	Prec@5 100.000 (99.990)
2022-06-17 19:03:11 - INFO - TRAINING - Epoch: [169][50/196]	Time 0.118 (0.148)	Data 0.000 (0.040)	Loss 0.0740 (0.0700)	Prec@1 98.047 (97.809)	Prec@5 100.000 (99.992)
2022-06-17 19:03:12 - INFO - TRAINING - Epoch: [169][60/196]	Time 0.112 (0.142)	Data 0.000 (0.034)	Loss 0.0610 (0.0703)	Prec@1 97.656 (97.810)	Prec@5 100.000 (99.994)
2022-06-17 19:03:14 - INFO - TRAINING - Epoch: [169][70/196]	Time 0.116 (0.139)	Data 0.000 (0.029)	Loss 0.0403 (0.0682)	Prec@1 99.219 (97.882)	Prec@5 100.000 (99.989)
2022-06-17 19:03:15 - INFO - TRAINING - Epoch: [169][80/196]	Time 0.107 (0.136)	Data 0.000 (0.025)	Loss 0.0733 (0.0677)	Prec@1 97.656 (97.864)	Prec@5 100.000 (99.990)
2022-06-17 19:03:16 - INFO - TRAINING - Epoch: [169][90/196]	Time 0.135 (0.134)	Data 0.000 (0.023)	Loss 0.0925 (0.0682)	Prec@1 96.875 (97.819)	Prec@5 100.000 (99.991)
2022-06-17 19:03:17 - INFO - TRAINING - Epoch: [169][100/196]	Time 0.126 (0.132)	Data 0.000 (0.020)	Loss 0.1516 (0.0688)	Prec@1 95.312 (97.799)	Prec@5 100.000 (99.992)
2022-06-17 19:03:18 - INFO - TRAINING - Epoch: [169][110/196]	Time 0.137 (0.131)	Data 0.000 (0.019)	Loss 0.0812 (0.0687)	Prec@1 97.656 (97.793)	Prec@5 100.000 (99.993)
2022-06-17 19:03:19 - INFO - TRAINING - Epoch: [169][120/196]	Time 0.115 (0.129)	Data 0.000 (0.017)	Loss 0.0284 (0.0689)	Prec@1 99.219 (97.776)	Prec@5 100.000 (99.994)
2022-06-17 19:03:21 - INFO - TRAINING - Epoch: [169][130/196]	Time 0.123 (0.128)	Data 0.000 (0.016)	Loss 0.0923 (0.0685)	Prec@1 97.656 (97.799)	Prec@5 100.000 (99.994)
2022-06-17 19:03:22 - INFO - TRAINING - Epoch: [169][140/196]	Time 0.123 (0.127)	Data 0.000 (0.015)	Loss 0.0844 (0.0692)	Prec@1 96.875 (97.756)	Prec@5 100.000 (99.994)
2022-06-17 19:03:23 - INFO - TRAINING - Epoch: [169][150/196]	Time 0.119 (0.126)	Data 0.000 (0.014)	Loss 0.0430 (0.0686)	Prec@1 98.828 (97.778)	Prec@5 100.000 (99.995)
2022-06-17 19:03:24 - INFO - TRAINING - Epoch: [169][160/196]	Time 0.104 (0.125)	Data 0.000 (0.013)	Loss 0.0410 (0.0693)	Prec@1 98.828 (97.761)	Prec@5 100.000 (99.990)
2022-06-17 19:03:25 - INFO - TRAINING - Epoch: [169][170/196]	Time 0.122 (0.125)	Data 0.000 (0.012)	Loss 0.0260 (0.0692)	Prec@1 99.609 (97.754)	Prec@5 100.000 (99.991)
2022-06-17 19:03:26 - INFO - TRAINING - Epoch: [169][180/196]	Time 0.113 (0.124)	Data 0.000 (0.012)	Loss 0.0466 (0.0688)	Prec@1 98.438 (97.760)	Prec@5 100.000 (99.991)
2022-06-17 19:03:27 - INFO - TRAINING - Epoch: [169][190/196]	Time 0.104 (0.124)	Data 0.000 (0.011)	Loss 0.0540 (0.0690)	Prec@1 98.438 (97.748)	Prec@5 100.000 (99.992)
2022-06-17 19:03:30 - INFO - EVALUATING - Epoch: [169][0/40]	Time 1.615 (1.615)	Data 1.568 (1.568)	Loss 0.2771 (0.2771)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 19:03:30 - INFO - EVALUATING - Epoch: [169][10/40]	Time 0.054 (0.230)	Data 0.000 (0.181)	Loss 0.4825 (0.4297)	Prec@1 87.500 (88.459)	Prec@5 99.219 (99.467)
2022-06-17 19:03:31 - INFO - EVALUATING - Epoch: [169][20/40]	Time 0.098 (0.157)	Data 0.058 (0.110)	Loss 0.3545 (0.4331)	Prec@1 87.891 (88.170)	Prec@5 99.609 (99.405)
2022-06-17 19:03:32 - INFO - EVALUATING - Epoch: [169][30/40]	Time 0.087 (0.139)	Data 0.046 (0.094)	Loss 0.5355 (0.4240)	Prec@1 87.500 (88.332)	Prec@5 100.000 (99.471)
2022-06-17 19:03:34 - INFO - 
 Epoch: 170	Training Loss 0.0698 	Training Prec@1 97.710 	Training Prec@5 99.992 	Validation Loss 0.4191 	Validation Prec@1 88.330 	Validation Prec@5 99.550 

2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:03:34 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:03:36 - INFO - TRAINING - Epoch: [170][0/196]	Time 1.760 (1.760)	Data 1.707 (1.707)	Loss 0.0843 (0.0843)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:03:37 - INFO - TRAINING - Epoch: [170][10/196]	Time 0.115 (0.266)	Data 0.000 (0.155)	Loss 0.0572 (0.0797)	Prec@1 98.438 (97.053)	Prec@5 100.000 (100.000)
2022-06-17 19:03:38 - INFO - TRAINING - Epoch: [170][20/196]	Time 0.129 (0.196)	Data 0.000 (0.082)	Loss 0.0876 (0.0808)	Prec@1 96.484 (97.228)	Prec@5 100.000 (100.000)
2022-06-17 19:03:40 - INFO - TRAINING - Epoch: [170][30/196]	Time 0.121 (0.172)	Data 0.000 (0.055)	Loss 0.0737 (0.0753)	Prec@1 97.656 (97.492)	Prec@5 100.000 (100.000)
2022-06-17 19:03:41 - INFO - TRAINING - Epoch: [170][40/196]	Time 0.111 (0.159)	Data 0.000 (0.042)	Loss 0.0606 (0.0739)	Prec@1 97.656 (97.561)	Prec@5 100.000 (100.000)
2022-06-17 19:03:42 - INFO - TRAINING - Epoch: [170][50/196]	Time 0.111 (0.151)	Data 0.000 (0.034)	Loss 0.0454 (0.0707)	Prec@1 99.609 (97.725)	Prec@5 100.000 (100.000)
2022-06-17 19:03:43 - INFO - TRAINING - Epoch: [170][60/196]	Time 0.135 (0.146)	Data 0.000 (0.028)	Loss 0.0693 (0.0697)	Prec@1 98.047 (97.739)	Prec@5 100.000 (100.000)
2022-06-17 19:03:44 - INFO - TRAINING - Epoch: [170][70/196]	Time 0.102 (0.142)	Data 0.000 (0.024)	Loss 0.0452 (0.0699)	Prec@1 99.219 (97.728)	Prec@5 100.000 (100.000)
2022-06-17 19:03:45 - INFO - TRAINING - Epoch: [170][80/196]	Time 0.129 (0.139)	Data 0.000 (0.021)	Loss 0.0847 (0.0707)	Prec@1 97.266 (97.690)	Prec@5 100.000 (99.995)
2022-06-17 19:03:47 - INFO - TRAINING - Epoch: [170][90/196]	Time 0.120 (0.136)	Data 0.000 (0.019)	Loss 0.0721 (0.0709)	Prec@1 98.047 (97.678)	Prec@5 100.000 (99.991)
2022-06-17 19:03:48 - INFO - TRAINING - Epoch: [170][100/196]	Time 0.104 (0.134)	Data 0.000 (0.017)	Loss 0.0529 (0.0707)	Prec@1 98.047 (97.691)	Prec@5 100.000 (99.988)
2022-06-17 19:03:49 - INFO - TRAINING - Epoch: [170][110/196]	Time 0.130 (0.133)	Data 0.000 (0.016)	Loss 0.0829 (0.0702)	Prec@1 96.875 (97.688)	Prec@5 100.000 (99.989)
2022-06-17 19:03:50 - INFO - TRAINING - Epoch: [170][120/196]	Time 0.105 (0.131)	Data 0.000 (0.014)	Loss 0.0444 (0.0698)	Prec@1 98.438 (97.711)	Prec@5 100.000 (99.990)
2022-06-17 19:03:51 - INFO - TRAINING - Epoch: [170][130/196]	Time 0.104 (0.130)	Data 0.000 (0.013)	Loss 0.0698 (0.0693)	Prec@1 96.484 (97.716)	Prec@5 100.000 (99.991)
2022-06-17 19:03:52 - INFO - TRAINING - Epoch: [170][140/196]	Time 0.107 (0.129)	Data 0.000 (0.012)	Loss 0.0808 (0.0697)	Prec@1 97.656 (97.706)	Prec@5 100.000 (99.992)
2022-06-17 19:03:54 - INFO - TRAINING - Epoch: [170][150/196]	Time 0.122 (0.129)	Data 0.000 (0.012)	Loss 0.0766 (0.0689)	Prec@1 98.047 (97.724)	Prec@5 100.000 (99.992)
2022-06-17 19:03:55 - INFO - TRAINING - Epoch: [170][160/196]	Time 0.129 (0.128)	Data 0.000 (0.011)	Loss 0.0545 (0.0688)	Prec@1 98.438 (97.729)	Prec@5 100.000 (99.993)
2022-06-17 19:03:56 - INFO - TRAINING - Epoch: [170][170/196]	Time 0.109 (0.127)	Data 0.000 (0.010)	Loss 0.0576 (0.0687)	Prec@1 98.047 (97.725)	Prec@5 100.000 (99.993)
2022-06-17 19:03:57 - INFO - TRAINING - Epoch: [170][180/196]	Time 0.111 (0.127)	Data 0.000 (0.010)	Loss 0.0363 (0.0685)	Prec@1 99.219 (97.725)	Prec@5 100.000 (99.994)
2022-06-17 19:03:58 - INFO - TRAINING - Epoch: [170][190/196]	Time 0.103 (0.126)	Data 0.000 (0.009)	Loss 0.0735 (0.0686)	Prec@1 97.656 (97.714)	Prec@5 100.000 (99.994)
2022-06-17 19:04:00 - INFO - EVALUATING - Epoch: [170][0/40]	Time 1.559 (1.559)	Data 1.514 (1.514)	Loss 0.2712 (0.2712)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:04:02 - INFO - EVALUATING - Epoch: [170][10/40]	Time 0.242 (0.266)	Data 0.198 (0.219)	Loss 0.4817 (0.4297)	Prec@1 88.281 (88.175)	Prec@5 99.219 (99.432)
2022-06-17 19:04:03 - INFO - EVALUATING - Epoch: [170][20/40]	Time 0.105 (0.172)	Data 0.062 (0.125)	Loss 0.3521 (0.4326)	Prec@1 87.891 (88.039)	Prec@5 99.609 (99.386)
2022-06-17 19:04:04 - INFO - EVALUATING - Epoch: [170][30/40]	Time 0.101 (0.151)	Data 0.057 (0.105)	Loss 0.5409 (0.4248)	Prec@1 86.328 (88.319)	Prec@5 100.000 (99.458)
2022-06-17 19:04:05 - INFO - 
 Epoch: 171	Training Loss 0.0689 	Training Prec@1 97.696 	Training Prec@5 99.994 	Validation Loss 0.4197 	Validation Prec@1 88.350 	Validation Prec@5 99.520 

2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:04:05 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:04:07 - INFO - TRAINING - Epoch: [171][0/196]	Time 1.245 (1.245)	Data 1.192 (1.192)	Loss 0.0559 (0.0559)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 19:04:08 - INFO - TRAINING - Epoch: [171][10/196]	Time 0.148 (0.250)	Data 0.000 (0.158)	Loss 0.0465 (0.0671)	Prec@1 99.219 (97.727)	Prec@5 100.000 (100.000)
2022-06-17 19:04:09 - INFO - TRAINING - Epoch: [171][20/196]	Time 0.108 (0.182)	Data 0.000 (0.083)	Loss 0.0725 (0.0693)	Prec@1 96.875 (97.712)	Prec@5 100.000 (99.981)
2022-06-17 19:04:10 - INFO - TRAINING - Epoch: [171][30/196]	Time 0.107 (0.160)	Data 0.000 (0.056)	Loss 0.0439 (0.0709)	Prec@1 98.438 (97.593)	Prec@5 100.000 (99.975)
2022-06-17 19:04:11 - INFO - TRAINING - Epoch: [171][40/196]	Time 0.101 (0.146)	Data 0.000 (0.043)	Loss 0.0640 (0.0713)	Prec@1 97.656 (97.590)	Prec@5 100.000 (99.971)
2022-06-17 19:04:13 - INFO - TRAINING - Epoch: [171][50/196]	Time 0.103 (0.138)	Data 0.000 (0.034)	Loss 0.0513 (0.0709)	Prec@1 98.438 (97.626)	Prec@5 100.000 (99.977)
2022-06-17 19:04:14 - INFO - TRAINING - Epoch: [171][60/196]	Time 0.102 (0.132)	Data 0.000 (0.029)	Loss 0.0634 (0.0696)	Prec@1 97.266 (97.650)	Prec@5 100.000 (99.981)
2022-06-17 19:04:15 - INFO - TRAINING - Epoch: [171][70/196]	Time 0.110 (0.128)	Data 0.000 (0.025)	Loss 0.0757 (0.0685)	Prec@1 97.656 (97.717)	Prec@5 100.000 (99.983)
2022-06-17 19:04:16 - INFO - TRAINING - Epoch: [171][80/196]	Time 0.110 (0.126)	Data 0.000 (0.022)	Loss 0.0804 (0.0688)	Prec@1 97.266 (97.700)	Prec@5 100.000 (99.986)
2022-06-17 19:04:17 - INFO - TRAINING - Epoch: [171][90/196]	Time 0.113 (0.125)	Data 0.000 (0.019)	Loss 0.0487 (0.0680)	Prec@1 99.219 (97.734)	Prec@5 100.000 (99.987)
2022-06-17 19:04:18 - INFO - TRAINING - Epoch: [171][100/196]	Time 0.121 (0.124)	Data 0.000 (0.018)	Loss 0.0721 (0.0684)	Prec@1 97.656 (97.718)	Prec@5 100.000 (99.985)
2022-06-17 19:04:19 - INFO - TRAINING - Epoch: [171][110/196]	Time 0.112 (0.123)	Data 0.001 (0.016)	Loss 0.0613 (0.0690)	Prec@1 98.047 (97.691)	Prec@5 100.000 (99.986)
2022-06-17 19:04:20 - INFO - TRAINING - Epoch: [171][120/196]	Time 0.101 (0.121)	Data 0.000 (0.015)	Loss 0.0578 (0.0687)	Prec@1 98.438 (97.692)	Prec@5 100.000 (99.987)
2022-06-17 19:04:21 - INFO - TRAINING - Epoch: [171][130/196]	Time 0.101 (0.120)	Data 0.000 (0.014)	Loss 0.0894 (0.0694)	Prec@1 97.656 (97.656)	Prec@5 100.000 (99.988)
2022-06-17 19:04:22 - INFO - TRAINING - Epoch: [171][140/196]	Time 0.106 (0.119)	Data 0.000 (0.013)	Loss 0.0651 (0.0705)	Prec@1 98.047 (97.581)	Prec@5 100.000 (99.989)
2022-06-17 19:04:23 - INFO - TRAINING - Epoch: [171][150/196]	Time 0.111 (0.118)	Data 0.000 (0.012)	Loss 0.0770 (0.0700)	Prec@1 97.656 (97.607)	Prec@5 100.000 (99.990)
2022-06-17 19:04:24 - INFO - TRAINING - Epoch: [171][160/196]	Time 0.130 (0.118)	Data 0.000 (0.011)	Loss 0.0509 (0.0703)	Prec@1 99.219 (97.608)	Prec@5 100.000 (99.988)
2022-06-17 19:04:26 - INFO - TRAINING - Epoch: [171][170/196]	Time 0.111 (0.118)	Data 0.000 (0.010)	Loss 0.0897 (0.0705)	Prec@1 96.094 (97.592)	Prec@5 100.000 (99.989)
2022-06-17 19:04:27 - INFO - TRAINING - Epoch: [171][180/196]	Time 0.114 (0.117)	Data 0.000 (0.010)	Loss 0.0952 (0.0704)	Prec@1 95.312 (97.600)	Prec@5 100.000 (99.987)
2022-06-17 19:04:28 - INFO - TRAINING - Epoch: [171][190/196]	Time 0.103 (0.117)	Data 0.000 (0.009)	Loss 0.0730 (0.0699)	Prec@1 96.875 (97.619)	Prec@5 100.000 (99.988)
2022-06-17 19:04:30 - INFO - EVALUATING - Epoch: [171][0/40]	Time 1.981 (1.981)	Data 1.936 (1.936)	Loss 0.2618 (0.2618)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:04:31 - INFO - EVALUATING - Epoch: [171][10/40]	Time 0.052 (0.271)	Data 0.000 (0.224)	Loss 0.4928 (0.4291)	Prec@1 87.500 (88.246)	Prec@5 98.828 (99.396)
2022-06-17 19:04:32 - INFO - EVALUATING - Epoch: [171][20/40]	Time 0.065 (0.167)	Data 0.000 (0.117)	Loss 0.3498 (0.4324)	Prec@1 87.109 (87.965)	Prec@5 99.609 (99.368)
2022-06-17 19:04:33 - INFO - EVALUATING - Epoch: [171][30/40]	Time 0.052 (0.149)	Data 0.000 (0.102)	Loss 0.5384 (0.4235)	Prec@1 86.719 (88.243)	Prec@5 100.000 (99.446)
2022-06-17 19:04:35 - INFO - 
 Epoch: 172	Training Loss 0.0699 	Training Prec@1 97.624 	Training Prec@5 99.988 	Validation Loss 0.4187 	Validation Prec@1 88.280 	Validation Prec@5 99.520 

2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:04:35 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:04:36 - INFO - TRAINING - Epoch: [172][0/196]	Time 1.372 (1.372)	Data 1.318 (1.318)	Loss 0.0503 (0.0503)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 19:04:38 - INFO - TRAINING - Epoch: [172][10/196]	Time 0.123 (0.251)	Data 0.000 (0.167)	Loss 0.0858 (0.0723)	Prec@1 96.484 (97.514)	Prec@5 100.000 (100.000)
2022-06-17 19:04:39 - INFO - TRAINING - Epoch: [172][20/196]	Time 0.120 (0.185)	Data 0.000 (0.094)	Loss 0.0653 (0.0715)	Prec@1 97.656 (97.526)	Prec@5 100.000 (100.000)
2022-06-17 19:04:40 - INFO - TRAINING - Epoch: [172][30/196]	Time 0.105 (0.163)	Data 0.000 (0.063)	Loss 0.0601 (0.0676)	Prec@1 98.047 (97.694)	Prec@5 100.000 (100.000)
2022-06-17 19:04:41 - INFO - TRAINING - Epoch: [172][40/196]	Time 0.131 (0.150)	Data 0.000 (0.048)	Loss 0.0933 (0.0677)	Prec@1 96.875 (97.618)	Prec@5 100.000 (100.000)
2022-06-17 19:04:42 - INFO - TRAINING - Epoch: [172][50/196]	Time 0.128 (0.144)	Data 0.000 (0.039)	Loss 0.0937 (0.0673)	Prec@1 96.484 (97.626)	Prec@5 100.000 (100.000)
2022-06-17 19:04:43 - INFO - TRAINING - Epoch: [172][60/196]	Time 0.116 (0.140)	Data 0.000 (0.032)	Loss 0.0921 (0.0673)	Prec@1 97.266 (97.631)	Prec@5 100.000 (100.000)
2022-06-17 19:04:45 - INFO - TRAINING - Epoch: [172][70/196]	Time 0.108 (0.136)	Data 0.000 (0.028)	Loss 0.0667 (0.0675)	Prec@1 98.438 (97.645)	Prec@5 100.000 (100.000)
2022-06-17 19:04:46 - INFO - TRAINING - Epoch: [172][80/196]	Time 0.123 (0.134)	Data 0.000 (0.024)	Loss 0.0407 (0.0673)	Prec@1 97.656 (97.666)	Prec@5 100.000 (100.000)
2022-06-17 19:04:47 - INFO - TRAINING - Epoch: [172][90/196]	Time 0.123 (0.131)	Data 0.000 (0.022)	Loss 0.0558 (0.0681)	Prec@1 98.438 (97.635)	Prec@5 100.000 (100.000)
2022-06-17 19:04:48 - INFO - TRAINING - Epoch: [172][100/196]	Time 0.105 (0.130)	Data 0.000 (0.020)	Loss 0.0493 (0.0676)	Prec@1 98.828 (97.664)	Prec@5 100.000 (100.000)
2022-06-17 19:04:49 - INFO - TRAINING - Epoch: [172][110/196]	Time 0.103 (0.129)	Data 0.000 (0.018)	Loss 0.0693 (0.0677)	Prec@1 98.828 (97.681)	Prec@5 100.000 (99.996)
2022-06-17 19:04:50 - INFO - TRAINING - Epoch: [172][120/196]	Time 0.125 (0.128)	Data 0.000 (0.016)	Loss 0.0810 (0.0685)	Prec@1 98.047 (97.634)	Prec@5 100.000 (99.994)
2022-06-17 19:04:52 - INFO - TRAINING - Epoch: [172][130/196]	Time 0.107 (0.127)	Data 0.000 (0.015)	Loss 0.0691 (0.0681)	Prec@1 97.266 (97.656)	Prec@5 100.000 (99.994)
2022-06-17 19:04:53 - INFO - TRAINING - Epoch: [172][140/196]	Time 0.114 (0.126)	Data 0.000 (0.014)	Loss 0.0945 (0.0682)	Prec@1 96.875 (97.659)	Prec@5 100.000 (99.994)
2022-06-17 19:04:54 - INFO - TRAINING - Epoch: [172][150/196]	Time 0.104 (0.125)	Data 0.000 (0.013)	Loss 0.0360 (0.0671)	Prec@1 99.609 (97.718)	Prec@5 100.000 (99.995)
2022-06-17 19:04:55 - INFO - TRAINING - Epoch: [172][160/196]	Time 0.129 (0.125)	Data 0.000 (0.012)	Loss 0.0816 (0.0669)	Prec@1 96.875 (97.744)	Prec@5 100.000 (99.995)
2022-06-17 19:04:56 - INFO - TRAINING - Epoch: [172][170/196]	Time 0.121 (0.124)	Data 0.000 (0.012)	Loss 0.0363 (0.0671)	Prec@1 99.219 (97.736)	Prec@5 100.000 (99.995)
2022-06-17 19:04:57 - INFO - TRAINING - Epoch: [172][180/196]	Time 0.104 (0.124)	Data 0.000 (0.011)	Loss 0.0934 (0.0675)	Prec@1 96.484 (97.727)	Prec@5 100.000 (99.996)
2022-06-17 19:04:58 - INFO - TRAINING - Epoch: [172][190/196]	Time 0.104 (0.122)	Data 0.000 (0.011)	Loss 0.0660 (0.0677)	Prec@1 98.438 (97.714)	Prec@5 100.000 (99.996)
2022-06-17 19:05:01 - INFO - EVALUATING - Epoch: [172][0/40]	Time 1.845 (1.845)	Data 1.799 (1.799)	Loss 0.2677 (0.2677)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:05:02 - INFO - EVALUATING - Epoch: [172][10/40]	Time 0.045 (0.280)	Data 0.001 (0.230)	Loss 0.4927 (0.4311)	Prec@1 88.281 (87.997)	Prec@5 99.219 (99.467)
2022-06-17 19:05:03 - INFO - EVALUATING - Epoch: [172][20/40]	Time 0.045 (0.171)	Data 0.000 (0.121)	Loss 0.3549 (0.4333)	Prec@1 88.672 (88.039)	Prec@5 100.000 (99.423)
2022-06-17 19:05:04 - INFO - EVALUATING - Epoch: [172][30/40]	Time 0.041 (0.151)	Data 0.000 (0.102)	Loss 0.5408 (0.4237)	Prec@1 86.719 (88.256)	Prec@5 100.000 (99.483)
2022-06-17 19:05:06 - INFO - 
 Epoch: 173	Training Loss 0.0679 	Training Prec@1 97.710 	Training Prec@5 99.996 	Validation Loss 0.4196 	Validation Prec@1 88.200 	Validation Prec@5 99.560 

2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:05:06 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:05:08 - INFO - TRAINING - Epoch: [173][0/196]	Time 1.975 (1.975)	Data 1.923 (1.923)	Loss 0.0772 (0.0772)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 19:05:09 - INFO - TRAINING - Epoch: [173][10/196]	Time 0.105 (0.282)	Data 0.000 (0.175)	Loss 0.0493 (0.0626)	Prec@1 97.656 (98.011)	Prec@5 100.000 (100.000)
2022-06-17 19:05:10 - INFO - TRAINING - Epoch: [173][20/196]	Time 0.108 (0.199)	Data 0.000 (0.092)	Loss 0.0792 (0.0622)	Prec@1 96.484 (97.917)	Prec@5 100.000 (100.000)
2022-06-17 19:05:11 - INFO - TRAINING - Epoch: [173][30/196]	Time 0.106 (0.170)	Data 0.000 (0.062)	Loss 0.0461 (0.0650)	Prec@1 99.219 (97.770)	Prec@5 100.000 (100.000)
2022-06-17 19:05:12 - INFO - TRAINING - Epoch: [173][40/196]	Time 0.120 (0.155)	Data 0.000 (0.047)	Loss 0.0538 (0.0671)	Prec@1 98.438 (97.761)	Prec@5 100.000 (99.990)
2022-06-17 19:05:13 - INFO - TRAINING - Epoch: [173][50/196]	Time 0.109 (0.147)	Data 0.000 (0.038)	Loss 0.0656 (0.0656)	Prec@1 97.656 (97.848)	Prec@5 100.000 (99.992)
2022-06-17 19:05:14 - INFO - TRAINING - Epoch: [173][60/196]	Time 0.129 (0.143)	Data 0.000 (0.032)	Loss 0.0472 (0.0647)	Prec@1 98.438 (97.893)	Prec@5 100.000 (99.994)
2022-06-17 19:05:15 - INFO - TRAINING - Epoch: [173][70/196]	Time 0.117 (0.139)	Data 0.000 (0.027)	Loss 0.0546 (0.0648)	Prec@1 97.656 (97.926)	Prec@5 100.000 (99.994)
2022-06-17 19:05:17 - INFO - TRAINING - Epoch: [173][80/196]	Time 0.112 (0.136)	Data 0.000 (0.024)	Loss 0.0437 (0.0643)	Prec@1 99.219 (97.950)	Prec@5 100.000 (99.995)
2022-06-17 19:05:18 - INFO - TRAINING - Epoch: [173][90/196]	Time 0.103 (0.133)	Data 0.000 (0.021)	Loss 0.0447 (0.0640)	Prec@1 99.219 (97.978)	Prec@5 100.000 (99.996)
2022-06-17 19:05:19 - INFO - TRAINING - Epoch: [173][100/196]	Time 0.104 (0.130)	Data 0.000 (0.019)	Loss 0.0974 (0.0656)	Prec@1 97.266 (97.919)	Prec@5 100.000 (99.992)
2022-06-17 19:05:20 - INFO - TRAINING - Epoch: [173][110/196]	Time 0.107 (0.129)	Data 0.000 (0.018)	Loss 0.0565 (0.0659)	Prec@1 98.438 (97.892)	Prec@5 100.000 (99.993)
2022-06-17 19:05:21 - INFO - TRAINING - Epoch: [173][120/196]	Time 0.102 (0.127)	Data 0.000 (0.016)	Loss 0.0566 (0.0656)	Prec@1 98.438 (97.911)	Prec@5 100.000 (99.994)
2022-06-17 19:05:22 - INFO - TRAINING - Epoch: [173][130/196]	Time 0.119 (0.126)	Data 0.000 (0.015)	Loss 0.0667 (0.0662)	Prec@1 98.047 (97.874)	Prec@5 100.000 (99.991)
2022-06-17 19:05:23 - INFO - TRAINING - Epoch: [173][140/196]	Time 0.105 (0.125)	Data 0.000 (0.014)	Loss 0.0648 (0.0656)	Prec@1 98.438 (97.922)	Prec@5 100.000 (99.989)
2022-06-17 19:05:24 - INFO - TRAINING - Epoch: [173][150/196]	Time 0.119 (0.124)	Data 0.000 (0.013)	Loss 0.0525 (0.0662)	Prec@1 98.828 (97.902)	Prec@5 100.000 (99.990)
2022-06-17 19:05:25 - INFO - TRAINING - Epoch: [173][160/196]	Time 0.104 (0.124)	Data 0.000 (0.012)	Loss 0.0528 (0.0669)	Prec@1 98.047 (97.877)	Prec@5 100.000 (99.990)
2022-06-17 19:05:27 - INFO - TRAINING - Epoch: [173][170/196]	Time 0.115 (0.123)	Data 0.000 (0.012)	Loss 0.0470 (0.0669)	Prec@1 98.438 (97.871)	Prec@5 100.000 (99.991)
2022-06-17 19:05:28 - INFO - TRAINING - Epoch: [173][180/196]	Time 0.102 (0.122)	Data 0.000 (0.011)	Loss 0.0504 (0.0671)	Prec@1 97.266 (97.857)	Prec@5 100.000 (99.991)
2022-06-17 19:05:29 - INFO - TRAINING - Epoch: [173][190/196]	Time 0.102 (0.121)	Data 0.000 (0.010)	Loss 0.0906 (0.0673)	Prec@1 95.312 (97.838)	Prec@5 100.000 (99.992)
2022-06-17 19:05:31 - INFO - EVALUATING - Epoch: [173][0/40]	Time 1.858 (1.858)	Data 1.811 (1.811)	Loss 0.2626 (0.2626)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 19:05:32 - INFO - EVALUATING - Epoch: [173][10/40]	Time 0.202 (0.267)	Data 0.158 (0.218)	Loss 0.5029 (0.4324)	Prec@1 87.500 (88.175)	Prec@5 99.219 (99.503)
2022-06-17 19:05:33 - INFO - EVALUATING - Epoch: [173][20/40]	Time 0.041 (0.174)	Data 0.000 (0.123)	Loss 0.3541 (0.4354)	Prec@1 87.891 (88.021)	Prec@5 100.000 (99.423)
2022-06-17 19:05:34 - INFO - EVALUATING - Epoch: [173][30/40]	Time 0.211 (0.151)	Data 0.167 (0.101)	Loss 0.5347 (0.4267)	Prec@1 87.109 (88.256)	Prec@5 100.000 (99.483)
2022-06-17 19:05:36 - INFO - 
 Epoch: 174	Training Loss 0.0671 	Training Prec@1 97.842 	Training Prec@5 99.992 	Validation Loss 0.4214 	Validation Prec@1 88.320 	Validation Prec@5 99.550 

2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:05:36 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:05:37 - INFO - TRAINING - Epoch: [174][0/196]	Time 1.282 (1.282)	Data 1.228 (1.228)	Loss 0.0813 (0.0813)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 19:05:39 - INFO - TRAINING - Epoch: [174][10/196]	Time 0.105 (0.257)	Data 0.000 (0.165)	Loss 0.0709 (0.0631)	Prec@1 98.047 (98.224)	Prec@5 100.000 (100.000)
2022-06-17 19:05:40 - INFO - TRAINING - Epoch: [174][20/196]	Time 0.125 (0.188)	Data 0.000 (0.086)	Loss 0.0723 (0.0679)	Prec@1 97.656 (97.861)	Prec@5 100.000 (100.000)
2022-06-17 19:05:41 - INFO - TRAINING - Epoch: [174][30/196]	Time 0.129 (0.165)	Data 0.000 (0.059)	Loss 0.0533 (0.0670)	Prec@1 97.266 (97.870)	Prec@5 100.000 (100.000)
2022-06-17 19:05:42 - INFO - TRAINING - Epoch: [174][40/196]	Time 0.102 (0.154)	Data 0.000 (0.044)	Loss 0.0710 (0.0673)	Prec@1 98.047 (97.828)	Prec@5 100.000 (99.990)
2022-06-17 19:05:43 - INFO - TRAINING - Epoch: [174][50/196]	Time 0.114 (0.146)	Data 0.001 (0.036)	Loss 0.0767 (0.0685)	Prec@1 97.266 (97.756)	Prec@5 100.000 (99.992)
2022-06-17 19:05:44 - INFO - TRAINING - Epoch: [174][60/196]	Time 0.123 (0.142)	Data 0.000 (0.030)	Loss 0.0372 (0.0678)	Prec@1 99.219 (97.778)	Prec@5 100.000 (99.994)
2022-06-17 19:05:46 - INFO - TRAINING - Epoch: [174][70/196]	Time 0.107 (0.138)	Data 0.000 (0.026)	Loss 0.0353 (0.0656)	Prec@1 98.828 (97.849)	Prec@5 100.000 (99.994)
2022-06-17 19:05:47 - INFO - TRAINING - Epoch: [174][80/196]	Time 0.105 (0.136)	Data 0.000 (0.023)	Loss 0.0737 (0.0644)	Prec@1 97.266 (97.897)	Prec@5 100.000 (99.995)
2022-06-17 19:05:48 - INFO - TRAINING - Epoch: [174][90/196]	Time 0.123 (0.134)	Data 0.000 (0.020)	Loss 0.0630 (0.0664)	Prec@1 98.828 (97.811)	Prec@5 100.000 (99.991)
2022-06-17 19:05:49 - INFO - TRAINING - Epoch: [174][100/196]	Time 0.129 (0.132)	Data 0.000 (0.018)	Loss 0.0736 (0.0665)	Prec@1 97.266 (97.799)	Prec@5 100.000 (99.992)
2022-06-17 19:05:50 - INFO - TRAINING - Epoch: [174][110/196]	Time 0.109 (0.131)	Data 0.000 (0.017)	Loss 0.1039 (0.0663)	Prec@1 97.266 (97.822)	Prec@5 100.000 (99.993)
2022-06-17 19:05:52 - INFO - TRAINING - Epoch: [174][120/196]	Time 0.105 (0.130)	Data 0.000 (0.015)	Loss 0.0559 (0.0662)	Prec@1 98.047 (97.821)	Prec@5 100.000 (99.994)
2022-06-17 19:05:53 - INFO - TRAINING - Epoch: [174][130/196]	Time 0.121 (0.129)	Data 0.000 (0.014)	Loss 0.0822 (0.0661)	Prec@1 97.266 (97.829)	Prec@5 100.000 (99.994)
2022-06-17 19:05:54 - INFO - TRAINING - Epoch: [174][140/196]	Time 0.120 (0.128)	Data 0.000 (0.013)	Loss 0.0665 (0.0667)	Prec@1 97.656 (97.809)	Prec@5 100.000 (99.994)
2022-06-17 19:05:55 - INFO - TRAINING - Epoch: [174][150/196]	Time 0.110 (0.127)	Data 0.000 (0.012)	Loss 0.0475 (0.0662)	Prec@1 98.828 (97.817)	Prec@5 100.000 (99.995)
2022-06-17 19:05:56 - INFO - TRAINING - Epoch: [174][160/196]	Time 0.103 (0.127)	Data 0.000 (0.012)	Loss 0.0599 (0.0673)	Prec@1 97.656 (97.790)	Prec@5 100.000 (99.993)
2022-06-17 19:05:57 - INFO - TRAINING - Epoch: [174][170/196]	Time 0.123 (0.126)	Data 0.000 (0.011)	Loss 0.0751 (0.0674)	Prec@1 97.656 (97.770)	Prec@5 100.000 (99.993)
2022-06-17 19:05:59 - INFO - TRAINING - Epoch: [174][180/196]	Time 0.120 (0.126)	Data 0.000 (0.010)	Loss 0.0574 (0.0671)	Prec@1 98.438 (97.775)	Prec@5 100.000 (99.994)
2022-06-17 19:06:00 - INFO - TRAINING - Epoch: [174][190/196]	Time 0.118 (0.125)	Data 0.000 (0.010)	Loss 0.0479 (0.0670)	Prec@1 98.047 (97.783)	Prec@5 100.000 (99.992)
2022-06-17 19:06:02 - INFO - EVALUATING - Epoch: [174][0/40]	Time 1.874 (1.874)	Data 1.828 (1.828)	Loss 0.2670 (0.2670)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:06:03 - INFO - EVALUATING - Epoch: [174][10/40]	Time 0.066 (0.277)	Data 0.000 (0.228)	Loss 0.4919 (0.4343)	Prec@1 87.891 (88.068)	Prec@5 99.219 (99.503)
2022-06-17 19:06:04 - INFO - EVALUATING - Epoch: [174][20/40]	Time 0.042 (0.169)	Data 0.000 (0.120)	Loss 0.3578 (0.4369)	Prec@1 87.500 (87.909)	Prec@5 100.000 (99.442)
2022-06-17 19:06:05 - INFO - EVALUATING - Epoch: [174][30/40]	Time 0.065 (0.158)	Data 0.000 (0.109)	Loss 0.5413 (0.4274)	Prec@1 86.719 (88.168)	Prec@5 100.000 (99.483)
2022-06-17 19:06:07 - INFO - 
 Epoch: 175	Training Loss 0.0668 	Training Prec@1 97.792 	Training Prec@5 99.992 	Validation Loss 0.4218 	Validation Prec@1 88.220 	Validation Prec@5 99.550 

2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:06:07 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:06:09 - INFO - TRAINING - Epoch: [175][0/196]	Time 1.720 (1.720)	Data 1.668 (1.668)	Loss 0.0700 (0.0700)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 19:06:10 - INFO - TRAINING - Epoch: [175][10/196]	Time 0.102 (0.282)	Data 0.000 (0.191)	Loss 0.0616 (0.0696)	Prec@1 98.047 (97.621)	Prec@5 100.000 (100.000)
2022-06-17 19:06:11 - INFO - TRAINING - Epoch: [175][20/196]	Time 0.129 (0.201)	Data 0.000 (0.100)	Loss 0.0285 (0.0677)	Prec@1 99.219 (97.786)	Prec@5 100.000 (99.981)
2022-06-17 19:06:12 - INFO - TRAINING - Epoch: [175][30/196]	Time 0.129 (0.174)	Data 0.000 (0.068)	Loss 0.0498 (0.0682)	Prec@1 97.656 (97.681)	Prec@5 100.000 (99.987)
2022-06-17 19:06:14 - INFO - TRAINING - Epoch: [175][40/196]	Time 0.121 (0.161)	Data 0.000 (0.051)	Loss 0.0476 (0.0669)	Prec@1 98.438 (97.723)	Prec@5 100.000 (99.990)
2022-06-17 19:06:15 - INFO - TRAINING - Epoch: [175][50/196]	Time 0.104 (0.152)	Data 0.000 (0.041)	Loss 0.0443 (0.0658)	Prec@1 99.219 (97.794)	Prec@5 100.000 (99.992)
2022-06-17 19:06:16 - INFO - TRAINING - Epoch: [175][60/196]	Time 0.128 (0.146)	Data 0.000 (0.035)	Loss 0.0543 (0.0671)	Prec@1 98.438 (97.765)	Prec@5 100.000 (99.994)
2022-06-17 19:06:17 - INFO - TRAINING - Epoch: [175][70/196]	Time 0.129 (0.143)	Data 0.000 (0.030)	Loss 0.0791 (0.0661)	Prec@1 97.266 (97.799)	Prec@5 100.000 (99.994)
2022-06-17 19:06:18 - INFO - TRAINING - Epoch: [175][80/196]	Time 0.122 (0.140)	Data 0.000 (0.026)	Loss 0.0587 (0.0663)	Prec@1 98.438 (97.825)	Prec@5 100.000 (99.995)
2022-06-17 19:06:20 - INFO - TRAINING - Epoch: [175][90/196]	Time 0.106 (0.138)	Data 0.000 (0.023)	Loss 0.0736 (0.0675)	Prec@1 97.266 (97.781)	Prec@5 100.000 (99.991)
2022-06-17 19:06:21 - INFO - TRAINING - Epoch: [175][100/196]	Time 0.137 (0.136)	Data 0.000 (0.021)	Loss 0.0435 (0.0679)	Prec@1 98.828 (97.745)	Prec@5 100.000 (99.992)
2022-06-17 19:06:22 - INFO - TRAINING - Epoch: [175][110/196]	Time 0.129 (0.135)	Data 0.000 (0.019)	Loss 0.0667 (0.0679)	Prec@1 97.266 (97.727)	Prec@5 100.000 (99.993)
2022-06-17 19:06:23 - INFO - TRAINING - Epoch: [175][120/196]	Time 0.126 (0.134)	Data 0.000 (0.018)	Loss 0.0635 (0.0672)	Prec@1 97.656 (97.747)	Prec@5 100.000 (99.994)
2022-06-17 19:06:24 - INFO - TRAINING - Epoch: [175][130/196]	Time 0.102 (0.133)	Data 0.000 (0.016)	Loss 0.0449 (0.0665)	Prec@1 97.656 (97.767)	Prec@5 100.000 (99.994)
2022-06-17 19:06:26 - INFO - TRAINING - Epoch: [175][140/196]	Time 0.125 (0.132)	Data 0.000 (0.015)	Loss 0.1248 (0.0675)	Prec@1 95.703 (97.720)	Prec@5 100.000 (99.994)
2022-06-17 19:06:27 - INFO - TRAINING - Epoch: [175][150/196]	Time 0.117 (0.131)	Data 0.000 (0.014)	Loss 0.0577 (0.0675)	Prec@1 98.438 (97.736)	Prec@5 100.000 (99.995)
2022-06-17 19:06:28 - INFO - TRAINING - Epoch: [175][160/196]	Time 0.124 (0.130)	Data 0.000 (0.013)	Loss 0.0806 (0.0675)	Prec@1 98.438 (97.751)	Prec@5 100.000 (99.995)
2022-06-17 19:06:29 - INFO - TRAINING - Epoch: [175][170/196]	Time 0.115 (0.130)	Data 0.000 (0.013)	Loss 0.0678 (0.0676)	Prec@1 97.656 (97.766)	Prec@5 100.000 (99.995)
2022-06-17 19:06:30 - INFO - TRAINING - Epoch: [175][180/196]	Time 0.112 (0.129)	Data 0.000 (0.012)	Loss 0.0621 (0.0672)	Prec@1 97.656 (97.792)	Prec@5 100.000 (99.994)
2022-06-17 19:06:31 - INFO - TRAINING - Epoch: [175][190/196]	Time 0.102 (0.128)	Data 0.000 (0.011)	Loss 0.0474 (0.0668)	Prec@1 98.828 (97.806)	Prec@5 100.000 (99.994)
2022-06-17 19:06:34 - INFO - EVALUATING - Epoch: [175][0/40]	Time 1.792 (1.792)	Data 1.746 (1.746)	Loss 0.2610 (0.2610)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 19:06:35 - INFO - EVALUATING - Epoch: [175][10/40]	Time 0.044 (0.260)	Data 0.001 (0.212)	Loss 0.4972 (0.4298)	Prec@1 87.891 (88.565)	Prec@5 99.219 (99.467)
2022-06-17 19:06:36 - INFO - EVALUATING - Epoch: [175][20/40]	Time 0.042 (0.177)	Data 0.000 (0.130)	Loss 0.3600 (0.4334)	Prec@1 87.500 (88.114)	Prec@5 100.000 (99.423)
2022-06-17 19:06:37 - INFO - EVALUATING - Epoch: [175][30/40]	Time 0.047 (0.156)	Data 0.000 (0.110)	Loss 0.5369 (0.4250)	Prec@1 87.500 (88.281)	Prec@5 100.000 (99.483)
2022-06-17 19:06:39 - INFO - 
 Epoch: 176	Training Loss 0.0667 	Training Prec@1 97.816 	Training Prec@5 99.994 	Validation Loss 0.4197 	Validation Prec@1 88.330 	Validation Prec@5 99.550 

2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:06:39 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:06:40 - INFO - TRAINING - Epoch: [176][0/196]	Time 1.764 (1.764)	Data 1.711 (1.711)	Loss 0.0776 (0.0776)	Prec@1 98.828 (98.828)	Prec@5 100.000 (100.000)
2022-06-17 19:06:42 - INFO - TRAINING - Epoch: [176][10/196]	Time 0.103 (0.275)	Data 0.000 (0.184)	Loss 0.0791 (0.0677)	Prec@1 97.266 (97.798)	Prec@5 99.609 (99.964)
2022-06-17 19:06:43 - INFO - TRAINING - Epoch: [176][20/196]	Time 0.108 (0.196)	Data 0.000 (0.097)	Loss 0.0659 (0.0663)	Prec@1 96.875 (97.768)	Prec@5 100.000 (99.981)
2022-06-17 19:06:44 - INFO - TRAINING - Epoch: [176][30/196]	Time 0.105 (0.170)	Data 0.000 (0.066)	Loss 0.0541 (0.0668)	Prec@1 98.047 (97.719)	Prec@5 100.000 (99.987)
2022-06-17 19:06:45 - INFO - TRAINING - Epoch: [176][40/196]	Time 0.105 (0.155)	Data 0.000 (0.050)	Loss 0.0659 (0.0650)	Prec@1 97.656 (97.771)	Prec@5 100.000 (99.981)
2022-06-17 19:06:46 - INFO - TRAINING - Epoch: [176][50/196]	Time 0.115 (0.147)	Data 0.000 (0.040)	Loss 0.0259 (0.0643)	Prec@1 99.609 (97.840)	Prec@5 100.000 (99.985)
2022-06-17 19:06:47 - INFO - TRAINING - Epoch: [176][60/196]	Time 0.124 (0.141)	Data 0.000 (0.033)	Loss 0.0588 (0.0666)	Prec@1 98.828 (97.784)	Prec@5 100.000 (99.987)
2022-06-17 19:06:48 - INFO - TRAINING - Epoch: [176][70/196]	Time 0.108 (0.137)	Data 0.000 (0.029)	Loss 0.1011 (0.0665)	Prec@1 97.266 (97.788)	Prec@5 100.000 (99.989)
2022-06-17 19:06:50 - INFO - TRAINING - Epoch: [176][80/196]	Time 0.112 (0.135)	Data 0.000 (0.025)	Loss 0.0677 (0.0675)	Prec@1 97.656 (97.724)	Prec@5 100.000 (99.990)
2022-06-17 19:06:51 - INFO - TRAINING - Epoch: [176][90/196]	Time 0.113 (0.133)	Data 0.000 (0.023)	Loss 0.0709 (0.0675)	Prec@1 98.438 (97.734)	Prec@5 100.000 (99.991)
2022-06-17 19:06:52 - INFO - TRAINING - Epoch: [176][100/196]	Time 0.121 (0.130)	Data 0.000 (0.020)	Loss 0.0413 (0.0673)	Prec@1 98.828 (97.734)	Prec@5 100.000 (99.992)
2022-06-17 19:06:53 - INFO - TRAINING - Epoch: [176][110/196]	Time 0.105 (0.128)	Data 0.000 (0.019)	Loss 0.0554 (0.0682)	Prec@1 98.438 (97.698)	Prec@5 100.000 (99.993)
2022-06-17 19:06:54 - INFO - TRAINING - Epoch: [176][120/196]	Time 0.117 (0.127)	Data 0.000 (0.017)	Loss 0.0728 (0.0676)	Prec@1 97.656 (97.747)	Prec@5 100.000 (99.990)
2022-06-17 19:06:55 - INFO - TRAINING - Epoch: [176][130/196]	Time 0.121 (0.126)	Data 0.000 (0.016)	Loss 0.0773 (0.0674)	Prec@1 96.875 (97.749)	Prec@5 100.000 (99.991)
2022-06-17 19:06:56 - INFO - TRAINING - Epoch: [176][140/196]	Time 0.121 (0.125)	Data 0.000 (0.015)	Loss 0.0844 (0.0676)	Prec@1 97.266 (97.750)	Prec@5 100.000 (99.989)
2022-06-17 19:06:57 - INFO - TRAINING - Epoch: [176][150/196]	Time 0.122 (0.124)	Data 0.000 (0.014)	Loss 0.0634 (0.0675)	Prec@1 97.656 (97.742)	Prec@5 100.000 (99.990)
2022-06-17 19:06:59 - INFO - TRAINING - Epoch: [176][160/196]	Time 0.104 (0.123)	Data 0.000 (0.013)	Loss 0.0614 (0.0677)	Prec@1 98.047 (97.727)	Prec@5 100.000 (99.990)
2022-06-17 19:07:00 - INFO - TRAINING - Epoch: [176][170/196]	Time 0.115 (0.123)	Data 0.000 (0.012)	Loss 0.0979 (0.0682)	Prec@1 96.875 (97.720)	Prec@5 100.000 (99.991)
2022-06-17 19:07:01 - INFO - TRAINING - Epoch: [176][180/196]	Time 0.117 (0.122)	Data 0.000 (0.011)	Loss 0.1028 (0.0680)	Prec@1 97.266 (97.734)	Prec@5 100.000 (99.991)
2022-06-17 19:07:02 - INFO - TRAINING - Epoch: [176][190/196]	Time 0.102 (0.121)	Data 0.000 (0.011)	Loss 0.0714 (0.0678)	Prec@1 96.484 (97.740)	Prec@5 100.000 (99.992)
2022-06-17 19:07:04 - INFO - EVALUATING - Epoch: [176][0/40]	Time 1.654 (1.654)	Data 1.608 (1.608)	Loss 0.2635 (0.2635)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:07:05 - INFO - EVALUATING - Epoch: [176][10/40]	Time 0.044 (0.272)	Data 0.000 (0.225)	Loss 0.4912 (0.4374)	Prec@1 88.281 (88.033)	Prec@5 99.219 (99.503)
2022-06-17 19:07:06 - INFO - EVALUATING - Epoch: [176][20/40]	Time 0.117 (0.169)	Data 0.074 (0.121)	Loss 0.3554 (0.4403)	Prec@1 87.109 (87.798)	Prec@5 99.609 (99.423)
2022-06-17 19:07:07 - INFO - EVALUATING - Epoch: [176][30/40]	Time 0.098 (0.150)	Data 0.057 (0.103)	Loss 0.5595 (0.4339)	Prec@1 86.328 (87.966)	Prec@5 100.000 (99.483)
2022-06-17 19:07:09 - INFO - 
 Epoch: 177	Training Loss 0.0679 	Training Prec@1 97.746 	Training Prec@5 99.990 	Validation Loss 0.4277 	Validation Prec@1 87.990 	Validation Prec@5 99.550 

2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:07:09 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:07:10 - INFO - TRAINING - Epoch: [177][0/196]	Time 1.255 (1.255)	Data 1.202 (1.202)	Loss 0.0794 (0.0794)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 19:07:12 - INFO - TRAINING - Epoch: [177][10/196]	Time 0.105 (0.281)	Data 0.000 (0.176)	Loss 0.0493 (0.0592)	Prec@1 98.047 (98.011)	Prec@5 100.000 (100.000)
2022-06-17 19:07:13 - INFO - TRAINING - Epoch: [177][20/196]	Time 0.119 (0.204)	Data 0.000 (0.092)	Loss 0.0563 (0.0608)	Prec@1 97.266 (97.991)	Prec@5 100.000 (100.000)
2022-06-17 19:07:15 - INFO - TRAINING - Epoch: [177][30/196]	Time 0.125 (0.176)	Data 0.000 (0.063)	Loss 0.0689 (0.0639)	Prec@1 96.094 (97.795)	Prec@5 100.000 (100.000)
2022-06-17 19:07:16 - INFO - TRAINING - Epoch: [177][40/196]	Time 0.108 (0.161)	Data 0.000 (0.048)	Loss 0.1040 (0.0670)	Prec@1 97.266 (97.675)	Prec@5 100.000 (99.990)
2022-06-17 19:07:17 - INFO - TRAINING - Epoch: [177][50/196]	Time 0.126 (0.153)	Data 0.000 (0.038)	Loss 0.0794 (0.0672)	Prec@1 95.703 (97.718)	Prec@5 100.000 (99.985)
2022-06-17 19:07:18 - INFO - TRAINING - Epoch: [177][60/196]	Time 0.116 (0.147)	Data 0.000 (0.032)	Loss 0.0751 (0.0679)	Prec@1 98.047 (97.707)	Prec@5 100.000 (99.987)
2022-06-17 19:07:19 - INFO - TRAINING - Epoch: [177][70/196]	Time 0.113 (0.144)	Data 0.000 (0.028)	Loss 0.0807 (0.0691)	Prec@1 97.266 (97.651)	Prec@5 100.000 (99.983)
2022-06-17 19:07:21 - INFO - TRAINING - Epoch: [177][80/196]	Time 0.112 (0.141)	Data 0.000 (0.024)	Loss 0.0546 (0.0684)	Prec@1 98.047 (97.680)	Prec@5 100.000 (99.986)
2022-06-17 19:07:22 - INFO - TRAINING - Epoch: [177][90/196]	Time 0.103 (0.139)	Data 0.000 (0.022)	Loss 0.0875 (0.0684)	Prec@1 98.047 (97.682)	Prec@5 99.609 (99.983)
2022-06-17 19:07:23 - INFO - TRAINING - Epoch: [177][100/196]	Time 0.119 (0.137)	Data 0.000 (0.019)	Loss 0.0800 (0.0686)	Prec@1 96.484 (97.672)	Prec@5 100.000 (99.985)
2022-06-17 19:07:24 - INFO - TRAINING - Epoch: [177][110/196]	Time 0.114 (0.136)	Data 0.000 (0.018)	Loss 0.0603 (0.0678)	Prec@1 97.266 (97.734)	Prec@5 100.000 (99.986)
2022-06-17 19:07:25 - INFO - TRAINING - Epoch: [177][120/196]	Time 0.109 (0.134)	Data 0.000 (0.016)	Loss 0.0593 (0.0676)	Prec@1 98.047 (97.734)	Prec@5 99.609 (99.984)
2022-06-17 19:07:26 - INFO - TRAINING - Epoch: [177][130/196]	Time 0.101 (0.133)	Data 0.000 (0.015)	Loss 0.0641 (0.0676)	Prec@1 97.656 (97.728)	Prec@5 100.000 (99.985)
2022-06-17 19:07:28 - INFO - TRAINING - Epoch: [177][140/196]	Time 0.120 (0.132)	Data 0.000 (0.014)	Loss 0.0461 (0.0685)	Prec@1 98.438 (97.689)	Prec@5 100.000 (99.986)
2022-06-17 19:07:29 - INFO - TRAINING - Epoch: [177][150/196]	Time 0.117 (0.131)	Data 0.000 (0.013)	Loss 0.0844 (0.0694)	Prec@1 96.484 (97.643)	Prec@5 100.000 (99.987)
2022-06-17 19:07:30 - INFO - TRAINING - Epoch: [177][160/196]	Time 0.113 (0.130)	Data 0.000 (0.012)	Loss 0.0737 (0.0691)	Prec@1 97.266 (97.649)	Prec@5 100.000 (99.985)
2022-06-17 19:07:31 - INFO - TRAINING - Epoch: [177][170/196]	Time 0.101 (0.129)	Data 0.000 (0.012)	Loss 0.0408 (0.0692)	Prec@1 98.438 (97.654)	Prec@5 100.000 (99.986)
2022-06-17 19:07:32 - INFO - TRAINING - Epoch: [177][180/196]	Time 0.130 (0.128)	Data 0.000 (0.011)	Loss 0.0542 (0.0687)	Prec@1 98.438 (97.680)	Prec@5 100.000 (99.987)
2022-06-17 19:07:33 - INFO - TRAINING - Epoch: [177][190/196]	Time 0.105 (0.127)	Data 0.000 (0.010)	Loss 0.0642 (0.0687)	Prec@1 96.875 (97.675)	Prec@5 100.000 (99.988)
2022-06-17 19:07:36 - INFO - EVALUATING - Epoch: [177][0/40]	Time 1.539 (1.539)	Data 1.494 (1.494)	Loss 0.2640 (0.2640)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
2022-06-17 19:07:37 - INFO - EVALUATING - Epoch: [177][10/40]	Time 0.044 (0.278)	Data 0.000 (0.229)	Loss 0.4808 (0.4337)	Prec@1 87.891 (88.068)	Prec@5 99.219 (99.361)
2022-06-17 19:07:38 - INFO - EVALUATING - Epoch: [177][20/40]	Time 0.200 (0.178)	Data 0.158 (0.127)	Loss 0.3561 (0.4355)	Prec@1 87.891 (87.965)	Prec@5 99.609 (99.349)
2022-06-17 19:07:39 - INFO - EVALUATING - Epoch: [177][30/40]	Time 0.042 (0.153)	Data 0.000 (0.104)	Loss 0.5421 (0.4261)	Prec@1 87.500 (88.168)	Prec@5 100.000 (99.433)
2022-06-17 19:07:41 - INFO - 
 Epoch: 178	Training Loss 0.0689 	Training Prec@1 97.680 	Training Prec@5 99.986 	Validation Loss 0.4206 	Validation Prec@1 88.230 	Validation Prec@5 99.520 

2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:07:41 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:07:42 - INFO - TRAINING - Epoch: [178][0/196]	Time 1.479 (1.479)	Data 1.425 (1.425)	Loss 0.0610 (0.0610)	Prec@1 98.828 (98.828)	Prec@5 100.000 (100.000)
2022-06-17 19:07:44 - INFO - TRAINING - Epoch: [178][10/196]	Time 0.109 (0.273)	Data 0.000 (0.182)	Loss 0.0470 (0.0628)	Prec@1 98.438 (98.189)	Prec@5 100.000 (99.964)
2022-06-17 19:07:45 - INFO - TRAINING - Epoch: [178][20/196]	Time 0.107 (0.193)	Data 0.000 (0.095)	Loss 0.0391 (0.0645)	Prec@1 98.828 (97.861)	Prec@5 100.000 (99.981)
2022-06-17 19:07:46 - INFO - TRAINING - Epoch: [178][30/196]	Time 0.105 (0.168)	Data 0.000 (0.065)	Loss 0.0519 (0.0646)	Prec@1 98.047 (97.908)	Prec@5 100.000 (99.987)
2022-06-17 19:07:47 - INFO - TRAINING - Epoch: [178][40/196]	Time 0.105 (0.156)	Data 0.000 (0.049)	Loss 0.0667 (0.0630)	Prec@1 97.266 (97.933)	Prec@5 100.000 (99.990)
2022-06-17 19:07:48 - INFO - TRAINING - Epoch: [178][50/196]	Time 0.104 (0.147)	Data 0.000 (0.039)	Loss 0.0524 (0.0631)	Prec@1 97.656 (97.825)	Prec@5 100.000 (99.992)
2022-06-17 19:07:49 - INFO - TRAINING - Epoch: [178][60/196]	Time 0.111 (0.141)	Data 0.000 (0.033)	Loss 0.0917 (0.0637)	Prec@1 97.266 (97.829)	Prec@5 100.000 (99.994)
2022-06-17 19:07:50 - INFO - TRAINING - Epoch: [178][70/196]	Time 0.103 (0.136)	Data 0.000 (0.028)	Loss 0.0503 (0.0627)	Prec@1 98.828 (97.920)	Prec@5 100.000 (99.994)
2022-06-17 19:07:51 - INFO - TRAINING - Epoch: [178][80/196]	Time 0.107 (0.133)	Data 0.000 (0.025)	Loss 0.0837 (0.0648)	Prec@1 97.656 (97.844)	Prec@5 100.000 (99.990)
2022-06-17 19:07:53 - INFO - TRAINING - Epoch: [178][90/196]	Time 0.115 (0.130)	Data 0.000 (0.022)	Loss 0.0449 (0.0653)	Prec@1 98.828 (97.824)	Prec@5 100.000 (99.991)
2022-06-17 19:07:54 - INFO - TRAINING - Epoch: [178][100/196]	Time 0.112 (0.128)	Data 0.000 (0.020)	Loss 0.0701 (0.0657)	Prec@1 97.656 (97.784)	Prec@5 100.000 (99.988)
2022-06-17 19:07:55 - INFO - TRAINING - Epoch: [178][110/196]	Time 0.112 (0.127)	Data 0.000 (0.018)	Loss 0.0669 (0.0658)	Prec@1 97.656 (97.762)	Prec@5 100.000 (99.989)
2022-06-17 19:07:56 - INFO - TRAINING - Epoch: [178][120/196]	Time 0.104 (0.126)	Data 0.000 (0.017)	Loss 0.0844 (0.0653)	Prec@1 96.094 (97.792)	Prec@5 100.000 (99.990)
2022-06-17 19:07:57 - INFO - TRAINING - Epoch: [178][130/196]	Time 0.122 (0.125)	Data 0.000 (0.016)	Loss 0.0547 (0.0659)	Prec@1 98.828 (97.773)	Prec@5 100.000 (99.991)
2022-06-17 19:07:58 - INFO - TRAINING - Epoch: [178][140/196]	Time 0.115 (0.124)	Data 0.000 (0.014)	Loss 0.0555 (0.0668)	Prec@1 98.047 (97.734)	Prec@5 100.000 (99.992)
2022-06-17 19:07:59 - INFO - TRAINING - Epoch: [178][150/196]	Time 0.125 (0.124)	Data 0.000 (0.014)	Loss 0.0770 (0.0668)	Prec@1 97.266 (97.731)	Prec@5 100.000 (99.992)
2022-06-17 19:08:00 - INFO - TRAINING - Epoch: [178][160/196]	Time 0.103 (0.123)	Data 0.000 (0.013)	Loss 0.0913 (0.0665)	Prec@1 96.484 (97.739)	Prec@5 100.000 (99.993)
2022-06-17 19:08:02 - INFO - TRAINING - Epoch: [178][170/196]	Time 0.114 (0.122)	Data 0.000 (0.012)	Loss 0.0593 (0.0664)	Prec@1 97.266 (97.741)	Prec@5 100.000 (99.993)
2022-06-17 19:08:03 - INFO - TRAINING - Epoch: [178][180/196]	Time 0.119 (0.122)	Data 0.000 (0.011)	Loss 0.0466 (0.0665)	Prec@1 98.047 (97.740)	Prec@5 100.000 (99.994)
2022-06-17 19:08:04 - INFO - TRAINING - Epoch: [178][190/196]	Time 0.104 (0.121)	Data 0.000 (0.011)	Loss 0.0870 (0.0669)	Prec@1 96.875 (97.716)	Prec@5 100.000 (99.994)
2022-06-17 19:08:06 - INFO - EVALUATING - Epoch: [178][0/40]	Time 1.849 (1.849)	Data 1.804 (1.804)	Loss 0.2621 (0.2621)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 19:08:07 - INFO - EVALUATING - Epoch: [178][10/40]	Time 0.180 (0.276)	Data 0.136 (0.228)	Loss 0.4845 (0.4333)	Prec@1 87.891 (88.104)	Prec@5 99.219 (99.361)
2022-06-17 19:08:08 - INFO - EVALUATING - Epoch: [178][20/40]	Time 0.044 (0.180)	Data 0.000 (0.129)	Loss 0.3476 (0.4375)	Prec@1 87.891 (87.816)	Prec@5 100.000 (99.368)
2022-06-17 19:08:09 - INFO - EVALUATING - Epoch: [178][30/40]	Time 0.093 (0.153)	Data 0.050 (0.104)	Loss 0.5399 (0.4288)	Prec@1 87.500 (88.067)	Prec@5 100.000 (99.446)
2022-06-17 19:08:11 - INFO - 
 Epoch: 179	Training Loss 0.0668 	Training Prec@1 97.726 	Training Prec@5 99.994 	Validation Loss 0.4235 	Validation Prec@1 88.150 	Validation Prec@5 99.520 

2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:08:11 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:08:13 - INFO - TRAINING - Epoch: [179][0/196]	Time 1.871 (1.871)	Data 1.818 (1.818)	Loss 0.0319 (0.0319)	Prec@1 99.609 (99.609)	Prec@5 100.000 (100.000)
2022-06-17 19:08:14 - INFO - TRAINING - Epoch: [179][10/196]	Time 0.120 (0.278)	Data 0.000 (0.189)	Loss 0.0782 (0.0655)	Prec@1 97.656 (97.798)	Prec@5 100.000 (100.000)
2022-06-17 19:08:15 - INFO - TRAINING - Epoch: [179][20/196]	Time 0.112 (0.201)	Data 0.000 (0.099)	Loss 0.0641 (0.0667)	Prec@1 98.438 (97.731)	Prec@5 100.000 (100.000)
2022-06-17 19:08:16 - INFO - TRAINING - Epoch: [179][30/196]	Time 0.119 (0.173)	Data 0.000 (0.067)	Loss 0.0666 (0.0681)	Prec@1 98.438 (97.795)	Prec@5 100.000 (100.000)
2022-06-17 19:08:18 - INFO - TRAINING - Epoch: [179][40/196]	Time 0.107 (0.160)	Data 0.000 (0.051)	Loss 0.0331 (0.0655)	Prec@1 98.828 (97.761)	Prec@5 100.000 (100.000)
2022-06-17 19:08:19 - INFO - TRAINING - Epoch: [179][50/196]	Time 0.109 (0.152)	Data 0.000 (0.041)	Loss 0.0831 (0.0674)	Prec@1 95.703 (97.702)	Prec@5 100.000 (100.000)
2022-06-17 19:08:20 - INFO - TRAINING - Epoch: [179][60/196]	Time 0.114 (0.146)	Data 0.000 (0.034)	Loss 0.0490 (0.0660)	Prec@1 98.438 (97.778)	Prec@5 100.000 (100.000)
2022-06-17 19:08:21 - INFO - TRAINING - Epoch: [179][70/196]	Time 0.131 (0.142)	Data 0.000 (0.030)	Loss 0.0823 (0.0670)	Prec@1 96.484 (97.755)	Prec@5 100.000 (100.000)
2022-06-17 19:08:22 - INFO - TRAINING - Epoch: [179][80/196]	Time 0.111 (0.139)	Data 0.000 (0.026)	Loss 0.1195 (0.0675)	Prec@1 94.922 (97.709)	Prec@5 100.000 (100.000)
2022-06-17 19:08:23 - INFO - TRAINING - Epoch: [179][90/196]	Time 0.130 (0.137)	Data 0.000 (0.023)	Loss 0.0939 (0.0669)	Prec@1 96.094 (97.725)	Prec@5 100.000 (100.000)
2022-06-17 19:08:25 - INFO - TRAINING - Epoch: [179][100/196]	Time 0.136 (0.135)	Data 0.000 (0.021)	Loss 0.0806 (0.0671)	Prec@1 98.047 (97.768)	Prec@5 100.000 (99.996)
2022-06-17 19:08:26 - INFO - TRAINING - Epoch: [179][110/196]	Time 0.110 (0.133)	Data 0.000 (0.019)	Loss 0.0561 (0.0683)	Prec@1 98.047 (97.720)	Prec@5 100.000 (99.996)
2022-06-17 19:08:27 - INFO - TRAINING - Epoch: [179][120/196]	Time 0.112 (0.132)	Data 0.000 (0.017)	Loss 0.0421 (0.0677)	Prec@1 98.828 (97.750)	Prec@5 100.000 (99.997)
2022-06-17 19:08:28 - INFO - TRAINING - Epoch: [179][130/196]	Time 0.135 (0.131)	Data 0.000 (0.016)	Loss 0.0816 (0.0675)	Prec@1 96.484 (97.758)	Prec@5 100.000 (99.994)
2022-06-17 19:08:29 - INFO - TRAINING - Epoch: [179][140/196]	Time 0.127 (0.130)	Data 0.000 (0.015)	Loss 0.0583 (0.0673)	Prec@1 98.047 (97.753)	Prec@5 100.000 (99.994)
2022-06-17 19:08:31 - INFO - TRAINING - Epoch: [179][150/196]	Time 0.126 (0.129)	Data 0.000 (0.014)	Loss 0.0588 (0.0672)	Prec@1 98.438 (97.773)	Prec@5 100.000 (99.995)
2022-06-17 19:08:32 - INFO - TRAINING - Epoch: [179][160/196]	Time 0.104 (0.128)	Data 0.000 (0.013)	Loss 0.0581 (0.0667)	Prec@1 97.656 (97.785)	Prec@5 100.000 (99.995)
2022-06-17 19:08:33 - INFO - TRAINING - Epoch: [179][170/196]	Time 0.137 (0.128)	Data 0.000 (0.012)	Loss 0.0691 (0.0671)	Prec@1 98.047 (97.764)	Prec@5 100.000 (99.995)
2022-06-17 19:08:34 - INFO - TRAINING - Epoch: [179][180/196]	Time 0.129 (0.127)	Data 0.000 (0.012)	Loss 0.0839 (0.0672)	Prec@1 97.656 (97.764)	Prec@5 100.000 (99.996)
2022-06-17 19:08:35 - INFO - TRAINING - Epoch: [179][190/196]	Time 0.104 (0.126)	Data 0.000 (0.011)	Loss 0.0505 (0.0670)	Prec@1 97.656 (97.759)	Prec@5 100.000 (99.996)
2022-06-17 19:08:38 - INFO - EVALUATING - Epoch: [179][0/40]	Time 1.760 (1.760)	Data 1.713 (1.713)	Loss 0.2676 (0.2676)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
2022-06-17 19:08:39 - INFO - EVALUATING - Epoch: [179][10/40]	Time 0.055 (0.258)	Data 0.000 (0.209)	Loss 0.4733 (0.4292)	Prec@1 88.672 (88.352)	Prec@5 99.219 (99.503)
2022-06-17 19:08:39 - INFO - EVALUATING - Epoch: [179][20/40]	Time 0.067 (0.161)	Data 0.000 (0.110)	Loss 0.3470 (0.4330)	Prec@1 87.891 (88.170)	Prec@5 99.609 (99.442)
2022-06-17 19:08:40 - INFO - EVALUATING - Epoch: [179][30/40]	Time 0.094 (0.141)	Data 0.050 (0.092)	Loss 0.5376 (0.4246)	Prec@1 86.719 (88.294)	Prec@5 100.000 (99.496)
2022-06-17 19:08:42 - INFO - 
 Epoch: 180	Training Loss 0.0671 	Training Prec@1 97.764 	Training Prec@5 99.996 	Validation Loss 0.4199 	Validation Prec@1 88.240 	Validation Prec@5 99.550 

2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:08:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:08:43 - INFO - TRAINING - Epoch: [180][0/196]	Time 1.437 (1.437)	Data 1.384 (1.384)	Loss 0.0493 (0.0493)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 19:08:45 - INFO - TRAINING - Epoch: [180][10/196]	Time 0.169 (0.250)	Data 0.122 (0.164)	Loss 0.0657 (0.0636)	Prec@1 98.047 (97.834)	Prec@5 100.000 (100.000)
2022-06-17 19:08:46 - INFO - TRAINING - Epoch: [180][20/196]	Time 0.104 (0.182)	Data 0.000 (0.086)	Loss 0.0596 (0.0637)	Prec@1 97.656 (97.731)	Prec@5 100.000 (100.000)
2022-06-17 19:08:47 - INFO - TRAINING - Epoch: [180][30/196]	Time 0.115 (0.158)	Data 0.000 (0.059)	Loss 0.0534 (0.0612)	Prec@1 97.656 (97.833)	Prec@5 100.000 (100.000)
2022-06-17 19:08:48 - INFO - TRAINING - Epoch: [180][40/196]	Time 0.110 (0.146)	Data 0.000 (0.044)	Loss 0.0495 (0.0633)	Prec@1 98.438 (97.723)	Prec@5 100.000 (100.000)
2022-06-17 19:08:49 - INFO - TRAINING - Epoch: [180][50/196]	Time 0.108 (0.139)	Data 0.000 (0.036)	Loss 0.1069 (0.0652)	Prec@1 96.484 (97.672)	Prec@5 100.000 (100.000)
2022-06-17 19:08:50 - INFO - TRAINING - Epoch: [180][60/196]	Time 0.105 (0.134)	Data 0.000 (0.030)	Loss 0.0573 (0.0668)	Prec@1 98.438 (97.618)	Prec@5 100.000 (100.000)
2022-06-17 19:08:51 - INFO - TRAINING - Epoch: [180][70/196]	Time 0.118 (0.131)	Data 0.000 (0.026)	Loss 0.0589 (0.0673)	Prec@1 97.656 (97.590)	Prec@5 100.000 (99.994)
2022-06-17 19:08:52 - INFO - TRAINING - Epoch: [180][80/196]	Time 0.120 (0.129)	Data 0.000 (0.023)	Loss 0.0449 (0.0682)	Prec@1 98.828 (97.603)	Prec@5 100.000 (99.990)
2022-06-17 19:08:54 - INFO - TRAINING - Epoch: [180][90/196]	Time 0.128 (0.128)	Data 0.000 (0.020)	Loss 0.0847 (0.0687)	Prec@1 98.438 (97.622)	Prec@5 100.000 (99.991)
2022-06-17 19:08:55 - INFO - TRAINING - Epoch: [180][100/196]	Time 0.124 (0.127)	Data 0.000 (0.018)	Loss 0.0828 (0.0688)	Prec@1 96.875 (97.633)	Prec@5 100.000 (99.992)
2022-06-17 19:08:56 - INFO - TRAINING - Epoch: [180][110/196]	Time 0.107 (0.126)	Data 0.000 (0.017)	Loss 0.0624 (0.0682)	Prec@1 97.656 (97.677)	Prec@5 100.000 (99.993)
2022-06-17 19:08:57 - INFO - TRAINING - Epoch: [180][120/196]	Time 0.125 (0.125)	Data 0.000 (0.015)	Loss 0.0485 (0.0691)	Prec@1 98.438 (97.653)	Prec@5 100.000 (99.994)
2022-06-17 19:08:58 - INFO - TRAINING - Epoch: [180][130/196]	Time 0.111 (0.124)	Data 0.000 (0.014)	Loss 0.0803 (0.0690)	Prec@1 96.875 (97.662)	Prec@5 100.000 (99.994)
2022-06-17 19:08:59 - INFO - TRAINING - Epoch: [180][140/196]	Time 0.107 (0.123)	Data 0.000 (0.013)	Loss 0.0864 (0.0690)	Prec@1 97.656 (97.667)	Prec@5 99.609 (99.992)
2022-06-17 19:09:00 - INFO - TRAINING - Epoch: [180][150/196]	Time 0.108 (0.122)	Data 0.000 (0.012)	Loss 0.0781 (0.0696)	Prec@1 97.266 (97.654)	Prec@5 100.000 (99.992)
2022-06-17 19:09:02 - INFO - TRAINING - Epoch: [180][160/196]	Time 0.107 (0.122)	Data 0.000 (0.011)	Loss 0.0571 (0.0692)	Prec@1 98.047 (97.661)	Prec@5 100.000 (99.993)
2022-06-17 19:09:03 - INFO - TRAINING - Epoch: [180][170/196]	Time 0.105 (0.122)	Data 0.000 (0.011)	Loss 0.0668 (0.0691)	Prec@1 97.656 (97.679)	Prec@5 100.000 (99.993)
2022-06-17 19:09:04 - INFO - TRAINING - Epoch: [180][180/196]	Time 0.103 (0.121)	Data 0.000 (0.010)	Loss 0.0657 (0.0693)	Prec@1 96.875 (97.671)	Prec@5 100.000 (99.994)
2022-06-17 19:09:05 - INFO - TRAINING - Epoch: [180][190/196]	Time 0.102 (0.121)	Data 0.000 (0.010)	Loss 0.0971 (0.0692)	Prec@1 96.875 (97.673)	Prec@5 100.000 (99.994)
2022-06-17 19:09:07 - INFO - EVALUATING - Epoch: [180][0/40]	Time 1.648 (1.648)	Data 1.602 (1.602)	Loss 0.2634 (0.2634)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:09:08 - INFO - EVALUATING - Epoch: [180][10/40]	Time 0.044 (0.255)	Data 0.000 (0.206)	Loss 0.5011 (0.4367)	Prec@1 87.891 (87.926)	Prec@5 99.219 (99.467)
2022-06-17 19:09:09 - INFO - EVALUATING - Epoch: [180][20/40]	Time 0.044 (0.159)	Data 0.001 (0.108)	Loss 0.3610 (0.4395)	Prec@1 87.891 (87.872)	Prec@5 99.609 (99.405)
2022-06-17 19:09:10 - INFO - EVALUATING - Epoch: [180][30/40]	Time 0.043 (0.148)	Data 0.000 (0.099)	Loss 0.5305 (0.4291)	Prec@1 87.109 (88.206)	Prec@5 100.000 (99.471)
2022-06-17 19:09:12 - INFO - 
 Epoch: 181	Training Loss 0.0691 	Training Prec@1 97.682 	Training Prec@5 99.994 	Validation Loss 0.4237 	Validation Prec@1 88.220 	Validation Prec@5 99.540 

2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:09:12 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:09:13 - INFO - TRAINING - Epoch: [181][0/196]	Time 1.350 (1.350)	Data 1.297 (1.297)	Loss 0.0669 (0.0669)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:09:15 - INFO - TRAINING - Epoch: [181][10/196]	Time 0.107 (0.249)	Data 0.056 (0.163)	Loss 0.0638 (0.0617)	Prec@1 98.047 (98.118)	Prec@5 100.000 (100.000)
2022-06-17 19:09:16 - INFO - TRAINING - Epoch: [181][20/196]	Time 0.115 (0.182)	Data 0.000 (0.085)	Loss 0.0842 (0.0689)	Prec@1 96.484 (97.731)	Prec@5 100.000 (100.000)
2022-06-17 19:09:17 - INFO - TRAINING - Epoch: [181][30/196]	Time 0.105 (0.158)	Data 0.000 (0.058)	Loss 0.0726 (0.0683)	Prec@1 97.266 (97.694)	Prec@5 100.000 (100.000)
2022-06-17 19:09:18 - INFO - TRAINING - Epoch: [181][40/196]	Time 0.104 (0.146)	Data 0.000 (0.044)	Loss 0.0380 (0.0669)	Prec@1 98.438 (97.723)	Prec@5 100.000 (100.000)
2022-06-17 19:09:19 - INFO - TRAINING - Epoch: [181][50/196]	Time 0.114 (0.139)	Data 0.000 (0.035)	Loss 0.0534 (0.0657)	Prec@1 98.828 (97.817)	Prec@5 100.000 (100.000)
2022-06-17 19:09:20 - INFO - TRAINING - Epoch: [181][60/196]	Time 0.115 (0.135)	Data 0.000 (0.030)	Loss 0.0587 (0.0663)	Prec@1 98.438 (97.791)	Prec@5 100.000 (100.000)
2022-06-17 19:09:21 - INFO - TRAINING - Epoch: [181][70/196]	Time 0.117 (0.132)	Data 0.000 (0.026)	Loss 0.0784 (0.0661)	Prec@1 98.047 (97.772)	Prec@5 100.000 (100.000)
2022-06-17 19:09:23 - INFO - TRAINING - Epoch: [181][80/196]	Time 0.110 (0.130)	Data 0.000 (0.022)	Loss 0.0543 (0.0661)	Prec@1 98.047 (97.762)	Prec@5 100.000 (100.000)
2022-06-17 19:09:24 - INFO - TRAINING - Epoch: [181][90/196]	Time 0.102 (0.128)	Data 0.000 (0.020)	Loss 0.0694 (0.0653)	Prec@1 97.266 (97.781)	Prec@5 100.000 (100.000)
2022-06-17 19:09:25 - INFO - TRAINING - Epoch: [181][100/196]	Time 0.108 (0.126)	Data 0.000 (0.018)	Loss 0.0482 (0.0649)	Prec@1 98.047 (97.811)	Prec@5 100.000 (100.000)
2022-06-17 19:09:26 - INFO - TRAINING - Epoch: [181][110/196]	Time 0.113 (0.125)	Data 0.000 (0.016)	Loss 0.0327 (0.0655)	Prec@1 99.609 (97.797)	Prec@5 100.000 (100.000)
2022-06-17 19:09:27 - INFO - TRAINING - Epoch: [181][120/196]	Time 0.106 (0.123)	Data 0.000 (0.015)	Loss 0.0536 (0.0655)	Prec@1 98.438 (97.789)	Prec@5 100.000 (100.000)
2022-06-17 19:09:28 - INFO - TRAINING - Epoch: [181][130/196]	Time 0.112 (0.123)	Data 0.000 (0.014)	Loss 0.0854 (0.0661)	Prec@1 97.266 (97.764)	Prec@5 100.000 (100.000)
2022-06-17 19:09:29 - INFO - TRAINING - Epoch: [181][140/196]	Time 0.121 (0.123)	Data 0.000 (0.013)	Loss 0.0565 (0.0661)	Prec@1 98.438 (97.767)	Prec@5 100.000 (100.000)
2022-06-17 19:09:30 - INFO - TRAINING - Epoch: [181][150/196]	Time 0.113 (0.122)	Data 0.000 (0.012)	Loss 0.0523 (0.0664)	Prec@1 98.828 (97.770)	Prec@5 100.000 (100.000)
2022-06-17 19:09:32 - INFO - TRAINING - Epoch: [181][160/196]	Time 0.106 (0.122)	Data 0.000 (0.011)	Loss 0.0670 (0.0662)	Prec@1 98.438 (97.782)	Prec@5 100.000 (100.000)
2022-06-17 19:09:33 - INFO - TRAINING - Epoch: [181][170/196]	Time 0.120 (0.121)	Data 0.000 (0.011)	Loss 0.0834 (0.0664)	Prec@1 96.094 (97.773)	Prec@5 99.609 (99.998)
2022-06-17 19:09:34 - INFO - TRAINING - Epoch: [181][180/196]	Time 0.118 (0.121)	Data 0.000 (0.010)	Loss 0.0758 (0.0665)	Prec@1 96.875 (97.771)	Prec@5 100.000 (99.996)
2022-06-17 19:09:35 - INFO - TRAINING - Epoch: [181][190/196]	Time 0.130 (0.120)	Data 0.000 (0.010)	Loss 0.0714 (0.0669)	Prec@1 97.656 (97.759)	Prec@5 100.000 (99.996)
2022-06-17 19:09:37 - INFO - EVALUATING - Epoch: [181][0/40]	Time 1.386 (1.386)	Data 1.340 (1.340)	Loss 0.2775 (0.2775)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 19:09:38 - INFO - EVALUATING - Epoch: [181][10/40]	Time 0.338 (0.258)	Data 0.294 (0.211)	Loss 0.4942 (0.4396)	Prec@1 87.500 (87.713)	Prec@5 98.828 (99.396)
2022-06-17 19:09:39 - INFO - EVALUATING - Epoch: [181][20/40]	Time 0.041 (0.163)	Data 0.000 (0.115)	Loss 0.3535 (0.4425)	Prec@1 87.500 (87.630)	Prec@5 99.609 (99.368)
2022-06-17 19:09:40 - INFO - EVALUATING - Epoch: [181][30/40]	Time 0.095 (0.144)	Data 0.054 (0.097)	Loss 0.5539 (0.4331)	Prec@1 86.719 (87.916)	Prec@5 100.000 (99.446)
2022-06-17 19:09:42 - INFO - 
 Epoch: 182	Training Loss 0.0672 	Training Prec@1 97.746 	Training Prec@5 99.996 	Validation Loss 0.4271 	Validation Prec@1 87.950 	Validation Prec@5 99.510 

2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:09:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:09:43 - INFO - TRAINING - Epoch: [182][0/196]	Time 1.223 (1.223)	Data 1.169 (1.169)	Loss 0.0489 (0.0489)	Prec@1 98.828 (98.828)	Prec@5 100.000 (100.000)
2022-06-17 19:09:45 - INFO - TRAINING - Epoch: [182][10/196]	Time 0.101 (0.265)	Data 0.000 (0.173)	Loss 0.0940 (0.0683)	Prec@1 96.094 (97.869)	Prec@5 100.000 (100.000)
2022-06-17 19:09:46 - INFO - TRAINING - Epoch: [182][20/196]	Time 0.109 (0.189)	Data 0.000 (0.090)	Loss 0.0612 (0.0625)	Prec@1 98.828 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:09:47 - INFO - TRAINING - Epoch: [182][30/196]	Time 0.104 (0.163)	Data 0.000 (0.061)	Loss 0.0817 (0.0617)	Prec@1 97.266 (97.984)	Prec@5 100.000 (100.000)
2022-06-17 19:09:48 - INFO - TRAINING - Epoch: [182][40/196]	Time 0.109 (0.149)	Data 0.000 (0.046)	Loss 0.0599 (0.0603)	Prec@1 97.656 (97.999)	Prec@5 100.000 (100.000)
2022-06-17 19:09:49 - INFO - TRAINING - Epoch: [182][50/196]	Time 0.103 (0.141)	Data 0.000 (0.037)	Loss 0.0591 (0.0604)	Prec@1 98.828 (98.016)	Prec@5 100.000 (100.000)
2022-06-17 19:09:50 - INFO - TRAINING - Epoch: [182][60/196]	Time 0.108 (0.137)	Data 0.000 (0.031)	Loss 0.0647 (0.0614)	Prec@1 97.266 (97.989)	Prec@5 100.000 (99.994)
2022-06-17 19:09:51 - INFO - TRAINING - Epoch: [182][70/196]	Time 0.109 (0.133)	Data 0.000 (0.027)	Loss 0.0892 (0.0635)	Prec@1 97.266 (97.871)	Prec@5 100.000 (99.994)
2022-06-17 19:09:52 - INFO - TRAINING - Epoch: [182][80/196]	Time 0.113 (0.130)	Data 0.000 (0.024)	Loss 0.0526 (0.0638)	Prec@1 98.828 (97.878)	Prec@5 100.000 (99.995)
2022-06-17 19:09:54 - INFO - TRAINING - Epoch: [182][90/196]	Time 0.107 (0.128)	Data 0.000 (0.021)	Loss 0.0881 (0.0636)	Prec@1 95.703 (97.897)	Prec@5 100.000 (99.991)
2022-06-17 19:09:55 - INFO - TRAINING - Epoch: [182][100/196]	Time 0.109 (0.126)	Data 0.000 (0.019)	Loss 0.0550 (0.0632)	Prec@1 98.438 (97.892)	Prec@5 100.000 (99.992)
2022-06-17 19:09:56 - INFO - TRAINING - Epoch: [182][110/196]	Time 0.107 (0.125)	Data 0.000 (0.017)	Loss 0.0552 (0.0637)	Prec@1 98.438 (97.871)	Prec@5 100.000 (99.993)
2022-06-17 19:09:57 - INFO - TRAINING - Epoch: [182][120/196]	Time 0.114 (0.124)	Data 0.000 (0.016)	Loss 0.0395 (0.0632)	Prec@1 99.609 (97.895)	Prec@5 100.000 (99.994)
2022-06-17 19:09:58 - INFO - TRAINING - Epoch: [182][130/196]	Time 0.102 (0.123)	Data 0.000 (0.015)	Loss 0.0780 (0.0645)	Prec@1 97.266 (97.871)	Prec@5 100.000 (99.994)
2022-06-17 19:09:59 - INFO - TRAINING - Epoch: [182][140/196]	Time 0.111 (0.122)	Data 0.000 (0.014)	Loss 0.0667 (0.0643)	Prec@1 97.656 (97.878)	Prec@5 100.000 (99.994)
2022-06-17 19:10:00 - INFO - TRAINING - Epoch: [182][150/196]	Time 0.108 (0.122)	Data 0.000 (0.013)	Loss 0.0777 (0.0643)	Prec@1 97.656 (97.879)	Prec@5 100.000 (99.995)
2022-06-17 19:10:01 - INFO - TRAINING - Epoch: [182][160/196]	Time 0.129 (0.121)	Data 0.000 (0.012)	Loss 0.0436 (0.0646)	Prec@1 99.219 (97.858)	Prec@5 100.000 (99.995)
2022-06-17 19:10:02 - INFO - TRAINING - Epoch: [182][170/196]	Time 0.103 (0.120)	Data 0.000 (0.011)	Loss 0.0805 (0.0644)	Prec@1 97.656 (97.866)	Prec@5 100.000 (99.995)
2022-06-17 19:10:04 - INFO - TRAINING - Epoch: [182][180/196]	Time 0.111 (0.120)	Data 0.000 (0.011)	Loss 0.0361 (0.0646)	Prec@1 99.609 (97.853)	Prec@5 100.000 (99.994)
2022-06-17 19:10:05 - INFO - TRAINING - Epoch: [182][190/196]	Time 0.106 (0.120)	Data 0.000 (0.010)	Loss 0.0448 (0.0652)	Prec@1 98.828 (97.836)	Prec@5 100.000 (99.994)
2022-06-17 19:10:07 - INFO - EVALUATING - Epoch: [182][0/40]	Time 1.432 (1.432)	Data 1.387 (1.387)	Loss 0.2748 (0.2748)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 19:10:08 - INFO - EVALUATING - Epoch: [182][10/40]	Time 0.051 (0.270)	Data 0.000 (0.220)	Loss 0.4842 (0.4327)	Prec@1 87.891 (88.281)	Prec@5 99.219 (99.432)
2022-06-17 19:10:09 - INFO - EVALUATING - Epoch: [182][20/40]	Time 0.041 (0.165)	Data 0.000 (0.115)	Loss 0.3507 (0.4359)	Prec@1 87.500 (87.891)	Prec@5 100.000 (99.423)
2022-06-17 19:10:10 - INFO - EVALUATING - Epoch: [182][30/40]	Time 0.050 (0.158)	Data 0.000 (0.109)	Loss 0.5312 (0.4276)	Prec@1 87.500 (88.193)	Prec@5 100.000 (99.483)
2022-06-17 19:10:12 - INFO - 
 Epoch: 183	Training Loss 0.0654 	Training Prec@1 97.822 	Training Prec@5 99.994 	Validation Loss 0.4221 	Validation Prec@1 88.200 	Validation Prec@5 99.550 

2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:10:12 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:10:13 - INFO - TRAINING - Epoch: [183][0/196]	Time 1.214 (1.214)	Data 1.160 (1.160)	Loss 0.0640 (0.0640)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 19:10:15 - INFO - TRAINING - Epoch: [183][10/196]	Time 0.104 (0.256)	Data 0.000 (0.164)	Loss 0.0449 (0.0726)	Prec@1 99.219 (97.408)	Prec@5 100.000 (100.000)
2022-06-17 19:10:16 - INFO - TRAINING - Epoch: [183][20/196]	Time 0.117 (0.186)	Data 0.000 (0.086)	Loss 0.0746 (0.0650)	Prec@1 97.266 (97.879)	Prec@5 100.000 (100.000)
2022-06-17 19:10:17 - INFO - TRAINING - Epoch: [183][30/196]	Time 0.108 (0.163)	Data 0.000 (0.058)	Loss 0.0875 (0.0677)	Prec@1 96.875 (97.732)	Prec@5 100.000 (100.000)
2022-06-17 19:10:18 - INFO - TRAINING - Epoch: [183][40/196]	Time 0.108 (0.149)	Data 0.000 (0.044)	Loss 0.0597 (0.0672)	Prec@1 98.828 (97.799)	Prec@5 100.000 (100.000)
2022-06-17 19:10:19 - INFO - TRAINING - Epoch: [183][50/196]	Time 0.114 (0.142)	Data 0.000 (0.036)	Loss 0.0521 (0.0654)	Prec@1 98.047 (97.863)	Prec@5 100.000 (100.000)
2022-06-17 19:10:20 - INFO - TRAINING - Epoch: [183][60/196]	Time 0.120 (0.138)	Data 0.000 (0.030)	Loss 0.0643 (0.0655)	Prec@1 97.266 (97.829)	Prec@5 100.000 (100.000)
2022-06-17 19:10:22 - INFO - TRAINING - Epoch: [183][70/196]	Time 0.108 (0.135)	Data 0.000 (0.026)	Loss 0.0699 (0.0637)	Prec@1 96.875 (97.915)	Prec@5 100.000 (100.000)
2022-06-17 19:10:23 - INFO - TRAINING - Epoch: [183][80/196]	Time 0.114 (0.132)	Data 0.000 (0.022)	Loss 0.0401 (0.0631)	Prec@1 98.828 (97.907)	Prec@5 100.000 (100.000)
2022-06-17 19:10:24 - INFO - TRAINING - Epoch: [183][90/196]	Time 0.105 (0.130)	Data 0.000 (0.020)	Loss 0.0544 (0.0633)	Prec@1 98.047 (97.901)	Prec@5 100.000 (99.996)
2022-06-17 19:10:25 - INFO - TRAINING - Epoch: [183][100/196]	Time 0.108 (0.128)	Data 0.000 (0.018)	Loss 0.0525 (0.0635)	Prec@1 98.828 (97.896)	Prec@5 100.000 (99.996)
2022-06-17 19:10:26 - INFO - TRAINING - Epoch: [183][110/196]	Time 0.104 (0.127)	Data 0.000 (0.016)	Loss 0.0591 (0.0630)	Prec@1 97.266 (97.920)	Prec@5 100.000 (99.996)
2022-06-17 19:10:27 - INFO - TRAINING - Epoch: [183][120/196]	Time 0.121 (0.126)	Data 0.000 (0.015)	Loss 0.0580 (0.0627)	Prec@1 97.656 (97.940)	Prec@5 100.000 (99.997)
2022-06-17 19:10:28 - INFO - TRAINING - Epoch: [183][130/196]	Time 0.107 (0.124)	Data 0.000 (0.014)	Loss 0.0569 (0.0628)	Prec@1 97.656 (97.943)	Prec@5 100.000 (99.997)
2022-06-17 19:10:29 - INFO - TRAINING - Epoch: [183][140/196]	Time 0.107 (0.123)	Data 0.000 (0.013)	Loss 0.0459 (0.0624)	Prec@1 98.047 (97.944)	Prec@5 100.000 (99.997)
2022-06-17 19:10:31 - INFO - TRAINING - Epoch: [183][150/196]	Time 0.106 (0.123)	Data 0.000 (0.012)	Loss 0.0519 (0.0622)	Prec@1 98.828 (97.956)	Prec@5 100.000 (99.997)
2022-06-17 19:10:32 - INFO - TRAINING - Epoch: [183][160/196]	Time 0.117 (0.122)	Data 0.000 (0.011)	Loss 0.0513 (0.0627)	Prec@1 98.438 (97.926)	Prec@5 100.000 (99.998)
2022-06-17 19:10:33 - INFO - TRAINING - Epoch: [183][170/196]	Time 0.104 (0.121)	Data 0.000 (0.011)	Loss 0.0522 (0.0626)	Prec@1 98.828 (97.928)	Prec@5 100.000 (99.998)
2022-06-17 19:10:34 - INFO - TRAINING - Epoch: [183][180/196]	Time 0.112 (0.121)	Data 0.000 (0.010)	Loss 0.0577 (0.0628)	Prec@1 98.438 (97.920)	Prec@5 100.000 (99.998)
2022-06-17 19:10:35 - INFO - TRAINING - Epoch: [183][190/196]	Time 0.102 (0.120)	Data 0.000 (0.010)	Loss 0.0535 (0.0631)	Prec@1 98.438 (97.906)	Prec@5 100.000 (99.998)
2022-06-17 19:10:38 - INFO - EVALUATING - Epoch: [183][0/40]	Time 1.913 (1.913)	Data 1.867 (1.867)	Loss 0.2696 (0.2696)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 19:10:39 - INFO - EVALUATING - Epoch: [183][10/40]	Time 0.043 (0.268)	Data 0.001 (0.218)	Loss 0.4990 (0.4392)	Prec@1 88.281 (88.423)	Prec@5 99.219 (99.432)
2022-06-17 19:10:39 - INFO - EVALUATING - Epoch: [183][20/40]	Time 0.072 (0.169)	Data 0.000 (0.119)	Loss 0.3579 (0.4412)	Prec@1 87.109 (88.095)	Prec@5 100.000 (99.405)
2022-06-17 19:10:40 - INFO - EVALUATING - Epoch: [183][30/40]	Time 0.118 (0.147)	Data 0.078 (0.098)	Loss 0.5494 (0.4334)	Prec@1 87.109 (88.256)	Prec@5 100.000 (99.471)
2022-06-17 19:10:42 - INFO - 
 Epoch: 184	Training Loss 0.0637 	Training Prec@1 97.880 	Training Prec@5 99.998 	Validation Loss 0.4276 	Validation Prec@1 88.280 	Validation Prec@5 99.530 

2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:10:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:10:44 - INFO - TRAINING - Epoch: [184][0/196]	Time 1.696 (1.696)	Data 1.642 (1.642)	Loss 0.0523 (0.0523)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:10:45 - INFO - TRAINING - Epoch: [184][10/196]	Time 0.116 (0.284)	Data 0.000 (0.189)	Loss 0.0512 (0.0607)	Prec@1 98.828 (97.834)	Prec@5 100.000 (100.000)
2022-06-17 19:10:47 - INFO - TRAINING - Epoch: [184][20/196]	Time 0.124 (0.202)	Data 0.000 (0.099)	Loss 0.0550 (0.0636)	Prec@1 97.266 (97.824)	Prec@5 100.000 (100.000)
2022-06-17 19:10:48 - INFO - TRAINING - Epoch: [184][30/196]	Time 0.104 (0.174)	Data 0.000 (0.067)	Loss 0.0772 (0.0679)	Prec@1 97.656 (97.744)	Prec@5 100.000 (99.987)
2022-06-17 19:10:49 - INFO - TRAINING - Epoch: [184][40/196]	Time 0.133 (0.160)	Data 0.000 (0.051)	Loss 0.0632 (0.0676)	Prec@1 97.656 (97.742)	Prec@5 100.000 (99.990)
2022-06-17 19:10:50 - INFO - TRAINING - Epoch: [184][50/196]	Time 0.117 (0.150)	Data 0.000 (0.041)	Loss 0.0729 (0.0677)	Prec@1 97.266 (97.786)	Prec@5 100.000 (99.992)
2022-06-17 19:10:51 - INFO - TRAINING - Epoch: [184][60/196]	Time 0.103 (0.144)	Data 0.000 (0.034)	Loss 0.0566 (0.0673)	Prec@1 97.656 (97.778)	Prec@5 100.000 (99.994)
2022-06-17 19:10:52 - INFO - TRAINING - Epoch: [184][70/196]	Time 0.118 (0.140)	Data 0.000 (0.030)	Loss 0.0690 (0.0668)	Prec@1 98.047 (97.788)	Prec@5 100.000 (99.994)
2022-06-17 19:10:53 - INFO - TRAINING - Epoch: [184][80/196]	Time 0.108 (0.137)	Data 0.000 (0.026)	Loss 0.0918 (0.0667)	Prec@1 96.875 (97.782)	Prec@5 100.000 (99.995)
2022-06-17 19:10:55 - INFO - TRAINING - Epoch: [184][90/196]	Time 0.111 (0.134)	Data 0.000 (0.023)	Loss 0.0750 (0.0669)	Prec@1 97.266 (97.764)	Prec@5 100.000 (99.996)
2022-06-17 19:10:56 - INFO - TRAINING - Epoch: [184][100/196]	Time 0.105 (0.132)	Data 0.000 (0.021)	Loss 0.0605 (0.0672)	Prec@1 98.438 (97.768)	Prec@5 100.000 (99.996)
2022-06-17 19:10:57 - INFO - TRAINING - Epoch: [184][110/196]	Time 0.105 (0.130)	Data 0.000 (0.019)	Loss 0.0730 (0.0665)	Prec@1 98.047 (97.786)	Prec@5 100.000 (99.996)
2022-06-17 19:10:58 - INFO - TRAINING - Epoch: [184][120/196]	Time 0.105 (0.128)	Data 0.000 (0.017)	Loss 0.0903 (0.0661)	Prec@1 97.656 (97.802)	Prec@5 100.000 (99.997)
2022-06-17 19:10:59 - INFO - TRAINING - Epoch: [184][130/196]	Time 0.112 (0.127)	Data 0.000 (0.016)	Loss 0.0750 (0.0664)	Prec@1 97.266 (97.779)	Prec@5 100.000 (99.997)
2022-06-17 19:11:00 - INFO - TRAINING - Epoch: [184][140/196]	Time 0.107 (0.126)	Data 0.000 (0.015)	Loss 0.0553 (0.0662)	Prec@1 98.438 (97.773)	Prec@5 100.000 (99.997)
2022-06-17 19:11:01 - INFO - TRAINING - Epoch: [184][150/196]	Time 0.111 (0.125)	Data 0.000 (0.014)	Loss 0.0649 (0.0658)	Prec@1 98.438 (97.801)	Prec@5 100.000 (99.997)
2022-06-17 19:11:02 - INFO - TRAINING - Epoch: [184][160/196]	Time 0.108 (0.124)	Data 0.000 (0.013)	Loss 0.0628 (0.0653)	Prec@1 97.656 (97.821)	Prec@5 100.000 (99.998)
2022-06-17 19:11:03 - INFO - TRAINING - Epoch: [184][170/196]	Time 0.109 (0.123)	Data 0.000 (0.012)	Loss 0.0693 (0.0662)	Prec@1 96.484 (97.791)	Prec@5 100.000 (99.998)
2022-06-17 19:11:04 - INFO - TRAINING - Epoch: [184][180/196]	Time 0.105 (0.122)	Data 0.000 (0.012)	Loss 0.0671 (0.0662)	Prec@1 97.656 (97.790)	Prec@5 100.000 (99.998)
2022-06-17 19:11:06 - INFO - TRAINING - Epoch: [184][190/196]	Time 0.107 (0.122)	Data 0.000 (0.011)	Loss 0.0799 (0.0663)	Prec@1 97.266 (97.808)	Prec@5 100.000 (99.998)
2022-06-17 19:11:08 - INFO - EVALUATING - Epoch: [184][0/40]	Time 1.943 (1.943)	Data 1.897 (1.897)	Loss 0.2732 (0.2732)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:11:09 - INFO - EVALUATING - Epoch: [184][10/40]	Time 0.068 (0.276)	Data 0.000 (0.224)	Loss 0.4892 (0.4344)	Prec@1 87.891 (88.565)	Prec@5 99.219 (99.361)
2022-06-17 19:11:10 - INFO - EVALUATING - Epoch: [184][20/40]	Time 0.042 (0.173)	Data 0.000 (0.121)	Loss 0.3608 (0.4366)	Prec@1 86.328 (88.151)	Prec@5 99.609 (99.330)
2022-06-17 19:11:11 - INFO - EVALUATING - Epoch: [184][30/40]	Time 0.125 (0.149)	Data 0.083 (0.099)	Loss 0.5417 (0.4280)	Prec@1 86.719 (88.243)	Prec@5 100.000 (99.433)
2022-06-17 19:11:13 - INFO - 
 Epoch: 185	Training Loss 0.0667 	Training Prec@1 97.794 	Training Prec@5 99.998 	Validation Loss 0.4231 	Validation Prec@1 88.230 	Validation Prec@5 99.520 

2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:11:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:11:14 - INFO - TRAINING - Epoch: [185][0/196]	Time 1.339 (1.339)	Data 1.283 (1.283)	Loss 0.0852 (0.0852)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2022-06-17 19:11:16 - INFO - TRAINING - Epoch: [185][10/196]	Time 0.115 (0.254)	Data 0.000 (0.153)	Loss 0.0927 (0.0660)	Prec@1 97.656 (97.834)	Prec@5 100.000 (99.964)
2022-06-17 19:11:17 - INFO - TRAINING - Epoch: [185][20/196]	Time 0.126 (0.190)	Data 0.000 (0.080)	Loss 0.0387 (0.0629)	Prec@1 98.828 (97.879)	Prec@5 100.000 (99.981)
2022-06-17 19:11:18 - INFO - TRAINING - Epoch: [185][30/196]	Time 0.117 (0.167)	Data 0.000 (0.054)	Loss 0.0369 (0.0621)	Prec@1 98.828 (98.009)	Prec@5 100.000 (99.987)
2022-06-17 19:11:19 - INFO - TRAINING - Epoch: [185][40/196]	Time 0.109 (0.155)	Data 0.000 (0.041)	Loss 0.0362 (0.0622)	Prec@1 98.828 (98.018)	Prec@5 100.000 (99.981)
2022-06-17 19:11:20 - INFO - TRAINING - Epoch: [185][50/196]	Time 0.106 (0.147)	Data 0.000 (0.033)	Loss 0.0634 (0.0616)	Prec@1 97.656 (98.001)	Prec@5 100.000 (99.985)
2022-06-17 19:11:21 - INFO - TRAINING - Epoch: [185][60/196]	Time 0.123 (0.142)	Data 0.000 (0.028)	Loss 0.0600 (0.0626)	Prec@1 98.438 (97.951)	Prec@5 99.609 (99.981)
2022-06-17 19:11:23 - INFO - TRAINING - Epoch: [185][70/196]	Time 0.137 (0.138)	Data 0.000 (0.024)	Loss 0.0872 (0.0636)	Prec@1 96.875 (97.904)	Prec@5 100.000 (99.983)
2022-06-17 19:11:24 - INFO - TRAINING - Epoch: [185][80/196]	Time 0.117 (0.135)	Data 0.000 (0.021)	Loss 0.0540 (0.0631)	Prec@1 98.047 (97.941)	Prec@5 100.000 (99.986)
2022-06-17 19:11:25 - INFO - TRAINING - Epoch: [185][90/196]	Time 0.105 (0.132)	Data 0.000 (0.019)	Loss 0.0902 (0.0641)	Prec@1 96.875 (97.905)	Prec@5 100.000 (99.983)
2022-06-17 19:11:26 - INFO - TRAINING - Epoch: [185][100/196]	Time 0.108 (0.131)	Data 0.000 (0.017)	Loss 0.0739 (0.0647)	Prec@1 96.875 (97.865)	Prec@5 100.000 (99.985)
2022-06-17 19:11:27 - INFO - TRAINING - Epoch: [185][110/196]	Time 0.120 (0.129)	Data 0.000 (0.015)	Loss 0.0653 (0.0642)	Prec@1 97.656 (97.899)	Prec@5 100.000 (99.986)
2022-06-17 19:11:28 - INFO - TRAINING - Epoch: [185][120/196]	Time 0.115 (0.128)	Data 0.000 (0.014)	Loss 0.0908 (0.0640)	Prec@1 98.047 (97.918)	Prec@5 100.000 (99.987)
2022-06-17 19:11:29 - INFO - TRAINING - Epoch: [185][130/196]	Time 0.120 (0.127)	Data 0.000 (0.013)	Loss 0.0294 (0.0636)	Prec@1 98.828 (97.934)	Prec@5 100.000 (99.988)
2022-06-17 19:11:31 - INFO - TRAINING - Epoch: [185][140/196]	Time 0.142 (0.126)	Data 0.000 (0.012)	Loss 0.0992 (0.0640)	Prec@1 95.312 (97.903)	Prec@5 100.000 (99.989)
2022-06-17 19:11:32 - INFO - TRAINING - Epoch: [185][150/196]	Time 0.111 (0.125)	Data 0.000 (0.011)	Loss 0.0536 (0.0639)	Prec@1 98.828 (97.894)	Prec@5 100.000 (99.990)
2022-06-17 19:11:33 - INFO - TRAINING - Epoch: [185][160/196]	Time 0.110 (0.124)	Data 0.000 (0.011)	Loss 0.0466 (0.0632)	Prec@1 99.219 (97.923)	Prec@5 100.000 (99.990)
2022-06-17 19:11:34 - INFO - TRAINING - Epoch: [185][170/196]	Time 0.118 (0.124)	Data 0.000 (0.010)	Loss 0.0421 (0.0638)	Prec@1 98.828 (97.908)	Prec@5 100.000 (99.989)
2022-06-17 19:11:35 - INFO - TRAINING - Epoch: [185][180/196]	Time 0.110 (0.124)	Data 0.000 (0.010)	Loss 0.0426 (0.0643)	Prec@1 98.047 (97.885)	Prec@5 100.000 (99.989)
2022-06-17 19:11:36 - INFO - TRAINING - Epoch: [185][190/196]	Time 0.103 (0.123)	Data 0.000 (0.009)	Loss 0.0844 (0.0645)	Prec@1 97.656 (97.879)	Prec@5 100.000 (99.988)
2022-06-17 19:11:39 - INFO - EVALUATING - Epoch: [185][0/40]	Time 1.627 (1.627)	Data 1.581 (1.581)	Loss 0.2733 (0.2733)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:11:40 - INFO - EVALUATING - Epoch: [185][10/40]	Time 0.115 (0.259)	Data 0.071 (0.213)	Loss 0.4944 (0.4400)	Prec@1 87.891 (88.175)	Prec@5 99.219 (99.432)
2022-06-17 19:11:41 - INFO - EVALUATING - Epoch: [185][20/40]	Time 0.134 (0.170)	Data 0.090 (0.121)	Loss 0.3662 (0.4411)	Prec@1 86.719 (88.077)	Prec@5 99.609 (99.386)
2022-06-17 19:11:42 - INFO - EVALUATING - Epoch: [185][30/40]	Time 0.103 (0.148)	Data 0.061 (0.100)	Loss 0.5424 (0.4344)	Prec@1 87.500 (88.206)	Prec@5 100.000 (99.446)
2022-06-17 19:11:43 - INFO - 
 Epoch: 186	Training Loss 0.0643 	Training Prec@1 97.892 	Training Prec@5 99.988 	Validation Loss 0.4290 	Validation Prec@1 88.220 	Validation Prec@5 99.520 

2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:11:43 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:11:45 - INFO - TRAINING - Epoch: [186][0/196]	Time 1.231 (1.231)	Data 1.178 (1.178)	Loss 0.0451 (0.0451)	Prec@1 98.828 (98.828)	Prec@5 100.000 (100.000)
2022-06-17 19:11:46 - INFO - TRAINING - Epoch: [186][10/196]	Time 0.111 (0.238)	Data 0.000 (0.155)	Loss 0.0757 (0.0563)	Prec@1 96.484 (98.082)	Prec@5 100.000 (100.000)
2022-06-17 19:11:47 - INFO - TRAINING - Epoch: [186][20/196]	Time 0.102 (0.175)	Data 0.000 (0.083)	Loss 0.0624 (0.0605)	Prec@1 98.438 (97.805)	Prec@5 100.000 (100.000)
2022-06-17 19:11:48 - INFO - TRAINING - Epoch: [186][30/196]	Time 0.112 (0.154)	Data 0.000 (0.057)	Loss 0.0725 (0.0619)	Prec@1 98.438 (97.744)	Prec@5 100.000 (100.000)
2022-06-17 19:11:49 - INFO - TRAINING - Epoch: [186][40/196]	Time 0.101 (0.144)	Data 0.000 (0.043)	Loss 0.0445 (0.0597)	Prec@1 98.828 (97.875)	Prec@5 100.000 (100.000)
2022-06-17 19:11:50 - INFO - TRAINING - Epoch: [186][50/196]	Time 0.107 (0.138)	Data 0.000 (0.035)	Loss 0.0444 (0.0595)	Prec@1 99.219 (97.886)	Prec@5 100.000 (100.000)
2022-06-17 19:11:52 - INFO - TRAINING - Epoch: [186][60/196]	Time 0.104 (0.133)	Data 0.000 (0.029)	Loss 0.0765 (0.0607)	Prec@1 96.484 (97.861)	Prec@5 100.000 (100.000)
2022-06-17 19:11:53 - INFO - TRAINING - Epoch: [186][70/196]	Time 0.131 (0.130)	Data 0.000 (0.025)	Loss 0.0672 (0.0607)	Prec@1 96.875 (97.865)	Prec@5 100.000 (100.000)
2022-06-17 19:11:54 - INFO - TRAINING - Epoch: [186][80/196]	Time 0.106 (0.128)	Data 0.000 (0.022)	Loss 0.0804 (0.0610)	Prec@1 96.094 (97.873)	Prec@5 100.000 (100.000)
2022-06-17 19:11:55 - INFO - TRAINING - Epoch: [186][90/196]	Time 0.110 (0.126)	Data 0.000 (0.019)	Loss 0.0357 (0.0603)	Prec@1 99.219 (97.948)	Prec@5 100.000 (100.000)
2022-06-17 19:11:56 - INFO - TRAINING - Epoch: [186][100/196]	Time 0.104 (0.124)	Data 0.000 (0.018)	Loss 0.0686 (0.0601)	Prec@1 98.047 (97.954)	Prec@5 100.000 (100.000)
2022-06-17 19:11:57 - INFO - TRAINING - Epoch: [186][110/196]	Time 0.128 (0.123)	Data 0.000 (0.016)	Loss 0.0709 (0.0604)	Prec@1 96.484 (97.934)	Prec@5 100.000 (100.000)
2022-06-17 19:11:58 - INFO - TRAINING - Epoch: [186][120/196]	Time 0.107 (0.122)	Data 0.000 (0.015)	Loss 0.0735 (0.0609)	Prec@1 96.875 (97.927)	Prec@5 100.000 (100.000)
2022-06-17 19:11:59 - INFO - TRAINING - Epoch: [186][130/196]	Time 0.112 (0.121)	Data 0.000 (0.014)	Loss 0.0605 (0.0616)	Prec@1 98.047 (97.928)	Prec@5 100.000 (100.000)
2022-06-17 19:12:00 - INFO - TRAINING - Epoch: [186][140/196]	Time 0.109 (0.120)	Data 0.000 (0.013)	Loss 0.0692 (0.0615)	Prec@1 98.828 (97.936)	Prec@5 100.000 (100.000)
2022-06-17 19:12:01 - INFO - TRAINING - Epoch: [186][150/196]	Time 0.120 (0.120)	Data 0.000 (0.012)	Loss 0.0629 (0.0613)	Prec@1 98.047 (97.956)	Prec@5 100.000 (100.000)
2022-06-17 19:12:03 - INFO - TRAINING - Epoch: [186][160/196]	Time 0.113 (0.119)	Data 0.000 (0.011)	Loss 0.0764 (0.0619)	Prec@1 98.438 (97.935)	Prec@5 100.000 (100.000)
2022-06-17 19:12:04 - INFO - TRAINING - Epoch: [186][170/196]	Time 0.110 (0.119)	Data 0.000 (0.010)	Loss 0.0584 (0.0615)	Prec@1 98.047 (97.956)	Prec@5 100.000 (100.000)
2022-06-17 19:12:05 - INFO - TRAINING - Epoch: [186][180/196]	Time 0.109 (0.118)	Data 0.000 (0.010)	Loss 0.0487 (0.0615)	Prec@1 97.656 (97.945)	Prec@5 100.000 (99.998)
2022-06-17 19:12:06 - INFO - TRAINING - Epoch: [186][190/196]	Time 0.101 (0.118)	Data 0.000 (0.009)	Loss 0.0927 (0.0612)	Prec@1 97.656 (97.967)	Prec@5 100.000 (99.998)
2022-06-17 19:12:08 - INFO - EVALUATING - Epoch: [186][0/40]	Time 1.603 (1.603)	Data 1.557 (1.557)	Loss 0.2613 (0.2613)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:12:09 - INFO - EVALUATING - Epoch: [186][10/40]	Time 0.141 (0.261)	Data 0.097 (0.213)	Loss 0.4860 (0.4295)	Prec@1 87.891 (88.317)	Prec@5 99.219 (99.432)
2022-06-17 19:12:10 - INFO - EVALUATING - Epoch: [186][20/40]	Time 0.042 (0.171)	Data 0.000 (0.122)	Loss 0.3591 (0.4334)	Prec@1 87.500 (88.002)	Prec@5 99.609 (99.368)
2022-06-17 19:12:11 - INFO - EVALUATING - Epoch: [186][30/40]	Time 0.094 (0.144)	Data 0.051 (0.097)	Loss 0.5360 (0.4271)	Prec@1 86.719 (88.231)	Prec@5 100.000 (99.446)
2022-06-17 19:12:13 - INFO - 
 Epoch: 187	Training Loss 0.0614 	Training Prec@1 97.962 	Training Prec@5 99.998 	Validation Loss 0.4220 	Validation Prec@1 88.300 	Validation Prec@5 99.530 

2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:12:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:12:15 - INFO - TRAINING - Epoch: [187][0/196]	Time 1.740 (1.740)	Data 1.687 (1.687)	Loss 0.0787 (0.0787)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
2022-06-17 19:12:16 - INFO - TRAINING - Epoch: [187][10/196]	Time 0.101 (0.260)	Data 0.000 (0.158)	Loss 0.0526 (0.0620)	Prec@1 98.438 (97.834)	Prec@5 100.000 (100.000)
2022-06-17 19:12:17 - INFO - TRAINING - Epoch: [187][20/196]	Time 0.108 (0.188)	Data 0.000 (0.083)	Loss 0.0504 (0.0645)	Prec@1 98.438 (97.693)	Prec@5 100.000 (100.000)
2022-06-17 19:12:18 - INFO - TRAINING - Epoch: [187][30/196]	Time 0.111 (0.162)	Data 0.000 (0.056)	Loss 0.0722 (0.0616)	Prec@1 96.484 (97.858)	Prec@5 100.000 (100.000)
2022-06-17 19:12:19 - INFO - TRAINING - Epoch: [187][40/196]	Time 0.102 (0.148)	Data 0.000 (0.043)	Loss 0.0718 (0.0613)	Prec@1 96.875 (97.818)	Prec@5 100.000 (100.000)
2022-06-17 19:12:20 - INFO - TRAINING - Epoch: [187][50/196]	Time 0.105 (0.139)	Data 0.000 (0.034)	Loss 0.0542 (0.0610)	Prec@1 98.438 (97.832)	Prec@5 100.000 (100.000)
2022-06-17 19:12:21 - INFO - TRAINING - Epoch: [187][60/196]	Time 0.112 (0.134)	Data 0.000 (0.029)	Loss 0.0681 (0.0611)	Prec@1 97.656 (97.861)	Prec@5 100.000 (100.000)
2022-06-17 19:12:23 - INFO - TRAINING - Epoch: [187][70/196]	Time 0.105 (0.132)	Data 0.000 (0.025)	Loss 0.0814 (0.0615)	Prec@1 96.875 (97.843)	Prec@5 100.000 (100.000)
2022-06-17 19:12:24 - INFO - TRAINING - Epoch: [187][80/196]	Time 0.108 (0.129)	Data 0.000 (0.022)	Loss 0.0462 (0.0613)	Prec@1 98.438 (97.878)	Prec@5 100.000 (100.000)
2022-06-17 19:12:25 - INFO - TRAINING - Epoch: [187][90/196]	Time 0.103 (0.126)	Data 0.000 (0.019)	Loss 0.0430 (0.0612)	Prec@1 98.828 (97.888)	Prec@5 100.000 (100.000)
2022-06-17 19:12:26 - INFO - TRAINING - Epoch: [187][100/196]	Time 0.112 (0.124)	Data 0.000 (0.017)	Loss 0.0651 (0.0606)	Prec@1 97.656 (97.908)	Prec@5 100.000 (100.000)
2022-06-17 19:12:27 - INFO - TRAINING - Epoch: [187][110/196]	Time 0.116 (0.123)	Data 0.000 (0.016)	Loss 0.0449 (0.0612)	Prec@1 98.828 (97.913)	Prec@5 100.000 (100.000)
2022-06-17 19:12:28 - INFO - TRAINING - Epoch: [187][120/196]	Time 0.108 (0.122)	Data 0.000 (0.015)	Loss 0.0544 (0.0623)	Prec@1 98.438 (97.892)	Prec@5 100.000 (100.000)
2022-06-17 19:12:29 - INFO - TRAINING - Epoch: [187][130/196]	Time 0.105 (0.121)	Data 0.000 (0.014)	Loss 0.0592 (0.0619)	Prec@1 97.656 (97.904)	Prec@5 100.000 (100.000)
2022-06-17 19:12:30 - INFO - TRAINING - Epoch: [187][140/196]	Time 0.107 (0.120)	Data 0.000 (0.013)	Loss 0.0439 (0.0624)	Prec@1 98.828 (97.861)	Prec@5 100.000 (100.000)
2022-06-17 19:12:31 - INFO - TRAINING - Epoch: [187][150/196]	Time 0.107 (0.119)	Data 0.000 (0.012)	Loss 0.0676 (0.0619)	Prec@1 96.875 (97.866)	Prec@5 100.000 (100.000)
2022-06-17 19:12:32 - INFO - TRAINING - Epoch: [187][160/196]	Time 0.102 (0.119)	Data 0.000 (0.011)	Loss 0.0709 (0.0623)	Prec@1 98.047 (97.872)	Prec@5 100.000 (100.000)
2022-06-17 19:12:33 - INFO - TRAINING - Epoch: [187][170/196]	Time 0.105 (0.118)	Data 0.000 (0.010)	Loss 0.0825 (0.0626)	Prec@1 96.484 (97.862)	Prec@5 100.000 (100.000)
2022-06-17 19:12:34 - INFO - TRAINING - Epoch: [187][180/196]	Time 0.108 (0.117)	Data 0.000 (0.010)	Loss 0.0943 (0.0629)	Prec@1 96.875 (97.850)	Prec@5 100.000 (100.000)
2022-06-17 19:12:35 - INFO - TRAINING - Epoch: [187][190/196]	Time 0.110 (0.117)	Data 0.000 (0.009)	Loss 0.0553 (0.0631)	Prec@1 98.438 (97.844)	Prec@5 100.000 (100.000)
2022-06-17 19:12:37 - INFO - EVALUATING - Epoch: [187][0/40]	Time 1.298 (1.298)	Data 1.252 (1.252)	Loss 0.2719 (0.2719)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:12:39 - INFO - EVALUATING - Epoch: [187][10/40]	Time 0.043 (0.236)	Data 0.000 (0.191)	Loss 0.4862 (0.4376)	Prec@1 87.891 (88.068)	Prec@5 99.219 (99.396)
2022-06-17 19:12:40 - INFO - EVALUATING - Epoch: [187][20/40]	Time 0.059 (0.177)	Data 0.000 (0.132)	Loss 0.3522 (0.4394)	Prec@1 86.719 (87.872)	Prec@5 99.609 (99.349)
2022-06-17 19:12:41 - INFO - EVALUATING - Epoch: [187][30/40]	Time 0.094 (0.153)	Data 0.050 (0.107)	Loss 0.5558 (0.4322)	Prec@1 86.328 (88.080)	Prec@5 100.000 (99.433)
2022-06-17 19:12:43 - INFO - 
 Epoch: 188	Training Loss 0.0631 	Training Prec@1 97.838 	Training Prec@5 100.000 	Validation Loss 0.4268 	Validation Prec@1 88.130 	Validation Prec@5 99.510 

2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:12:43 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:12:44 - INFO - TRAINING - Epoch: [188][0/196]	Time 1.392 (1.392)	Data 1.338 (1.338)	Loss 0.0634 (0.0634)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:12:46 - INFO - TRAINING - Epoch: [188][10/196]	Time 0.107 (0.250)	Data 0.000 (0.146)	Loss 0.0661 (0.0565)	Prec@1 98.047 (98.189)	Prec@5 100.000 (100.000)
2022-06-17 19:12:47 - INFO - TRAINING - Epoch: [188][20/196]	Time 0.133 (0.187)	Data 0.000 (0.077)	Loss 0.0860 (0.0607)	Prec@1 96.875 (97.972)	Prec@5 100.000 (100.000)
2022-06-17 19:12:48 - INFO - TRAINING - Epoch: [188][30/196]	Time 0.107 (0.164)	Data 0.000 (0.052)	Loss 0.0856 (0.0624)	Prec@1 96.484 (97.946)	Prec@5 100.000 (100.000)
2022-06-17 19:12:49 - INFO - TRAINING - Epoch: [188][40/196]	Time 0.104 (0.151)	Data 0.000 (0.039)	Loss 0.0948 (0.0645)	Prec@1 96.484 (97.828)	Prec@5 100.000 (100.000)
2022-06-17 19:12:50 - INFO - TRAINING - Epoch: [188][50/196]	Time 0.111 (0.144)	Data 0.000 (0.032)	Loss 0.0603 (0.0627)	Prec@1 97.656 (97.894)	Prec@5 100.000 (100.000)
2022-06-17 19:12:51 - INFO - TRAINING - Epoch: [188][60/196]	Time 0.103 (0.138)	Data 0.000 (0.027)	Loss 0.0508 (0.0631)	Prec@1 98.828 (97.868)	Prec@5 100.000 (100.000)
2022-06-17 19:12:52 - INFO - TRAINING - Epoch: [188][70/196]	Time 0.110 (0.135)	Data 0.000 (0.023)	Loss 0.0870 (0.0636)	Prec@1 97.266 (97.893)	Prec@5 100.000 (100.000)
2022-06-17 19:12:54 - INFO - TRAINING - Epoch: [188][80/196]	Time 0.122 (0.132)	Data 0.000 (0.020)	Loss 0.1015 (0.0641)	Prec@1 95.312 (97.849)	Prec@5 100.000 (100.000)
2022-06-17 19:12:55 - INFO - TRAINING - Epoch: [188][90/196]	Time 0.111 (0.130)	Data 0.000 (0.018)	Loss 0.0430 (0.0638)	Prec@1 99.219 (97.879)	Prec@5 100.000 (100.000)
2022-06-17 19:12:56 - INFO - TRAINING - Epoch: [188][100/196]	Time 0.115 (0.128)	Data 0.000 (0.016)	Loss 0.0443 (0.0637)	Prec@1 98.047 (97.900)	Prec@5 100.000 (100.000)
2022-06-17 19:12:57 - INFO - TRAINING - Epoch: [188][110/196]	Time 0.119 (0.126)	Data 0.000 (0.015)	Loss 0.0799 (0.0644)	Prec@1 97.656 (97.846)	Prec@5 100.000 (99.996)
2022-06-17 19:12:58 - INFO - TRAINING - Epoch: [188][120/196]	Time 0.107 (0.125)	Data 0.000 (0.014)	Loss 0.0364 (0.0649)	Prec@1 99.219 (97.837)	Prec@5 100.000 (99.997)
2022-06-17 19:12:59 - INFO - TRAINING - Epoch: [188][130/196]	Time 0.107 (0.124)	Data 0.000 (0.013)	Loss 0.0722 (0.0651)	Prec@1 98.047 (97.820)	Prec@5 100.000 (99.997)
2022-06-17 19:13:00 - INFO - TRAINING - Epoch: [188][140/196]	Time 0.110 (0.123)	Data 0.000 (0.012)	Loss 0.0510 (0.0654)	Prec@1 99.219 (97.795)	Prec@5 100.000 (99.997)
2022-06-17 19:13:01 - INFO - TRAINING - Epoch: [188][150/196]	Time 0.120 (0.122)	Data 0.000 (0.011)	Loss 0.0820 (0.0653)	Prec@1 96.875 (97.796)	Prec@5 100.000 (99.997)
2022-06-17 19:13:02 - INFO - TRAINING - Epoch: [188][160/196]	Time 0.127 (0.121)	Data 0.000 (0.010)	Loss 0.0546 (0.0659)	Prec@1 98.047 (97.770)	Prec@5 100.000 (99.998)
2022-06-17 19:13:03 - INFO - TRAINING - Epoch: [188][170/196]	Time 0.108 (0.121)	Data 0.000 (0.010)	Loss 0.0561 (0.0654)	Prec@1 98.828 (97.793)	Prec@5 99.609 (99.995)
2022-06-17 19:13:05 - INFO - TRAINING - Epoch: [188][180/196]	Time 0.111 (0.120)	Data 0.000 (0.009)	Loss 0.0539 (0.0659)	Prec@1 97.656 (97.777)	Prec@5 100.000 (99.996)
2022-06-17 19:13:06 - INFO - TRAINING - Epoch: [188][190/196]	Time 0.100 (0.119)	Data 0.000 (0.009)	Loss 0.0440 (0.0655)	Prec@1 99.219 (97.783)	Prec@5 100.000 (99.996)
2022-06-17 19:13:08 - INFO - EVALUATING - Epoch: [188][0/40]	Time 1.760 (1.760)	Data 1.714 (1.714)	Loss 0.2662 (0.2662)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 19:13:09 - INFO - EVALUATING - Epoch: [188][10/40]	Time 0.053 (0.270)	Data 0.000 (0.220)	Loss 0.4939 (0.4367)	Prec@1 87.891 (88.175)	Prec@5 99.219 (99.467)
2022-06-17 19:13:10 - INFO - EVALUATING - Epoch: [188][20/40]	Time 0.043 (0.168)	Data 0.000 (0.118)	Loss 0.3553 (0.4376)	Prec@1 88.281 (88.058)	Prec@5 99.609 (99.405)
2022-06-17 19:13:11 - INFO - EVALUATING - Epoch: [188][30/40]	Time 0.146 (0.152)	Data 0.104 (0.103)	Loss 0.5555 (0.4299)	Prec@1 86.719 (88.168)	Prec@5 100.000 (99.458)
2022-06-17 19:13:13 - INFO - 
 Epoch: 189	Training Loss 0.0653 	Training Prec@1 97.780 	Training Prec@5 99.996 	Validation Loss 0.4250 	Validation Prec@1 88.220 	Validation Prec@5 99.530 

2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:13:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:13:15 - INFO - TRAINING - Epoch: [189][0/196]	Time 1.934 (1.934)	Data 1.883 (1.883)	Loss 0.0472 (0.0472)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 19:13:16 - INFO - TRAINING - Epoch: [189][10/196]	Time 0.134 (0.279)	Data 0.000 (0.171)	Loss 0.0379 (0.0598)	Prec@1 98.828 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:13:17 - INFO - TRAINING - Epoch: [189][20/196]	Time 0.135 (0.201)	Data 0.000 (0.090)	Loss 0.0578 (0.0615)	Prec@1 98.438 (97.898)	Prec@5 100.000 (100.000)
2022-06-17 19:13:18 - INFO - TRAINING - Epoch: [189][30/196]	Time 0.115 (0.171)	Data 0.000 (0.061)	Loss 0.0633 (0.0639)	Prec@1 98.047 (97.807)	Prec@5 100.000 (100.000)
2022-06-17 19:13:19 - INFO - TRAINING - Epoch: [189][40/196]	Time 0.106 (0.156)	Data 0.000 (0.046)	Loss 0.0684 (0.0653)	Prec@1 98.047 (97.799)	Prec@5 100.000 (99.990)
2022-06-17 19:13:20 - INFO - TRAINING - Epoch: [189][50/196]	Time 0.107 (0.147)	Data 0.000 (0.037)	Loss 0.0870 (0.0640)	Prec@1 97.266 (97.886)	Prec@5 100.000 (99.992)
2022-06-17 19:13:21 - INFO - TRAINING - Epoch: [189][60/196]	Time 0.103 (0.140)	Data 0.000 (0.031)	Loss 0.0439 (0.0619)	Prec@1 98.438 (98.015)	Prec@5 100.000 (99.987)
2022-06-17 19:13:22 - INFO - TRAINING - Epoch: [189][70/196]	Time 0.113 (0.136)	Data 0.000 (0.027)	Loss 0.0478 (0.0607)	Prec@1 98.828 (98.047)	Prec@5 100.000 (99.989)
2022-06-17 19:13:24 - INFO - TRAINING - Epoch: [189][80/196]	Time 0.106 (0.132)	Data 0.000 (0.024)	Loss 0.0490 (0.0603)	Prec@1 97.656 (98.037)	Prec@5 100.000 (99.990)
2022-06-17 19:13:25 - INFO - TRAINING - Epoch: [189][90/196]	Time 0.105 (0.130)	Data 0.000 (0.021)	Loss 0.0697 (0.0612)	Prec@1 96.875 (97.974)	Prec@5 100.000 (99.991)
2022-06-17 19:13:26 - INFO - TRAINING - Epoch: [189][100/196]	Time 0.107 (0.128)	Data 0.000 (0.019)	Loss 0.0746 (0.0619)	Prec@1 97.266 (97.950)	Prec@5 100.000 (99.992)
2022-06-17 19:13:27 - INFO - TRAINING - Epoch: [189][110/196]	Time 0.117 (0.126)	Data 0.000 (0.017)	Loss 0.0678 (0.0625)	Prec@1 97.656 (97.910)	Prec@5 100.000 (99.989)
2022-06-17 19:13:28 - INFO - TRAINING - Epoch: [189][120/196]	Time 0.107 (0.125)	Data 0.000 (0.016)	Loss 0.0617 (0.0627)	Prec@1 97.656 (97.924)	Prec@5 100.000 (99.990)
2022-06-17 19:13:29 - INFO - TRAINING - Epoch: [189][130/196]	Time 0.110 (0.124)	Data 0.000 (0.015)	Loss 0.0330 (0.0625)	Prec@1 99.609 (97.937)	Prec@5 100.000 (99.988)
2022-06-17 19:13:30 - INFO - TRAINING - Epoch: [189][140/196]	Time 0.104 (0.123)	Data 0.000 (0.014)	Loss 0.0396 (0.0621)	Prec@1 98.828 (97.972)	Prec@5 100.000 (99.989)
2022-06-17 19:13:31 - INFO - TRAINING - Epoch: [189][150/196]	Time 0.113 (0.122)	Data 0.000 (0.013)	Loss 0.0762 (0.0623)	Prec@1 97.656 (97.969)	Prec@5 100.000 (99.990)
2022-06-17 19:13:32 - INFO - TRAINING - Epoch: [189][160/196]	Time 0.112 (0.121)	Data 0.000 (0.012)	Loss 0.0514 (0.0622)	Prec@1 98.438 (97.960)	Prec@5 100.000 (99.990)
2022-06-17 19:13:33 - INFO - TRAINING - Epoch: [189][170/196]	Time 0.114 (0.120)	Data 0.000 (0.011)	Loss 0.0875 (0.0624)	Prec@1 97.266 (97.953)	Prec@5 100.000 (99.991)
2022-06-17 19:13:35 - INFO - TRAINING - Epoch: [189][180/196]	Time 0.102 (0.120)	Data 0.000 (0.011)	Loss 0.0629 (0.0629)	Prec@1 98.047 (97.926)	Prec@5 100.000 (99.991)
2022-06-17 19:13:36 - INFO - TRAINING - Epoch: [189][190/196]	Time 0.105 (0.119)	Data 0.000 (0.010)	Loss 0.0742 (0.0629)	Prec@1 96.094 (97.928)	Prec@5 100.000 (99.992)
2022-06-17 19:13:38 - INFO - EVALUATING - Epoch: [189][0/40]	Time 1.562 (1.562)	Data 1.516 (1.516)	Loss 0.2728 (0.2728)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
2022-06-17 19:13:39 - INFO - EVALUATING - Epoch: [189][10/40]	Time 0.050 (0.225)	Data 0.000 (0.178)	Loss 0.4946 (0.4363)	Prec@1 87.109 (88.210)	Prec@5 99.219 (99.432)
2022-06-17 19:13:40 - INFO - EVALUATING - Epoch: [189][20/40]	Time 0.044 (0.171)	Data 0.000 (0.125)	Loss 0.3490 (0.4369)	Prec@1 87.891 (88.002)	Prec@5 99.609 (99.368)
2022-06-17 19:13:41 - INFO - EVALUATING - Epoch: [189][30/40]	Time 0.130 (0.150)	Data 0.086 (0.104)	Loss 0.5514 (0.4296)	Prec@1 86.328 (88.092)	Prec@5 100.000 (99.433)
2022-06-17 19:13:43 - INFO - 
 Epoch: 190	Training Loss 0.0628 	Training Prec@1 97.944 	Training Prec@5 99.992 	Validation Loss 0.4247 	Validation Prec@1 88.130 	Validation Prec@5 99.510 

2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:13:43 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:13:44 - INFO - TRAINING - Epoch: [190][0/196]	Time 1.324 (1.324)	Data 1.271 (1.271)	Loss 0.0720 (0.0720)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 19:13:45 - INFO - TRAINING - Epoch: [190][10/196]	Time 0.104 (0.251)	Data 0.000 (0.159)	Loss 0.0745 (0.0556)	Prec@1 98.828 (98.295)	Prec@5 100.000 (100.000)
2022-06-17 19:13:47 - INFO - TRAINING - Epoch: [190][20/196]	Time 0.109 (0.184)	Data 0.000 (0.087)	Loss 0.0399 (0.0584)	Prec@1 98.828 (98.196)	Prec@5 100.000 (99.981)
2022-06-17 19:13:48 - INFO - TRAINING - Epoch: [190][30/196]	Time 0.115 (0.160)	Data 0.000 (0.059)	Loss 0.0692 (0.0614)	Prec@1 98.047 (98.022)	Prec@5 100.000 (99.987)
2022-06-17 19:13:49 - INFO - TRAINING - Epoch: [190][40/196]	Time 0.111 (0.149)	Data 0.000 (0.045)	Loss 0.0578 (0.0605)	Prec@1 98.438 (98.066)	Prec@5 100.000 (99.990)
2022-06-17 19:13:50 - INFO - TRAINING - Epoch: [190][50/196]	Time 0.106 (0.141)	Data 0.000 (0.036)	Loss 0.0492 (0.0611)	Prec@1 98.828 (98.001)	Prec@5 100.000 (99.992)
2022-06-17 19:13:51 - INFO - TRAINING - Epoch: [190][60/196]	Time 0.103 (0.135)	Data 0.000 (0.030)	Loss 0.0687 (0.0611)	Prec@1 98.047 (97.989)	Prec@5 100.000 (99.994)
2022-06-17 19:13:52 - INFO - TRAINING - Epoch: [190][70/196]	Time 0.110 (0.132)	Data 0.000 (0.026)	Loss 0.0707 (0.0620)	Prec@1 96.484 (97.948)	Prec@5 100.000 (99.994)
2022-06-17 19:13:53 - INFO - TRAINING - Epoch: [190][80/196]	Time 0.106 (0.129)	Data 0.000 (0.023)	Loss 0.0592 (0.0627)	Prec@1 98.047 (97.931)	Prec@5 100.000 (99.995)
2022-06-17 19:13:54 - INFO - TRAINING - Epoch: [190][90/196]	Time 0.105 (0.127)	Data 0.000 (0.020)	Loss 0.0413 (0.0625)	Prec@1 98.828 (97.918)	Prec@5 100.000 (99.996)
2022-06-17 19:13:55 - INFO - TRAINING - Epoch: [190][100/196]	Time 0.103 (0.126)	Data 0.000 (0.018)	Loss 0.0423 (0.0612)	Prec@1 98.828 (97.970)	Prec@5 100.000 (99.996)
2022-06-17 19:13:57 - INFO - TRAINING - Epoch: [190][110/196]	Time 0.111 (0.124)	Data 0.000 (0.017)	Loss 0.1316 (0.0628)	Prec@1 95.703 (97.917)	Prec@5 100.000 (99.996)
2022-06-17 19:13:58 - INFO - TRAINING - Epoch: [190][120/196]	Time 0.110 (0.123)	Data 0.000 (0.015)	Loss 0.0453 (0.0625)	Prec@1 99.219 (97.940)	Prec@5 100.000 (99.997)
2022-06-17 19:13:59 - INFO - TRAINING - Epoch: [190][130/196]	Time 0.101 (0.122)	Data 0.000 (0.014)	Loss 0.0602 (0.0631)	Prec@1 98.438 (97.931)	Prec@5 100.000 (99.997)
2022-06-17 19:14:00 - INFO - TRAINING - Epoch: [190][140/196]	Time 0.110 (0.121)	Data 0.000 (0.013)	Loss 0.0576 (0.0632)	Prec@1 98.438 (97.931)	Prec@5 100.000 (99.994)
2022-06-17 19:14:01 - INFO - TRAINING - Epoch: [190][150/196]	Time 0.112 (0.121)	Data 0.000 (0.012)	Loss 0.0504 (0.0628)	Prec@1 98.438 (97.949)	Prec@5 100.000 (99.995)
2022-06-17 19:14:02 - INFO - TRAINING - Epoch: [190][160/196]	Time 0.111 (0.120)	Data 0.000 (0.012)	Loss 0.0748 (0.0633)	Prec@1 98.047 (97.933)	Prec@5 100.000 (99.995)
2022-06-17 19:14:03 - INFO - TRAINING - Epoch: [190][170/196]	Time 0.105 (0.119)	Data 0.000 (0.011)	Loss 0.0550 (0.0635)	Prec@1 98.438 (97.919)	Prec@5 100.000 (99.995)
2022-06-17 19:14:04 - INFO - TRAINING - Epoch: [190][180/196]	Time 0.103 (0.119)	Data 0.000 (0.010)	Loss 0.0567 (0.0640)	Prec@1 97.266 (97.898)	Prec@5 100.000 (99.996)
2022-06-17 19:14:05 - INFO - TRAINING - Epoch: [190][190/196]	Time 0.101 (0.118)	Data 0.000 (0.010)	Loss 0.0702 (0.0639)	Prec@1 96.875 (97.891)	Prec@5 100.000 (99.996)
2022-06-17 19:14:08 - INFO - EVALUATING - Epoch: [190][0/40]	Time 1.951 (1.951)	Data 1.906 (1.906)	Loss 0.2652 (0.2652)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 19:14:09 - INFO - EVALUATING - Epoch: [190][10/40]	Time 0.488 (0.265)	Data 0.444 (0.217)	Loss 0.4898 (0.4438)	Prec@1 88.672 (88.104)	Prec@5 99.219 (99.361)
2022-06-17 19:14:10 - INFO - EVALUATING - Epoch: [190][20/40]	Time 0.340 (0.183)	Data 0.298 (0.135)	Loss 0.3623 (0.4448)	Prec@1 87.109 (87.872)	Prec@5 100.000 (99.368)
2022-06-17 19:14:11 - INFO - EVALUATING - Epoch: [190][30/40]	Time 0.092 (0.150)	Data 0.052 (0.101)	Loss 0.5616 (0.4357)	Prec@1 87.109 (88.080)	Prec@5 100.000 (99.433)
2022-06-17 19:14:12 - INFO - 
 Epoch: 191	Training Loss 0.0640 	Training Prec@1 97.884 	Training Prec@5 99.996 	Validation Loss 0.4299 	Validation Prec@1 88.110 	Validation Prec@5 99.520 

2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:14:12 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:14:14 - INFO - TRAINING - Epoch: [191][0/196]	Time 1.735 (1.735)	Data 1.684 (1.684)	Loss 0.0395 (0.0395)	Prec@1 99.609 (99.609)	Prec@5 100.000 (100.000)
2022-06-17 19:14:15 - INFO - TRAINING - Epoch: [191][10/196]	Time 0.140 (0.259)	Data 0.091 (0.162)	Loss 0.1226 (0.0705)	Prec@1 96.875 (97.940)	Prec@5 100.000 (100.000)
2022-06-17 19:14:16 - INFO - TRAINING - Epoch: [191][20/196]	Time 0.123 (0.190)	Data 0.000 (0.085)	Loss 0.0700 (0.0679)	Prec@1 98.828 (97.935)	Prec@5 100.000 (100.000)
2022-06-17 19:14:17 - INFO - TRAINING - Epoch: [191][30/196]	Time 0.103 (0.164)	Data 0.000 (0.058)	Loss 0.0730 (0.0663)	Prec@1 96.875 (97.858)	Prec@5 100.000 (100.000)
2022-06-17 19:14:18 - INFO - TRAINING - Epoch: [191][40/196]	Time 0.102 (0.151)	Data 0.000 (0.044)	Loss 0.0704 (0.0665)	Prec@1 98.047 (97.847)	Prec@5 100.000 (100.000)
2022-06-17 19:14:20 - INFO - TRAINING - Epoch: [191][50/196]	Time 0.136 (0.144)	Data 0.000 (0.035)	Loss 0.0623 (0.0670)	Prec@1 97.656 (97.855)	Prec@5 100.000 (100.000)
2022-06-17 19:14:21 - INFO - TRAINING - Epoch: [191][60/196]	Time 0.112 (0.139)	Data 0.000 (0.029)	Loss 0.0404 (0.0660)	Prec@1 99.219 (97.887)	Prec@5 100.000 (100.000)
2022-06-17 19:14:22 - INFO - TRAINING - Epoch: [191][70/196]	Time 0.111 (0.135)	Data 0.000 (0.025)	Loss 0.0514 (0.0654)	Prec@1 98.438 (97.915)	Prec@5 100.000 (100.000)
2022-06-17 19:14:23 - INFO - TRAINING - Epoch: [191][80/196]	Time 0.107 (0.133)	Data 0.000 (0.022)	Loss 0.0669 (0.0658)	Prec@1 97.656 (97.888)	Prec@5 100.000 (100.000)
2022-06-17 19:14:24 - INFO - TRAINING - Epoch: [191][90/196]	Time 0.114 (0.130)	Data 0.000 (0.020)	Loss 0.0627 (0.0652)	Prec@1 98.047 (97.914)	Prec@5 100.000 (100.000)
2022-06-17 19:14:25 - INFO - TRAINING - Epoch: [191][100/196]	Time 0.111 (0.128)	Data 0.000 (0.018)	Loss 0.0628 (0.0639)	Prec@1 98.438 (97.973)	Prec@5 100.000 (100.000)
2022-06-17 19:14:26 - INFO - TRAINING - Epoch: [191][110/196]	Time 0.108 (0.127)	Data 0.000 (0.016)	Loss 0.0568 (0.0629)	Prec@1 98.047 (97.994)	Prec@5 100.000 (100.000)
2022-06-17 19:14:27 - INFO - TRAINING - Epoch: [191][120/196]	Time 0.106 (0.125)	Data 0.000 (0.015)	Loss 0.0356 (0.0631)	Prec@1 98.828 (97.992)	Prec@5 100.000 (100.000)
2022-06-17 19:14:29 - INFO - TRAINING - Epoch: [191][130/196]	Time 0.114 (0.124)	Data 0.000 (0.014)	Loss 0.0938 (0.0637)	Prec@1 96.875 (97.975)	Prec@5 100.000 (100.000)
2022-06-17 19:14:30 - INFO - TRAINING - Epoch: [191][140/196]	Time 0.111 (0.124)	Data 0.000 (0.013)	Loss 0.0539 (0.0629)	Prec@1 98.047 (98.000)	Prec@5 100.000 (100.000)
2022-06-17 19:14:31 - INFO - TRAINING - Epoch: [191][150/196]	Time 0.111 (0.123)	Data 0.000 (0.012)	Loss 0.0538 (0.0626)	Prec@1 97.266 (97.985)	Prec@5 100.000 (100.000)
2022-06-17 19:14:32 - INFO - TRAINING - Epoch: [191][160/196]	Time 0.102 (0.122)	Data 0.000 (0.011)	Loss 0.0741 (0.0627)	Prec@1 96.875 (97.977)	Prec@5 100.000 (100.000)
2022-06-17 19:14:33 - INFO - TRAINING - Epoch: [191][170/196]	Time 0.109 (0.122)	Data 0.000 (0.011)	Loss 0.0539 (0.0631)	Prec@1 98.438 (97.953)	Prec@5 100.000 (99.998)
2022-06-17 19:14:34 - INFO - TRAINING - Epoch: [191][180/196]	Time 0.132 (0.121)	Data 0.000 (0.010)	Loss 0.0362 (0.0635)	Prec@1 99.609 (97.958)	Prec@5 100.000 (99.996)
2022-06-17 19:14:35 - INFO - TRAINING - Epoch: [191][190/196]	Time 0.101 (0.120)	Data 0.000 (0.010)	Loss 0.0484 (0.0634)	Prec@1 98.828 (97.955)	Prec@5 100.000 (99.996)
2022-06-17 19:14:37 - INFO - EVALUATING - Epoch: [191][0/40]	Time 1.559 (1.559)	Data 1.513 (1.513)	Loss 0.2687 (0.2687)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:14:39 - INFO - EVALUATING - Epoch: [191][10/40]	Time 0.073 (0.243)	Data 0.000 (0.195)	Loss 0.4768 (0.4331)	Prec@1 87.891 (88.672)	Prec@5 99.219 (99.396)
2022-06-17 19:14:39 - INFO - EVALUATING - Epoch: [191][20/40]	Time 0.140 (0.169)	Data 0.096 (0.121)	Loss 0.3596 (0.4351)	Prec@1 87.109 (88.263)	Prec@5 100.000 (99.368)
2022-06-17 19:14:41 - INFO - EVALUATING - Epoch: [191][30/40]	Time 0.050 (0.151)	Data 0.000 (0.103)	Loss 0.5429 (0.4278)	Prec@1 87.891 (88.395)	Prec@5 100.000 (99.458)
2022-06-17 19:14:42 - INFO - 
 Epoch: 192	Training Loss 0.0636 	Training Prec@1 97.942 	Training Prec@5 99.996 	Validation Loss 0.4228 	Validation Prec@1 88.320 	Validation Prec@5 99.540 

2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:14:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:14:44 - INFO - TRAINING - Epoch: [192][0/196]	Time 1.312 (1.312)	Data 1.259 (1.259)	Loss 0.0813 (0.0813)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2022-06-17 19:14:45 - INFO - TRAINING - Epoch: [192][10/196]	Time 0.101 (0.243)	Data 0.000 (0.157)	Loss 0.0546 (0.0648)	Prec@1 99.219 (97.869)	Prec@5 100.000 (100.000)
2022-06-17 19:14:46 - INFO - TRAINING - Epoch: [192][20/196]	Time 0.110 (0.179)	Data 0.000 (0.085)	Loss 0.0921 (0.0649)	Prec@1 96.094 (97.861)	Prec@5 100.000 (100.000)
2022-06-17 19:14:47 - INFO - TRAINING - Epoch: [192][30/196]	Time 0.109 (0.158)	Data 0.000 (0.058)	Loss 0.0653 (0.0667)	Prec@1 96.875 (97.694)	Prec@5 100.000 (100.000)
2022-06-17 19:14:48 - INFO - TRAINING - Epoch: [192][40/196]	Time 0.107 (0.145)	Data 0.000 (0.044)	Loss 0.0451 (0.0648)	Prec@1 98.828 (97.790)	Prec@5 100.000 (100.000)
2022-06-17 19:14:49 - INFO - TRAINING - Epoch: [192][50/196]	Time 0.121 (0.138)	Data 0.000 (0.035)	Loss 0.0344 (0.0636)	Prec@1 99.609 (97.894)	Prec@5 100.000 (100.000)
2022-06-17 19:14:51 - INFO - TRAINING - Epoch: [192][60/196]	Time 0.111 (0.134)	Data 0.000 (0.029)	Loss 0.0567 (0.0641)	Prec@1 98.438 (97.893)	Prec@5 100.000 (100.000)
2022-06-17 19:14:52 - INFO - TRAINING - Epoch: [192][70/196]	Time 0.111 (0.131)	Data 0.000 (0.025)	Loss 0.0521 (0.0642)	Prec@1 98.438 (97.865)	Prec@5 100.000 (100.000)
2022-06-17 19:14:53 - INFO - TRAINING - Epoch: [192][80/196]	Time 0.110 (0.129)	Data 0.000 (0.022)	Loss 0.0509 (0.0637)	Prec@1 97.656 (97.854)	Prec@5 100.000 (100.000)
2022-06-17 19:14:54 - INFO - TRAINING - Epoch: [192][90/196]	Time 0.123 (0.128)	Data 0.000 (0.020)	Loss 0.0637 (0.0642)	Prec@1 97.656 (97.824)	Prec@5 100.000 (100.000)
2022-06-17 19:14:55 - INFO - TRAINING - Epoch: [192][100/196]	Time 0.104 (0.126)	Data 0.000 (0.018)	Loss 0.0547 (0.0644)	Prec@1 98.438 (97.819)	Prec@5 100.000 (99.996)
2022-06-17 19:14:56 - INFO - TRAINING - Epoch: [192][110/196]	Time 0.101 (0.125)	Data 0.000 (0.016)	Loss 0.0724 (0.0646)	Prec@1 98.047 (97.808)	Prec@5 100.000 (99.996)
2022-06-17 19:14:57 - INFO - TRAINING - Epoch: [192][120/196]	Time 0.122 (0.124)	Data 0.000 (0.015)	Loss 0.0657 (0.0645)	Prec@1 97.266 (97.795)	Prec@5 100.000 (99.997)
2022-06-17 19:14:59 - INFO - TRAINING - Epoch: [192][130/196]	Time 0.123 (0.124)	Data 0.000 (0.014)	Loss 0.0871 (0.0650)	Prec@1 96.094 (97.764)	Prec@5 100.000 (99.997)
2022-06-17 19:15:00 - INFO - TRAINING - Epoch: [192][140/196]	Time 0.102 (0.123)	Data 0.000 (0.013)	Loss 0.0744 (0.0651)	Prec@1 98.438 (97.784)	Prec@5 100.000 (99.997)
2022-06-17 19:15:01 - INFO - TRAINING - Epoch: [192][150/196]	Time 0.103 (0.122)	Data 0.000 (0.012)	Loss 0.0600 (0.0652)	Prec@1 98.438 (97.775)	Prec@5 100.000 (99.997)
2022-06-17 19:15:02 - INFO - TRAINING - Epoch: [192][160/196]	Time 0.116 (0.122)	Data 0.000 (0.011)	Loss 0.0650 (0.0644)	Prec@1 98.047 (97.809)	Prec@5 100.000 (99.998)
2022-06-17 19:15:03 - INFO - TRAINING - Epoch: [192][170/196]	Time 0.116 (0.121)	Data 0.000 (0.011)	Loss 0.0519 (0.0649)	Prec@1 97.656 (97.793)	Prec@5 100.000 (99.998)
2022-06-17 19:15:04 - INFO - TRAINING - Epoch: [192][180/196]	Time 0.106 (0.121)	Data 0.000 (0.010)	Loss 0.0430 (0.0655)	Prec@1 98.828 (97.762)	Prec@5 100.000 (99.996)
2022-06-17 19:15:05 - INFO - TRAINING - Epoch: [192][190/196]	Time 0.101 (0.120)	Data 0.000 (0.010)	Loss 0.0853 (0.0652)	Prec@1 96.875 (97.779)	Prec@5 100.000 (99.996)
2022-06-17 19:15:08 - INFO - EVALUATING - Epoch: [192][0/40]	Time 1.674 (1.674)	Data 1.626 (1.626)	Loss 0.2699 (0.2699)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:15:09 - INFO - EVALUATING - Epoch: [192][10/40]	Time 0.050 (0.265)	Data 0.000 (0.218)	Loss 0.4871 (0.4339)	Prec@1 87.500 (88.317)	Prec@5 99.219 (99.503)
2022-06-17 19:15:09 - INFO - EVALUATING - Epoch: [192][20/40]	Time 0.044 (0.163)	Data 0.000 (0.114)	Loss 0.3686 (0.4384)	Prec@1 88.281 (88.114)	Prec@5 100.000 (99.423)
2022-06-17 19:15:10 - INFO - EVALUATING - Epoch: [192][30/40]	Time 0.103 (0.145)	Data 0.062 (0.098)	Loss 0.5449 (0.4305)	Prec@1 87.109 (88.269)	Prec@5 100.000 (99.483)
2022-06-17 19:15:12 - INFO - 
 Epoch: 193	Training Loss 0.0651 	Training Prec@1 97.784 	Training Prec@5 99.996 	Validation Loss 0.4259 	Validation Prec@1 88.250 	Validation Prec@5 99.560 

2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:15:12 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:15:14 - INFO - TRAINING - Epoch: [193][0/196]	Time 1.420 (1.420)	Data 1.366 (1.366)	Loss 0.0452 (0.0452)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
2022-06-17 19:15:15 - INFO - TRAINING - Epoch: [193][10/196]	Time 0.109 (0.260)	Data 0.000 (0.159)	Loss 0.0599 (0.0627)	Prec@1 98.438 (97.763)	Prec@5 100.000 (100.000)
2022-06-17 19:15:16 - INFO - TRAINING - Epoch: [193][20/196]	Time 0.111 (0.187)	Data 0.000 (0.083)	Loss 0.0728 (0.0616)	Prec@1 98.047 (97.917)	Prec@5 100.000 (100.000)
2022-06-17 19:15:17 - INFO - TRAINING - Epoch: [193][30/196]	Time 0.109 (0.162)	Data 0.000 (0.057)	Loss 0.0896 (0.0628)	Prec@1 96.875 (97.845)	Prec@5 100.000 (100.000)
2022-06-17 19:15:19 - INFO - TRAINING - Epoch: [193][40/196]	Time 0.110 (0.151)	Data 0.000 (0.043)	Loss 0.0579 (0.0610)	Prec@1 98.438 (97.990)	Prec@5 100.000 (100.000)
2022-06-17 19:15:20 - INFO - TRAINING - Epoch: [193][50/196]	Time 0.125 (0.143)	Data 0.000 (0.035)	Loss 0.0702 (0.0617)	Prec@1 96.875 (97.940)	Prec@5 100.000 (100.000)
2022-06-17 19:15:21 - INFO - TRAINING - Epoch: [193][60/196]	Time 0.103 (0.138)	Data 0.000 (0.029)	Loss 0.0658 (0.0611)	Prec@1 97.266 (97.951)	Prec@5 100.000 (100.000)
2022-06-17 19:15:22 - INFO - TRAINING - Epoch: [193][70/196]	Time 0.119 (0.134)	Data 0.000 (0.025)	Loss 0.0415 (0.0603)	Prec@1 98.438 (97.975)	Prec@5 100.000 (100.000)
2022-06-17 19:15:23 - INFO - TRAINING - Epoch: [193][80/196]	Time 0.103 (0.132)	Data 0.000 (0.022)	Loss 0.0380 (0.0601)	Prec@1 99.609 (97.984)	Prec@5 100.000 (100.000)
2022-06-17 19:15:24 - INFO - TRAINING - Epoch: [193][90/196]	Time 0.109 (0.129)	Data 0.000 (0.019)	Loss 0.0735 (0.0609)	Prec@1 98.047 (97.991)	Prec@5 100.000 (100.000)
2022-06-17 19:15:25 - INFO - TRAINING - Epoch: [193][100/196]	Time 0.108 (0.127)	Data 0.000 (0.018)	Loss 0.0402 (0.0621)	Prec@1 98.438 (97.970)	Prec@5 100.000 (99.996)
2022-06-17 19:15:26 - INFO - TRAINING - Epoch: [193][110/196]	Time 0.114 (0.126)	Data 0.000 (0.016)	Loss 0.0589 (0.0635)	Prec@1 98.828 (97.899)	Prec@5 100.000 (99.993)
2022-06-17 19:15:28 - INFO - TRAINING - Epoch: [193][120/196]	Time 0.116 (0.125)	Data 0.000 (0.015)	Loss 0.0524 (0.0646)	Prec@1 98.047 (97.850)	Prec@5 100.000 (99.994)
2022-06-17 19:15:29 - INFO - TRAINING - Epoch: [193][130/196]	Time 0.113 (0.124)	Data 0.000 (0.014)	Loss 0.0616 (0.0649)	Prec@1 98.828 (97.814)	Prec@5 100.000 (99.994)
2022-06-17 19:15:30 - INFO - TRAINING - Epoch: [193][140/196]	Time 0.102 (0.124)	Data 0.000 (0.013)	Loss 0.0605 (0.0644)	Prec@1 98.828 (97.831)	Prec@5 100.000 (99.994)
2022-06-17 19:15:31 - INFO - TRAINING - Epoch: [193][150/196]	Time 0.108 (0.123)	Data 0.000 (0.012)	Loss 0.0560 (0.0645)	Prec@1 97.656 (97.814)	Prec@5 100.000 (99.995)
2022-06-17 19:15:32 - INFO - TRAINING - Epoch: [193][160/196]	Time 0.104 (0.123)	Data 0.000 (0.011)	Loss 0.0675 (0.0643)	Prec@1 97.656 (97.829)	Prec@5 100.000 (99.993)
2022-06-17 19:15:33 - INFO - TRAINING - Epoch: [193][170/196]	Time 0.109 (0.122)	Data 0.000 (0.010)	Loss 0.0734 (0.0645)	Prec@1 97.266 (97.830)	Prec@5 100.000 (99.993)
2022-06-17 19:15:34 - INFO - TRAINING - Epoch: [193][180/196]	Time 0.110 (0.122)	Data 0.000 (0.010)	Loss 0.0355 (0.0642)	Prec@1 100.000 (97.842)	Prec@5 100.000 (99.994)
2022-06-17 19:15:35 - INFO - TRAINING - Epoch: [193][190/196]	Time 0.101 (0.121)	Data 0.000 (0.009)	Loss 0.0537 (0.0645)	Prec@1 98.047 (97.832)	Prec@5 100.000 (99.992)
2022-06-17 19:15:37 - INFO - EVALUATING - Epoch: [193][0/40]	Time 1.240 (1.240)	Data 1.195 (1.195)	Loss 0.2767 (0.2767)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2022-06-17 19:15:39 - INFO - EVALUATING - Epoch: [193][10/40]	Time 0.131 (0.240)	Data 0.087 (0.194)	Loss 0.4885 (0.4384)	Prec@1 88.281 (88.210)	Prec@5 99.219 (99.396)
2022-06-17 19:15:40 - INFO - EVALUATING - Epoch: [193][20/40]	Time 0.124 (0.163)	Data 0.080 (0.115)	Loss 0.3600 (0.4413)	Prec@1 87.500 (88.058)	Prec@5 100.000 (99.386)
2022-06-17 19:15:41 - INFO - EVALUATING - Epoch: [193][30/40]	Time 0.277 (0.151)	Data 0.232 (0.104)	Loss 0.5470 (0.4328)	Prec@1 87.109 (88.105)	Prec@5 100.000 (99.458)
2022-06-17 19:15:42 - INFO - 
 Epoch: 194	Training Loss 0.0649 	Training Prec@1 97.818 	Training Prec@5 99.992 	Validation Loss 0.4275 	Validation Prec@1 88.160 	Validation Prec@5 99.530 

2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:15:42 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:15:45 - INFO - TRAINING - Epoch: [194][0/196]	Time 2.120 (2.120)	Data 2.067 (2.067)	Loss 0.0729 (0.0729)	Prec@1 97.656 (97.656)	Prec@5 99.609 (99.609)
2022-06-17 19:15:46 - INFO - TRAINING - Epoch: [194][10/196]	Time 0.109 (0.303)	Data 0.000 (0.197)	Loss 0.0571 (0.0674)	Prec@1 98.047 (97.585)	Prec@5 100.000 (99.964)
2022-06-17 19:15:47 - INFO - TRAINING - Epoch: [194][20/196]	Time 0.101 (0.209)	Data 0.000 (0.103)	Loss 0.0686 (0.0641)	Prec@1 96.875 (97.582)	Prec@5 100.000 (99.981)
2022-06-17 19:15:48 - INFO - TRAINING - Epoch: [194][30/196]	Time 0.102 (0.179)	Data 0.000 (0.070)	Loss 0.0404 (0.0612)	Prec@1 98.047 (97.732)	Prec@5 100.000 (99.987)
2022-06-17 19:15:49 - INFO - TRAINING - Epoch: [194][40/196]	Time 0.114 (0.163)	Data 0.000 (0.053)	Loss 0.0456 (0.0604)	Prec@1 98.438 (97.790)	Prec@5 100.000 (99.990)
2022-06-17 19:15:50 - INFO - TRAINING - Epoch: [194][50/196]	Time 0.102 (0.153)	Data 0.000 (0.043)	Loss 0.0742 (0.0600)	Prec@1 97.656 (97.871)	Prec@5 100.000 (99.985)
2022-06-17 19:15:51 - INFO - TRAINING - Epoch: [194][60/196]	Time 0.117 (0.146)	Data 0.000 (0.036)	Loss 0.0741 (0.0610)	Prec@1 97.656 (97.848)	Prec@5 100.000 (99.987)
2022-06-17 19:15:53 - INFO - TRAINING - Epoch: [194][70/196]	Time 0.111 (0.141)	Data 0.000 (0.031)	Loss 0.0746 (0.0613)	Prec@1 96.875 (97.821)	Prec@5 100.000 (99.989)
2022-06-17 19:15:54 - INFO - TRAINING - Epoch: [194][80/196]	Time 0.102 (0.137)	Data 0.000 (0.027)	Loss 0.0477 (0.0616)	Prec@1 98.828 (97.806)	Prec@5 100.000 (99.990)
2022-06-17 19:15:55 - INFO - TRAINING - Epoch: [194][90/196]	Time 0.101 (0.134)	Data 0.000 (0.024)	Loss 0.0650 (0.0620)	Prec@1 98.047 (97.824)	Prec@5 100.000 (99.991)
2022-06-17 19:15:56 - INFO - TRAINING - Epoch: [194][100/196]	Time 0.119 (0.132)	Data 0.000 (0.022)	Loss 0.0625 (0.0622)	Prec@1 97.656 (97.846)	Prec@5 100.000 (99.985)
2022-06-17 19:15:57 - INFO - TRAINING - Epoch: [194][110/196]	Time 0.108 (0.131)	Data 0.000 (0.020)	Loss 0.0459 (0.0615)	Prec@1 97.656 (97.889)	Prec@5 100.000 (99.986)
2022-06-17 19:15:58 - INFO - TRAINING - Epoch: [194][120/196]	Time 0.128 (0.129)	Data 0.000 (0.018)	Loss 0.0585 (0.0620)	Prec@1 98.438 (97.879)	Prec@5 100.000 (99.987)
2022-06-17 19:15:59 - INFO - TRAINING - Epoch: [194][130/196]	Time 0.110 (0.128)	Data 0.000 (0.017)	Loss 0.0650 (0.0616)	Prec@1 98.047 (97.895)	Prec@5 100.000 (99.988)
2022-06-17 19:16:00 - INFO - TRAINING - Epoch: [194][140/196]	Time 0.136 (0.127)	Data 0.000 (0.016)	Loss 0.0619 (0.0614)	Prec@1 98.047 (97.881)	Prec@5 100.000 (99.989)
2022-06-17 19:16:02 - INFO - TRAINING - Epoch: [194][150/196]	Time 0.117 (0.126)	Data 0.000 (0.015)	Loss 0.0587 (0.0613)	Prec@1 98.438 (97.892)	Prec@5 100.000 (99.990)
2022-06-17 19:16:03 - INFO - TRAINING - Epoch: [194][160/196]	Time 0.106 (0.125)	Data 0.000 (0.014)	Loss 0.0578 (0.0610)	Prec@1 97.266 (97.901)	Prec@5 100.000 (99.990)
2022-06-17 19:16:04 - INFO - TRAINING - Epoch: [194][170/196]	Time 0.102 (0.125)	Data 0.000 (0.013)	Loss 0.0391 (0.0609)	Prec@1 99.609 (97.919)	Prec@5 100.000 (99.991)
2022-06-17 19:16:05 - INFO - TRAINING - Epoch: [194][180/196]	Time 0.114 (0.124)	Data 0.000 (0.012)	Loss 0.0594 (0.0615)	Prec@1 97.656 (97.902)	Prec@5 100.000 (99.991)
2022-06-17 19:16:06 - INFO - TRAINING - Epoch: [194][190/196]	Time 0.101 (0.123)	Data 0.000 (0.012)	Loss 0.0714 (0.0610)	Prec@1 97.656 (97.951)	Prec@5 100.000 (99.992)
2022-06-17 19:16:08 - INFO - EVALUATING - Epoch: [194][0/40]	Time 1.746 (1.746)	Data 1.700 (1.700)	Loss 0.2624 (0.2624)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 19:16:10 - INFO - EVALUATING - Epoch: [194][10/40]	Time 0.060 (0.277)	Data 0.000 (0.230)	Loss 0.4788 (0.4337)	Prec@1 88.672 (88.565)	Prec@5 98.828 (99.396)
2022-06-17 19:16:10 - INFO - EVALUATING - Epoch: [194][20/40]	Time 0.066 (0.170)	Data 0.000 (0.121)	Loss 0.3611 (0.4377)	Prec@1 87.891 (88.281)	Prec@5 99.609 (99.368)
2022-06-17 19:16:12 - INFO - EVALUATING - Epoch: [194][30/40]	Time 0.056 (0.159)	Data 0.000 (0.111)	Loss 0.5379 (0.4318)	Prec@1 86.719 (88.369)	Prec@5 100.000 (99.446)
2022-06-17 19:16:13 - INFO - 
 Epoch: 195	Training Loss 0.0607 	Training Prec@1 97.964 	Training Prec@5 99.992 	Validation Loss 0.4268 	Validation Prec@1 88.380 	Validation Prec@5 99.510 

2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:16:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:16:15 - INFO - TRAINING - Epoch: [195][0/196]	Time 1.760 (1.760)	Data 1.706 (1.706)	Loss 0.0637 (0.0637)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:16:16 - INFO - TRAINING - Epoch: [195][10/196]	Time 0.105 (0.262)	Data 0.000 (0.155)	Loss 0.0835 (0.0705)	Prec@1 97.656 (97.940)	Prec@5 100.000 (100.000)
2022-06-17 19:16:17 - INFO - TRAINING - Epoch: [195][20/196]	Time 0.114 (0.190)	Data 0.000 (0.081)	Loss 0.0473 (0.0676)	Prec@1 98.047 (97.768)	Prec@5 100.000 (100.000)
2022-06-17 19:16:18 - INFO - TRAINING - Epoch: [195][30/196]	Time 0.101 (0.163)	Data 0.000 (0.055)	Loss 0.0436 (0.0672)	Prec@1 98.828 (97.833)	Prec@5 100.000 (100.000)
2022-06-17 19:16:19 - INFO - TRAINING - Epoch: [195][40/196]	Time 0.112 (0.150)	Data 0.000 (0.042)	Loss 0.0586 (0.0668)	Prec@1 97.656 (97.818)	Prec@5 100.000 (100.000)
2022-06-17 19:16:20 - INFO - TRAINING - Epoch: [195][50/196]	Time 0.105 (0.142)	Data 0.000 (0.034)	Loss 0.0484 (0.0652)	Prec@1 98.438 (97.840)	Prec@5 100.000 (100.000)
2022-06-17 19:16:22 - INFO - TRAINING - Epoch: [195][60/196]	Time 0.105 (0.137)	Data 0.000 (0.028)	Loss 0.0522 (0.0641)	Prec@1 98.438 (97.880)	Prec@5 100.000 (99.994)
2022-06-17 19:16:23 - INFO - TRAINING - Epoch: [195][70/196]	Time 0.104 (0.132)	Data 0.000 (0.024)	Loss 0.0727 (0.0638)	Prec@1 98.047 (97.920)	Prec@5 100.000 (99.994)
2022-06-17 19:16:24 - INFO - TRAINING - Epoch: [195][80/196]	Time 0.110 (0.129)	Data 0.001 (0.021)	Loss 0.0456 (0.0636)	Prec@1 98.438 (97.917)	Prec@5 100.000 (99.995)
2022-06-17 19:16:25 - INFO - TRAINING - Epoch: [195][90/196]	Time 0.102 (0.128)	Data 0.000 (0.019)	Loss 0.0381 (0.0625)	Prec@1 99.609 (97.991)	Prec@5 100.000 (99.996)
2022-06-17 19:16:26 - INFO - TRAINING - Epoch: [195][100/196]	Time 0.124 (0.126)	Data 0.001 (0.017)	Loss 0.0477 (0.0617)	Prec@1 97.266 (98.008)	Prec@5 100.000 (99.996)
2022-06-17 19:16:27 - INFO - TRAINING - Epoch: [195][110/196]	Time 0.109 (0.124)	Data 0.000 (0.016)	Loss 0.0376 (0.0615)	Prec@1 98.438 (98.005)	Prec@5 100.000 (99.996)
2022-06-17 19:16:28 - INFO - TRAINING - Epoch: [195][120/196]	Time 0.107 (0.123)	Data 0.000 (0.014)	Loss 0.0730 (0.0621)	Prec@1 98.438 (97.973)	Prec@5 100.000 (99.994)
2022-06-17 19:16:29 - INFO - TRAINING - Epoch: [195][130/196]	Time 0.143 (0.123)	Data 0.000 (0.013)	Loss 0.0835 (0.0618)	Prec@1 96.875 (97.996)	Prec@5 100.000 (99.994)
2022-06-17 19:16:30 - INFO - TRAINING - Epoch: [195][140/196]	Time 0.107 (0.122)	Data 0.000 (0.012)	Loss 0.0569 (0.0623)	Prec@1 98.438 (97.986)	Prec@5 100.000 (99.992)
2022-06-17 19:16:32 - INFO - TRAINING - Epoch: [195][150/196]	Time 0.111 (0.121)	Data 0.000 (0.012)	Loss 0.0292 (0.0624)	Prec@1 100.000 (97.998)	Prec@5 100.000 (99.992)
2022-06-17 19:16:33 - INFO - TRAINING - Epoch: [195][160/196]	Time 0.107 (0.121)	Data 0.000 (0.011)	Loss 0.0495 (0.0623)	Prec@1 98.828 (97.993)	Prec@5 100.000 (99.993)
2022-06-17 19:16:34 - INFO - TRAINING - Epoch: [195][170/196]	Time 0.109 (0.120)	Data 0.000 (0.010)	Loss 0.0498 (0.0618)	Prec@1 98.438 (98.006)	Prec@5 100.000 (99.993)
2022-06-17 19:16:35 - INFO - TRAINING - Epoch: [195][180/196]	Time 0.110 (0.120)	Data 0.000 (0.010)	Loss 0.0813 (0.0622)	Prec@1 96.875 (97.984)	Prec@5 100.000 (99.991)
2022-06-17 19:16:36 - INFO - TRAINING - Epoch: [195][190/196]	Time 0.102 (0.119)	Data 0.000 (0.009)	Loss 0.0482 (0.0620)	Prec@1 99.219 (98.000)	Prec@5 100.000 (99.992)
2022-06-17 19:16:38 - INFO - EVALUATING - Epoch: [195][0/40]	Time 1.415 (1.415)	Data 1.370 (1.370)	Loss 0.2718 (0.2718)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:16:40 - INFO - EVALUATING - Epoch: [195][10/40]	Time 0.055 (0.268)	Data 0.000 (0.220)	Loss 0.4872 (0.4345)	Prec@1 89.062 (88.565)	Prec@5 98.828 (99.361)
2022-06-17 19:16:40 - INFO - EVALUATING - Epoch: [195][20/40]	Time 0.069 (0.168)	Data 0.000 (0.119)	Loss 0.3586 (0.4390)	Prec@1 87.500 (88.114)	Prec@5 99.609 (99.330)
2022-06-17 19:16:41 - INFO - EVALUATING - Epoch: [195][30/40]	Time 0.044 (0.147)	Data 0.000 (0.099)	Loss 0.5381 (0.4311)	Prec@1 87.109 (88.231)	Prec@5 100.000 (99.420)
2022-06-17 19:16:43 - INFO - 
 Epoch: 196	Training Loss 0.0620 	Training Prec@1 97.998 	Training Prec@5 99.992 	Validation Loss 0.4255 	Validation Prec@1 88.270 	Validation Prec@5 99.500 

2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:16:43 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:16:45 - INFO - TRAINING - Epoch: [196][0/196]	Time 1.662 (1.662)	Data 1.608 (1.608)	Loss 0.0523 (0.0523)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 19:16:46 - INFO - TRAINING - Epoch: [196][10/196]	Time 0.106 (0.255)	Data 0.000 (0.149)	Loss 0.0466 (0.0581)	Prec@1 98.828 (98.153)	Prec@5 100.000 (100.000)
2022-06-17 19:16:47 - INFO - TRAINING - Epoch: [196][20/196]	Time 0.111 (0.189)	Data 0.000 (0.078)	Loss 0.0626 (0.0615)	Prec@1 98.047 (98.028)	Prec@5 100.000 (100.000)
2022-06-17 19:16:48 - INFO - TRAINING - Epoch: [196][30/196]	Time 0.113 (0.165)	Data 0.000 (0.053)	Loss 0.0565 (0.0624)	Prec@1 98.047 (98.009)	Prec@5 100.000 (100.000)
2022-06-17 19:16:49 - INFO - TRAINING - Epoch: [196][40/196]	Time 0.113 (0.151)	Data 0.000 (0.040)	Loss 0.0552 (0.0629)	Prec@1 98.828 (97.999)	Prec@5 100.000 (100.000)
2022-06-17 19:16:50 - INFO - TRAINING - Epoch: [196][50/196]	Time 0.104 (0.143)	Data 0.000 (0.032)	Loss 0.0536 (0.0640)	Prec@1 98.047 (97.924)	Prec@5 100.000 (100.000)
2022-06-17 19:16:52 - INFO - TRAINING - Epoch: [196][60/196]	Time 0.106 (0.138)	Data 0.000 (0.027)	Loss 0.0469 (0.0631)	Prec@1 98.438 (97.951)	Prec@5 100.000 (100.000)
2022-06-17 19:16:53 - INFO - TRAINING - Epoch: [196][70/196]	Time 0.124 (0.135)	Data 0.000 (0.023)	Loss 0.0770 (0.0637)	Prec@1 97.266 (97.860)	Prec@5 100.000 (100.000)
2022-06-17 19:16:54 - INFO - TRAINING - Epoch: [196][80/196]	Time 0.103 (0.131)	Data 0.000 (0.021)	Loss 0.0750 (0.0633)	Prec@1 96.484 (97.854)	Prec@5 100.000 (99.995)
2022-06-17 19:16:55 - INFO - TRAINING - Epoch: [196][90/196]	Time 0.107 (0.129)	Data 0.000 (0.018)	Loss 0.0654 (0.0630)	Prec@1 96.875 (97.871)	Prec@5 100.000 (99.996)
2022-06-17 19:16:56 - INFO - TRAINING - Epoch: [196][100/196]	Time 0.116 (0.127)	Data 0.000 (0.017)	Loss 0.0575 (0.0631)	Prec@1 97.656 (97.861)	Prec@5 100.000 (99.996)
2022-06-17 19:16:57 - INFO - TRAINING - Epoch: [196][110/196]	Time 0.127 (0.126)	Data 0.000 (0.015)	Loss 0.0613 (0.0631)	Prec@1 97.266 (97.853)	Prec@5 100.000 (99.996)
2022-06-17 19:16:58 - INFO - TRAINING - Epoch: [196][120/196]	Time 0.131 (0.125)	Data 0.000 (0.014)	Loss 0.0566 (0.0631)	Prec@1 97.656 (97.831)	Prec@5 100.000 (99.997)
2022-06-17 19:16:59 - INFO - TRAINING - Epoch: [196][130/196]	Time 0.108 (0.124)	Data 0.000 (0.013)	Loss 0.0406 (0.0629)	Prec@1 98.828 (97.838)	Prec@5 100.000 (99.997)
2022-06-17 19:17:00 - INFO - TRAINING - Epoch: [196][140/196]	Time 0.106 (0.123)	Data 0.000 (0.012)	Loss 0.0634 (0.0626)	Prec@1 97.656 (97.856)	Prec@5 100.000 (99.997)
2022-06-17 19:17:02 - INFO - TRAINING - Epoch: [196][150/196]	Time 0.113 (0.122)	Data 0.000 (0.011)	Loss 0.0539 (0.0623)	Prec@1 98.828 (97.850)	Prec@5 100.000 (99.997)
2022-06-17 19:17:03 - INFO - TRAINING - Epoch: [196][160/196]	Time 0.106 (0.122)	Data 0.000 (0.011)	Loss 0.0513 (0.0624)	Prec@1 98.828 (97.858)	Prec@5 100.000 (99.995)
2022-06-17 19:17:04 - INFO - TRAINING - Epoch: [196][170/196]	Time 0.120 (0.121)	Data 0.000 (0.010)	Loss 0.0317 (0.0628)	Prec@1 99.219 (97.848)	Prec@5 100.000 (99.995)
2022-06-17 19:17:05 - INFO - TRAINING - Epoch: [196][180/196]	Time 0.113 (0.121)	Data 0.000 (0.009)	Loss 0.0365 (0.0625)	Prec@1 98.828 (97.861)	Prec@5 100.000 (99.996)
2022-06-17 19:17:06 - INFO - TRAINING - Epoch: [196][190/196]	Time 0.105 (0.120)	Data 0.000 (0.009)	Loss 0.1113 (0.0625)	Prec@1 95.703 (97.861)	Prec@5 100.000 (99.996)
2022-06-17 19:17:09 - INFO - EVALUATING - Epoch: [196][0/40]	Time 2.034 (2.034)	Data 1.988 (1.988)	Loss 0.2701 (0.2701)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2022-06-17 19:17:10 - INFO - EVALUATING - Epoch: [196][10/40]	Time 0.044 (0.267)	Data 0.000 (0.213)	Loss 0.4911 (0.4385)	Prec@1 87.891 (88.388)	Prec@5 98.828 (99.467)
2022-06-17 19:17:10 - INFO - EVALUATING - Epoch: [196][20/40]	Time 0.064 (0.176)	Data 0.000 (0.125)	Loss 0.3681 (0.4407)	Prec@1 88.281 (88.151)	Prec@5 99.609 (99.386)
2022-06-17 19:17:11 - INFO - EVALUATING - Epoch: [196][30/40]	Time 0.096 (0.151)	Data 0.052 (0.102)	Loss 0.5344 (0.4344)	Prec@1 87.500 (88.256)	Prec@5 100.000 (99.458)
2022-06-17 19:17:13 - INFO - 
 Epoch: 197	Training Loss 0.0626 	Training Prec@1 97.848 	Training Prec@5 99.996 	Validation Loss 0.4284 	Validation Prec@1 88.250 	Validation Prec@5 99.520 

2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:17:13 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:17:15 - INFO - TRAINING - Epoch: [197][0/196]	Time 1.721 (1.721)	Data 1.668 (1.668)	Loss 0.0714 (0.0714)	Prec@1 98.828 (98.828)	Prec@5 100.000 (100.000)
2022-06-17 19:17:16 - INFO - TRAINING - Epoch: [197][10/196]	Time 0.111 (0.259)	Data 0.000 (0.152)	Loss 0.0519 (0.0684)	Prec@1 99.219 (97.905)	Prec@5 100.000 (100.000)
2022-06-17 19:17:17 - INFO - TRAINING - Epoch: [197][20/196]	Time 0.101 (0.190)	Data 0.000 (0.080)	Loss 0.0586 (0.0616)	Prec@1 98.047 (98.047)	Prec@5 100.000 (100.000)
2022-06-17 19:17:19 - INFO - TRAINING - Epoch: [197][30/196]	Time 0.114 (0.166)	Data 0.000 (0.054)	Loss 0.0738 (0.0598)	Prec@1 96.875 (97.996)	Prec@5 100.000 (99.987)
2022-06-17 19:17:20 - INFO - TRAINING - Epoch: [197][40/196]	Time 0.121 (0.154)	Data 0.000 (0.041)	Loss 0.0600 (0.0599)	Prec@1 97.656 (97.961)	Prec@5 100.000 (99.990)
2022-06-17 19:17:21 - INFO - TRAINING - Epoch: [197][50/196]	Time 0.107 (0.146)	Data 0.000 (0.033)	Loss 0.0809 (0.0617)	Prec@1 97.656 (97.901)	Prec@5 100.000 (99.992)
2022-06-17 19:17:22 - INFO - TRAINING - Epoch: [197][60/196]	Time 0.120 (0.141)	Data 0.000 (0.028)	Loss 0.0591 (0.0614)	Prec@1 98.438 (97.874)	Prec@5 100.000 (99.994)
2022-06-17 19:17:23 - INFO - TRAINING - Epoch: [197][70/196]	Time 0.111 (0.137)	Data 0.000 (0.024)	Loss 0.0464 (0.0625)	Prec@1 99.609 (97.816)	Prec@5 100.000 (99.994)
2022-06-17 19:17:24 - INFO - TRAINING - Epoch: [197][80/196]	Time 0.128 (0.134)	Data 0.000 (0.021)	Loss 0.0713 (0.0631)	Prec@1 96.875 (97.777)	Prec@5 100.000 (99.990)
2022-06-17 19:17:25 - INFO - TRAINING - Epoch: [197][90/196]	Time 0.115 (0.132)	Data 0.000 (0.019)	Loss 0.0850 (0.0630)	Prec@1 96.875 (97.789)	Prec@5 100.000 (99.991)
2022-06-17 19:17:27 - INFO - TRAINING - Epoch: [197][100/196]	Time 0.123 (0.131)	Data 0.000 (0.017)	Loss 0.0916 (0.0635)	Prec@1 97.266 (97.776)	Prec@5 99.609 (99.985)
2022-06-17 19:17:28 - INFO - TRAINING - Epoch: [197][110/196]	Time 0.124 (0.129)	Data 0.000 (0.015)	Loss 0.0751 (0.0638)	Prec@1 97.656 (97.783)	Prec@5 100.000 (99.986)
2022-06-17 19:17:29 - INFO - TRAINING - Epoch: [197][120/196]	Time 0.132 (0.128)	Data 0.000 (0.014)	Loss 0.0585 (0.0640)	Prec@1 96.484 (97.769)	Prec@5 100.000 (99.987)
2022-06-17 19:17:30 - INFO - TRAINING - Epoch: [197][130/196]	Time 0.110 (0.126)	Data 0.000 (0.013)	Loss 0.0872 (0.0644)	Prec@1 97.266 (97.755)	Prec@5 100.000 (99.988)
2022-06-17 19:17:31 - INFO - TRAINING - Epoch: [197][140/196]	Time 0.109 (0.125)	Data 0.000 (0.012)	Loss 0.0735 (0.0640)	Prec@1 97.656 (97.784)	Prec@5 100.000 (99.989)
2022-06-17 19:17:32 - INFO - TRAINING - Epoch: [197][150/196]	Time 0.122 (0.124)	Data 0.000 (0.011)	Loss 0.1010 (0.0638)	Prec@1 96.094 (97.804)	Prec@5 100.000 (99.990)
2022-06-17 19:17:33 - INFO - TRAINING - Epoch: [197][160/196]	Time 0.124 (0.123)	Data 0.000 (0.011)	Loss 0.0402 (0.0632)	Prec@1 98.438 (97.819)	Prec@5 100.000 (99.990)
2022-06-17 19:17:34 - INFO - TRAINING - Epoch: [197][170/196]	Time 0.113 (0.123)	Data 0.000 (0.010)	Loss 0.0464 (0.0633)	Prec@1 98.047 (97.821)	Prec@5 100.000 (99.991)
2022-06-17 19:17:35 - INFO - TRAINING - Epoch: [197][180/196]	Time 0.105 (0.122)	Data 0.000 (0.010)	Loss 0.0524 (0.0633)	Prec@1 98.438 (97.848)	Prec@5 100.000 (99.991)
2022-06-17 19:17:37 - INFO - TRAINING - Epoch: [197][190/196]	Time 0.106 (0.121)	Data 0.000 (0.009)	Loss 0.0508 (0.0637)	Prec@1 99.219 (97.834)	Prec@5 100.000 (99.992)
2022-06-17 19:17:39 - INFO - EVALUATING - Epoch: [197][0/40]	Time 1.563 (1.563)	Data 1.517 (1.517)	Loss 0.2628 (0.2628)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2022-06-17 19:17:40 - INFO - EVALUATING - Epoch: [197][10/40]	Time 0.045 (0.253)	Data 0.000 (0.205)	Loss 0.4912 (0.4411)	Prec@1 88.281 (87.962)	Prec@5 98.828 (99.396)
2022-06-17 19:17:41 - INFO - EVALUATING - Epoch: [197][20/40]	Time 0.043 (0.174)	Data 0.000 (0.126)	Loss 0.3534 (0.4424)	Prec@1 87.891 (88.002)	Prec@5 100.000 (99.386)
2022-06-17 19:17:42 - INFO - EVALUATING - Epoch: [197][30/40]	Time 0.089 (0.153)	Data 0.046 (0.106)	Loss 0.5418 (0.4351)	Prec@1 86.719 (88.155)	Prec@5 100.000 (99.471)
2022-06-17 19:17:44 - INFO - 
 Epoch: 198	Training Loss 0.0640 	Training Prec@1 97.822 	Training Prec@5 99.992 	Validation Loss 0.4293 	Validation Prec@1 88.250 	Validation Prec@5 99.540 

2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:17:44 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:17:46 - INFO - TRAINING - Epoch: [198][0/196]	Time 1.962 (1.962)	Data 1.908 (1.908)	Loss 0.0603 (0.0603)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
2022-06-17 19:17:47 - INFO - TRAINING - Epoch: [198][10/196]	Time 0.102 (0.276)	Data 0.000 (0.174)	Loss 0.0797 (0.0644)	Prec@1 97.656 (97.727)	Prec@5 100.000 (100.000)
2022-06-17 19:17:48 - INFO - TRAINING - Epoch: [198][20/196]	Time 0.102 (0.195)	Data 0.000 (0.091)	Loss 0.0736 (0.0619)	Prec@1 98.047 (97.917)	Prec@5 100.000 (100.000)
2022-06-17 19:17:49 - INFO - TRAINING - Epoch: [198][30/196]	Time 0.116 (0.168)	Data 0.000 (0.062)	Loss 0.0404 (0.0640)	Prec@1 99.219 (97.807)	Prec@5 100.000 (100.000)
2022-06-17 19:17:50 - INFO - TRAINING - Epoch: [198][40/196]	Time 0.106 (0.154)	Data 0.000 (0.047)	Loss 0.0591 (0.0608)	Prec@1 98.438 (97.952)	Prec@5 100.000 (100.000)
2022-06-17 19:17:51 - INFO - TRAINING - Epoch: [198][50/196]	Time 0.115 (0.145)	Data 0.000 (0.038)	Loss 0.0817 (0.0619)	Prec@1 96.484 (97.901)	Prec@5 100.000 (100.000)
2022-06-17 19:17:52 - INFO - TRAINING - Epoch: [198][60/196]	Time 0.103 (0.139)	Data 0.000 (0.032)	Loss 0.0586 (0.0623)	Prec@1 97.656 (97.893)	Prec@5 100.000 (100.000)
2022-06-17 19:17:53 - INFO - TRAINING - Epoch: [198][70/196]	Time 0.103 (0.134)	Data 0.000 (0.027)	Loss 0.0562 (0.0626)	Prec@1 98.438 (97.882)	Prec@5 100.000 (100.000)
2022-06-17 19:17:54 - INFO - TRAINING - Epoch: [198][80/196]	Time 0.125 (0.131)	Data 0.000 (0.024)	Loss 0.0464 (0.0621)	Prec@1 97.656 (97.912)	Prec@5 100.000 (100.000)
2022-06-17 19:17:56 - INFO - TRAINING - Epoch: [198][90/196]	Time 0.103 (0.128)	Data 0.000 (0.021)	Loss 0.0692 (0.0619)	Prec@1 98.047 (97.922)	Prec@5 100.000 (100.000)
2022-06-17 19:17:57 - INFO - TRAINING - Epoch: [198][100/196]	Time 0.102 (0.127)	Data 0.000 (0.019)	Loss 0.0293 (0.0616)	Prec@1 98.828 (97.915)	Prec@5 100.000 (100.000)
2022-06-17 19:17:58 - INFO - TRAINING - Epoch: [198][110/196]	Time 0.109 (0.125)	Data 0.000 (0.017)	Loss 0.0536 (0.0612)	Prec@1 98.438 (97.959)	Prec@5 100.000 (100.000)
2022-06-17 19:17:59 - INFO - TRAINING - Epoch: [198][120/196]	Time 0.108 (0.124)	Data 0.000 (0.016)	Loss 0.0995 (0.0616)	Prec@1 96.875 (97.960)	Prec@5 100.000 (100.000)
2022-06-17 19:18:00 - INFO - TRAINING - Epoch: [198][130/196]	Time 0.135 (0.123)	Data 0.000 (0.015)	Loss 0.0948 (0.0623)	Prec@1 95.312 (97.910)	Prec@5 100.000 (100.000)
2022-06-17 19:18:01 - INFO - TRAINING - Epoch: [198][140/196]	Time 0.104 (0.122)	Data 0.000 (0.014)	Loss 0.0747 (0.0625)	Prec@1 96.875 (97.892)	Prec@5 100.000 (100.000)
2022-06-17 19:18:02 - INFO - TRAINING - Epoch: [198][150/196]	Time 0.111 (0.121)	Data 0.000 (0.013)	Loss 0.0422 (0.0620)	Prec@1 99.219 (97.930)	Prec@5 100.000 (100.000)
2022-06-17 19:18:03 - INFO - TRAINING - Epoch: [198][160/196]	Time 0.113 (0.121)	Data 0.000 (0.012)	Loss 0.0628 (0.0621)	Prec@1 97.266 (97.906)	Prec@5 100.000 (100.000)
2022-06-17 19:18:04 - INFO - TRAINING - Epoch: [198][170/196]	Time 0.102 (0.120)	Data 0.000 (0.011)	Loss 0.0604 (0.0618)	Prec@1 97.266 (97.908)	Prec@5 100.000 (100.000)
2022-06-17 19:18:05 - INFO - TRAINING - Epoch: [198][180/196]	Time 0.105 (0.119)	Data 0.000 (0.011)	Loss 0.1000 (0.0624)	Prec@1 96.094 (97.857)	Prec@5 100.000 (100.000)
2022-06-17 19:18:07 - INFO - TRAINING - Epoch: [198][190/196]	Time 0.103 (0.119)	Data 0.000 (0.010)	Loss 0.0476 (0.0626)	Prec@1 98.438 (97.846)	Prec@5 100.000 (100.000)
2022-06-17 19:18:09 - INFO - EVALUATING - Epoch: [198][0/40]	Time 1.930 (1.930)	Data 1.885 (1.885)	Loss 0.2637 (0.2637)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2022-06-17 19:18:10 - INFO - EVALUATING - Epoch: [198][10/40]	Time 0.044 (0.261)	Data 0.000 (0.214)	Loss 0.4903 (0.4370)	Prec@1 88.281 (88.352)	Prec@5 99.219 (99.538)
2022-06-17 19:18:11 - INFO - EVALUATING - Epoch: [198][20/40]	Time 0.062 (0.169)	Data 0.000 (0.121)	Loss 0.3583 (0.4403)	Prec@1 88.281 (88.263)	Prec@5 100.000 (99.461)
2022-06-17 19:18:12 - INFO - EVALUATING - Epoch: [198][30/40]	Time 0.044 (0.147)	Data 0.000 (0.100)	Loss 0.5480 (0.4335)	Prec@1 86.328 (88.294)	Prec@5 100.000 (99.521)
2022-06-17 19:18:14 - INFO - 
 Epoch: 199	Training Loss 0.0627 	Training Prec@1 97.846 	Training Prec@5 100.000 	Validation Loss 0.4274 	Validation Prec@1 88.340 	Validation Prec@5 99.570 

2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting method = SGD
2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting lr = 0.01
2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting weight_decay = 0.0005
2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting lr = 0.005
2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting lr = 0.001
2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting weight_decay = 0
2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting lr = 0.0005
2022-06-17 19:18:14 - DEBUG - OPTIMIZER - setting lr = 0.0001
2022-06-17 19:18:16 - INFO - TRAINING - Epoch: [199][0/196]	Time 1.947 (1.947)	Data 1.895 (1.895)	Loss 0.0523 (0.0523)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
2022-06-17 19:18:17 - INFO - TRAINING - Epoch: [199][10/196]	Time 0.126 (0.284)	Data 0.000 (0.173)	Loss 0.0918 (0.0637)	Prec@1 98.047 (98.011)	Prec@5 100.000 (100.000)
2022-06-17 19:18:18 - INFO - TRAINING - Epoch: [199][20/196]	Time 0.108 (0.201)	Data 0.000 (0.091)	Loss 0.0350 (0.0618)	Prec@1 99.219 (98.084)	Prec@5 100.000 (100.000)
2022-06-17 19:18:19 - INFO - TRAINING - Epoch: [199][30/196]	Time 0.122 (0.173)	Data 0.000 (0.061)	Loss 0.0944 (0.0660)	Prec@1 98.047 (97.984)	Prec@5 100.000 (100.000)
2022-06-17 19:18:20 - INFO - TRAINING - Epoch: [199][40/196]	Time 0.104 (0.158)	Data 0.000 (0.047)	Loss 0.0463 (0.0652)	Prec@1 98.047 (97.894)	Prec@5 100.000 (100.000)
2022-06-17 19:18:21 - INFO - TRAINING - Epoch: [199][50/196]	Time 0.115 (0.149)	Data 0.000 (0.038)	Loss 0.0644 (0.0649)	Prec@1 96.484 (97.863)	Prec@5 100.000 (100.000)
2022-06-17 19:18:22 - INFO - TRAINING - Epoch: [199][60/196]	Time 0.105 (0.143)	Data 0.000 (0.031)	Loss 0.0869 (0.0646)	Prec@1 96.875 (97.810)	Prec@5 100.000 (100.000)
2022-06-17 19:18:23 - INFO - TRAINING - Epoch: [199][70/196]	Time 0.107 (0.138)	Data 0.000 (0.027)	Loss 0.0599 (0.0646)	Prec@1 98.438 (97.854)	Prec@5 100.000 (100.000)
2022-06-17 19:18:25 - INFO - TRAINING - Epoch: [199][80/196]	Time 0.107 (0.135)	Data 0.000 (0.024)	Loss 0.0680 (0.0641)	Prec@1 98.047 (97.868)	Prec@5 100.000 (100.000)
2022-06-17 19:18:26 - INFO - TRAINING - Epoch: [199][90/196]	Time 0.116 (0.133)	Data 0.000 (0.021)	Loss 0.0518 (0.0640)	Prec@1 98.438 (97.897)	Prec@5 100.000 (100.000)
2022-06-17 19:18:27 - INFO - TRAINING - Epoch: [199][100/196]	Time 0.113 (0.131)	Data 0.000 (0.019)	Loss 0.0767 (0.0646)	Prec@1 97.656 (97.865)	Prec@5 100.000 (100.000)
2022-06-17 19:18:28 - INFO - TRAINING - Epoch: [199][110/196]	Time 0.106 (0.129)	Data 0.000 (0.017)	Loss 0.0444 (0.0647)	Prec@1 98.438 (97.846)	Prec@5 100.000 (100.000)
2022-06-17 19:18:29 - INFO - TRAINING - Epoch: [199][120/196]	Time 0.103 (0.128)	Data 0.000 (0.016)	Loss 0.0674 (0.0643)	Prec@1 98.047 (97.869)	Prec@5 100.000 (100.000)
2022-06-17 19:18:30 - INFO - TRAINING - Epoch: [199][130/196]	Time 0.124 (0.127)	Data 0.000 (0.015)	Loss 0.0492 (0.0646)	Prec@1 98.828 (97.841)	Prec@5 100.000 (99.997)
2022-06-17 19:18:31 - INFO - TRAINING - Epoch: [199][140/196]	Time 0.112 (0.126)	Data 0.000 (0.014)	Loss 0.0460 (0.0640)	Prec@1 98.438 (97.861)	Prec@5 100.000 (99.997)
2022-06-17 19:18:33 - INFO - TRAINING - Epoch: [199][150/196]	Time 0.117 (0.125)	Data 0.000 (0.013)	Loss 0.0497 (0.0631)	Prec@1 98.047 (97.889)	Prec@5 100.000 (99.997)
2022-06-17 19:18:34 - INFO - TRAINING - Epoch: [199][160/196]	Time 0.105 (0.125)	Data 0.000 (0.012)	Loss 0.0632 (0.0631)	Prec@1 99.219 (97.884)	Prec@5 100.000 (99.998)
2022-06-17 19:18:35 - INFO - TRAINING - Epoch: [199][170/196]	Time 0.117 (0.124)	Data 0.000 (0.011)	Loss 0.0511 (0.0629)	Prec@1 98.047 (97.882)	Prec@5 100.000 (99.998)
2022-06-17 19:18:36 - INFO - TRAINING - Epoch: [199][180/196]	Time 0.113 (0.123)	Data 0.000 (0.011)	Loss 0.0940 (0.0632)	Prec@1 96.094 (97.861)	Prec@5 100.000 (99.998)
2022-06-17 19:18:37 - INFO - TRAINING - Epoch: [199][190/196]	Time 0.109 (0.123)	Data 0.000 (0.010)	Loss 0.1163 (0.0635)	Prec@1 94.922 (97.848)	Prec@5 100.000 (99.998)
2022-06-17 19:18:39 - INFO - EVALUATING - Epoch: [199][0/40]	Time 1.351 (1.351)	Data 1.305 (1.305)	Loss 0.2647 (0.2647)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
2022-06-17 19:18:40 - INFO - EVALUATING - Epoch: [199][10/40]	Time 0.255 (0.253)	Data 0.212 (0.203)	Loss 0.4879 (0.4404)	Prec@1 88.281 (88.246)	Prec@5 98.828 (99.396)
2022-06-17 19:18:41 - INFO - EVALUATING - Epoch: [199][20/40]	Time 0.081 (0.164)	Data 0.041 (0.115)	Loss 0.3588 (0.4436)	Prec@1 88.281 (88.151)	Prec@5 100.000 (99.405)
2022-06-17 19:18:42 - INFO - EVALUATING - Epoch: [199][30/40]	Time 0.043 (0.148)	Data 0.000 (0.101)	Loss 0.5533 (0.4367)	Prec@1 87.109 (88.382)	Prec@5 100.000 (99.471)
2022-06-17 19:18:44 - INFO - 
 Epoch: 200	Training Loss 0.0633 	Training Prec@1 97.850 	Training Prec@5 99.998 	Validation Loss 0.4313 	Validation Prec@1 88.360 	Validation Prec@5 99.520 

